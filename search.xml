<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>NGServer Session设计</title>
    <url>/2014/10/ngserver-session/</url>
    <content><![CDATA[<p>在网络编程模型中，一个Session代表一次会话，主要维护网络数据的发送和接收。对外提供发送数据和处理数据的接口。一个高效的Session主要通过缓冲和异步来提高IO效率。NGServer的Session运用双缓冲和boost::asio的异步机制，很好地做到了这一点。</p>
<h2 id="一-双缓冲"><a href="#一-双缓冲" class="headerlink" title="一. 双缓冲"></a>一. 双缓冲</h2><p>在网络IO中，读写线程的互斥访问一直都是一个关乎性能的大问题。为了减少互斥锁的使用，环形缓冲和双缓冲是常见的策略。NGServer使用后者作为消息和数据缓冲。<br>在NGServer MessageQueue.h中，定义了两种双缓冲：基于消息的MessageQueue和基于数据的ByteBuff。下面简要介绍ByteBuff类：</p>
<p>ByteBuff类的基本思想是通过两个缓冲区_buff_read和_buff_write来使读写分离。通过<code>size_t Push(const char* data, size_t len)</code>来写入数据：</p>
<span id="more"></span>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 压入字节流数据 压入成功 则返回当前缓冲区长度 否则返回0</span><br><span class="line">size_t Push(const char* data, size_t len)</span><br><span class="line">&#123;</span><br><span class="line">	if(data !&#x3D; nullptr &amp;&amp; len &gt; 0)</span><br><span class="line">	&#123;</span><br><span class="line">		AutoLocker aLock(&amp;_lock);</span><br><span class="line">		if(_size+len &lt;&#x3D;  _capacity)</span><br><span class="line">		&#123;</span><br><span class="line">			memcpy(_buff_write+_size, data, len);</span><br><span class="line">			return _size +&#x3D; len;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Push方法是线程安全的，它通过AutoLocker来保证对_buff_write的互斥访问。</p>
<p><code>char* PopAll(size_t&amp; len)</code>用于读取数据:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 返回当前缓冲区指针 长度由len返回 若当前缓冲区无消息 返回nullptr</span><br><span class="line">char* PopAll(size_t&amp; len)</span><br><span class="line">&#123;</span><br><span class="line">	if(_size &gt; 0)</span><br><span class="line">	&#123;</span><br><span class="line">		AutoLocker aLock(&amp;_lock);</span><br><span class="line">		if(_size &gt; 0)</span><br><span class="line">		&#123;</span><br><span class="line">			swap(_buff_read, _buff_write);</span><br><span class="line">			len &#x3D; _size;</span><br><span class="line">			_size &#x3D; 0;</span><br><span class="line">			return _buff_read;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    len &#x3D; 0;</span><br><span class="line">	return nullptr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它返回当前_buff_write的指针，并且交换_buff_write和_buff_read的指针，这样下次再Push数据时，实际上写到了之前的_read_buff中，如此交替，完成读写分离。</p>
<p>需要注意到，Push接口是线程安全的，而对于PopAll：<br>由于PopAll直接返回缓冲区指针(避免内存拷贝)，因此同一时刻双缓冲中，必有一读一写，故同一时刻只能有一个线程读取和处理数据(处理数据时,_buff_read仍然是被占用的)。读取线程需要将上次PopAll的数据处理完成之后再次调用PopAll。因为调用PopAll时，之前的读缓冲已变成写缓冲，并且写缓冲将从头开始写。</p>
<p>基于消息的MessageQueue原理与ByteBuff一样，只不过_buff_read和_buff_write均为vector<MsgT\*>* 类型。MsgT是用户定义的消息类。由于使用的MsgT*，提高效率的同时，需要注意消息的释放问题。这在使用到MessageQueue时再提。</p>
<h2 id="二-Session类的设计"><a href="#二-Session类的设计" class="headerlink" title="二. Session类的设计"></a>二. Session类的设计</h2><p>Session类利用boost::asio异步读写提高IO性能，它使用线性缓冲作为接收缓冲，使用ByteBuff作为发送缓冲，提高发送性能。由于ByteBuff同一时刻只能由一个线程读取和处理，Session需要使用一个锁来保证同一时刻只有一个线程来读取ByteBuff并发送其中的数据：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 发送数据</span><br><span class="line">bool Session::SendAsync(const char* data, size_t len)</span><br><span class="line">&#123;</span><br><span class="line">	if (!_run)</span><br><span class="line">	return false;</span><br><span class="line"></span><br><span class="line">	if (_send_buf.Push(data, len))</span><br><span class="line">	&#123;</span><br><span class="line">		if (_sending_lock.TryLock())</span><br><span class="line">		&#123;</span><br><span class="line">			size_t sendlen;</span><br><span class="line">			const char* data &#x3D; _send_buf.PopAll(sendlen);</span><br><span class="line">			&#x2F;&#x2F; 异步发送数据 同一时刻仅有一个线程调用该函数</span><br><span class="line">			SendData(data, sendlen);</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	else</span><br><span class="line">		assert(0); &#x2F;&#x2F; 发送缓冲区满</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Session::SendComplete(const boost::system::error_code&amp; err, size_t bytes_to_transfer, size_t bytes_transferred)</span><br><span class="line">&#123;</span><br><span class="line">	if (err)</span><br><span class="line">	return;</span><br><span class="line"></span><br><span class="line">	assert(bytes_to_transfer &#x3D;&#x3D; bytes_transferred);</span><br><span class="line"></span><br><span class="line">	_send_total +&#x3D; bytes_transferred;</span><br><span class="line"></span><br><span class="line">	size_t len;</span><br><span class="line">	const char* data &#x3D; _send_buf.PopAll(len);</span><br><span class="line">	if (data) &#x2F;&#x2F; 如果还有数据  继续发送</span><br><span class="line">	&#123;</span><br><span class="line">		SendAsync(data, len);</span><br><span class="line">	&#125;</span><br><span class="line">	else</span><br><span class="line">	&#123;</span><br><span class="line">		_sending_lock.UnLock();</span><br><span class="line">	 	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当网络空闲时，在SendAsync中，消息通过Push压入缓冲区后，将即时发送。当网络IO繁忙时，调用SendAsync中，可能已有数据正在发送，在将新数据压入缓冲区后，_sending_lock.TryLock()将返回false，此时数据被放在缓冲区中。待已有数据发送完成后，_sending_lock解锁。那么下次调用SendAsync发送的数据将和缓冲区中已有的数据立即发送。而ByteBuff双缓冲最大程度避免了这个过程中的内存拷贝。</p>
<p>Session将收到的数据放在线性缓冲区中，如此方便解包。在每次接收数据完成后，都尝试解包，并校正缓冲区新的偏移。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>ngserver</tag>
      </tags>
  </entry>
  <entry>
    <title>NGServer 简介</title>
    <url>/2014/09/ngserver-startpage/</url>
    <content><![CDATA[<p>NGServer是一个迷你型C++游戏服务器框架。Github地址：<a href="https://github.com/wudaijun/NGServer。">https://github.com/wudaijun/NGServer。</a></p>
<h3 id="主要特性："><a href="#主要特性：" class="headerlink" title="主要特性："></a>主要特性：</h3><ul>
<li>框架用C++(11)和boost库实现。</li>
<li>基于单进程多线程。</li>
<li>框架屏蔽了多线程实现，上层体现为服务(Service)，服务之间通过消息进行通信。</li>
<li>有比较完善灵活的的消息回调和序列化机制，更方便地实现RPC。</li>
</ul>
<span id="more"></span>
<h3 id="设计原则："><a href="#设计原则：" class="headerlink" title="设计原则："></a>设计原则：</h3><ul>
<li>尽量小巧灵活，减少第三方库依赖，尽可能使用C++11新特性。</li>
<li>降低模块之间的耦合性，增强灵活性。</li>
</ul>
<h3 id="目前缺点："><a href="#目前缺点：" class="headerlink" title="目前缺点："></a>目前缺点：</h3><ul>
<li>当并发很高时，消息分流和拥塞控制做得不是很好。</li>
<li>服务之间，只支持通过消息异步通信。</li>
</ul>
<h3 id="更多文档："><a href="#更多文档：" class="headerlink" title="更多文档："></a>更多文档：</h3><p>关于NGServer的更详细的系列介绍可以在我的博客找到：<a href="http://wudaijun.com/tags/#NGServer。博客上的文章仅代表NGServer的最初设想，可能与Github上的最新代码有差异。">http://wudaijun.com/tags/#NGServer。博客上的文章仅代表NGServer的最初设想，可能与Github上的最新代码有差异。</a></p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>ngserver</tag>
      </tags>
  </entry>
  <entry>
    <title>NGServer Session -&gt; Player</title>
    <url>/2014/10/ngserver-player/</url>
    <content><![CDATA[<p>在服务器中，一般都有一个代表客户端或玩家的类，用来处理一些相关逻辑并保存必要数据。也就是NGServer中的Player类，在网络模型中，一般一个Player对应一次会话(Session)，因此在很多服务器模型中，客户端类直接从Session类派生，这样客户端可以直接通过父类Session的接口发送数据，并且通过实现Sessoin的虚函数对数据进行处理。这种模型的好处在于简单，客户端类能够完全控制网络IO，并且对IO事件进行及时地处理。比如连接断开，那么客户端类可以通过实现Session的OnClose()函数完成一些业务逻辑上的处理，比如保存用户数据。而这种编程模型，将客户端和网络会话的耦合性提到了最高：Client is a Session。方便的同时，很大程度上限制了模块的可拓展性，比如客户端的断线重连，由于这种继承关系，导致Session在销毁的同时必然导致Client”逻辑上”的断线，这样玩家重连的时候，数据只能重新加载，建立新的Session和Client。这种情况还会发生在客户端异处登录时，原有客户端被挤下线的同时，逻辑上的数据也丢失了，而新的客户端将重新加载数据。除了断线重连之外，该模型还会造成不必要的编译依赖。因此我们需要将逻辑上的客户端和底层的网络Session解耦。</p>
<span id="more"></span>
<p>一种可行的解耦方式是让Session和Player以”包含”的方式并存。即让Session指针或引用作为Player的一个成员。如此数据的发送仍然比较简单，而数据的接收和处理则需要Session通知Player类，这里有两种方式：</p>
<ol>
<li>让Session也包含一个Player的引用，如此Session在收到数据或连接关闭时也能调用Player接口进行业务逻辑上的处理。</li>
<li>通过std::bind直接让Player的数据解码接口(Decoder)交给Session，Session的数据接收和关闭均通过Decoder交由Player,如此实现更弱的耦合性。</li>
</ol>
<p>NGServer采用第二种方式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void PlayerManager::OnConnect(const std::shared_ptr&lt;Socket&gt;&amp; socket)</span><br><span class="line">&#123;</span><br><span class="line">	uint32_t id &#x3D; ++_connect_id;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; 创建Player和Session 并将Player和Session关联</span><br><span class="line">	std::shared_ptr&lt;Session&gt; session &#x3D; std::make_shared&lt;Session&gt;(socket, id);</span><br><span class="line">	std::shared_ptr&lt;Player&gt; player &#x3D; std::make_shared&lt;Player&gt;(session, LoginService::sDefaultSid);</span><br><span class="line">	std::function&lt;int32_t(const char*, size_t len)&gt; decoder &#x3D; std::bind(&amp;Player::Decode, player, std::placeholders::_1, std::placeholders::_2);</span><br><span class="line">	player-&gt;SetConnId(id);</span><br><span class="line">	session-&gt;SetDecoder(decoder);</span><br><span class="line"></span><br><span class="line">	AddPlayer(player);</span><br><span class="line"></span><br><span class="line">	session-&gt;StartRecv();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PlayerManager管理所有Player的连接，它继承于AsyncTcpListener，一个连接监听器，提供OnConnect接口处理客户端连接事件。因此PlayerManager负责Session和Player的创建和管理，并将Session和Player关联。当有新用户连接时，在OnConnect中，创建Player和Session，并相互关联。Session将收到的数据通过Player::Decode解码，该函数返回解包完成后缓冲区的剩余长度，以便Session调整缓冲区。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; Session收到新的数据</span><br><span class="line">void Session::ReadComplete(const boost::system::error_code&amp; err, size_t bytes_transferred)</span><br><span class="line">&#123;</span><br><span class="line">    if (err || bytes_transferred &#x3D;&#x3D; 0)</span><br><span class="line">    &#123;</span><br><span class="line">        DisConnect();</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">    _recv_total +&#x3D; bytes_transferred;</span><br><span class="line">    _recv_off +&#x3D; bytes_transferred;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 处理数据</span><br><span class="line">    if (ProcessData())</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; 继续接收数据</span><br><span class="line">        AsyncReadSome();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 对缓冲区中的数据解包 返回false则断开连接</span><br><span class="line">bool Session::ProcessData()</span><br><span class="line">&#123;</span><br><span class="line">    assert(_decoder);</span><br><span class="line">    &#x2F;&#x2F; 将数据交由解码器处理 返回处理之后的缓冲区剩余字节数 返回-1表示服务器主动断线</span><br><span class="line">    int32_t remain &#x3D; _decoder(_recv_buf,_recv_off);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 服务器断开连接</span><br><span class="line">    if (remain &lt; 0)</span><br><span class="line">    &#123;</span><br><span class="line">        ShutDown(ShutDownType::shutdown_receive);</span><br><span class="line">        DisConnect();</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 处理之后的偏移</span><br><span class="line">    if (remain &gt; 0 &amp;&amp; remain &lt; kBufferSize)</span><br><span class="line">    &#123;</span><br><span class="line">        size_t remain_off &#x3D; _recv_off - remain;</span><br><span class="line">        _recv_off &#x3D; (size_t)remain;</span><br><span class="line">        memcpy(_recv_buf, _recv_buf + remain_off, _recv_off);</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        _recv_off &#x3D; 0;</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>网络底层部分到此结束，焦点将由Player::Decode转向逻辑层。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>ngserver</tag>
      </tags>
  </entry>
  <entry>
    <title>NGServer 消息的编解码</title>
    <url>/2014/11/ngserver-message-encoder/</url>
    <content><![CDATA[<p>消息编解码(或序列化)主要是将消息体由一些标准库容器或自定义的类型，转化成二进制流，方便网络传输。为了减少网络IO，编解码中也可能在存在数据”压缩和解压”，但这种压缩是针对于特定的数据类型，并不是针对于二进制流的。在NGServer的消息编解码中，并不涉及数据压缩。</p>
<h3 id="一-消息编码格式"><a href="#一-消息编码格式" class="headerlink" title="一. 消息编码格式"></a>一. 消息编码格式</h3><p>NGServer的消息分为首部和消息体，首部共四个字节，包括消息长度(包括首部)和消息ID，各占两个字节。消息体为消息编码后的二进制数据。</p>
<p>在消息体中，针对于不同的数据类型而不同编码。对于POD类型，直接进行内存拷贝，对于非POD类型，如标准库容器，则需要自定义编码格式，以下是几种最常见的数据类型编码：</p>
<p>std::string 先写入字符串长度，占两个字节，再写入字符串内容。<br>std::vector 先写入vector的元素个数(占两个字节)，在对其元素逐个递归编码(如果元素类型为string，则使用string的编码方式)。<br>std::list    编码方式与vector类似<br>T arr[N]    对于这种类型，不需要写入元素个数，因为在消息结构体中指出了固定长度N，因此可以通过模板推导得到N。所以递归写入N个元素T即可。对于简单数据类型T，如T为char时，可以通过模板特例化对其优化。</p>
<span id="more"></span>
<h3 id="二-ProtocolStream"><a href="#二-ProtocolStream" class="headerlink" title="二. ProtocolStream"></a>二. ProtocolStream</h3><p>NGServer的消息编解码依靠两个类：ProtocolReader和ProtocolWriter。这两个类派生于ProtocolStream，ProtocolStream简单维护一个用于编码或解码的线性缓冲区，并记录缓冲区的当前状态，如总大小，当前偏移，等等。一个ProtocolStream的缓冲区即代表一条消息，因此它ProtocolReader/ProtocolWriter总是在缓冲区头四个字节中读出或写入消息长度和消息ID。</p>
<p>ProtocolReader从缓冲区中读出消息，也就是解码，由于缓冲区的数据是二进制的，因此我们需要提供需要读出的数据类型。因此ProtocolReader提供的接口如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">template&lt;typename T&gt;</span><br><span class="line">bool ProtocolReader::AutoDecode(T&amp; t);</span><br></pre></td></tr></table></figure>
<p>Decode在缓冲区的当前偏移处，读出数据t，并返回操作结果。而根据T的类型不同，读取方式也不一样，这需要通过模板推导来完成。</p>
<h3 id="三-数据类型"><a href="#三-数据类型" class="headerlink" title="三. 数据类型"></a>三. 数据类型</h3><p>T的类型概括有四种：</p>
<ul>
<li>基本POD类型，如 int, double, char 等  </li>
<li>标准库非POD类型，如 std::string, std::vector, std::list 等</li>
<li>自定义POD类型，如:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct A1</span><br><span class="line">&#123;</span><br><span class="line">	char name[36];</span><br><span class="line">	char pwd[36];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<ul>
<li>自定义非POD类型，如：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct A2</span><br><span class="line">&#123;</span><br><span class="line">	string name;</span><br><span class="line">	vector&lt;int&gt; data;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<ul>
<li>C数组类型 由于其推导方式不同 因此单独归为一类</li>
</ul>
<p>关于c++ POD类型和std::is_pod，std::is_standard_layout，std::is_trivial等函数，可参见下面两篇博客：</p>
<ol>
<li><a href="http://m.oschina.net/blog/156796">http://m.oschina.net/blog/156796</a></li>
<li><a href="http://www.cnblogs.com/hancm/p/3665998.html">http://www.cnblogs.com/hancm/p/3665998.html</a></li>
</ol>
<p>这里说的POD指的是 std::is_trivial<T\>::value &amp;&amp; std::is_standard_layout<T\>::value</p>
<h3 id="四-ProtocolReader解码推导流程"><a href="#四-ProtocolReader解码推导流程" class="headerlink" title="四. ProtocolReader解码推导流程"></a>四. ProtocolReader解码推导流程</h3><p>推导流程如下：</p>
<p><strong>1.如果T是C数组类型 (std::is_array<T>::value == true)</strong>，那么下一个推导模型应该为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">template&lt;typename T, size_t arraySize&gt;</span><br><span class="line">bool ProtocolReader::DecodeArray(const T (&amp;arr)[arraySize]);</span><br></pre></td></tr></table></figure>
<p>如此便能推导出数组的元素类型，以及数组的大小</p>
<p>注：std::is_array<T\>用于判别一个类型是否为<strong>C风格数组类型</strong>，对于c++的容器vector，std::is_array<vector<int\>&gt;::value的值为false，因为vector本身也是一个类。</p>
<p>根据我们对C数组的编码方式，下一步我们需要递归通过ProtocolReader::AutoDecode(arr[i])来依次递归对数组元素进行解码。</p>
<p><strong>2.如果T不是C型数组</strong>，那么T是一个类(或基本类型)。此时通过Decode来对该类进行编解码，Decode读取缓冲区数据，对POD类型和预定义的特例化类型(一般是标准库容器)进行读取并解码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">template&lt;typename T&gt;</span><br><span class="line">bool ProtocolReader::Decode(T&amp; t);</span><br></pre></td></tr></table></figure>
<p>对于POD类型，无论是基本数据类型或者自定义类型，均无需特例化，直接内存拷贝即可。这也是Decode()的默认实现。而对于标准库中的容器，则可以针对性的模板特例化：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">template&lt;typename T&gt;</span><br><span class="line">bool ProtocolReader::Decode(std::vector&lt;T&gt;&amp; vec);</span><br></pre></td></tr></table></figure>
<p>而对于最后一种类型，自定义非POD类型，模板自动推导则爱莫能助了，比如对于结构体A2，它的推导流程是: AutoDecode(A2&amp;) -&gt; Decode(A2&amp;) 到了这里，框架无法再推导出A2内部的乾坤了。这就需要A2的定义者提供一个特例化的解码函数AutoDecode(A2&amp;)，为什么不特例化Decode(A2&amp;)呢？因为AutoDecode()是解码的最外层接口，使用者通过自定义的AutoDecode能够获得最大的灵活性。</p>
<p>那么问题来了，由于上面提到的AutoDecode Decode等函数均是ProtocolReader的成员函数，那么AutoDecode(A2&amp;)也应该定义在ProtocolReader中，这样做有两点不足之处：</p>
<ol>
<li>大量的模板特例化会使ProtocolReader变得异常臃肿难读，并且消息的定义和特例化在不同的文件。容易在定义之后忘记特例化。</li>
<li>编译依赖性增大，添加任意一条非POD消息，都需要重新编译整个ProtocolReader.h以及包含它的所有模块。</li>
</ol>
<p>而解决方案就是将类中的模板推导转为全局模板推导AutoDecode，然后自定义类的特例化均在全局中，最后再通过Decode调用ProtocolReader接口进行已知类型的推导。</p>
<p>具体流程：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;******************* STEP 1 内部自动解码接口 转向全局自动模板推导 **************************&#x2F; </span><br><span class="line">template&lt;typename T&gt;</span><br><span class="line">bool ProtocolReader::Decode(T&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F; 转向全局推导</span><br><span class="line">	return AutoDecode(*this, t);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;****************** STEP 2 通过是否是C数组分发到不同推导接口 ******************************&#x2F;</span><br><span class="line">&#x2F;&#x2F; 全局自动推导 这是全局入口 也是自定义的非POD消息的重载入口</span><br><span class="line">template&lt;typename S, typename T&gt;</span><br><span class="line">bool AutoDecode(S&amp; s, T&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;* </span><br><span class="line">	*	Serializer是辅助类 它通过 std::is_array&lt;T&gt;::value 的不同值来转调到不同的模板推导接口</span><br><span class="line">   	*	即 Serializer&lt;true&gt;::DeSerialize(s,t) 和 Serializer&lt;false&gt;::DeSerialize(s,t)</span><br><span class="line">	*&#x2F;</span><br><span class="line">	return Serializer&lt;std::is_array&lt;T&gt;::value&gt;::DeSerialize(s, t);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;***************** STEP 3 Serializer 完成对C数组和非C数组的分发 *************************&#x2F;</span><br><span class="line">&#x2F;* Serializer对C数组的分发接口</span><br><span class="line">*	推导出数组元素类型和元素个数</span><br><span class="line">*	通过DecodeArray进行解码</span><br><span class="line">*&#x2F;</span><br><span class="line">template&lt;typename S, typename T, size_t arraySize&gt;</span><br><span class="line">bool Serializer&lt;true&gt;::DeSerialize(S&amp; s, T (&amp;t)[arraySize])</span><br><span class="line">&#123;</span><br><span class="line">	return DecodeArray(s, t, arraySize);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;* Serializer对非C数组的分发接口</span><br><span class="line">*  通过Decode尝试直接解码</span><br><span class="line">*&#x2F;</span><br><span class="line">template&lt;typename S, typename T&gt;</span><br><span class="line">bool Serializer&lt;false&gt;::DeSerialize(S&amp; s, T&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	return Decode(s, t);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;****************** STEP 4.A 对C数组 T[arraySize] 进行解码 *****************************&#x2F;</span><br><span class="line">&#x2F;*</span><br><span class="line">*	DecodeArray </span><br><span class="line">*	对固定长度的数组进行解码</span><br><span class="line">*&#x2F;</span><br><span class="line">template&lt;typename S, typename T&gt;</span><br><span class="line">bool DecodeArray(S&amp; s, T* t, size_t arraySize)</span><br><span class="line">&#123;</span><br><span class="line">	uint16_t size &#x3D; static_cast&lt;uint16_t&gt;(arraySize);</span><br><span class="line">	for(uint16_t i&#x3D;0; i&lt;size; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		&#x2F;&#x2F; 递归对元素进行自动解码</span><br><span class="line">		if(!AutoDecode(s, t[i]))</span><br><span class="line">			return false;</span><br><span class="line">	&#125;</span><br><span class="line">	return true;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 对基本类型的C数组特例化 直接内存拷贝</span><br><span class="line">template&lt;typename S&gt;</span><br><span class="line">bool DecodeArray(S&amp; s, int* arr, size_t arraySize)&#123; return s.Read((void*)arr, arraySize*sizeof(int)); &#125;</span><br><span class="line"></span><br><span class="line">template&lt;typename S&gt;</span><br><span class="line">bool DecodeArray(S&amp; s, float* arr, size_t arraySize)&#123; return s.Read((void*)arr, arraySize*sizeof(float)); &#125;</span><br><span class="line"></span><br><span class="line">template&lt;typename S&gt;</span><br><span class="line">bool DecodeArray(S&amp; s, double* arr, size_t arraySize)&#123; return s.Read((void*)arr, arraySize*sizeof(double)); &#125;</span><br><span class="line"></span><br><span class="line">template&lt;typename S&gt;</span><br><span class="line">bool DecodeArray(S&amp; s, int64_t* arr, size_t arraySize)&#123; return s.Read((void*)arr, arraySize*sizeof(int64_t)); &#125;</span><br><span class="line"></span><br><span class="line">&#x2F;*********************** STEP 4.B 对非C数组 进行直接解码 *******************************&#x2F;</span><br><span class="line">&#x2F;&#x2F; 默认解码 对于POD类型 直接内存拷贝</span><br><span class="line">template&lt;typename S, typename T&gt;</span><br><span class="line">bool Decode(S&amp; s, T&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">    static_assert(std::is_trivial&lt;T&gt;::value, &quot;is not trivial. need to customize&quot;);</span><br><span class="line">    static_assert(std::is_standard_layout&lt;T&gt;::value, &quot;is not standard_layout. need to customize&quot;);</span><br><span class="line">    return s.Read((void*)&amp;t, sizeof(t));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 预定义特例化</span><br><span class="line">&#x2F;&#x2F; 对string的解码 在ProtocolReader中完成 此时类型已确定</span><br><span class="line">template&lt;typename S&gt;</span><br><span class="line">bool Decode(S&amp; s, std::string&amp; t)&#123; return s.Read(t);  &#125;</span><br><span class="line"></span><br><span class="line">template&lt;typename S&gt;</span><br><span class="line">bool Decode(S&amp; s, std::wstring&amp; t)&#123; return s.Read(t);	&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 对标准库容器的解码 由于标准容器元素类型可能仍为自定义类型，因此需要继续递归解码</span><br><span class="line">template&lt;typename S, typename T&gt;</span><br><span class="line">bool Decode(S&amp; s, std::vector&lt;T&gt;&amp; t)&#123; return DecodeArray(s, t); &#125;</span><br><span class="line"></span><br><span class="line">template&lt;typename S, typename T&gt;</span><br><span class="line">bool Decode(S&amp; s, std::list&lt;T&gt;&amp; t)&#123; return DecodeArray(s, t); &#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 解码动态长度容器 </span><br><span class="line">template&lt;typename S, typename T&gt;</span><br><span class="line">bool DecodeArray(S&amp; s, T&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">    uint16_t size;</span><br><span class="line">    if (s.Read(size))</span><br><span class="line">    &#123;</span><br><span class="line">        for (uint16_t i &#x3D; 0; i &lt; size; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            T::value_type v;</span><br><span class="line">			&#x2F;&#x2F; 逐个对元素进行自动解码</span><br><span class="line">            if (!AutoDecode(s, v))</span><br><span class="line">                return false;</span><br><span class="line">            t.push_back(v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意，对数组元素或标准库容器元素解码时，都调用AutoDecode，这是因为如果容器元素是用户自定义的非POD类型，那么可以通过用户重载的AutoDecode进行正确解码。总之，对于未知类型，都应该通过AutoDecode确保用户自定义类型得到正确解码。而Decode只针对于两种类型：POD类型和标准库容器类型，对于前者默认内存拷贝，对于后者通过AutoDecode对元素逐个解码。如果用户没有提供自定义类型的AutoDecode特例化，那么Decode判断其POD类型并执行内存拷贝，如果该类型不是POD类型，那么static_assert将在编译器给出错误：”is not trivial. need to customize” 或 “is not standard layout. need to customize”。<br>而C数组通过在AutoDecode转向分支DecodeArray，DecodeArray完成元素个数解析之后，也通过AutoDecode对元素递归解码。</p>
<h3 id="五-自定义消息类型的特例化"><a href="#五-自定义消息类型的特例化" class="headerlink" title="五. 自定义消息类型的特例化"></a>五. 自定义消息类型的特例化</h3><p>自定义的非POD消息类型A2的特例化如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bool AutoDecode(ProtocolReader&amp; s, A2&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	return AutoDecode(s, t.name) &amp;&amp; AutoDecode(s, t.data);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这是全部特例化，它特例化了解码类ProtocolReader和解码类型A2。而自动化模板推导中使用typename S来模板化编解码类，这是为了提高灵活性，让全局自动模板推导框架可以用于多种编解码类。</p>
<p>如果自定义消息类更复杂一些：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct A3</span><br><span class="line">&#123;</span><br><span class="line">	std::string str;</span><br><span class="line">	A2 a2;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>此时A3为复合的自定义非POD类型，如果只为A3提供特例化而忘了给A2特例化：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bool AutoDecode(ProtocolReader&amp; s, A3&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	return AutoDecode(s, t.str) &amp;&amp; AutoDecode(s, t.a2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么 <code>AutoDecode(s, t.str)</code>能够解码成功，而<code>AutoDecode(s, t.a2)</code>，则会失败。因此最好在定义任何一个与客户端交互的非POD结构体时，都需要提供对应编解码规则。而不是在特例化消息的时候才去注意其成员有无非POD类型需要特例化。</p>
<h3 id="六-特例化宏"><a href="#六-特例化宏" class="headerlink" title="六. 特例化宏"></a>六. 特例化宏</h3><p>编码的推导过程和解码大同小异，只不过最终是写入缓冲区而不是读取缓冲区。NGServer还有一个ProtocolSize类，用于获取消息编码之后的大小，推导流程也和编解码流程一致。目前没有什么太大的作用。因此实际上在特例化自定义类的编解码规则时，需要同时提供AutoEncode，AutoDecode，AutoMsgSize三个全局函数。这样在消息比较多时，编写对应编解码规则是一件比较麻烦的事情，并且容易出错。</p>
<p>因此可以对这些编解码特例化提供一个宏，方便定义其编解码规则：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define AUTOCUSTOMMSG1(T, v1) \</span><br><span class="line">    bool Encode(ProtocolWriter&amp; s, const T&amp; t)&#123; \</span><br><span class="line">        return AutoEncode(s, t.v1); &#125; \</span><br><span class="line">    \</span><br><span class="line">    bool Decode(ProtocolReader&amp; s,  T&amp; t)&#123; \</span><br><span class="line">        return AutoDecode(s, t.v1); &#125; \</span><br><span class="line">    \</span><br><span class="line">    uint32_t GetMsgSize(ProtocolSize&amp; s, const T&amp; t )&#123; \</span><br><span class="line">        return AutoMsgSize(s, t.v1); &#125; </span><br><span class="line"></span><br><span class="line">#define AUTOCUSTOMMSG2(T, v1, v2) \</span><br><span class="line">    bool Encode(ProtocolWriter&amp; s, const T&amp; t)&#123; \</span><br><span class="line">        return AutoEncode(s, t.v1) &amp;&amp; AutoEncode(s, t.v2); &#125; \</span><br><span class="line">    \</span><br><span class="line">    bool Decode(ProtocolReader&amp; s,  T&amp; t)&#123; \</span><br><span class="line">        return AutoDecode(s, t.v1) &amp;&amp; AutoDecode(s, t.v2); &#125; \</span><br><span class="line">    \</span><br><span class="line">    uint32_t GetMsgSize(ProtocolSize&amp; s, const T&amp; t )&#123; \</span><br><span class="line">        return AutoMsgSize(s, t.v1) + AutoMsgSize(s, t.v2); &#125; </span><br><span class="line"></span><br><span class="line">#define AUTOCUSTOMMSG3(T, v1, v2, v3) \ </span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>如此，对于A2，我们只需在协议cpp文件添加：</p>
<pre><code>AUTOCUSTOMMSG2(A2, name, data);
</code></pre><p>即可。</p>
<h3 id="七-回到ProtocolReader"><a href="#七-回到ProtocolReader" class="headerlink" title="七. 回到ProtocolReader"></a>七. 回到ProtocolReader</h3><p>ProtocolReader通过Decode函数转向全局模板推导，最后再回到ProtocolReader进行缓冲读取，由于ProtocolReader缓冲区对应于一条消息，因此解码的缓冲区offset偏移初始化为4(前四个字节为消息头部)。它提供基本类型和string的读取，最后附上主要代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class ProtocolReader : public ProtocolStream</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    ProtocolReader(char* buf, uint32_t len) :</span><br><span class="line">        ProtocolStream(buf, len)&#123;&#125;</span><br><span class="line"></span><br><span class="line">    template&lt;typename T&gt;</span><br><span class="line">    bool Decode(T&amp; t)</span><br><span class="line">    &#123;</span><br><span class="line">        return AutoDecode(*this, t);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 读取二进制数据</span><br><span class="line">    bool Read(void* ptr, uint32_t len)</span><br><span class="line">    &#123;</span><br><span class="line">        if (Remain() &gt;&#x3D; len)</span><br><span class="line">        &#123;</span><br><span class="line">            memcpy(ptr, _buf + _offset, len);</span><br><span class="line">            _offset +&#x3D; len;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 读取基本类型的数据</span><br><span class="line">    inline bool Read(char&amp; v)    &#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line">    inline bool Read(int8_t&amp; v)  &#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line">    inline bool Read(uint8_t&amp; v) &#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line">    inline bool Read(int16_t&amp; v) &#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line">    inline bool Read(uint16_t&amp; v)&#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line">    inline bool Read(int32_t&amp; v) &#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line">    inline bool Read(uint32_t&amp; v)&#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line">    inline bool Read(int64_t&amp; v) &#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line">    inline bool Read(uint64_t&amp; v)&#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line">    inline bool Read(float&amp; v)   &#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line">    inline bool Read(double&amp; v)  &#123; return Read((void*)(&amp;v), sizeof(v)); &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 对string解码</span><br><span class="line">    inline bool Read(std::string&amp; v)     &#123; return ReadString(v); &#125;</span><br><span class="line">    inline bool Read(std::wstring&amp; v)    &#123; return ReadString(v); &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 读取头部和消息ID</span><br><span class="line">    inline uint16_t ReadHead()</span><br><span class="line">    &#123;</span><br><span class="line">        uint16_t* h &#x3D; (uint16_t*)_buf;</span><br><span class="line">        return *h;</span><br><span class="line">    &#125;</span><br><span class="line">    inline uint16_t ReadMsgId()</span><br><span class="line">    &#123;</span><br><span class="line">        uint16_t* h &#x3D; (uint16_t*)_buf;</span><br><span class="line">        return *(h + 1);</span><br><span class="line">    &#125;</span><br><span class="line">private:</span><br><span class="line">    bool ReadString(std::string&amp; v)</span><br><span class="line">    &#123;</span><br><span class="line">        uint16_t len;</span><br><span class="line">        if (Read(len))</span><br><span class="line">        &#123;</span><br><span class="line">            v.clear();</span><br><span class="line">            if (len &gt; 0)</span><br><span class="line">            &#123;</span><br><span class="line">                assert(Remain() &gt;&#x3D; len*sizeof(char));</span><br><span class="line">                v.append((const char*)(_buf + _offset), len);</span><br><span class="line">                _offset +&#x3D; len;</span><br><span class="line">            &#125;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bool ReadString(std::wstring&amp; v)</span><br><span class="line">    &#123;</span><br><span class="line">        uint16_t len;</span><br><span class="line">        if (Read(len))</span><br><span class="line">        &#123;</span><br><span class="line">            v.clear();</span><br><span class="line">            if (len &gt; 0)</span><br><span class="line">            &#123;</span><br><span class="line">                assert(Remain() &gt;&#x3D; len*sizeof(wchar_t));</span><br><span class="line">                v.append((const wchar_t*)(_buf + _offset), len);</span><br><span class="line">                _offset +&#x3D; len*sizeof(wchar_t);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>ngserver</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ 构造语义</title>
    <url>/2014/11/cpp-constructor/</url>
    <content><![CDATA[<p>本文是《深度探索C++对象模型》的读书笔记，主要根据自己的理解整理一下C++对象构造的实现细节以及其在实际编程中所带来的影响。</p>
<h2 id="一-构造函数"><a href="#一-构造函数" class="headerlink" title="一. 构造函数"></a>一. 构造函数</h2><p>C++95标准对构造函数如下描述：</p>
<blockquote>
<p>对于 class X，如果没有任何user-declared constructor，那么会有一个default constructor被<strong>隐式声明</strong>出来…..一个被隐式声明出来的 default constructor 将是一个<strong>trivial(浅薄无能的，没啥用的) constructor</strong> ……</p>
</blockquote>
<p>上面的话摘自《深度探索C++对象模型》P40，由于其省略了其中c++标准的部分内容，因此很容易造成误解：</p>
<p>编译器<strong>隐式生成</strong>的构造函数都是 trivial constructor …..</p>
<p>事实上，描述中提到 default constructor 被隐式声明出来（满足语法需要），而该构造函数是否被编译器合成（实现或定义），取决于<strong>编译器是否需要在构造函数中做些额外工作</strong>，一个没有被合成的 default constructor 被视为 trivial constructor(这也是c++标准原话的意思)，而当编译器在需要时合成了构造函数，那么该类构造函数将被视为 nontrivial。</p>
<p>另外，一个定义了 user-decalred constructor(用户定义的任何构造函数) 的类被视为具有 nontrivial constructor。</p>
<p>下面将着重讨论编译器隐式声明的构造函数在哪种情况下需要被合成(nontrivial)，哪种情况下无需被合成(trivial)：</p>
<!--more>

考虑下面这个类：

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class A</span><br><span class="line">&#123;</span><br><span class="line">private:</span><br><span class="line">	int _ivalue;</span><br><span class="line">	float _fvalue;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>对于类A来说，编译器将为其隐式声明的默认构造函数被视为trivial。因为编译器无需在其声明的构造函数中，对A类对象进行任何额外处理。注意，编译器生成的默认构造函数不会对 _ivalue 和 _fvalue 进行初始化。因此在这种情况下，编译器隐式生成的默认构造函数可有可无，视之为”trivial”。</p>
<p>而对于如下四种情况，编译器隐式生成的默认构造函数(以下简称”隐式构造函数”)是 nontrivial default constructor ：</p>
<h4 id="a-类中有-“带-nontrivial-default-constructor”-的对象成员"><a href="#a-类中有-“带-nontrivial-default-constructor”-的对象成员" class="headerlink" title="a. 类中有 “带 nontrivial default constructor” 的对象成员"></a>a. 类中有 “带 nontrivial default constructor” 的对象成员</h4><p>注意，这里的notrivial default constructor包括<strong>用户定义的任何构造函数</strong>或者<strong>编译器生成的notrivial构造函数</strong>。这实际上是一个递归定义，当类X中有具备notrivial default constructor的对象成员Y _y时，X的隐式构造函数需要调用Y的默认构造函数完成对成员_y的构造。如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class B</span><br><span class="line">&#123;</span><br><span class="line">private:</span><br><span class="line">	A _a;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class C</span><br><span class="line">&#123;</span><br><span class="line">private:</span><br><span class="line">	std::string _str;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>我们说类B中的对象成员 A _a “不带default constructor”，因为它只有一个隐式生成的 trivial default constructor。因此B的隐式构造函数中，无需操心对成员_a的构造。因而实际上B的隐式构造函数也被视为trivial(无关紧要)。而对于类C，由于其对象成员类型string具备用户(库作者)声明的默认构造函数，因此string的构造函数是nontrivial，所以编译器在为C合成的默认构造函数中，需要调用string的默认构造函数来为_str初始化，此时C的构造函数便不再是”无关紧要”的，被视为 nontrivial。</p>
<h4 id="b-类继承于-“带-nontrivial-default-constructor”-的基类"><a href="#b-类继承于-“带-nontrivial-default-constructor”-的基类" class="headerlink" title="b. 类继承于 “带 nontrivial default constructor” 的基类"></a>b. 类继承于 “带 nontrivial default constructor” 的基类</h4><p>情形b和情形a类似：当类具有 “带 nontrivial default constructor”的基类时，编译器隐式生成的默认构造函数需要调用基类的默认构造函数确保基类的正确初始化。此时该类构造函数视为nontrivial。</p>
<h4 id="c-类中有虚函数-或继承体系中有虚函数"><a href="#c-类中有虚函数-或继承体系中有虚函数" class="headerlink" title="c. 类中有虚函数(或继承体系中有虚函数)"></a>c. 类中有虚函数(或继承体系中有虚函数)</h4><p>在这种情况下，编译器生成的隐式构造函数需要完成对虚函数表vtable的构造，并且将vtable的指针安插到对象中(通常是头四个字节)。此时的隐式构造函数自然是必不可少(nontrivial)。</p>
<h4 id="d-类的继承体系中具有虚基类"><a href="#d-类的继承体系中具有虚基类" class="headerlink" title="d. 类的继承体系中具有虚基类"></a>d. 类的继承体系中具有虚基类</h4><p>和情形c一样，编译器需要在合成的构造函数中，对虚基类进行处理(处理方式和虚函数类似，通过一个指针来指向虚基类，以保证虚基类在其继承体系中，只有一份内容)，这样才能保证程序能在运行中正确存取虚基类数据。被视为nontrivial。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>编译器隐式声明的默认构造函数，是 trivial or nontrivial，取决于编译器是否需要在构造函数中做一些额外的处理，主要包括对象成员和基类的初始化(取决于对象成员或基类有无nontrivial default constructor)，以及对虚函数和虚基类的处理(取决于在其继承体系中是否有虚函数或虚基类)。这些工作使隐式构造函数不再是可有可无。</p>
<p>不存在以上四种情况并且没有用户定义的任何构造函数时，隐式构造函数也被称作 implicit trivial default constructors。这类构造函数实际上并不会被编译器合成出来。这也是对 trivial 和 nontrivial 的直观理解。</p>
<p>而实际上，即使你定义了自己的构造函数，如果类中满足以上四种情形之一，编译器也会将你的构造函数展开，将必要的处理(如vtable的构造)植入到你的构造函数中(一般是你的构造代码之前)。不过仍然请注意，一旦你定义了自己的构造函数，哪怕该函数什么也不做，该类也将被视为具备 nontrivial constrcutor。</p>
<h2 id="二-复制构造函数"><a href="#二-复制构造函数" class="headerlink" title="二. 复制构造函数"></a>二. 复制构造函数</h2><p>就像 default constructor 一样，C++ Standard 上说，如果 class 没有声明一个 copy constructor，就会有隐式的声明(implicitly declared)或隐式的定义(implicitly defined)出现，和以前一样，C++ Standard 把 copy constructor 区分为 trivial 和 nontrivial 两种，只有 nontrivial 的实例才会被合成于程序之中。决定一个 copy constructor 是否为 trivial 的标准在于 class 是否展现出所谓的 “bitwise copy semantics(按位拷贝语义)”。</p>
<p>“按位拷贝语义”是指该类对象之间的拷贝构造，可以通过简单的”位拷贝”(memcpy)来完成，并且与该对象拷贝的原本语义一致。例如 上面的类A，它便具有按位拷贝语义。因此它的拷贝构造函数也是 trivial copy constructor。这样的拷贝构造函数不会被编译器合成到程序中。直接将其作为内存块拷贝即可(类似于 int double 之类的基本类型)。</p>
<p>那么类何时不具有按位拷贝语义？ 和构造函数一样，当编译器声明的拷贝构造函数需要替程序做一些事情时，视为nontrivial。具有也有如下四种情况：</p>
<ol>
<li>类中有 “带 nontrivial copy constructor” 的对象成员</li>
<li>类继承于 “带 nontrivial copy constructor” 的基类</li>
<li>类中有虚函数(或继承体系中有虚函数)</li>
<li>类的继承体系中具有虚基类</li>
</ol>
<p>对于1，2，复制构造函数需要通过调用基类或对象成员的 nontrivial 拷贝构造函数来保证它们的正确拷贝。</p>
<p>而对于3，考虑如下情形：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F; class Derive public派生于 class Base</span><br><span class="line">Derive d;</span><br><span class="line">Derive d2 &#x3D; d;</span><br><span class="line">Base b &#x3D; d; &#x2F;&#x2F; 发生切割(sliced)行为</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>对于d2对象，编译器使用位拷贝并无问题(假设Derive并不存在1，2，4所述情况)，因为d和d2的虚函数表均来自于Derive。而对于<code>Base b = d;</code>编译器需要保证对象b的虚函数表为Base的虚函数表，而不是从对象d直接位拷贝过来的Derive类的虚函数表。否则在通过b调用Derive特有而基类Base没有的虚函数时，会发生崩溃(因为Base的虚函数表不含该函数)。因此对于有虚函数的类，编译器必须对该类的虚函数表”负责”，保证其正确初始化。</p>
<p>对于4，和情况3一样，编译器需要确保被构造的对象指向虚基类的指针(virtual base class point)得到正确初始化。</p>
<p>当类不满足以上四种情况时，我们说它的copy constructor为trivial。编译器不会合成trivial copy constrcutor到程序中。在拷贝对象时，执行简单的内存块拷贝。</p>
<h2 id="三-trivial的一些扩展"><a href="#三-trivial的一些扩展" class="headerlink" title="三. trivial的一些扩展"></a>三. trivial的一些扩展</h2><p>在std中，提供了对某个类各个trivial属性的判别。如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">class A</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    A()</span><br><span class="line">    &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">    int _i;</span><br><span class="line">    char* _str;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class B : public A</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">    double _d;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F; 0 A 有 user-declared constructor</span><br><span class="line">    std::cout &lt;&lt; std::is_trivially_constructible&lt;A&gt;::value &lt;&lt; std::endl; </span><br><span class="line">	&#x2F;&#x2F; 1 A 没有 user-declared copy constructor 并且不含abcd情形       </span><br><span class="line">    std::cout &lt;&lt; std::is_trivially_copy_constructible&lt;A&gt;::value &lt;&lt; std::endl;   </span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; 0 B 需要调用A::A() 完成对基类的构造</span><br><span class="line">    std::cout &lt;&lt; std::is_trivially_constructible&lt;B&gt;::value &lt;&lt; std::endl;</span><br><span class="line">	&#x2F;&#x2F; 1 B 没有 user-declared copy constructor 并且基类 A 没有 nontrivial copy constructor        </span><br><span class="line">    std::cout &lt;&lt; std::is_trivially_copy_constructible&lt;B&gt;::value &lt;&lt; std::endl;   </span><br><span class="line">    </span><br><span class="line">    std::cout &lt;&lt; std::is_trivial&lt;A&gt;::value &lt;&lt; std::endl;	&#x2F;&#x2F; 0</span><br><span class="line">    std::cout &lt;&lt; std::is_trivial&lt;B&gt;::value &lt;&lt; std::endl;    &#x2F;&#x2F; 0</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>std::is_<em>*</em>是c++11引入的关于类型特性(type_traits)的一些列模板，它们可以在编译器就获得有关类型的特性信息。也就是说：</p>
<pre><code>std::cout &lt;&lt; std::is_trivial&lt;A&gt;::value &lt;&lt; std::endl;
</code></pre><p>在运行时相当于：</p>
<pre><code>std::cout &lt;&lt; 1 &lt;&lt; std::endl;
</code></pre><p>这种编译期获得结果的特性让我们可以结合 static_assert 完成更多的事情。如：</p>
<pre><code>static_assert(std::is_trivially_constructible&lt;A&gt;::value, &quot;A is not pod type&quot;);
</code></pre><p>那么如果A不具备 trivial constructor，那么我们可以在程序编译期得到一个编译错误：A is not pod type</p>
<p>std::is_trivial判断一个类型是否为trivial类型。C++标准把trivial类型定义如下： </p>
<ul>
<li><p>没有 nontrivial constructor</p>
</li>
<li><p>没有 nontrivial copy constructor </p>
</li>
<li><p>没有 nontrivial move constructor</p>
</li>
<li><p>没有 nontrivial assignment operator </p>
</li>
<li><p>有一个 trivial destructor </p>
</li>
</ul>
<p>由于类A和类B均有 nontrivial constructor 因此它们都不是trivial类型。</p>
]]></content>
      <categories>
        <category>c/c++</category>
      </categories>
      <tags>
        <tag>c/c++</tag>
      </tags>
  </entry>
  <entry>
    <title>NGServer 消息的注册与回调</title>
    <url>/2014/11/ngserver-message-callback/</url>
    <content><![CDATA[<p>在前面Service框架的介绍中，提到在GameService的<code>ProcessMsg(UserMessage*)</code>和<code>ProcessMsg(InsideMessage*)</code>中，都完成了消息的回调处理。消息响应函数的注册是在服务初始化(Init())中完成的。需要注册和回调的消息有InsideMessage和UserMessage，对于InsideMessage，响应函数只有一种形式：即为响应服务的成员函数。而对于UserMessage，由于UserMessage有Player指针，响应函数则会有多种形式：</p>
<ol>
<li>作为注册Service的成员函数，并且将Player作为第一个参数。这常在登录和注册流程中发生，如 <code>LoginService::OnPlayerLogin(Player&amp; player, const C2S_Login&amp; msg)</code>。 登录和注册的验证流程在LoginService中统一处理。</li>
<li>作为Player的成员函数，当Player登录成功后，此时客户端与服务器进行的交互都是基于业务逻辑的，因此应在Player的成员函数处理。如 <code>Player::OnEnterGate(const C2S_EnterGate&amp; msg)</code></li>
<li>其它响应函数，如全局函数。</li>
</ol>
<span id="more"></span>
<p>事实上，基于UserMessage中的Player指针，我们可以实现上面的调用方式，现在就需要通过一种或多种的注册回调机制，来实现对各种响应函数形式的注册和回调。</p>
<h2 id="使用消息注册与回调"><a href="#使用消息注册与回调" class="headerlink" title="使用消息注册与回调"></a>使用消息注册与回调</h2><p>消息的注册通过指定消息ID和消息响应函数来完成，注册函数主要有如下形式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bool MapService::Init()</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F; 注册用户消息 响应函数原型： void MapService::OnWorldChat(Player* player, C2S_WorldChat&amp; msg)</span><br><span class="line">	RegistPlayer(MsgId::kC2S_WorldChat, &amp;MapService::OnWorldChat, this);</span><br><span class="line">	&#x2F;&#x2F; 注册用户消息 响应函数原型： void Player::OnEnterGate(const C2S_EnterGate&amp; msg)</span><br><span class="line">	RegistPlayer(yuedong::protocol::kC2S_EnterGate, &amp;Player::OnEnterGate);</span><br><span class="line">	&#x2F;&#x2F; 注册用户消息 响应函数原型：void Test(Player* player, Test);</span><br><span class="line">	</span><br><span class="line">	&#x2F;&#x2F; 注册响应服务之间的内部消息</span><br><span class="line">	RegistInside(SSMsgId::kSS_PlayerLogin, &amp;MapService::OnPlayerLogin, this);</span><br><span class="line">	return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面注册了三种主要消息，通过RegistPlayer注册玩家消息，通过RegistInside注册内部消息。RegistPlayer通过模板推导和函数重载完成了三种响应函数原型的注册。下面以RegistPlayer为例，讲述消息注册机的内部机制：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GameService</span> :</span> <span class="keyword">public</span> Service</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// ....</span></span><br><span class="line"><span class="comment">// 消息注册</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="comment">// 注册第一个参数为Player*的回调函数 </span></span><br><span class="line">	<span class="comment">// 当 F 模板推导为全局函数时，第一个参数为Player*  </span></span><br><span class="line">	<span class="comment">//	如 void Test(Player*, C2S_Test&amp;)</span></span><br><span class="line">	<span class="comment">// 当 F 模板推导为Player成员函数时，将解析出来的Player*直接作为this指针调用该成员函数</span></span><br><span class="line">	<span class="comment">//  如 Player::OnEnterGate(C2S_EnterGate&amp;)</span></span><br><span class="line">	<span class="keyword">template</span>&lt;<span class="keyword">typename</span> MsgEnum, <span class="keyword">typename</span> F&gt;</span><br><span class="line">	<span class="function"><span class="keyword">void</span> <span class="title">RegistPlayer</span><span class="params">(MsgEnum msgid, F f)</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">	    _calltype[(<span class="keyword">uint16_t</span>)msgid] = cbPlayerAgent;</span><br><span class="line">	    _player_delegate.Regist((<span class="keyword">uint16_t</span>)msgid, f);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 注册第一个参数为Player*的MapService成员函数 </span></span><br><span class="line">	<span class="comment">//	如MapService::OnWorldChat(Player*, C2S_WorldChat&amp;)</span></span><br><span class="line">	<span class="keyword">template</span>&lt;<span class="keyword">typename</span> MsgEnum, <span class="keyword">typename</span> F, <span class="keyword">typename</span> ObjT&gt;</span><br><span class="line">	<span class="function"><span class="keyword">void</span> <span class="title">RegistPlayer</span><span class="params">(MsgEnum msgid, F f, ObjT* obj)</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">	    _calltype[(<span class="keyword">uint16_t</span>)msgid] = cbPlayerAgent;</span><br><span class="line">	    _player_delegate.Regist((<span class="keyword">uint16_t</span>)msgid, f, obj);</span><br><span class="line">	&#125;</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	DelegateManager&lt;<span class="built_in">std</span>::<span class="built_in">pair</span>&lt;Player*, ProtocolReader&amp;&gt;&gt; _player_delegate;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>在<code>bool MapService::ProcessMsg(UserMessage* msg)</code>中回调响应函数：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">MapService::ProcessMsg</span><span class="params">(UserMessage* msg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    UserMessageT&lt;PlayerPtr&gt;* msgT = <span class="keyword">dynamic_cast</span>&lt;UserMessageT&lt;PlayerPtr&gt;*&gt;(msg);</span><br><span class="line">    <span class="keyword">if</span> (msgT == <span class="literal">nullptr</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    PlayerPtr player = msgT-&gt;GetClient();</span><br><span class="line">    <span class="keyword">int32_t</span> sid = player-&gt;GetSid();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 不是发送给当前服务的消息 转发</span></span><br><span class="line">    <span class="keyword">if</span> (sid != _sid)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> ServiceManager::Send(sid, msg);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 客户端断开连接</span></span><br><span class="line">    <span class="keyword">if</span> (msg-&gt;_len == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        player-&gt;Offline();</span><br><span class="line">        _session_manager-&gt;RemoveSession(player-&gt;GetConnId());</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function">ProtocolReader <span class="title">reader</span><span class="params">(msg-&gt;_data, msg-&gt;_len)</span></span>;</span><br><span class="line">    <span class="keyword">uint16_t</span> msgid = reader.ReadMsgId();</span><br><span class="line">    CallBackType cbType = _calltype[msgid];</span><br><span class="line">    <span class="keyword">switch</span> (cbType)</span><br><span class="line">    &#123;</span><br><span class="line">    <span class="keyword">case</span> cbPlayerDelegate:</span><br><span class="line">        <span class="keyword">auto</span> arg = <span class="built_in">std</span>::<span class="built_in">pair</span>&lt;Player*, ProtocolReader&amp;&gt;(player.get(), reader);</span><br><span class="line">        _player_delegate.Call(msgid, arg);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//case ...</span></span><br><span class="line">	<span class="comment">//	break;</span></span><br><span class="line">	</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		<span class="keyword">break</span>; </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>bool MapService::ProcessMsg(UserMessage* msg)</code>中，取出UserMessage中的PlayerPtr指针，将其与ProtocolReader一起打包成std::pair，而事实上，这个pair才是最终的解码器，在这一点上，也可以专门写一个UserMessageReader类来读取UserMessage的Player指针，以及消息数据。后面也会向这方面改进。可以注意到这个pair也是 <code>_player_delegate</code>的DelegateManager模板参数,下面介绍DelegateManager.</p>
<h4 id="DelegateManager"><a href="#DelegateManager" class="headerlink" title="DelegateManager"></a>DelegateManager</h4><p>DelegateManager是一个模板类，它第一个模板参数Decoder，是解码器</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// AutoCall.h</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Decoder, <span class="keyword">size_t</span> Capacity = <span class="number">65535</span>&gt;</span><br><span class="line">class DelegateManager</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">typedef</span> <span class="keyword">typename</span> IDelegate&lt;Decoder&gt;* DelegatePtr;</span><br><span class="line">    DelegatePtr _caller[Capacity];</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    DelegateManager()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">memset</span>(_caller, <span class="number">0</span>, <span class="keyword">sizeof</span>(_caller));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ~DelegateManager()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; Capacity; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (_caller[i] != <span class="literal">nullptr</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">delete</span> _caller[i];</span><br><span class="line">                _caller[i] = <span class="literal">nullptr</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Call</span><span class="params">(<span class="keyword">uint16_t</span> id, Decoder&amp; s)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (_caller[id] != <span class="literal">nullptr</span>)</span><br><span class="line">            <span class="keyword">return</span> _caller[id]-&gt;Call(s);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 内部注册接口</span></span><br><span class="line">    <span class="function">DelegatePtr <span class="title">Regist</span><span class="params">(<span class="keyword">uint16_t</span> id, DelegatePtr dp)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (_caller[id] != <span class="literal">nullptr</span>)</span><br><span class="line">            <span class="keyword">delete</span> _caller[id];</span><br><span class="line"></span><br><span class="line">        _caller[id] = dp;</span><br><span class="line">        <span class="keyword">return</span> dp;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 外部具体注册方式 省略了函数原型不完全匹配时的注册接口 此时参数类型需要显式给出 在调用时隐含转换</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="comment">// 完全匹配 全局函数</span></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> R&gt;</span><br><span class="line">    <span class="function">DelegatePtr <span class="title">Regist</span><span class="params">(<span class="keyword">uint16_t</span> id, R(*f)())</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Regist(id, CreateDelegate0&lt;Decoder&gt;(f));;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">typename</span> T1&gt;</span><br><span class="line">    <span class="function">DelegatePtr <span class="title">Regist</span><span class="params">(<span class="keyword">uint16_t</span> id, R(*f)(T1))</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Regist(id, CreateDelegate1&lt;Decoder, T1&gt;(f));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2&gt;</span><br><span class="line">    <span class="function">DelegatePtr <span class="title">Regist</span><span class="params">(<span class="keyword">uint16_t</span> id, R(*f)(T1, T2))</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Regist(id, CreateDelegate2&lt;Decoder, T1, T2&gt;(f));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 完全匹配 成员函数</span></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">typename</span> ObjT&gt;</span><br><span class="line">    <span class="function">DelegatePtr <span class="title">Regist</span><span class="params">(<span class="keyword">uint16_t</span> id, R(ObjT::*f)(), ObjT* obj)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::function&lt;R()&gt; bindf = <span class="built_in">std</span>::bind(f, obj);</span><br><span class="line">        <span class="keyword">return</span> Regist(id, CreateDelegate0&lt;Decoder&gt;(bindf));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">typename</span> ObjT, <span class="keyword">typename</span> T1&gt;</span><br><span class="line">    <span class="function">DelegatePtr <span class="title">Regist</span><span class="params">(<span class="keyword">uint16_t</span> id, R(ObjT::*f)(T1), ObjT* obj)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::function&lt;R(T1)&gt; bindf = <span class="built_in">std</span>::bind(f, obj, <span class="built_in">std</span>::placeholders::_1);</span><br><span class="line">        <span class="keyword">return</span> Regist(id, CreateDelegate1&lt;Decoder, T1&gt;(bindf));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">typename</span> ObjT, <span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2&gt;</span><br><span class="line">    <span class="function">DelegatePtr <span class="title">Regist</span><span class="params">(<span class="keyword">uint16_t</span> id, R(ObjT::*f)(T1, T2), ObjT* obj)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::function&lt;R(T1, T2)&gt; bindf = <span class="built_in">std</span>::bind(f, obj, <span class="built_in">std</span>::placeholders::_1, <span class="built_in">std</span>::placeholders::_2);</span><br><span class="line">        <span class="keyword">return</span> Regist(id, CreateDelegate2&lt;Decoder, T1, T2&gt;(bindf));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 完全匹配  成员函数  该成员函数的this指针从Decoder中读取</span></span><br><span class="line">    <span class="comment">// 这里必须要使用bind函数 预留出this指针的位置</span></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">typename</span> ObjT&gt;</span><br><span class="line">    <span class="function">DelegatePtr <span class="title">Regist</span><span class="params">(<span class="keyword">uint16_t</span> id, R(ObjT::*f)())</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> bindf = <span class="built_in">std</span>::bind(f, placeholders::_1);</span><br><span class="line">        <span class="keyword">return</span> Regist(id, CreateDelegate1&lt;Decoder, ObjT*&gt;(bindf));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">typename</span> ObjT, <span class="keyword">typename</span> T1&gt;</span><br><span class="line">    <span class="function">DelegatePtr <span class="title">Regist</span><span class="params">(<span class="keyword">uint16_t</span> id, R(ObjT::*f)(T1))</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> bindf = <span class="built_in">std</span>::bind(f, placeholders::_1, placeholders::_2);</span><br><span class="line">        <span class="keyword">return</span> Regist(id, CreateDelegate2&lt;Decoder, ObjT*, T1&gt;(bindf));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">typename</span> ObjT, <span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2&gt;</span><br><span class="line">    <span class="function">DelegatePtr <span class="title">Regist</span><span class="params">(<span class="keyword">uint16_t</span> id, R(ObjT::*f)(T1, T2))</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> bindf = <span class="built_in">std</span>::bind(f, placeholders::_1, placeholders::_2, placeholders::_3);</span><br><span class="line">        <span class="keyword">return</span> Regist(id, CreateDelegate3&lt;Decoder, ObjT*, T1, T2&gt;(bindf));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>DelegateManager管理所有消息ID到消息响应的映射，并提供注册和回调结果。<br>Regist的多种重载识别出需要创建的Delegate对象，由DelegateManager统一管理。</p>
<p>注册主要通过Regist函数的重载和模板推导来进行三种注册方式(实际上不止三种)：全局函数，Service成员函数，Player成员函数。</p>
<p>DelegateManager中，通过Delegate类来代理响应函数。CreateDelegate用于创建响应函数对应的Delegate：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// AutoCall.h</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Decoder, <span class="keyword">typename</span> FuncT&gt;</span><br><span class="line"><span class="function">IDelegate&lt;Decoder&gt;* <span class="title">CreateDelegate0</span><span class="params">(FuncT f)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Delegate0&lt;Decoder, FuncT&gt;(f);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Decoder, <span class="keyword">typename</span> T1, <span class="keyword">typename</span> FuncT&gt;</span><br><span class="line"><span class="function">IDelegate&lt;Decoder&gt;* <span class="title">CreateDelegate1</span><span class="params">(FuncT f)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Delegate1&lt;Decoder, T1, FuncT&gt;(f);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Decoder, <span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2, <span class="keyword">typename</span> FuncT&gt;</span><br><span class="line"><span class="function">IDelegate&lt;Decoder&gt;* <span class="title">CreateDelegate2</span><span class="params">(FuncT f)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Delegate2&lt;Decoder, T1, T2, FuncT&gt;(f);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终的Delegate，需要保存回调函数，并提供调用接口Call:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Decoder&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IDelegate</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">virtual</span> ~IDelegate()&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">bool</span> <span class="title">Call</span><span class="params">(Decoder&amp; s)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/***********************************************************/</span></span><br><span class="line"><span class="comment">/*    默认的Delegate，所有参数都通过Decode全局函数解码得出    */</span></span><br><span class="line"><span class="comment">/***********************************************************/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 0个参数的响应函数</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Decoder, <span class="keyword">typename</span> FuncT&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delegate0</span> :</span> <span class="keyword">public</span> IDelegate &lt; Decoder &gt;</span><br><span class="line">&#123;</span><br><span class="line">    FuncT _func;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Delegate0(FuncT func) :</span><br><span class="line">        _func(func)&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Call</span><span class="params">(Decoder&amp; s)</span> <span class="keyword">override</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        _func();</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1个参数的响应函数</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Decoder, <span class="keyword">typename</span> T1, <span class="keyword">typename</span> FuncT&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delegate1</span> :</span> <span class="keyword">public</span> IDelegate &lt; Decoder &gt;</span><br><span class="line">&#123;</span><br><span class="line">    FuncT _func;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Delegate1(FuncT func) :</span><br><span class="line">        _func(func)&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Call</span><span class="params">(Decoder&amp; s)</span> <span class="keyword">override</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::remove_const &lt; <span class="built_in">std</span>::remove_reference&lt;T1&gt;::type &gt;::type t1;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!Decode(s, t1))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        _func(t1);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2个参数</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Decoder, <span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2, <span class="keyword">typename</span> FuncT&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delegate2</span> :</span> <span class="keyword">public</span> IDelegate &lt; Decoder &gt;</span><br><span class="line">&#123;</span><br><span class="line">    FuncT _func;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Delegate2(FuncT func) :</span><br><span class="line">        _func(func)&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Call</span><span class="params">(Decoder&amp; s)</span> <span class="keyword">override</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::remove_const&lt; <span class="built_in">std</span>::remove_reference&lt;T1&gt;::type &gt;::type t1;</span><br><span class="line">        <span class="built_in">std</span>::remove_const&lt; <span class="built_in">std</span>::remove_reference&lt;T2&gt;::type &gt;::type t2;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!Decode(s, t1))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (!Decode(s, t2))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        _func(t1, t2);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>Delegate保存回调函数，并且提供调用接口，调用接口Call仅有一个参数，就是解码器，也是DelegateManager的模板参数。对于我们的<code>_player_delegate</code>来说，就是<code>pair&lt;Player*, ProtocolReader&amp;&gt;</code>。而上面的Delegate类是默认实现，通过Decode全局函数完成对Decoder的解码，在前面消息编解码中提到过，ProtocolReader实现了这样一个接口。而对于我们的pair，需要特例化，方式一是特例化Decode，方式二是特例化Delegate类。我们采用方法二：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// AutoCallSpecial.h</span></span><br><span class="line"><span class="comment">/*******************************************************************************************************/</span></span><br><span class="line"><span class="comment">/*   特例化Decoder: std::pair&lt;T1, ProtocolReader&amp;&gt; T1是响应函数的第一个参数 其他参数从ProtocolReader中读取  */</span></span><br><span class="line"><span class="comment">/*******************************************************************************************************/</span></span><br><span class="line"><span class="comment">// 带一个参数 T1</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T1, <span class="keyword">typename</span> FuncT&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delegate1</span>&lt;</span><span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T1, ProtocolReader&amp;&gt;, T1, FuncT&gt; : <span class="keyword">public</span> IDelegate &lt; <span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T1, ProtocolReader&amp;&gt; &gt;</span><br><span class="line">&#123;</span><br><span class="line">    FuncT _func;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Delegate1(FuncT f) :</span><br><span class="line">        _func(f)&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Call</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T1, ProtocolReader&amp;&gt;&amp; s)</span> <span class="keyword">override</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        _func(s.first);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 带两个参数  第一个参数为T1 第二个参数从ProtocolReader中读取</span></span><br><span class="line"><span class="keyword">template</span> &lt; <span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2, <span class="keyword">typename</span> FuncT &gt; </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delegate2</span>&lt;</span><span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T1, ProtocolReader&amp;&gt;, T1, T2, FuncT&gt; : <span class="keyword">public</span> IDelegate &lt; <span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T1, ProtocolReader&amp;&gt; &gt; </span><br><span class="line">&#123;</span><br><span class="line">    FuncT _func;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Delegate2(FuncT f) :</span><br><span class="line">        _func(f)&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Call</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T1, ProtocolReader&amp;&gt;&amp; s)</span> <span class="keyword">override</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::remove_const&lt; <span class="built_in">std</span>::remove_reference&lt;T2&gt;::type &gt;::type t2;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!Decode(s.second, t2))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        _func(s.first, t2);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>如果通过一个UserMessageReader来对UserMessage特殊解码的话，便可以直接特例化Decode，更加简便一些。</p>
<p>AutoCallSpecial.h中还对InsideMessage完成了特例化，而消息的回调方式也不仅限于cbPlayerDelegate一种。添加一种自定义的回调方式也比较简单：</p>
<ol>
<li>先自定义一个解码器，将所需参数包含进去，解码器可以是个自定义类，也可以是个容器或其它，将其作为DelegateManager的模板参数</li>
<li>在CallBackType中添加该回调类型</li>
<li>在对应ProcessMsg中，组建自己的解码器，调用<code>DelegateManager::Call</code>函数</li>
<li>DelegateManager会最终调到 <code>Delegate::Call</code> 因此如果有必要，需要对Delegate进行特例化，保证使用你的解码器能正确解码，或者直接使用默认Delegate类中的Decode方式，特例化全局Decode函数。</li>
</ol>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>ngserver</tag>
      </tags>
  </entry>
  <entry>
    <title>NGServer Service框架</title>
    <url>/2014/10/ngserver-service/</url>
    <content><![CDATA[<p>NGServer的核心概念便是服务(Service)，它对逻辑层表现为一个线程，处理各种特定的相关业务。如日志服务(LogService)，数据库服务(DBService)，登录服务(LoginService)。服务之间通过消息进行交互。Service实际上并不是一个独立线程，Service与线程是一种”多对多”的关系。即所有的Service通过ServiceManager来管理，后者维护一个线程池，并将线程池与”服务池”以某种调度方式关联，让线程充分被利用。</p>
<p>下面由下至上对Service框架和运行机制简单阐述：</p>
<span id="more"></span>
<h2 id="Message定义"><a href="#Message定义" class="headerlink" title="Message定义"></a>Message定义</h2><p>NGServer中的消息定义于Message.h中，主要定义了如下几种消息，它们的继承体系如下：</p>
<p> <img src="/assets/image/201410/NGServer_Message_Hierarchy.png" alt="" title="Message继承体系"></p>
<p>Message实现对消息的最高抽象，并不包含任何数据，只提供 GetType纯虚函数接口。用于标识消息类型。</p>
<p>UserMessage是用户发来的消息，内部包含 char* data , size_t len数据成员。</p>
<p>UserMessageT是更具体的用户消息，它是一个模板类，多了一个成员字段 T* user。在本服务器中 T 就是 Player 这样每条消息和包含一个用户指针。这在Service处理以及函数回调的时候非常重要：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F; 客户端的消息</span><br><span class="line">class UserMessage : public Message</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    UserMessage(const char* data, size_t len)</span><br><span class="line">    &#123;</span><br><span class="line">        if (data !&#x3D; nullptr)</span><br><span class="line">        &#123;</span><br><span class="line">            _data &#x3D; new char[len];</span><br><span class="line">            memcpy(_data, data, len);</span><br><span class="line">            _len &#x3D; len;</span><br><span class="line">        &#125;</span><br><span class="line">        else</span><br><span class="line">        &#123;</span><br><span class="line">            _data &#x3D; nullptr;</span><br><span class="line">            _len &#x3D; 0;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    MessageType GetType()  const override</span><br><span class="line">    &#123;</span><br><span class="line">        return MessageType::kUserMessage;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">    char* _data;</span><br><span class="line">    size_t _len;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 附加一个成员T的客户端消息</span><br><span class="line">template&lt; typename T &gt;</span><br><span class="line">class UserMessageT : public UserMessage</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    UserMessageT(const char* data, size_t len, T user) :</span><br><span class="line">        UserMessage(data, len), _user(user)&#123;&#125;</span><br><span class="line"></span><br><span class="line">    inline T GetClient() const &#123; return _user;  &#125;</span><br><span class="line">public:</span><br><span class="line">    T _user;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>对于其他消息放到后面介绍。纵观Message，通过继承完成对多类消息的分类处理，通过模板和继承完成对消息类的扩展，而模板参数则为消息结构(对于InsideMessageT)或其它附加成员(对UserMessageT)。</p>
<h2 id="Service-服务"><a href="#Service-服务" class="headerlink" title="Service 服务"></a>Service 服务</h2><p>整个NGServer核心概念便是Service,Service完成传统游戏服务器一个线程的任务，但它不完全是线程。目前先把它看作是一个线程。在NGServer中，包含如下Service：</p>
<p>LoginService(登录服务) MapService(地图服务)  DBService(数据库服务) LogService(日志服务)</p>
<p>它们的继承体系如下：</p>
<p><img src="/assets/image/201410/NGServer_Service_Hierarchy.png" alt="" title="Service继承体系"></p>
<p>下面简要介绍一下Service每一层实现的一些接口，以及意义：</p>
<p>服务基类Service：</p>
<p>抽象服务的公共接口，如压入消息，处理消息，发送消息等，以及提供一些服务会用到的公共组件，比如定时器，当前时间，处理情况等。<br>下面是一些重要接口：</p>
<p><img src="/assets/image/201410/NGServer_Service_ClassInterface.png" alt="" title="Service类接口"></p>
<h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><p>Service包含一个消息队列MessageQueue,保存待处理的消息。MessageQueue和ByteBuff类似，使用双缓冲。每个Service都包含一个_sid用于唯一标识自己。以下是一些主要接口：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F; 消息投递</span><br><span class="line">Service::PushMsg(Message* msg) &#x2F;&#x2F; 向该Service推送消息，即将消息压入消息队列</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 消息处理</span><br><span class="line">Service::Receive() &#x2F;&#x2F; 处理消息队列中的消息 取出消息队列中的消息并调用ReceiveMsg(msg)处理</span><br><span class="line">Service::ReceiveMsg(Message* msg) &#x2F;&#x2F; 处理单条消息 它取出消息类型，还原消息为本身指针，最后分发到ProcessMsg</span><br><span class="line">Service::ProcessMsg( ... ) &#x2F;&#x2F; 虚函数接口，通过重载处理各类消息</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 消息转发</span><br><span class="line">Service::SendMsg( ... ) &#x2F;&#x2F; 创建InsideMessage 并将消息通过Service::Send()转发到其它服务</span><br><span class="line">Service::Send( int32_t sid, Message* msg ) &#x2F;&#x2F; 静态函数 将msg转发到sid对应的Service</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="GameService"><a href="#GameService" class="headerlink" title="GameService"></a>GameService</h3><p>GameService是游戏业务逻辑处理服务的基类，它主要在Service的基础上加入服务器的具体业务，主要扩展了：</p>
<ul>
<li>关联PlayerManager</li>
</ul>
<p>PlayerManager管理了所有玩家的连接，当GameService::ProcessMsg(UserMessage*)收到客户端断开的消息时，需要通过PlayerManager管理所有连接的玩家。并且在游戏逻辑处理中，有时需要通过用户的连接ID获取用户(此时用户还没有对于服务器的ID，比如还在登录状态)。</p>
<ul>
<li>回调和消息处理机制:</li>
</ul>
<p>消息的注册于回调机制：提供RegistMsg RegistPlayer RegistInside等注册消息回调函数的方法。这些函数的具体处理和实现到后面再解析，这里只需明白可以通过它实现对消息的注册与回调。<br>GameService重写了ProcessMsg(InsideMsg<em> ) 和 ProcessMsg(UserMessage</em> )，在其中完成对消息回调的处理。这样只要调用Service::Receive()，将发生如下流程：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">Service::Receive() -&gt; Service::ReceiveMsg(msg) -&gt; GameService::ProcessMsg(msg) -&gt; 消息回调机制 -&gt; 对应回调函数</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>关联数据库和日志服务：</li>
</ul>
<p>添加LogService，DBService 和 HeroManager成员，并且提供设置它们的接口。方便游戏服务更加专心方便地处理业务逻辑。</p>
<ul>
<li>消息发送和转发：</li>
</ul>
<p>定义SendToDB SendToLog函数，与日志或数据库通信，它们将调用Service::SendMsg将消息推送到日志服务或数据库服务的消息队列。</p>
<p>添加SendToClient 将消息群发给所有管理的用户，将消息体编码成数据流，最后调用Send(data ,len)来发送数据。</p>
<p>Send(char* data, int len)是纯虚函数接口，用于服务具体定义如何将消息发送到所管理的所有用户(群发)。</p>
<h3 id="DBService-LogService"><a href="#DBService-LogService" class="headerlink" title="DBService LogService"></a>DBService LogService</h3><p>相对于GameService，LogService和DBService则要简单许多，它们负责接收GameService发来的消息，并且将记录写入日志或数据库。因此它们只处理InsideMsg消息。并不处理具体的玩家业务逻辑(UserMessage)，它们与数据库和日志系统打交道。但是由于直接派生于Service，因此对比于GameService，它们也需要消息注册与回调机制。另外，由于Service在运行时是单线程的(后面ServiceManager中解释)，因此它的处理是串行的，所以它可以通过记录_last_recv_service_id 来对源Service进行响应。比如响应数据库操作结果等。这样就实现了纯异步的交互。</p>
<h3 id="LoginService-MapService"><a href="#LoginService-MapService" class="headerlink" title="LoginService MapService"></a>LoginService MapService</h3><p>得益于GameService的再次封装，具体业务处理服务就真的只需要关心业务逻辑了，让我们以用户登录为例，看看LoginService需要做些什么：</p>
<ol>
<li>通过RegistPlayer注册用户登录消息响应函数OnPlayerLogin(Player&amp; player, C2S_Login&amp; msg) 并注册数据库响应消息 OnDBHeroLogin(Player&amp; player, D2S_Login&amp; msg) </li>
<li>在OnPlayerLogin中处理用户登录，通过SendToDB SendToLog与数据库交互</li>
<li>在OnDBPlayerLogin中处理数据发来的处理结果</li>
</ol>
<p>Done</p>
<p>注：消息回调机制会自动将UserMessageT中的client提取出来，并且将对应消息体解包，传入回调函数，因此OnDBHeroLogin可以获取到Player的引用，而UserMessageT中的client初始化是在消息构造时传入的，这中消息编解码中详解。对于其他类型消息处理，比如CycleMessage  LoginService需要自己重写ProcessMsg(CycleMessage*)</p>
<h2 id="ServiceManager"><a href="#ServiceManager" class="headerlink" title="ServiceManager"></a>ServiceManager</h2><p>ServiceManager是整个NGServer的消息集散中心，负责管理所有Service和Message。它将Service和它的_sid对应起来。事实上Service::Send就是通过ServiceManager::Send来转发消息的。</p>
<p>前面提到，Service对于业务逻辑层来说，可以看作一个线程。而它实际上并不是个线程，ServiceManager中提供一个线程池，由它们来将所有的Service”跑起来”，此时的Service相当于一个特殊的”消息队列”，只不过它提供了处理这些消息的接口，也就是Receive():</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F; 取出消息队列中的消息  调用ReceiveMsg处理消息</span><br><span class="line">&#x2F;&#x2F; 如果处理完之后 队列中还有剩余消息 则返回true 否则返回false</span><br><span class="line">bool Service::Receive()</span><br><span class="line">&#123;</span><br><span class="line">#ifdef _DEBUG</span><br><span class="line">    if (!_recvcheck.TryLock())</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt; &quot; # service Receive is not runing in single thread ! &quot; &lt;&lt; std::endl;</span><br><span class="line">        assert(0);</span><br><span class="line">    &#125;</span><br><span class="line">#endif</span><br><span class="line">    std::vector&lt;Message*&gt;* msgs &#x3D; _msgqueue.PopAll();</span><br><span class="line">    for(auto msg : *msgs)</span><br><span class="line">	&#123;</span><br><span class="line">        std::unique_ptr&lt;Message&gt; autodel(msg);</span><br><span class="line">        if (!ReceiveMsg(msg))</span><br><span class="line">        &#123;</span><br><span class="line">            autodel.release();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    msgs-&gt;clear();</span><br><span class="line"></span><br><span class="line">    if (_msgqueue.Size())</span><br><span class="line">        return true;</span><br><span class="line"></span><br><span class="line">#ifdef _DEBUG</span><br><span class="line">    _recvcheck.UnLock();</span><br><span class="line">#endif</span><br><span class="line"></span><br><span class="line">    _readylock.UnLock();</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>该接口确保单线程运行(Service内部MessageQueue双缓冲只能单线程处理数据)，取出消息队列中的消息，调用ReceiveMsg进行处理，后者通过Message::GetType()还原消息类型，调用ProcessMsg重载，然后GameService::ProcessMsg中完成对消息的回调…..</p>
<p>然而Receive()仅处理Service消息队列中已有的消息，并没有让Service一直”run”起来，这也是Service比直接用线程更为高效的地方：充分利用线程。只有当Service中有消息时，Service::Receive才会被调用，处理完成之后，线程就”离开”，去跑别的Service。而要做到这点，有两个要点：</p>
<ol>
<li>保证Service::Receive()同一时刻只被一个线程运行</li>
<li>捕捉Service中MessageQueue的状态变化，在MessageQueue中有消息时，在1的前提下，能够第一时间让Service分配到线程。</li>
</ol>
<p>为了做到以上两点，ServiceManager中维护一个Service队列ServiceQueue _ready_services，该队列线程安全。它保存那些消息队列不为空的Service，也就是”就绪”的Service。_ready_services可以看作一个特殊的”消息队列”：它们维护一组消息，并提供这些消息的处理接口。而ServiceManager中的线程池，则在处理这个特殊的”消息队列”(通过调用Service::Receive())。一个Service是否”就绪”，可以用一个锁_readylock来实现，_readylock锁定表示该Service消息队列不为空，已经就绪，否则表示该Service处于”空闲”状态。_readylock可能会在两个地方改变状态：</p>
<ol>
<li>Service::PushMsg()中，可能使消息队列由空变为不空。这可以通过 _readlock.TryLock()来检测并改变该状态。</li>
<li>Service::Receive()中，处理完消息队列中的消息后，如果消息队列为空(由于双缓冲机制，在处理读缓冲的数据时，可能有新的数据到达写缓冲)，则释放_readylock：_readylock.UnLock();否则_readylock仍然为Lock状态。</li>
</ol>
<p>接下来就是对Service _readylock的监测，如果_readlock为Lock状态，则将其加入到”就绪服务”队列_ready_services中。最好的办法当然是在状态可能改变的地方：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F; 发送消息到指定Service msg的管理权将转交 调用者不需再关心msg的释放问题</span><br><span class="line">bool ServiceManager::Send(int32_t sid, Message* msg)</span><br><span class="line">&#123;</span><br><span class="line">    if (sid &lt; kMaxServiceNum)</span><br><span class="line">    &#123;</span><br><span class="line">        ServicePtr sptr &#x3D; _serviceMap[sid];</span><br><span class="line">        if (sptr !&#x3D; nullptr)</span><br><span class="line">        &#123;</span><br><span class="line">            if (sptr-&gt;PushMsg(msg))</span><br><span class="line">            &#123;</span><br><span class="line">				&#x2F;&#x2F; 将该服务加入到就绪服务队列 该队列线程安全</span><br><span class="line">                PushService(sptr);</span><br><span class="line">            &#125;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    delete msg;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; ServiceManager线程入口，通过该入口让所有Service Run起来</span><br><span class="line">&#x2F;&#x2F; 该函数不断从就绪服务队列中取出服务，并执行其Receive入口处理Service中的消息</span><br><span class="line">void ServiceManager::ExecThread()</span><br><span class="line">&#123;</span><br><span class="line">    try</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; 不断执行_ready_services中的Service</span><br><span class="line">        while (_runing)</span><br><span class="line">        &#123;</span><br><span class="line">            ServicePtr sptr &#x3D; _ready_services.Pop();</span><br><span class="line">            if (sptr !&#x3D; nullptr)</span><br><span class="line">            &#123;</span><br><span class="line">                if (sptr-&gt;Receive()) </span><br><span class="line">                &#123;&#x2F;&#x2F; 如果执行完成后 还有未处理消息</span><br><span class="line">                    &#x2F;&#x2F; 重新投递到待执行队列</span><br><span class="line">                    PushService(sptr);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            else</span><br><span class="line">            &#123;</span><br><span class="line">                std::this_thread::sleep_for(std::chrono::milliseconds(1));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    catch (std::runtime_error&amp; err)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt; &quot;runing thread catch one exception : &quot; &lt;&lt; err.what() &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>ExecThread函数，就是整个Service，乃至整个框架的发动机，通过让多个thread执行该入口，即可充分利用多线程，均衡处理所有Service中的消息:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F; 开始运行</span><br><span class="line">&#x2F;&#x2F; threadNum：指定运行的线程数量</span><br><span class="line">&#x2F;&#x2F; 如果ServiceManager已经在运行中 则在原有线程基础上再新开threadNum个线程</span><br><span class="line">void ServiceManager::Start(int threadNum)</span><br><span class="line">&#123;</span><br><span class="line">    AutoLocker aLock(&amp;_locker);</span><br><span class="line">    if (_runing &#x3D;&#x3D; false)</span><br><span class="line">    &#123;   &#x2F;&#x2F; ServiceManager需要一个TimerThread用于管理所有定时消息</span><br><span class="line">        _runing &#x3D; true;</span><br><span class="line">        std::thread* t &#x3D; new std::thread(TimerThread);</span><br><span class="line">        _threads.push_back(t);</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    for (int i &#x3D; 0; i &lt; threadNum; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        std::thread* t &#x3D; new std::thread(ExecThread);</span><br><span class="line">        _threads.push_back(t);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="整个流程"><a href="#整个流程" class="headerlink" title="整个流程"></a>整个流程</h2><h3 id="一-框架消息处理流程"><a href="#一-框架消息处理流程" class="headerlink" title="一. 框架消息处理流程"></a>一. 框架消息处理流程</h3><ul>
<li>ServiceManager::Start(int threadNum) 指定线程池线程数 开始运行所有Service::Receive()</li>
<li>Service::Receive()从双缓冲消息队列中取出已有消息，逐个调用Service::ReceiveMsg(Message* msg)处理单条消息</li>
<li>Service::ReceiveMsg(Message* msg)通过Message::GetType()得到每条消息类型，并且通过std::dynamic_cast将msg转换成对应类型nmsg，最后调用ProcessMsg(nmsg)完成分发</li>
<li>基类Service::ProcessMsg定义了所有消息的处理接口：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F; 接口 处理各类消息 返回true代表消息将由框架删除 返回false自行管理该消息</span><br><span class="line">virtual bool ProcessMsg(Message* msg);</span><br><span class="line">virtual bool ProcessMsg(TimerMessage* msg);</span><br><span class="line">virtual bool ProcessMsg(UserMessage* msg);</span><br><span class="line">virtual void ProcessMsg(CycleMessage* msg);</span><br><span class="line">virtual bool ProcessMsg(InsideMessage* msg);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>如果调度的Service本身重写了对应ProcessMsg,那么将调用重写的ProcessMsg，否则将使用基类Service的ProcessMsg,后者只是忽略消息，不对消息做处理。对于GameService，它重写了ProcessMsg:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">bool ProcessMsg(UserMessage* msg) override;</span><br><span class="line">bool ProcessMsg(InsideMessage* msg) override;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>并完成了对消息的解码和响应函数的回调，因此对于LoginService和MapService，它们只需调用Regist注册消息响应函数后，ProcessMsg会将消息解码并回调到对应函数。ProcessMsg中的回调机制将逻辑由框架导出到了业务层。</p>
<ul>
<li><h3 id="二-服务的消息推送流程"><a href="#二-服务的消息推送流程" class="headerlink" title="二. 服务的消息推送流程"></a>二. 服务的消息推送流程</h3></li>
</ul>
<p>前面说的是消息的处理流程，下面从消息的产生开始讨论消息的生命周期和传递流程。消息一共有四种：UserMessage(T) InsideMessage(T) CycleMessag  TimerMessage，后两种定时器相关的消息由ServiceManager统一管理，因此这里不作阐述。</p>
<p><strong>UserMessage</strong>是来自客户端的消息，在前面的博客中，讲到了网络层到框架的接口函数：<code>Player::Decode(const char* data, size_t len)</code>，网络层将收到的数据交给该函数(当len==0时，表示客户端断开连接)：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">int32_t Player::Decode(const char* data, size_t len)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; 客户端断线</span><br><span class="line">    if (data &#x3D;&#x3D; nullptr || len &#x3D;&#x3D; 0)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; 通知业务逻辑层 处理下线逻辑</span><br><span class="line">        Message* msg &#x3D; new UserMessageT&lt;PlayerPtr&gt;(data, len, shared_from_this());</span><br><span class="line">        ServiceManager::Send(_sid, msg);</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 消息的解包</span><br><span class="line">    const char* buff &#x3D; data;</span><br><span class="line">    size_t remainLen &#x3D; len;</span><br><span class="line">    static const uint16_t headLen &#x3D; ProtocolStream::kHeadLen + ProtocolStream::kMsgIdLen;</span><br><span class="line">    while (remainLen &gt; headLen)</span><br><span class="line">    &#123;</span><br><span class="line">        int32_t msgLen &#x3D; std::max(headLen, *((uint16_t*)buff));</span><br><span class="line">        if (remainLen &lt; msgLen)</span><br><span class="line">        &#123;</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 发送到Service框架层</span><br><span class="line">        Message* msg &#x3D; new UserMessageT&lt;PlayerPtr&gt;(buff, msgLen, shared_from_this());</span><br><span class="line">        if (!ServiceManager::Send(_sid, msg))</span><br><span class="line">        &#123;</span><br><span class="line">            &#x2F;&#x2F; 服务器主动断线</span><br><span class="line">            return -1;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        remainLen -&#x3D; msgLen;</span><br><span class="line">        buff +&#x3D; msgLen;</span><br><span class="line">    &#125;</span><br><span class="line">    return remainLen;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Player::Decode简单解决粘包问题，当客户端有数据来临(len!=0)或断开连接时(len==0)，均创建UserMessageT并传入Player指针，通过ServiceManager::Send发送到Service框架。这里传入的Player指针很重要，框架的消息回调机制就是通过这个指针来将消息关联到Player的。在PlayerManager::OnConnect()中，有新用户连接时，创建Player的同时为Player指定了一个所属服务，这个服务的sid保存在Player中。Player的所有消息均发往其所属服务。对于刚连接的Player，该服务自然是LoginService。当Player登录成功时，将所属服务特换为MapService，之后所有的业务逻辑都在MapService上面跑。</p>
<p><strong>InsideMessage</strong>是服务之间的内部消息，它在Service之间转发消息时产生，通过Service::SendMsg创建内部消息，最后通过Service::Send发送。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F; 发送只包含消息ID的内部消息</span><br><span class="line">bool SendMsg(int32_t sid, int64_t sessionid, int16_t msgid)</span><br><span class="line">&#123;</span><br><span class="line">    InsideMessage* msg &#x3D; new InsideMessage();</span><br><span class="line">    msg-&gt;_dessid &#x3D; sid;</span><br><span class="line">    msg-&gt;_srcsid &#x3D; GetSid();</span><br><span class="line">    msg-&gt;_sessionid &#x3D; sessionid;</span><br><span class="line">    msg-&gt;_msgid &#x3D; msgid;</span><br><span class="line">    Service::Send(sid, msg);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 发送包含消息数据的内部消息</span><br><span class="line">template &lt; typename MsgT &gt; </span><br><span class="line">bool SendMsg(int32_t sid, int64_t sessionid, int16_t msgid, MsgT&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">    InsideMessageT* msg &#x3D; new InsideMessageT&lt;MsgT&gt;();</span><br><span class="line">    msg-&gt;_dessid &#x3D; sid;</span><br><span class="line">    msg-&gt;_srcsid &#x3D; GetSid();</span><br><span class="line">    msg-&gt;_sessionid &#x3D; sessionid;</span><br><span class="line">    msg-&gt;_msgid &#x3D; msgid;</span><br><span class="line">    msg-&gt;_data &#x3D; t;</span><br><span class="line">    Service::Send(sid, msg);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>UserMessage和InsideMessage在创建之后，都会交给ServiceManager::Send，之后便不用关心其生命周期。Message由框架管理。在Service处理这些消息时：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F; 取出消息队列中的消息  调用ReceiveMsg处理消息</span><br><span class="line">&#x2F;&#x2F; 如果处理完之后 队列中还有剩余消息 则返回true 否则返回false</span><br><span class="line">bool Service::Receive()</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F;....</span><br><span class="line"></span><br><span class="line">    std::vector&lt;Message*&gt;* msgs &#x3D; _msgqueue.PopAll();</span><br><span class="line">    for (auto msg : *msgs)</span><br><span class="line">    &#123;</span><br><span class="line">		&#x2F;&#x2F; 确保消息处理完成后自动删除</span><br><span class="line">        std::unique_ptr&lt;Message&gt; autodel(msg);</span><br><span class="line">        if (!ReceiveMsg(msg))</span><br><span class="line">        &#123;</span><br><span class="line">			&#x2F;&#x2F; ReceiveMsg返回false 取消自动删除</span><br><span class="line">            autodel.release();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    msgs-&gt;clear();</span><br><span class="line"></span><br><span class="line">    if (_msgqueue.Size())</span><br><span class="line">        return true;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; ...</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>ReceiveMsg处理完消息后，返回true，消息将由框架自动删除，否则消息将由逻辑自行保管。通常不自动删除的消息是帧消息，该消息始终只有一条，处理完成之后，调整下次触发时间，再将其加入到定时器队列。</p>
<h3 id="三-完整的消息请求与响应"><a href="#三-完整的消息请求与响应" class="headerlink" title="三. 完整的消息请求与响应"></a>三. 完整的消息请求与响应</h3><h4 id="1-用户连接"><a href="#1-用户连接" class="headerlink" title="1.用户连接"></a>1.用户连接</h4><p>PlayerManager::OnConnect 创建并关联Player和Session 并且为Player指定所属登录服务的_sid -&gt; Session::StartRecv 开始接收数据</p>
<h4 id="2-用户请求与响应"><a href="#2-用户请求与响应" class="headerlink" title="2.用户请求与响应"></a>2.用户请求与响应</h4><p>推送请求：Session::ReadComplete 数据到达 -&gt; Player::Decode 解包 -&gt; ServiceManager::Send 推送消息到指定服务 -&gt; Service::PushMsg 此时消息已经在服务的消息队列</p>
<p>处理和响应请求：Service::Receive 取出消息 -&gt; Service::ReceiveMsg 还原消息 -&gt; Service::ProcessMsg 重载各类消息的处理方式 GameService和DBService的ProcessMsg中，完成对消息的解码和回调 -&gt; 消息响应函数 -&gt; Player::SendMsg 发送响应 -&gt; Session::SendMsg 完成对消息的编码 -&gt; Session::SendAsync 发送消息数据 </p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>ngserver</tag>
      </tags>
  </entry>
  <entry>
    <title>NGServer 加入PlayerSession</title>
    <url>/2014/12/ngserver-playersession/</url>
    <content><![CDATA[<h2 id="PlayerSession类"><a href="#PlayerSession类" class="headerlink" title="PlayerSession类"></a>PlayerSession类</h2><p>在之前的网络底层设计中，Player和Session之间通过组合实现弱关联，但仍然有个诟病：Player类和Session类在网络连接到来时一并创建了。这样后面在做断线重连的时候，会有两个Player。而事实上LoginService只管登录认证，登录认证的时候并不需要创建Player类，因此可以延迟Player的创建，将其放在MapService中。而这之前LoginService的登录认证也需要用户的一些基本信息。基于这些，实现了PlayerSession类：</p>
<span id="more"></span>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class PlayerSession : public Session</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    PlayerSession(const std::shared_ptr&lt;Socket&gt; socket, int32_t conn_id);</span><br><span class="line">    ~PlayerSession();</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; .....</span><br><span class="line">	</span><br><span class="line">    &#x2F;&#x2F; 网络数据解码</span><br><span class="line">    int32_t Decode(const char* data, int32_t len);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 发送消息</span><br><span class="line">    template&lt;typename MsgT&gt;</span><br><span class="line">    bool SendMsg(MsgId msgid, MsgT&amp; t);</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; ....</span><br><span class="line">	</span><br><span class="line">private:</span><br><span class="line">    int32_t _sid &#x3D; 0;       &#x2F;&#x2F; 所属服务ID</span><br><span class="line">    std::shared_ptr&lt;Player&gt; _playerToken; &#x2F;&#x2F; 玩家指针</span><br><span class="line">    SessionState _state &#x3D; kSessionState_None;   &#x2F;&#x2F; 会话状态</span><br><span class="line">    std::string _owner;       &#x2F;&#x2F; 登录用户名</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>解码将在PlayerSession而不是Player中完成，在登录完成之前，LoginService通过PlayerSession与玩家交互，在登录验证完成之后，LoginService将玩家登录信息和PlayerSession一并发送到MapService，MapService完成对Player的创建，并于PlayerSession建立关联：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void MapService::OnPlayerLogin(SS_PlayerLogin&amp; msg)</span><br><span class="line">&#123;</span><br><span class="line">    PlayerSessionPtr session &#x3D; msg.session;</span><br><span class="line">    if (session &#x3D;&#x3D; nullptr)</span><br><span class="line">        return;</span><br><span class="line"></span><br><span class="line">    int64_t playerid &#x3D; msg.login_info.playerid;</span><br><span class="line">    &#x2F;&#x2F; 创建 Player 并与PlayerSession关联</span><br><span class="line">    PlayerPtr player &#x3D; std::make_shared&lt;Player&gt;(playerid, session);</span><br><span class="line">    player-&gt;SetMapService(dynamic_pointer_cast&lt;MapService&gt;(shared_from_this()));</span><br><span class="line">    session-&gt;SetPlayerToken(player);</span><br><span class="line">    session-&gt;SetSid(GetSid()); </span><br><span class="line">    </span><br><span class="line">    AddPlayer(player);</span><br><span class="line">    </span><br><span class="line">    &#x2F;&#x2F; 向数据库加载玩家信息</span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">    S2D_LoadPlayer loadmsg;</span><br><span class="line">    loadmsg.playerid &#x3D; playerid;</span><br><span class="line">    SendToDB(playerid, kS2D_LoadPlayer, loadmsg);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>之后客户端业务逻辑上与MapService交互，在GameService::Process(UserMessage*)解码时提取出_playerToken，即可通过Player类完成业务逻辑。</p>
<p>加入了PlayerSession之后，消息注册回调机制也更复杂了一些，为了方便管理，这些注册和回调均放在GameService中。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>ngserver</tag>
      </tags>
  </entry>
  <entry>
    <title>lua 与 C 交互</title>
    <url>/2014/12/lua-C/</url>
    <content><![CDATA[<p>lua和C交互的核心就是lua栈，lua和C的所有数据交互都是通过lua栈来完成的。</p>
<h3 id="一-C调用lua"><a href="#一-C调用lua" class="headerlink" title="一. C调用lua"></a>一. C调用lua</h3><p>C调用lua很简单，通常C以lua作为配置脚本，在运行时读取脚本数据，主要步骤：</p>
<ol>
<li>加载脚本    luaL_loadfile </li>
<li>运行脚本  lua_pcall </li>
<li>获取数据  lua_getglobal …. </li>
<li>使用数据  lua_tostring lua_pcall …</li>
</ol>
<h3 id="二-在lua脚本中调用C："><a href="#二-在lua脚本中调用C：" class="headerlink" title="二. 在lua脚本中调用C："></a>二. 在lua脚本中调用C：</h3><p>在C程序中，使用lua作为脚本，但是要在运行脚本时，访问C中定义的一些变量或函数。</p>
<ol>
<li>将C变量或函数(遵从指定函数原型，见下面三 Step 1)push到lua栈中</li>
<li>通过lua_setglobal为当前lua栈顶的函数或变量命名，这样在lua中可通过该名字完成对变量或函数的使用</li>
<li>之后可在加载的lua脚本中使用C变量或函数</li>
</ol>
<span id="more"></span>
<h3 id="三-将C函数封装为一个库，为lua所用"><a href="#三-将C函数封装为一个库，为lua所用" class="headerlink" title="三. 将C函数封装为一个库，为lua所用"></a>三. 将C函数封装为一个库，为lua所用</h3><p>将C函数编译为动态库文件，这样可以在lua主程序中，加载这个库文件，并使用其中的C函数。</p>
<p><strong>Step 1</strong>. 在mylib.c中定义给lua调用的C函数 函数原型为： int (lua_State*)<br>如：</p>
<pre><code>static int c_addsub(lua_State* L)
&#123;
    double a = luaL_checknumber(L,1); // 获取参数1
    double b = luaL_checknumber(L,2); // 获取参数2
    lua_pushnumber(L, a+b); // 压入返回值1
    lua_pushnumber(L, a-b); // 压入返回值2
    return 2; // 两个返回值
&#125;
</code></pre><p><strong>Step 2</strong>. 在mylib.c中定义一个注册函数，用于lua在加载C动态库时，调用该函数完成对库中所导出的C函数的注册。<br>如：</p>
<pre><code>// 将C模块中要导出的C函数放入到luaL_Reg结构体数组内
static const struct luaL_Reg l[] = &#123;
    &#123;&quot;addsub&quot;, c_addsub&#125;,
    &#123;NULL, NULL&#125; // 以NULL标识结束
&#125;;

// 该函数在导入C库时调用 完成对库中导出的函数的注册
// 必须是non-static
int luaopen_mylib(lua_State* L)
&#123;
    // 完成实际的注册工作
    // 注册方式一: luaL_openlib(lua_State* L, const char* name, const luaL_Reg* l, int nup)
    //   L : lua_State
    // name: 表明该C库被加载后，所导出的函数位于哪一个全局table之下 
    //       这里是&quot;clib&quot; 那么之后lua中通过clib.addsub完成对C函数的调用
    //   l : 要导出的函数的lua_Reg结构体数组
    //         luaL_openlib自动将该数组内的name-function对注册并填充到第二参数指定的table下
    // nup : upvalue的个数，如果不为0，则注册的所有函数都共享这些upvalues
    luaL_openlib(L, &quot;clib&quot;, l, 0);

    // 注册方式二: luaL_newlibtable + luaL_setfuncs (等价于lua_newlib)
    // luaL_newlibtable(L, l);
    // luaL_setfuncs(L, l, 0);
    // 前两句等价于：
    // luaL_newlib(L, l);

    // 将包含name-cfunction键值对的table返回给lua
    return 1;
&#125;
</code></pre><p>注意上面方式一和方式二的主要区别：前者(luaL_openlib)为name-cfunction对在lua中注册了一个名字(“clib”)。而后者(luaL_newlib)没有，它只是将这个table返回给了lua。可在lua层通过赋值为其命名。自然，通过 <code>luaL_openlib</code> 和 <code>return 1</code>可以将name-cfuncton对注册到两个lua table下。</p>
<p>关于luaL_openlib函数，在官方文档中没有找到它，lua5.2文档中给出的是luaL_newlibtable和lua_setfuncs等新API用以替代以前的luaL_register，而事实上根据前面lua和C交互的基本元素，我们可以自己实现一个类似lua_openlib的注册函数：</p>
<pre><code>int luaopen_mylib(lua_State* L)
&#123;
    // luaL_openlib(L, &quot;clib&quot;, clib, 0);
    int i = 0;
    lua_newtable(L); // push a new table
    while(clib[i].name != NULL)
    &#123;
        lua_pushstring(L, clib[i].name); // push name
        lua_pushcfunction(L, clib[i].func); // push function
        lua_settable(L, -3); // table[name] = function
        ++i;
    &#125;
    lua_setglobal(L, &quot;clib&quot;); // set table name
    return 1;        
&#125;
</code></pre><p>因此实际上将C作为动态库和前面二中的交互核心是一样的，只是将C作为动态库时，需要提供一个”入口函数”，用以在加载该动态库后执行，完成对库中所有导出函数的注册。</p>
<p><strong>Step 3</strong>. 将相关C文件编译成动态链接库:</p>
<p>需要说明的是Mac OS X需要使用gcc将mylualib.c编译为动态库，编译选项不同于Linux。<br>具体编译命令（粗体部分不同于Linux，如果不使用这些选项，liblua将会被编译到so文件中并引起“multiple lua vms detected”错误， bundle是Mac使用的文件格式）：</p>
<p>gcc -c mylib.c</p>
<p>gcc -O2 <strong>-bundle -undefined dynamic_lookup</strong> -o mylib.so mylib.o</p>
<p><strong>Step 4</strong>. 在lua中加载C动态库</p>
<p>方式一 : 使用 loadlib</p>
<pre><code>--加载C动态库 并将luaopen_mylib函数 导出到mylib变量中
mylib = loadlib(&quot;./mylib.so&quot;, &quot;luaopen_mylib&quot;) 

--调用mylib() 将执行lua_openmylib函数 完成对C动态库中所有导出函数的注册
--将C中返回的name-cfunction table赋给clualib变量
clualib = mylib()

--通过clualib完成C函数的调用
sum, diff = clualib.addsub(5.6, 2.4);

--针对于Step 2中的注册方式一，还可以通过luaL_openlib中传入的clib来使用C函数 
sum, diff = clib.addsub(5.6, 2.4)
</code></pre><p>loadlib会读取动态库文件的符号表，得到luaopen_mylib函数的实现，并导出到mylib变量中，通过执行mylib()，即可执行luaopen_mylib完成对整个C库导出函数的注册。luaopen_mylib将注册完成后的name-cfunction对返回给lua，lua可以通过<code>clualib = mylib()</code>为这个注册完成之后的table命名。之后可通过clualib调用C函数。</p>
<p>另外，luaL_openlib函数可以直接导出name-cfunction对并为其在lua中注册一个名字，因此通过clib也可以完成对C函数的调用。</p>
<p>方式二 : 使用 require</p>
<pre><code>clualib = require(&quot;mylib&quot;)

sum,diff = clualib.addsub(5.6, 2.4)

-- 对于luaL_openlib完成的注册，仍然可以通过clib来访问C函数
sum, diff = clib.addsub(5.6, 2.4)
</code></pre><p>require的工作原理：</p>
<p>当你在脚本中使用require加载一个模块xxx的时候，首先它会在Lua的环境路径中寻找以xxx命名的DLL，如果找到了，则会在这个DLL中寻找luaopen_xxx的函数用于加载模块。我们只需要将自己需要导出给Lua调用的C内容通过这个函数导出就可以了。</p>
<p>比如我们通过require(“mylib”)来导入模块，lua找到mylib.so库文件，并查找luaopen_mylib函数，然后调用该函数。因此我们需要注意两点：</p>
<ol>
<li>设置好库文件路径 确保库文件存在 </li>
<li>确保库定义了luaopen_mylib函数(而不像前一个方法一样，可以通过loadlib函数手动指定入口函数)</li>
</ol>
<p>require的优势在于自动化，而loadlib方式则更加灵活，loadlib可以指定注册函数名字，注册函数可以无需按照luaopen_xxx格式命名。</p>
<p>在一些库中，使用require(“mylib.core”)之类的格式来导入C模块，没有任何库文件时，通过require的报错可以看到其查找路径和规则：</p>
<pre><code>lua: testmylib.lua:1: module &#39;mylib.core&#39; not found:
no field package.preload[&#39;mylib.core&#39;]
no file &#39;/usr/local/share/lua/5.2/mylib/core.lua&#39;
no file &#39;/usr/local/share/lua/5.2/mylib/core/init.lua&#39;
no file &#39;/usr/local/lib/lua/5.2/mylib/core.lua&#39;
no file &#39;/usr/local/lib/lua/5.2/mylib/core/init.lua&#39;
no file &#39;./mylib/core.lua&#39;
no file &#39;/usr/local/lib/lua/5.2/mylib/core.so&#39;
no file &#39;/usr/local/lib/lua/5.2/loadall.so&#39;
no file &#39;./mylib/core.so&#39;
no file &#39;/usr/local/lib/lua/5.2/mylib.so&#39;
no file &#39;/usr/local/lib/lua/5.2/loadall.so&#39;
no file &#39;./mylib.so&#39;
</code></pre><p>先查找 PATH/mylib/core.so 如果没有，则直接使用 PATH/mylib.so。而C中的导出函数命名则必须为: luaopen_mylib_core(lua_State* L)。 </p>
]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title>shared_ptr的引用链</title>
    <url>/2014/12/shared_ptr-reference/</url>
    <content><![CDATA[<p>总结下几个使用shared_ptr需要注意的问题:</p>
<h3 id="一-相互引用链"><a href="#一-相互引用链" class="headerlink" title="一. 相互引用链"></a>一. 相互引用链</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class C;</span><br><span class="line">class B : public std::enable_shared_from_this&lt;B&gt;</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    ~B()&#123; cout &lt;&lt; &quot;~B&quot; &lt;&lt; endl; &#125;</span><br><span class="line">    void SetPC(std::shared_ptr&lt;C&gt;&amp; pc)&#123; _pc &#x3D; pc; &#125;    </span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">    std::shared_ptr&lt;C&gt; _pc;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class C : public std::enable_shared_from_this&lt;C&gt;</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    ~C()&#123; cout &lt;&lt; &quot;~C&quot; &lt;&lt; endl; &#125;</span><br><span class="line">    void SetPB(std::shared_ptr&lt;B&gt;&amp; pb)&#123; _pb &#x3D; pb; &#125;</span><br><span class="line">    </span><br><span class="line">private:</span><br><span class="line">    std::shared_ptr&lt;B&gt; _pb;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    std::shared_ptr&lt;C&gt; pc &#x3D; std::make_shared&lt;C&gt;();</span><br><span class="line">    std::shared_ptr&lt;B&gt; pb &#x3D; std::make_shared&lt;B&gt;();</span><br><span class="line">    pc-&gt;SetPB(pb);</span><br><span class="line">    pb-&gt;SetPC(pc);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码中，B和C均不能正确析构，正确的做法是，在B和C的释放函数，如Close中，将其包含的shared_ptr置空。这样才能解开引用链。</p>
<span id="more"></span>
<h3 id="二-自引用"><a href="#二-自引用" class="headerlink" title="二. 自引用"></a>二. 自引用</h3><p>还有个比较有意思的例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class C : public std::enable_shared_from_this &lt; C &gt;</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">    ~C()</span><br><span class="line">    &#123;</span><br><span class="line">        std::cout &lt;&lt; &quot;~C&quot; &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int32_t Decode(const char* data, size_t)</span><br><span class="line">    &#123;</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line">    void SetDecoder(std::function&lt;int32_t(const char*, size_t)&gt; decoder)</span><br><span class="line">    &#123;</span><br><span class="line">        _decoder &#x3D; decoder;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">    std::function&lt;int32_t(const char*, size_t)&gt; _decoder;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    &#123;</span><br><span class="line">        std::shared_ptr&lt;C&gt; pc &#x3D; std::make_shared&lt;C&gt;();</span><br><span class="line">        auto decoder &#x3D; std::bind(&amp;C::Decode, pc, std::placeholders::_1, std::placeholders::_2);</span><br><span class="line">        pc-&gt;SetDecoder(decoder);</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F; C不能正确析构 因为存在自引用</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的C类包含了一个function，该function通过std::bind引用了一个std::shared_ptr<C>，所以_decoder其实包含了一个对shared_ptr<C>的引用。导致C自引用了自身，不能正确析构。需要在C的Close之类的执行关闭函数中，将_decoder=nullptr，以解开这种自引用。</p>
<h3 id="三-类中传递"><a href="#三-类中传递" class="headerlink" title="三. 类中传递"></a>三. 类中传递</h3><p>下面的例子中有个更为隐蔽的问题：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Session : public std::enable_shared_from_this &lt; Session &gt;</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">    ~Session()</span><br><span class="line">    &#123;</span><br><span class="line">        std::cout &lt;&lt; &quot;~C&quot; &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void Start()</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; 进行一些异步调用</span><br><span class="line">        &#x2F;&#x2F; 如 _socket.async_connect(..., boost::bind(&amp;Session::ConnectCompleted, this), boost::asio::placeholders::error, ...)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void ConnectCompleted(const boost::system::err_code&amp; err)</span><br><span class="line">    &#123;</span><br><span class="line">		if(err)</span><br><span class="line">			return; </span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; ... 进行处理</span><br><span class="line">        &#x2F;&#x2F; 如 _socket.async_read(..., boost::bind(&amp;Session::ReadCompleted, this), boost::asio::placeholders::error, ...)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	void Session::ReadComplete(const boost::system::error_code&amp; err, size_t bytes_transferred)</span><br><span class="line">	&#123;</span><br><span class="line">	    if (err || bytes_transferred &#x3D;&#x3D; 0)</span><br><span class="line">	    &#123;</span><br><span class="line">	        DisConnect();</span><br><span class="line">	        return;</span><br><span class="line">	    &#125;</span><br><span class="line">		&#x2F;&#x2F; 处理数据 继续读</span><br><span class="line">		&#x2F;&#x2F; ProcessData();</span><br><span class="line">		&#x2F;&#x2F; _socket.async_read(...)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">    std::function&lt;int32_t(const char*, size_t)&gt; _decoder;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    &#123;</span><br><span class="line">        std::shared_ptr&lt;Session&gt; pc &#x3D; std::make_shared&lt;Session&gt;();</span><br><span class="line">        pc-&gt;Start();</span><br><span class="line">    &#125;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面Session，在调用Start时，调用了异步函数，并回调自身，如果在回调函数的 boost::bind 中 传入的是shared_from_this()，那么并无问题，shared_ptr将被一直传递下去，在网络处理正常时，Session将正常运行，即使main函数中已经没有它的引用，但是它靠boost::bind”活了下来”，boost::bind会保存传给它的shared_ptr，在调用函数时传入。当网络遇到错误时，函数直接返回。此时不再有新的bind为其”续命”。Session将被析构。</p>
<p>而真正的问题在于，如果在整个bind链中，直接传递了this指针而不是shared_from_this()，那么实际上当函数执行完成后，Session即会析构，包括其内部的资源(如 _socket)也会被释放。那么当boost底层去执行网络IO时，自然会遇到错误，并且仍然会”正常”回调到对应函数，如ReadCompleted，然后在err中告诉你：”由本地系统终止网络连接”(或:”An attempt to abort the evaluation failed. The process is now in an indeterminate state.” )。让人误以为是网络问题，很难调试。而事实上此时整个对象都已经被释放掉了。</p>
<p>注：由于C++对象模型实现所致，成员函数和普通函数的主要区别如下：</p>
<ol>
<li>成员函数带隐式this参数</li>
<li>成员函数具有访问作用域，并且函数内会对非静态成员变量访问做一些转换,如 _member_data 转换成 this-&gt;_member_data;</li>
</ol>
<p>也就是说，<strong>成员函数并不属于对象，非静态数据成员才属于对象</strong>。</p>
<p>因此如下调用在编译期是合法的：</p>
<p><code>((A*)nullptr)-&gt;Func();</code></p>
<p>而如果成员函数A::Func()没有访问A的非静态成员变量，这段代码甚至能正确运行，如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Test</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    void Say()</span><br><span class="line">    &#123;</span><br><span class="line">        std::cout &lt;&lt; &quot;Say Test&quot; &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void Set(int data)</span><br><span class="line">    &#123;</span><br><span class="line">        _data &#x3D; data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">    int _data;</span><br><span class="line">&#125;;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F; 运行成功</span><br><span class="line">    ((Test*)nullptr)-&gt;Say();</span><br><span class="line">	&#x2F;&#x2F; 运行会崩掉，尝试访问空指针所指内存(_data)</span><br><span class="line">    ((Test*)nullptr)-&gt;Set(1);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>正因为这种特性，有时候在成员函数中纠结半天，也不会注意到这个对象已经”不正常了”，被释放掉了。</p>
<h3 id="四-shared-ptr-使用总结"><a href="#四-shared-ptr-使用总结" class="headerlink" title="四. shared_ptr 使用总结"></a>四. shared_ptr 使用总结</h3><ol>
<li>尽量不要环引用或自引用，可通过weak_ptr来避免环引用：owner持有child的shared_ptr child持有owner的weak_ptr</li>
<li>如果存在环引用或自引用，记得在释放时解开这个引用链</li>
<li>对于通过智能指针管理的类，在类中通过shared_from_this()而不是this来传递本身</li>
<li>在类释放时，尽量手动置空其所有的shared_ptr成员，包括function</li>
</ol>
]]></content>
      <categories>
        <category>c/c++</category>
      </categories>
      <tags>
        <tag>c/c++</tag>
      </tags>
  </entry>
  <entry>
    <title>skynet C模块</title>
    <url>/2015/01/skynet-c-module/</url>
    <content><![CDATA[<p>这些天一直在拜读云风的<a href="https://github.com/cloudwu/skynet" title="skynet on github">skynet</a>，由于对lua不是很熟悉，也花了一些时间来学习lua。这里大概整理一下这些天学习skynet框架的一些东西。</p>
<p>skynet核心概念为服务，一个服务可以由C或lua实现，服务之间的通信已由底层C框架保证。用户要做的只是注册服务，处理消息。如云风的<a href="http://blog.codingnow.com/2012/09/the_design_of_skynet.html" title="skynet综述">skynet综述</a>中所说：</p>
<p><strong>作为核心功能，Skynet 仅解决一个问题：</strong></p>
<p><strong>把一个符合规范的 C 模块，从动态库（so 文件）中启动起来，绑定一个永不重复（即使模块退出）的数字 id 做为其 handle 。模块被称为服务（Service），服务间可以自由发送消息。每个模块可以向 Skynet 框架注册一个 callback 函数，用来接收发给它的消息。每个服务都是被一个个消息包驱动，当没有包到来的时候，它们就会处于挂起状态，对 CPU 资源零消耗。如果需要自主逻辑，则可以利用 Skynet 系统提供的 timeout 消息，定期触发。</strong></p>
<p><strong>Skynet 提供了名字服务，还可以给特定的服务起一个易读的名字，而不是用 id 来指代它。id 和运行时态相关，无法保证每次启动服务，都有一致的 id ，但名字可以。</strong></p>
<span id="more"></span>
<p>在云风的<a href="http://blog.codingnow.com/2012/08/skynet.html" title="skynet开源">这篇博客</a>中更详细地介绍道：</p>
<p><strong>这个系统是单进程多线程模型。</strong></p>
<p><strong>每个内部服务的实现，放在独立的动态库中。由动态库导出的三个接口 create init release 来创建出服务的实例。init 可以传递字符串参数来初始化实例。比如用 lua 实现的服务（这里叫 snlua ），可以在初始化时传递启动代码的 lua 文件名。</strong></p>
<p><strong>每个服务都是严格的被动的消息驱动的，以一个统一的 callback 函数的形式交给框架。框架从消息队列里取到消息，调度出接收的服务模块，找到 callback 函数入口，调用它。服务本身在没有被调度时，是不占用任何 CPU 的。框架做两个必要的保证。</strong></p>
<p><strong>一、一个服务的 callback 函数永远不会被并发。</strong></p>
<p><strong>二、一个服务向两一个服务发送的消息的次序是严格保证的。</strong></p>
<p><strong>我用多线程模型来实现它。底层有一个线程消息队列，消息由三部分构成：源地址、目的地址、以及数据块。框架启动固定的多条线程，每条工作线程不断的从消息队列取到消息。根据目的地址获得服务对象。当服务正在工作（被锁住）就把消息放到服务自己的私有队列中。否则调用服务的 callback 函数。当 callback 函数运行完后，检查私有队列，并处理完再解锁。</strong></p>
<h3 id="符合规范的C模块"><a href="#符合规范的C模块" class="headerlink" title="符合规范的C模块"></a>符合规范的C模块</h3><p>skynet C服务均被编译为动态链接库so文件，由框架在需要时加载并使用。前面说的”符合规范的C模块”指的是一个能被框架正确加载使用的C服务模块应该导出如下三个接口：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 服务创建接口 返回服务实例数据结构</span><br><span class="line">struct xyz* xyz_create(void);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 初始化服务 主要是根据param启动参数初始化服务 并注册回调函数</span><br><span class="line">int xyz_init(struct xyz * inst, struct skynet_context *ctx, const char * param)；</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 释放服务</span><br><span class="line">void xyz_release(struct xyz* inst);</span><br></pre></td></tr></table></figure>
<p>其中”xyz”是C服务名，需要和最终编译的动态库名一致，skynet根据这个名字来查找”xyz.so”并加载。服务模块还需要导出 xyz_create xyz_init xyz_release三个函数用于服务的创建，初始化和释放。xyz_create返回服务自定义的数据结构，代表一个服务实例的具体数据。xyz_init中根据启动参数完成服务的初始化，并且注册回调函数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef int (*skynet_cb)(</span><br><span class="line"> 		struct skynet_context * context,</span><br><span class="line"> 		void * ud,</span><br><span class="line"> 		int type,</span><br><span class="line"> 		int session, </span><br><span class="line"> 		uint32_t source ,</span><br><span class="line"> 		const void * msg,</span><br><span class="line"> 		size_t sz</span><br><span class="line">);</span><br><span class="line">&#x2F;&#x2F; 注册消息回调函数cb和回调数据ud</span><br><span class="line">skynet_callback(struct skynet_context * context, void *ud, skynet_cb cb);</span><br></pre></td></tr></table></figure>
<p>通过skynet_callback可以注册回调函数和回调自定义数据ud(一般就是模块create函数的返回值)，之后每次调用回调函数都会传入ud。</p>
<p>在skynet/service-src/下，定义了四个C服务，其中最简单的是skynet_logger.c，它是C写的一个logger服务。关于C服务的写法一看便知。</p>
<h3 id="C服务上下文skynet-context"><a href="#C服务上下文skynet-context" class="headerlink" title="C服务上下文skynet_context"></a>C服务上下文skynet_context</h3><p>skynet_context保存一个C服务相关的上下文。包括服务的消息队列，回调函数cb，回调数据ud，所在模块，以及服务的一些状态等。skynet核心层管理的每个C服务都需要对应一个skynet_context。skynet建立服务的唯一id(handle)到skynet_context的一一对应。</p>
<p>在向服务发送消息时，指定其handle即可。skynet根据该handle找到skynet_context，并将消息push到skynet_context的msgqueue中。skynet还为服务提供了全局名字注册，这样可以通过指定服务名向服务发送消息，skynet会根据name找到handle，最终仍通过handle来找到服务的消息队列。</p>
<p>msgqueue中也保存了其所属服务handle。这样消息调度器在处理到某个msgqueue时，可通过msgqueue中的handle找到skynet_context，并调用其回调函数。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>lua</tag>
        <tag>skynet</tag>
      </tags>
  </entry>
  <entry>
    <title>false sharing</title>
    <url>/2015/01/false-sharing/</url>
    <content><![CDATA[<p>在多核的CPU架构中，每一个核心core都会有自己的缓存行(cache line)，因此如果一个变量如果同时存在不同的核心的cache line时，就会出现伪共享（false sharing)的问题。此时如果一个核心修改了该变量，该修改需要同步到其它核心的缓存。</p>
<p><img src="/assets/image/201501/cache-line.png" alt="" title="cache-line示意图"></p>
<p>上图说明了伪共享的问题。在核心1上运行的线程想更新变量X，同时核心2上的线程想要更新变量Y。不幸的是，这两个变量在同一个缓存行中。每个线程都要去竞争缓存行的所有权来更新变量。如果核心1获得了所有权，缓存子系统将会使核心2中对应的缓存行失效。当核心2获得了所有权然后执行更新操作，核心1就要使自己对应的缓存行失效。这会来来回回的经过L3缓存，大大影响了性能。如果互相竞争的核心位于不同的插槽，就要额外横跨插槽连接，问题可能更加严重。 </p>
<p>我们可以通过padding来确保两个共享变量不位于同一个cache-line中，这对于链表等传统结构的共享(首尾节点通常位于同一cache-line)有重大意义。如下面这个例子：</p>
<span id="more"></span>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#include&lt;thread&gt;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct foo &#123;</span><br><span class="line">    int x;</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">    int64_t pad1;</span><br><span class="line">    int64_t pad2;</span><br><span class="line">    int64_t pad3;</span><br><span class="line">    int64_t pad4;</span><br><span class="line">    int64_t pad5;</span><br><span class="line">    int64_t pad6;</span><br><span class="line">    int64_t pad7;</span><br><span class="line">    int64_t pad8;</span><br><span class="line">    int64_t pad9;</span><br><span class="line">    int64_t pad10;</span><br><span class="line">    int64_t pad11;</span><br><span class="line">    int64_t pad12;</span><br><span class="line">    int64_t pad13;</span><br><span class="line">    int64_t pad14;</span><br><span class="line">    int64_t pad15;</span><br><span class="line">    int64_t pad16;</span><br><span class="line">*&#x2F;    </span><br><span class="line"></span><br><span class="line">    int y;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">static struct foo f;</span><br><span class="line"></span><br><span class="line">void sum_a(void)</span><br><span class="line">&#123;</span><br><span class="line">    clock_t start &#x3D; clock();</span><br><span class="line">    int s &#x3D; 0;</span><br><span class="line">    int i;</span><br><span class="line">    for (i &#x3D; 0; i &lt; 1000000000; ++i)</span><br><span class="line">        s +&#x3D; f.x;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;sum_a cost: &quot;&lt;&lt; clock()-start &lt;&lt; &quot;ms&quot;&lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void inc_b(void)</span><br><span class="line">&#123;</span><br><span class="line">    clock_t start &#x3D; clock();</span><br><span class="line">    int i;</span><br><span class="line">    for (i &#x3D; 0; i &lt; 1000000000; ++i)</span><br><span class="line">        ++f.y;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;inc_b cost: &quot;&lt;&lt; clock()-start &lt;&lt; &quot;ms&quot;&lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    std::thread t1(sum_a);</span><br><span class="line">    std::thread t2(inc_b);</span><br><span class="line"></span><br><span class="line">    t1.join();</span><br><span class="line">    t2.join();</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>未添加padding时，在我的机器上运行结果为：</p>
<pre><code>inc_b cost: 4692ms
sum_a cost: 5722ms
</code></pre><p>添加padding后，运行结果为：</p>
<pre><code>inc_b cost: 2161ms
sum_a cost: 2194ms
</code></pre>]]></content>
      <categories>
        <category>os</category>
      </categories>
  </entry>
  <entry>
    <title>skynet lua服务</title>
    <url>/2015/01/skynet-luaservice/</url>
    <content><![CDATA[<h2 id="C模块的导出"><a href="#C模块的导出" class="headerlink" title="C模块的导出"></a>C模块的导出</h2><p>从skynet核心模块来看，它只认得C服务，每个服务被编译为动态库，在需要时由skynet加载。skynet提供发送消息和注册回调函数的接口，并保证消息的正确到达，并调用目标服务回调函数。其它东西，如消息调度，线程池等，对于用户来说都是透明的。</p>
<p>skynet服务可以由lua编写，因此skynet将C模块核心接口通过skynet/lualib-src/lua-skynet.c导出为 skynet.so提供给lua使用。在lua层，通过skynet/lualib/skynet.lua加载C模块(<code>require &quot;skynet.core&quot;</code>)完成对C API的封装。主要涉及lua服务的加载和退出，消息的发送，回调函数的注册等。用户定义的lua服务通过<code>require &quot;skynet&quot;</code>的接口即可完成服务的注册，启动和退出等。关于skynet lua api可以参见<a href="https://github.com/cloudwu/skynet/wiki/LuaAPI" title="skynet wiki">skynet wiki</a>。</p>
<span id="more"></span>
<p>skynet.lua 中，提供的比较重要的接口有：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 注册特定类型消息的处理函数</span><br><span class="line">function skynet.dispatch(typename, func)</span><br><span class="line"></span><br><span class="line">-- 服务启动函数 在lua服务中调用该函数启动服务 并执行用户定义的start_func</span><br><span class="line">function skynet.start(start_func)</span><br><span class="line"></span><br><span class="line">-- 启动一个lua服务，name为lua脚本名字,返回服务地址</span><br><span class="line">function skynet.newservice(name, ...)</span><br><span class="line"></span><br><span class="line">-- 启动一个C服务，第一个参数为服务名字，后续为服务参数。返回服务地址</span><br><span class="line">function skynet.launch(...)</span><br><span class="line"></span><br><span class="line">-- 为服务地址映射一个全局名字	</span><br><span class="line">function skynet.name(name, handle)</span><br><span class="line"></span><br><span class="line">-- 向其它服务发送消息</span><br><span class="line">function skynet.send(addr, typename, ...)</span><br><span class="line"></span><br><span class="line">-- 同步发送消息 并阻塞等待回应	</span><br><span class="line">function skynet.call(addr, typename, ...)</span><br></pre></td></tr></table></figure>
<h2 id="lua服务如何关联到C核心层"><a href="#lua服务如何关联到C核心层" class="headerlink" title="lua服务如何关联到C核心层"></a>lua服务如何关联到C核心层</h2><p>下面主要提一下skynet是如何在这套C框架上承载lua服务的。</p>
<p>skynet 预置了一个C服务，叫snlua(位于skynet/service-src/skynet_snlua.c)，这个服务的主要任务就是承载lua服务。一个snlua服务可以承载一个lua服务，可以启动任意份snlua服务。我们直接从snlua这个C服务开始，介绍一个lua服务是如何融合到C框架中的。当需要加载一个名为”console.lua””的服务时，我们将启动一个参数为”console”的snlua服务。主要流程：</p>
<ol>
<li>调用skynet.launch(“sunlua”, “console”)</li>
<li><p>skynet.launch对应C中的cmd_launch，它通过skynet_context_new加载snlua服务：</p>
<p> a.创建服务对应的skynet_context</p>
<p>  b.加载snlua.so模块，并调用模块导出的snlua_create创建snlua服务，snlua_create会创建一个lua_State，这样每个lua服务拥有自己的lua_State。</p>
<p> c.创建服务消息队列，并为skynet_context绑定唯一handle，将消息队列放入全局消息队列中</p>
<p> d.调用snlua_init初始化服务，在snlua_init中，完成对snlua回调函数的注册。并且构造一条消息，将要加载的lua服务名(“console”)发给自己。</p>
</li>
</ol>
<ol>
<li>在snlua服务的消息回调函数中，先注销回调函数。然后通过加载并运行一个叫loader.lua的脚本，并解析收到的数据(“console”)来完成实际服务的加载。</li>
<li>loader.lua在指定路径(可配置)下找到console.lua脚本，并执行 console.lua 脚本</li>
<li>此时回调函数就返回了。由于之前已经注销了snlua的回调函数。此时snlua看似”报废”了。而事实在重点在console.lua 当中：</li>
</ol>
<p>每个skynet lua服务都需要有一个启动函数，通过调用 <code>skynet.start(function ... end )</code>来启动lua服务。在skynet.start中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c &#x3D; require &quot;skynet.core&quot;</span><br><span class="line">function skynet.start(start_func)</span><br><span class="line">	c.callback(dispatch_message)</span><br><span class="line">	skynet.timeout(0, function()</span><br><span class="line">		init_service(start_func)</span><br><span class="line">	end)</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<p>通过c.callback注册了lua服务的回调函数dispatch_message，c.callback由skynet.so导出，它最终调用skynet_callback这个函数完成对本服务(当前是snlua)的回调函数注册。dispatch_message也定义于skynet.lua中，它主要的功能是根据消息类型(C层定义于skynet.h中，lua层定义于skynet.lua)将消息分发到lua服务指定的回调函数，前面提到过skynet.dispatch可以注册特定类型的处理函数。c.callback将dispatch_message注册为snlua新的回调函数。此时snlua这个服务就承载了lua服务，因为它收到的消息将通过dispath_message转发到lua服务注册的回调函数中。</p>
<p>那么c.callback如何将一个lua函数(dispatch_message)注册为一个C服务(snlua)的回调函数的呢？在skynet/lualib-src/lua-skynet.c中，c.callback对应的C函数实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static int</span><br><span class="line">_callback(lua_State *L) &#123;</span><br><span class="line">	struct skynet_context * context &#x3D; lua_touserdata(L, lua_upvalueindex(1));</span><br><span class="line">	int forward &#x3D; lua_toboolean(L, 2);</span><br><span class="line">	luaL_checktype(L,1,LUA_TFUNCTION);</span><br><span class="line">	lua_settop(L,1);</span><br><span class="line">	lua_rawsetp(L, LUA_REGISTRYINDEX, _cb);</span><br><span class="line"></span><br><span class="line">	lua_rawgeti(L, LUA_REGISTRYINDEX, LUA_RIDX_MAINTHREAD);</span><br><span class="line">	lua_State *gL &#x3D; lua_tothread(L,-1);</span><br><span class="line"></span><br><span class="line">	if (forward) &#123;</span><br><span class="line">		skynet_callback(context, gL, forward_cb);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		skynet_callback(context, gL, _cb);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>_callback将lua服务消息回调dispatch_message以_cb函数地址为key保存到lua注册表中。再将_cb函数作为lua服务的”代理回调函数”注册到C核心框架中。这样真正的回调函数_cb就能够满足C服务回调函数形式。这里C中的_cb和lua中的\dispatch_message都是预先定义好的，可以通过lua全局注册表做一一映射。</p>
<p>当消息到达snlua时，在_cb中，通过<code>lua_rawgetp(L, LUA_REGISTRYINDEX, _cb);</code>从lua注册表中取出lua服务的真正回调函数dispatch_message，压入消息参数。然后调用dispatch_message。dispatch_message根据消息类型将消息分到到lua服务注册的回调函数中。</p>
<p>总结一下，snlua帮lua服务做了如下工作：</p>
<ul>
<li>创建服务上下文skynet_context</li>
<li>创建lua_State</li>
<li>分配并绑定唯一handle</li>
<li>创建服务消息队列</li>
<li>执行指定lua服务脚本</li>
</ul>
<p>在最后一步中，lua服务脚本会通过skynet.start启动服务，后者通过c.callback完成回调函数的替换。之后snlua便成功代理了lua服务，它收到的消息都会转发给lua层的dispatch_message。</p>
<h2 id="launcher服务"><a href="#launcher服务" class="headerlink" title="launcher服务"></a>launcher服务</h2><p>skynet中所有的lua服务都是通过snlua来承载的，skynet提供了一个lua服务launcher.lua(skynet/service/下)专门用来启动其它lua服务，launcer服务本身通过skynet.launch(“snlua”, “launcher”)来创建，而其它的lua服务则更推荐使用skynet.newservice(“console”)来启动：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function skynet.newservice(name, ...)</span><br><span class="line">	return skynet.call(&quot;.launcher&quot;, &quot;lua&quot; , &quot;LAUNCH&quot;, &quot;snlua&quot;, name, ...)</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<p>根据前面skynet.call的原型，skynet.call向名为”.launcher”的服务发送一条类型为”lua”的消息，之后的参数便是消息数据，一般来说，消息的第一个字段代表命令，如这里向”.launcher”服务发送了一个”LAUNCH”命令。launcher.lua的实现比较简单，通过它也能了解lua服务的惯用写法。因此这里我摘录了部分重要代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local services &#x3D; &#123;&#125; -- 记录各lua服务的启动时参数</span><br><span class="line">local command &#x3D; &#123;&#125; -- 保存各命令对应的处理函数</span><br><span class="line">local instance &#x3D; &#123;&#125; -- for confirm (function command.LAUNCH &#x2F; command.ERROR &#x2F; command.LAUNCHOK)</span><br><span class="line"></span><br><span class="line">-- 通过skynet.launch完成服务的加载 并返回服务地址</span><br><span class="line">local function launch_service(service, ...)</span><br><span class="line">	local param &#x3D; table.concat(&#123;...&#125;, &quot; &quot;)</span><br><span class="line">	local inst &#x3D; skynet.launch(service, param)</span><br><span class="line">	local response &#x3D; skynet.response()</span><br><span class="line">	if inst then</span><br><span class="line">		services[inst] &#x3D; service .. &quot; &quot; .. param</span><br><span class="line">		instance[inst] &#x3D; response</span><br><span class="line">	else</span><br><span class="line">		response(false)</span><br><span class="line">		return</span><br><span class="line">	end</span><br><span class="line">	return inst</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">-- 加载lua服务</span><br><span class="line">function command.LAUNCH(_, service, ...)</span><br><span class="line">	launch_service(service, ...)</span><br><span class="line">	return NORET</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">-- lua服务加载完成 通常在skynet.start完成服务初始化后 发送该命令通知launcher</span><br><span class="line">function command.LAUNCHOK(address)</span><br><span class="line">	-- init notice</span><br><span class="line">	local response &#x3D; instance[address]</span><br><span class="line">	if response then</span><br><span class="line">		response(true, address)</span><br><span class="line">		instance[address] &#x3D; nil</span><br><span class="line">	end</span><br><span class="line"></span><br><span class="line">	return NORET</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">-- 注册&quot;lua&quot;类型(对应C中的type字段为PTYPE_LUA)消息的回调函数</span><br><span class="line">skynet.dispatch(&quot;lua&quot;, function(session, address, cmd , ...)</span><br><span class="line">	cmd &#x3D; string.upper(cmd)</span><br><span class="line">	local f &#x3D; command[cmd]</span><br><span class="line">	if f then</span><br><span class="line">		local ret &#x3D; f(address, ...)</span><br><span class="line">		if ret ~&#x3D; NORET then</span><br><span class="line">			skynet.ret(skynet.pack(ret))</span><br><span class="line">		end</span><br><span class="line">	else</span><br><span class="line">		skynet.ret(skynet.pack &#123;&quot;Unknown command&quot;&#125; )</span><br><span class="line">	end</span><br><span class="line">end)</span><br><span class="line"></span><br><span class="line">-- lua服务启动函数</span><br><span class="line">skynet.start(function() end)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这样lua服务的启动通过launcher服务添加一层沙盒，更加安全。launcher还会记录服务的加载状态，输出日志等。launcher一般在bootstrap.lua中创建，并且为其命名”.launcher”。bootstrap.lua是skynet启动执行的第一个lua脚本。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>lua</tag>
        <tag>skynet</tag>
      </tags>
  </entry>
  <entry>
    <title>lua 协程</title>
    <url>/2015/01/lua-coroutine/</url>
    <content><![CDATA[<h3 id="协程基础"><a href="#协程基础" class="headerlink" title="协程基础"></a>协程基础</h3><p>协程(协同式多线程)是一种用户级的非抢占式线程。”用户级”是指它的切换和调度由开发者控制，”非抢占”指一个协程只有在其挂起(yield)或者协程结束才会返回。协程和C线程一样，有自己的堆栈，自己的局部变量，自己的指令指针，并且和其它协程共享全局变量等信息。很多语言都有协程的概念，但在我看来，Python、JS、Lua这类语言的协程概念是类似的，C#有枚举器(迭代器)，但没有协程(我在<a href="https://wudaijun.com/2021/11/c-sharp-unity-async-programing/">C#/Unity中的异步编程</a>中有聊这个话题)，Go语言中的goroutine也被翻译为协程，但实际上它是抢占式的轻量级线程，被称作协程(“协”本身就有协作协同之意)是有歧义的。在我的理解中，协程的本质就是用户级的控制权(执行权)的让出和恢复机制(以及相关的上下文保存和值传递机制)，在理解这一点之后，其它如: </p>
<ul>
<li>协程是本质单线程的，协程可以实现单线程内的异步操作，并且无需考虑同步和加锁的问题</li>
<li>在单线程内，同一时刻只有一个协程在运行</li>
<li>协程可以以类似同步的方式来写异步代码</li>
<li>协程可以让函数返回多次</li>
</ul>
<p>等说法，也就比较好理解了。本文主要简单介绍下Lua协程。</p>
<h3 id="Lua协程"><a href="#Lua协程" class="headerlink" title="Lua协程"></a>Lua协程</h3><p>Lua协程的相关函数封装在coroutine中，对应的 C API为<code>lua_newthread</code>，<code>lua_resume</code>等。Lua文档中的thread和coroutine是一个概念，但与操作系统的线程是两个东西。</p>
<p>C API通过<code>lua_State</code>维护一个协程的状态(以及Lua虚拟机状态的引用)，协程的状态主要指协程上下文(如交互栈)，Lua虚拟机状态是全局的，可被多个协程共享。以下描述摘自Lua5.3官方文档：</p>
<blockquote>
<blockquote>
<p>An opaque structure that points to a thread and indirectly (through the thread) to the whole state of a Lua interpreter. The Lua library is fully reentrant: it has no global variables. All information about a state is accessible through this structure.</p>
<p>A pointer to this structure must be passed as the first argument to every function in the library, except to lua_newstate, which creates a Lua state from scratch.</p>
</blockquote>
</blockquote>
<p>当调用<code>lua_newstate</code>时，实际上分为两步，1. 创建并初始化一个Lua虚拟机(<code>global_State</code>)；2.创建一个主协程运行于虚拟机中，并返回主协程的执行上下文(LuaState)。调用<code>lua_newthread</code>时，将在已有Lua虚拟机上，创建另一个协程执行环境，该协程与已有协程共享虚拟机状态(同一个Lua虚拟机中的不同协程共享<code>global_State</code>)，并返回新的执行上下文。因此将LuaState理解为协程执行上下文可能更合适，LuaState本身也是一个类型为thread的GCObject，无需手动释放(Lua也没有提供对应close或destroy接口)。</p>
<p>Lua协程的的核心API主要是三个，<code>coroutine.create</code>，<code>coroutine.yield</code>，<code>coroutine.resume</code>，分别对应创建(通常是基于函数)、让出执行权(但不知道让出给谁)，和恢复执行权(需要明确指定恢复哪个coroutine)三个操作。</p>
<h3 id="两个例子"><a href="#两个例子" class="headerlink" title="两个例子"></a>两个例子</h3><p>pil上关于协程有两个非常经典的例子。</p>
<p>在生产者消费者例子中，当消费者需要生产者的数据时(相当于一个异步回调)，切换到生产者协程(resume)，生产者开始运行，生产完成后，挂起自己(yield)并且传入生产的数据。此时调度回到消费者协程中，消费者从resume的返回值中得到数据，使用数据，在需要数据时再次唤醒生产者。这样我们像写同步代码一样(resume相当于函数调用，yield相当于函数返回)，完成了异步功能。而无需考虑传统生产者和消费者模型中的同步问题，因为这两者是在单线程内统一协同的。代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pfun &#x3D; function()</span><br><span class="line">	while true do</span><br><span class="line">		local value &#x3D; io.read()</span><br><span class="line">		print(&quot;生产: &quot;, value)</span><br><span class="line">		coroutine.yield(value)</span><br><span class="line">	end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">cfun &#x3D; function(p)</span><br><span class="line">	while true do</span><br><span class="line">		local _, value &#x3D; coroutine.resume(p)</span><br><span class="line">		print(&quot;消费: &quot;, value)</span><br><span class="line">	end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">p &#x3D; coroutine.create(pfun)</span><br><span class="line">cfun(p) -- 消费者作为恢复方，需要持有让出方的coroutine引用，作为resume参数</span><br></pre></td></tr></table></figure>
<p>这个例子本身很简单，甚至不大有必要强行用协程，但用协程的一大好处，就是有清晰生产者和消费者的边界，如果不使用协程，要么使用多线程，如此调度不受应用层控制，需要额外加队列缓冲和互斥机制，要么就在单线程内让生产者和消费者强耦合，如cfun中通过while循环去依次<code>io.read</code>，也就是将执行权的让出和恢复机制实现在一个function中(变成函数控制流跳转)，代价是降低可维护性(协程提供一种封装解耦的机制)。</p>
<p>另一个例子是关于模拟多线程下载文件的，每个协程下载一个文件，由我们控制各个协程的调度，当某个协程暂时没有数据可读时(非阻塞IO)，挂起(yield)自己，返回到调度器，开始调度(resume)下一个协程。这样总是能保证将时间片分给读取数据的协程上，而不是等待数据的协程上。不过这样有个小问题是，当所有协程都没有数据可读时，分配器将进入忙查询，这样会空转CPU，这可以通过select函数来优化，在所有协程都没有数据时，让出CPU。最终代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">socket &#x3D; require &quot;socket&quot;</span><br><span class="line"></span><br><span class="line">-- 下载文件 在超时时挂起(返回: 连接c) 在接收完成时结束协程(返回: nil)</span><br><span class="line">function download(host, file)</span><br><span class="line">	local c, err &#x3D; assert(socket.connect(host, 80))</span><br><span class="line">	if err then print(&quot;-- connect host&quot;, file, &quot;error: &quot;, err) end</span><br><span class="line">	local count &#x3D; 0</span><br><span class="line">	c:send(&quot;GET &quot;.. file .. &quot; HTTP&#x2F;1.0\r\n\r\n&quot;)</span><br><span class="line">	while true do</span><br><span class="line">		local s, status &#x3D; receive(c)	</span><br><span class="line">		if status &#x3D;&#x3D; &quot;closed&quot; then break end</span><br><span class="line">		if s then </span><br><span class="line">			count &#x3D; count + string.len(s) </span><br><span class="line">			break </span><br><span class="line">		end </span><br><span class="line">	end</span><br><span class="line">	c:close()</span><br><span class="line">	print(&quot;-- download &quot;, file, &quot; completed. file size: &quot;, count)</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">function receive(conn)</span><br><span class="line">	conn:settimeout(0) -- 设置非阻塞模式，协程想要在应用层让出执行权，当然需要非阻塞&#x2F;异步操作的支持</span><br><span class="line">	local s, status &#x3D; conn:receive(&quot;*a&quot;)</span><br><span class="line">	if status &#x3D;&#x3D; &quot;timeout&quot; then -- 暂时无数据可读</span><br><span class="line">		coroutine.yield(conn) -- 这里让出了执行权，执行权将直接跳转到resume方，也就是dispatcher</span><br><span class="line">								  -- 待dispatcher觉得可能有数据可读，再恢复执行权到这里</span><br><span class="line">	end</span><br><span class="line">	return s, status</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">-- 保存所有协程</span><br><span class="line">local threads &#x3D; &#123;&#125;</span><br><span class="line">-- 创建一个协程 对应下载一个文件</span><br><span class="line">function get(host, file)</span><br><span class="line">	local co &#x3D; coroutine.create(function() </span><br><span class="line">		download(host, file)</span><br><span class="line">	end)</span><br><span class="line"></span><br><span class="line">	table.insert(threads, co)</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">-- 调度线程</span><br><span class="line">function dispatcher()</span><br><span class="line">	while true do</span><br><span class="line">		local conns &#x3D; &#123;&#125;</span><br><span class="line">		local n &#x3D; #threads</span><br><span class="line">		if n &#x3D;&#x3D; 0 then break end</span><br><span class="line">		for i &#x3D; 1,n do</span><br><span class="line">			local status, c &#x3D; coroutine.resume(threads[i])</span><br><span class="line">			if not c then -- 接收数据完成 即download 函数正常返回</span><br><span class="line">				table.remove(threads, i) -- 移除协程</span><br><span class="line">				break -- 重新遍历</span><br><span class="line">			else</span><br><span class="line">				table.insert(conns, c)</span><br><span class="line">			end</span><br><span class="line">		end</span><br><span class="line">		if #conns &gt; 0 then</span><br><span class="line">			socket.select(conns) -- 阻塞直到有socket读就绪，这里简单起见，未处理返回值，只是在select结束后，尝试resume所有的threads</span><br><span class="line">		end</span><br><span class="line">	end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">get(&quot;www.baidu.com&quot;, &quot;&#x2F;index.html&quot;)</span><br><span class="line">get(&quot;tieba.baidu.com&quot;, &quot;&#x2F;index.html&quot;)</span><br><span class="line">get(&quot;news.baidu.com&quot;, &quot;&#x2F;index.html&quot;)</span><br><span class="line"></span><br><span class="line">dispatcher()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
        <tag>coroutine</tag>
        <tag>async programing</tag>
      </tags>
  </entry>
  <entry>
    <title>c++ disruptor 无锁消息队列</title>
    <url>/2015/02/cpp-disruptor/</url>
    <content><![CDATA[<p>前段时间关注到<a href="http://ifeve.com/disruptor/" title="disruptor">disruptor</a>，一个高并发框架。能够在无锁(lock-free)的情况下处理多生产者消费者的并发问题。它可以看作一个消息队列，通过<a href="http://coolshell.cn/articles/8239.html" title="compare and swap">CAS</a>而不是锁来处理并发。</p>
<p>因此实现了一个C++版本的disruptor，基于ring buffer，实现一个发送缓冲(多生产者，单消费者)。</p>
<h3 id="写入缓冲"><a href="#写入缓冲" class="headerlink" title="写入缓冲"></a>写入缓冲</h3><p>某个生产者要写入数据时，先申请所需空间(需要共享当前分配位置)，然后直接执行写入，最后提交写入结果(需要共享当前写入位置)。整个写入过程由两个关键共享变量: <code>atomic_ullong _alloc_count</code>和<code>atomic_ullong _write_count</code>。前者负责管理和同步当前分配的空间，后者负责同步当前已经写入的空间。也就是说，整个过程分为三步：申请，写入，提交。</p>
<p>比如，有两个生产者P1和P2。P1申请到大小为50的空间，假设此时_alloc_count=10，那么P1将得到可写入位置10，此时_alloc_count更新为60。P1此时可以执行写入(无需上锁)。这个时候P2开始申请大小为10的空间，它将得到写入位置60，_alloc_count更新为70。因此实际上P1和P2是可以并发写的。如果P2比P1先写完，它会尝试提交，此时由于P1还没有提交它的写入结果，因此P2会自旋等待(不断尝试CAS操作)。直到P1提交写入结果后，P2才能提交。通过CAS可以保证这种提交顺序。提交操作会更新_write_count变量，提交之后的数据便可以被消费者读取使用。</p>
<p>上面的描述并没有提到缓冲区不够的问题，为了判断缓冲区当前可写空间，还需要一个变量 <code>atomic_ullong _idle_count</code>用于记录当前缓冲区空闲大小。该变量在生产者申请空间后减小，在消费者使用数据后变大。初始等于整个ring buffer的大小。</p>
<span id="more"></span>
<h3 id="核心代码"><a href="#核心代码" class="headerlink" title="核心代码"></a>核心代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SendBuffer::SendBuffer(size_t capacity &#x2F;* &#x3D; 65536 *&#x2F;)</span><br><span class="line">&#123;</span><br><span class="line">    size_t fix_capacity &#x3D; 16;</span><br><span class="line">    while (fix_capacity &lt; capacity)</span><br><span class="line">        fix_capacity &lt;&lt;&#x3D; 1;</span><br><span class="line"></span><br><span class="line">    _capacity &#x3D; fix_capacity;</span><br><span class="line">    _capacity_mask &#x3D; _capacity - 1;</span><br><span class="line"></span><br><span class="line">    _buffer &#x3D; new char[_capacity];</span><br><span class="line"></span><br><span class="line">    _alloc_count &#x3D; 0;</span><br><span class="line">    _read_count &#x3D; 0;</span><br><span class="line">    _write_count &#x3D; 0;</span><br><span class="line">    _idle_count &#x3D; _capacity;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">SendBuffer::~SendBuffer()</span><br><span class="line">&#123;</span><br><span class="line">    delete []_buffer;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bool SendBuffer::Push(const char* data, size_t len)</span><br><span class="line">&#123;</span><br><span class="line">    if (nullptr &#x3D;&#x3D; data || len &#x3D;&#x3D; 0 || len &gt; _capacity)</span><br><span class="line">        return false;</span><br><span class="line"></span><br><span class="line">    auto idle &#x3D; _idle_count.fetch_sub(len);</span><br><span class="line">    if (idle &gt;&#x3D; len)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F; 1.申请写入空间</span><br><span class="line">        auto alloc_start &#x3D; _alloc_count.fetch_add(len);</span><br><span class="line">        auto alloc_end &#x3D; alloc_start + len;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 2.执行写入</span><br><span class="line">        auto fix_start &#x3D; alloc_start &amp; _capacity_mask;</span><br><span class="line">        auto fix_end &#x3D; alloc_end &amp; _capacity_mask;</span><br><span class="line">        if (fix_start &lt; fix_end)</span><br><span class="line">        &#123;</span><br><span class="line">            memcpy(_buffer + fix_start, data, len);</span><br><span class="line">        &#125;</span><br><span class="line">        else&#x2F;&#x2F; 分两段写</span><br><span class="line">        &#123;</span><br><span class="line">            auto first_len &#x3D; _capacity - fix_start;</span><br><span class="line">            memcpy(_buffer + fix_start, data, first_len);</span><br><span class="line">            memcpy(_buffer, data + first_len, fix_end);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 3.提交写入结果</span><br><span class="line">        while (true)</span><br><span class="line">        &#123;</span><br><span class="line">            auto tmp &#x3D; alloc_start;</span><br><span class="line">            if (_write_count.compare_exchange_weak(tmp, alloc_end))</span><br><span class="line">                break;</span><br><span class="line">        &#125;</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        _idle_count.fetch_add(len);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">char* SendBuffer::Peek(size_t&amp; len)</span><br><span class="line">&#123;</span><br><span class="line">    if (_read_count &lt; _write_count)</span><br><span class="line">    &#123;</span><br><span class="line">        auto can_read &#x3D; _write_count - _read_count;</span><br><span class="line">        auto fix_start &#x3D; _read_count &amp; _capacity_mask;</span><br><span class="line">        auto fix_end &#x3D; (_read_count + can_read) &amp; _capacity_mask;</span><br><span class="line">        if (fix_start &gt;&#x3D; fix_end) </span><br><span class="line">        &#123;</span><br><span class="line">            &#x2F;&#x2F; 只返回第一段</span><br><span class="line">            can_read &#x3D; _capacity - fix_start;</span><br><span class="line">        &#125;</span><br><span class="line">        len &#x3D; static_cast&lt;size_t&gt;(can_read);</span><br><span class="line">        return _buffer + fix_start;</span><br><span class="line">    &#125;</span><br><span class="line">    return nullptr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bool SendBuffer::Pop(size_t len)</span><br><span class="line">&#123;</span><br><span class="line">    if (_read_count + len &lt;&#x3D; _write_count)</span><br><span class="line">    &#123;</span><br><span class="line">        _read_count +&#x3D; len;</span><br><span class="line">        _idle_count.fetch_add(len);</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码看起来不多，理解起来也不难。主要有以下三点：</p>
<h4 id="1-对原子变量的访问"><a href="#1-对原子变量的访问" class="headerlink" title="1. 对原子变量的访问"></a>1. 对原子变量的访问</h4><p>对原子变量的使用要特别小心，由于没有锁的保护，对原子变量的每一次访问都要考虑到它的值已经改变。比如在Push函数的申请空间操作中，你不能通过</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if(_idle_count &gt; len)</span><br><span class="line">&#123;</span><br><span class="line">	_idle_count.fetch_sub(len)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>来判断空闲空间是否足够，因为在if中它可能大于len，但是当你执行<code>_idle_count.fetch_sub(len)</code>时，它的值可能就改变了，不再满足 &gt; len。同理以下代码也是错的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">_idle_count.fetch_sub(len);</span><br><span class="line">if(_idle_count &gt; 0)</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F;....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对原子变量的访问应该做到”原子性”，即每次逻辑上使用，都只访问一次。这也是和传统锁不一样的地方。而引进_idle_count这个原子变量而不是使用_read_count和_alloc_count来算出空闲空间(<code>_capacity-(_alloc_count-_read_count)</code>)也是基于这个原因，多个生产者依赖于这个表达式的值，并且会对表达式的值造成更改(修改_alloc_count)，就会导致P1读取表达式值后，判断空闲空间足够，在P1更改_alloc_count前，P2生产者更改_alloc_count分配了空间，使得空闲空间已经不足。这种读写分步的操作必须通过原子变量来保证访问的一致性。</p>
<p>而为什么我们在Peek中可以通过<code>_write_count - _read_count</code>来得到当前可读数据，是因为我们只有一个消费者依赖于<code>_write_count - _read_count</code>的值，并且其它生产者对_write_count做出的更改对消费者来说是”无害的”，即生产者只会使_write_count增加，让消费者读到更多的数据。</p>
<h4 id="2-通过CAS保证顺序提交"><a href="#2-通过CAS保证顺序提交" class="headerlink" title="2. 通过CAS保证顺序提交"></a>2. 通过CAS保证顺序提交</h4><p>在Push函数中的第三步提交中，生产者自旋等待，直到它前面(按照申请顺序)的所有生产者都已提交完毕，此时_write_count即为本生产者的写入位置alloc_start，代表alloc_start之前的缓冲区都已经提交完成，此时该你提交写入结果了。提交完成之后，更新_write_count，而消费者则根据_write_count来判断哪些内容是可读的。</p>
<h4 id="3-单消费者无需原子变量"><a href="#3-单消费者无需原子变量" class="headerlink" title="3. 单消费者无需原子变量"></a>3. 单消费者无需原子变量</h4><p>最后，由于只有一个消费者，因此_read_count不是原子变量。它只会在Peek和Pop中读取和修改。</p>
<p>源码地址：<a href="https://github.com/wudaijun/Code/tree/master/Demo/disruptor">https://github.com/wudaijun/Code/tree/master/Demo/disruptor</a></p>
]]></content>
      <categories>
        <category>c/c++</category>
      </categories>
  </entry>
  <entry>
    <title>skynet socketserver</title>
    <url>/2015/02/skynet-socketserver/</url>
    <content><![CDATA[<h3 id="1-异步IO"><a href="#1-异步IO" class="headerlink" title="1. 异步IO"></a>1. 异步IO</h3><p>skynet用C编写的sokcet模块使用异步回调机制，通过lualib-src/lua-socket.c导出为socketdriver模块。skynet socket C API使用的异步回调方式是：在启动socket时，记录当前服务handle，之后该socket上面的消息(底层使用epoll机制)通过skynet消息的方式发往该服务。这里的当前服务指的是socket启动时所在的服务，对于被请求方来说，为调用<code>socketdriver.start(id)</code>的服务，对于请求方来说，为调用<code>socketdriver.connect(addr,port)</code>的服务。skynet不使用套接字fd在上层传播，因为在某些系统上fd的复用会导致上层遇到麻烦，skynet socket C API为每个fd分配一个ID，是自增不重复的。</p>
<span id="more"></span>
<p>socket C API 的核心是三个poll:</p>
<h4 id="socket-poll"><a href="#socket-poll" class="headerlink" title="socket poll"></a>socket poll</h4><p>位于skynet-src/socket_poll.h 底层异步IO，监听可读可写状态，对于linux系统，使用的是epoll模型。</p>
<h4 id="socket-server-poll"><a href="#socket-server-poll" class="headerlink" title="socket_server_poll"></a>socket_server_poll</h4><p>位于skynet-src/socket_server.c 使用socket poll，处理所有套接字上的IO事件和控制事件。socket_server_poll处理这些事件，并返回处理结果(返回一个type代表事件类型，通过socket_message* result指针参数返回处理结果)。</p>
<p>IO事件主要包括可读，可写，新连接到达，连接成功。对于可读事件，socket_server_poll会读取对应套接字上的数据，如果读取成功，返回SOCKET_DATA类型，并且通过result参数返回读取的buffer。同样对于可写事件，会尝试发送缓冲区中的数据，并返回处理结果。</p>
<p>而控制事件指的是上层调用，由于skynet上层使用的是一个id而不是socket fd来代表一个套接字。skynet在该id上做的所有操作(如设置套接字属性，接受连接，关闭连接，发送数据等等)都会被写入特殊的ctrl套接字(recvctrl_fd sendctrl_fd)，这些ctrl fd位于socket_server结构中，是唯一的，因此写入ctrl的控制信息要包括被操作的套接字ID。这些控制信息统一通过socket poll来处理。再在socket_server_poll中，根据id提出对应的socket fd来完成操作。</p>
<h4 id="skynet-socket-poll"><a href="#skynet-socket-poll" class="headerlink" title="skynet_socket_poll"></a>skynet_socket_poll</h4><p>通过socket poll 和 socket_server_poll，此时数据已就绪，新连接也已经被接受，需要通知上层处理这些数据，而skynet_socket_poll就是来完成这些工作的。它调用socket_server_poll，根据其返回的type和result来将这些套接字事件发送给套接字所属服务(服务handle已由socket_server_poll填充在result-&gt;opaque字段中)。skynet_socket_poll将socket_message* result 和 type 字段组装成skynet_socket_message，并且通过skynet_message消息发送给指定服务，消息类型为PTYPE_SOCKET。这样一次异步IO就完成了。</p>
<p>skynet_socket_poll通过一个单独的线程跑起来，线程入口为_socket函数，位于skynet-src/skynet_start.c。</p>
<h3 id="2-lua层封装"><a href="#2-lua层封装" class="headerlink" title="2. lua层封装"></a>2. lua层封装</h3><p>skynet socket C API提供的是异步IO，为方便使用，在lua层提供了一个socket(lualib/socket.lua)模块来实现阻塞读写。该模块是对socketdriver的封装。它通过lua协程模拟阻塞读写。</p>
<p>和gateserver模块一样，socket模块对PTYPE_SOCKET类型的消息进行了注册处理，它使用socketdriver.unpack作为该类型消息的unpack函数。socketdriver.unpack并不进行实际的分包，它只解析出原始数据，socket模块会缓存套接字上收到的数据。缓存结构由socketdriver提供。当调用socket.readline时，将通过socketdriver.readline尝试从缓冲区中读取一行数据。如果缓冲区数据不足，则挂起自身，待数据足够时唤醒。虽然底层仍然是异步，但是由于协程的特性，对上层体现为同步。通过socket模块的API读到的数据可以看做原始数据。</p>
<h3 id="3-消息分包"><a href="#3-消息分包" class="headerlink" title="3. 消息分包"></a>3. 消息分包</h3><p>大多数时候，在收到套接字数据时，要按照消息协议进行消息分包。skynet提供一个netpack库用于处理分包问题，netpack由C编写，位于lualib-src/lua-netpack.c。skynet范例使用的包格式是两个字节的消息长度(Big-Endian)加上消息数据。netpack根据包格式处理分包问题，netpack提供一个<code>netpack.filter(queue, msg, size)</code>接口，它返回一个type(“data”, “more”, “error”, “open”, “close”)代表具体IO事件，其后返回每个事件所需参数。</p>
<p>对于SOCKET_DATA事件，filter会进行数据分包，如果分包后刚好只有一条完整消息，filter返回的type为”data”，其后跟fd msg size。如果不止一条消息，那么消息将被依次压入queue参数中，并且仅返回一个type为”more”。queue是一个结构体指针，可以通过<code>netpack.pop</code>弹出queue中的一条消息。</p>
<p>其余type类型”open”，”error”, “close”分别对应于socket_message中的SOCKET_ACCEPT SOCKET_ERROR SOCKET_CLOSE事件。netpack的使用者可以通过filter返回的type来进行事件处理。</p>
<p>netpack会尽可能多地分包，交给上层。并且通过一个哈希表保存每个套接字ID对应的粘包，在下次数据到达时，取出上次留下的粘包数据，重新分包。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>lua</tag>
        <tag>skynet</tag>
      </tags>
  </entry>
  <entry>
    <title>skynet gateserver</title>
    <url>/2015/02/skynet-gateserver/</url>
    <content><![CDATA[<p>skynet提供一个gateserver用于处理网络事件，位于lualib/snax/gateserver.lua。云风在<a href="https://github.com/cloudwu/skynet/wiki/GateServer" title="skynet wiki: GateServer">skynet wiki</a>上介绍了gateserver的功能和使用范例。用户可以通过向gateserver提供一个自定义handle来向gateserver注册事件处理(玩家登录，断开，数据到达等)。</p>
<p>gateserver模块使用C编写的<a href="http://wudaijun.com/2015/02/skynet-socketserver/">socketdriver和netpack模块</a>，gateserver被加载时，会注册对”socket”(PTYPE_SOCKET)类型消息的处理，并且通过netpack.filter对收到的数据进行分包。分包完成后调用传入的handler对应的处理函数进行处理。它替上层使用者，完成对PTYPE_SOCKET消息的注册分发，以及消息分包。这样在使用时，只需提供一个handler，然后调用gateserver.start(handler)即可。</p>
<p>在skynet中，如果你要自定义你的gate网关服务gate.lua，需要执行以下几步：</p>
<ol>
<li><code>gateserver = require snax.gateserver</code></li>
<li><code>gateserver.start(handler)</code>向gateserver注册网络事件处理。</li>
<li><code>skynet.call(gate, &quot;lua&quot;, &quot;open&quot;, conf)</code>在外部向你定义的gate服务发送启动消息，并传入启动配置(端口，最大连接数等)来启动gate服务。</li>
</ol>
<span id="more"></span>
<p>skynet中也提供了一个gate服务，位于skynet/service/gate.lua，作为使用gateserver的一个范例。gate服务由watchdog启动，gate服务维护外部连接状态，并且转发收到的数据包。skynet提供的gate服务使用<strong>agent</strong>模式，关于gate服务的工作模式，在<a href="http://blog.codingnow.com/2012/09/the_design_of_skynet.html" title="skynet 设计综述">skynet 设计综述</a>中有段介绍：</p>
<p><strong>Gate 会接受外部连接，并把连接相关信息转发给另一个服务去处理。它自己不做数据处理是因为我们需要保持 gate 实现的简洁高效。C 语言足以胜任这项工作。而包处理工作则和业务逻辑精密相关，我们可以用 Lua 完成。</strong></p>
<p><strong>外部信息分两类，一类是连接本身的接入和断开消息，另一类是连接上的数据包。一开始，Gate 无条件转发这两类消息到同一个处理服务。但对于连接数据包，添加一个包头无疑有性能上的开销。所以 Gate 还接收另一种工作模式：把每个不同连接上的数据包转发给不同的独立服务上。每个独立服务处理单一连接上的数据包。</strong></p>
<p><strong>或者，我们也可以选择把不同连接上的数据包从控制信息包（建立/断开连接）中分离开，但不区分不同连接而转发给同一数据处理服务（对数据来源不敏感，只对数据内容敏感的场合）</strong></p>
<p><strong>这三种模式，我分别称为 watchdog 模式，由 gate 加上包头，同时处理控制信息和数据信息的所有数据；agent 模式，让每个 agent 处理独立连接；以及 broker 模式，由一个 broker 服务处理不同连接上的所有数据包。无论是哪种模式，控制信息都是交给 watchdog 去处理的，而数据包如果不发给 watchdog 而是发送给 agent 或 broker 的话，则不会有额外的数据头（也减少了数据拷贝）。识别这些包是从外部发送进来的方法是检查消息包的类型是否为 PTYPE_CLIENT 。当然，你也可以自己定制消息类型让 gate 通知你</strong></p>
<p>skynet中提供的gate服务使用的agent模式，意味着，一开始，gate将新连接的连接控制信息转发给watchdog，如收到用户连接消息后，watchdog可以完成一些登录验证等，验证完成之后，由watchdog创建并启动agent服务，agent服务启动之后，会立即向gate服务发送一条”foward”消息，表示”现在玩家已经登录完成，你收到的消息可以交给我了”。gate收到”forward”消息会记录agent地址，并将之后玩家的数据消息转发给agent而不是之前watchdog。gate将消息转发给agent时，会通过skynet.redirect将源地址改为玩家地址，方便业务处理。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>lua</tag>
        <tag>skynet</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ 右值引用</title>
    <url>/2015/03/cpp-rvalue-referrence/</url>
    <content><![CDATA[<h2 id="一-定义"><a href="#一-定义" class="headerlink" title="一. 定义"></a>一. 定义</h2><p>通常意义上，在C++中，可取地址，有名字的即为左值。不可取地址，没有名字的为右值。右值主要包括字面量，函数返回的临时变量值，表达式临时值等。右值引用即为对右值进行引用的类型，在C++98中的引用称为左值引用。</p>
<p>如有以下类和函数:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">class A</span><br><span class="line">&#123;</span><br><span class="line">private:</span><br><span class="line">	int* _p;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">A ReturnValue()</span><br><span class="line">&#123;</span><br><span class="line">	return A();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>ReturnValue()</code>的返回值即为右值，它是一个不具名的临时变量。在C++98中，只有常量左值引用才能引用这个值。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">A&amp; a &#x3D; ReturnValue(); &#x2F;&#x2F; error: non-const lvalue reference to type &#39;A&#39; cannot bind to a temporary of type &#39;A&#39;</span><br><span class="line">      </span><br><span class="line">const A&amp; a2 &#x3D; ReturnValue(); &#x2F;&#x2F; ok</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>通过常量左值引用，可以延长ReturnValue()返回值的生命周期，但是不能修改它。C++11的右值引用出场了：</p>
<p><code>A&amp;&amp; a3 = ReturnValue();</code></p>
<p>右值引用通过”&amp;&amp;”来声明， a3引用了ReturnValue()的返回值，延长了它的生命周期，并且可以对该临时值进行修改。</p>
<span id="more"></span>
<h2 id="二-移动语义"><a href="#二-移动语义" class="headerlink" title="二. 移动语义"></a>二. 移动语义</h2><p>右值引用可以引用并修改右值，但是通常情况下，修改一个临时值是没有意义的。然而在对临时值进行拷贝时，我们可以通过右值引用来将临时值内部的资源移为己用，从而避免了资源的拷贝：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#include&lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">class A</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">	A(int a)</span><br><span class="line">		:_p(new int(a))</span><br><span class="line">	&#123;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; 移动构造函数 移动语义</span><br><span class="line">	A(A&amp;&amp; rhs)</span><br><span class="line">		: _p(rhs._p)</span><br><span class="line">	&#123;</span><br><span class="line">		&#x2F;&#x2F; 将临时值资源置空 避免多次释放 现在资源的归属权已经转移</span><br><span class="line">		rhs._p &#x3D; nullptr; </span><br><span class="line">		std::cout&lt;&lt;&quot;Move Constructor&quot;&lt;&lt;std::endl;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F; 拷贝构造函数 复制语义</span><br><span class="line">	A(const A&amp; rhs)</span><br><span class="line">		: _p(new int(*rhs._p))</span><br><span class="line">	&#123;</span><br><span class="line">		std::cout&lt;&lt;&quot;Copy Constructor&quot;&lt;&lt;std::endl;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">private:</span><br><span class="line">	int* _p;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">A ReturnValue() &#123; return A(5); &#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	A a &#x3D; ReturnValue();</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>运行该代码，发现Move Constructor被调用(在g++中会对返回值进行优化，不会有任何输出。可以通过<code>-fno-elide-constructors</code>关闭这个选项)。在用右值构造对象时，编译器会调用<code>A(A&amp;&amp; rhs)</code>形式的移动构造函数，在移动构造函数中，你可以实现自己的<strong>移动语义</strong>，这里将临时对象中_p指向内存直接移为己用，避免了资源拷贝。当资源非常大或构造非常耗时时，效率提升将非常明显。如果A没有定义移动构造函数，那么像在C++98中那样，将调用拷贝构造函数，执行<strong>拷贝语义</strong>。移动不成，还可以拷贝。</p>
<h3 id="std-move"><a href="#std-move" class="headerlink" title="std::move"></a>std::move</h3><p>C++11提供一个函数std::move()来将一个左值强制转化为右值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A a1(5);</span><br><span class="line">A a2 &#x3D; std::move(a1);</span><br></pre></td></tr></table></figure>
<p>上面的代码在构造a2时将会调用移动构造函数，并且a1的_p会被置空，因为资源已经被移动了。而a1的生命周期和作用域并没有变，仍然要等到main函数结束后再析构，因此之后对a1的_p的访问将导致运行错误。</p>
<p>std::move乍一看没什么用。它主要用在两个地方：</p>
<ol>
<li>帮助更好地实现移动语义</li>
<li>实现完美转发(下面会提到)</li>
</ol>
<p>考虑如下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class B</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">	B(B&amp;&amp; rhs)</span><br><span class="line">		: _pb(rhs._pb)</span><br><span class="line">	&#123;</span><br><span class="line">		&#x2F;&#x2F; how can i move rhs._a to this-&gt;_a ?</span><br><span class="line">		rhs._pb &#x3D; nullptr;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">	A _a;</span><br><span class="line">	int * pb;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于B的移动构造函数来说，由于rhs是右值，即将被释放，因此我们不只希望将_pb的资源移动过来，还希望利用A类的移动构造函数，将A的资源也执行移动语义。然而问题出在如果我们直接在初始化列表中使用：<code>_a(rhs._a)</code> 将调用A的拷贝构造函数。因为参数 rhs._a 此时是一个具名值，并且可以取址。实际上，B的移动构造函数的参数rhs也是一个左值，因为它也具名，并且可取址。这是在C++11右值引用中让人很迷惑的一点：<strong>可以接受右值的右值引用本身却是个左值</strong></p>
<p>这一点在后面的完美转发还会提到。现在我们可以用std::move来将rhs._a转换为右值：<code>_a(std::move(rhs._a))</code>，这样将调用A的移动构造。实现移动语义。当然这里我们确信rhs._a之后不会在使用，因为rhs即将被释放。</p>
<h2 id="三-完美转发"><a href="#三-完美转发" class="headerlink" title="三. 完美转发"></a>三. 完美转发</h2><p>如果仅仅为了实现移动语义，右值引用是没有必要被提出来的，因为我们在调用函数时，可以通过传引用的方式来避免临时值的生成，尽管代码不是那么直观，但效率比使用右值引用只高不低。</p>
<p>右值引用的另一个作用是完美转发，完美转发出现在泛型编程中，将模板函数参数传递给该函数调用的下一个模板函数。如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">template&lt;typename T&gt;</span><br><span class="line">void Forward(T t)</span><br><span class="line">&#123;</span><br><span class="line">	Do(t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码中，我们希望Forward函数将传入参数类型原封不动地传递给Do函数，即Forward函数接收的左值，则Do接收到左值，Forward接收到右值，Do也将得到右值。上面的代码能够正确转发参数，但是是不完美的，因为Forward接收参数时执行了一次拷贝。</p>
<p>考虑到避免拷贝，我们可以传递引用，形如<code>Forward(T&amp; t)</code>，但是这种形式的Forward并不能接收右值作为参数，如Forward(5)。因为非常量左值不能绑定到右值。考虑常量左值引用：<code>Forward(const T&amp; t)</code>，这种形式的Forward能够接收任何类型(常量左值引用是万能引用)，但是由于加上了常量修饰符，因此无法正确转发非常量左值引用：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void Do(int&amp; i)</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F; do something...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">template&lt;typename T&gt;</span><br><span class="line">void Forward(const T&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	Do(t);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	int a &#x3D; 8;</span><br><span class="line">	Forward(a); &#x2F;&#x2F; error. &#39;void Do(int&amp;)&#39; : cannot convert argument 1 from &#39;const int&#39; to &#39;int&amp;&#39;</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>基于这种情况， 我们可以对Forward的参数进行const重载，即可正确传递左值引用。但是当Do函数参数为右值引用时，Forward(5)仍然不能正确传递，因为Forward中的参数都是左值引用。</p>
<p>下面介绍在 C++11 中的解决方案。</p>
<h3 id="引用折叠"><a href="#引用折叠" class="headerlink" title="引用折叠"></a>引用折叠</h3><p>C++11引入了引用折叠规则，结合右值引用来解决完美转发问题：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">typedef const int T;</span><br><span class="line">typedef T&amp; TR;</span><br><span class="line">TR&amp; v &#x3D; 1; &#x2F;&#x2F; 在C++11中 v的实际类型为 const int&amp;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>如上代码中，发生了引用折叠，将TR展开，得到 T&amp; &amp; v = 1(注意这里不是右值引用)。 这里的 T&amp; + &amp; 被折叠为 T&amp;。更为详细的，根据TR的类型定义，以及v的声明，发生的折叠规则如下：</p>
<pre><code>T&amp;  + &amp;   = T&amp;
T&amp;  + &amp;&amp;  = T&amp;
T&amp;&amp; + &amp;   = T&amp;
T&amp;&amp; + &amp;&amp;  = T&amp;&amp;
</code></pre><p>上面的规则被简化为：只要出现左值引用，规则总是优先折叠为左值引用。仅当出现两个右值引用才会折叠为右值引用。</p>
<h3 id="再谈转发"><a href="#再谈转发" class="headerlink" title="再谈转发"></a>再谈转发</h3><p>那么上面的引用折叠规则，对完美转发有什么用呢？我们注意到，对于T&amp;&amp;类型，它和左值引用折叠为左值引用，和右值引用折叠为右值引用。基于这种特性，我们可以用 T&amp;&amp; 作为我们的转发函数模板参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">template&lt;typename T&gt;</span><br><span class="line">void Forward(T&amp;&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	Do(static_cast&lt;T&amp;&amp;&gt;(t));</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这样，无论Forward接收到的是左值，右值，常量，非常量，t都能保持为其正确类型。</p>
<p>当传入左值引用 X&amp; 时：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void Forward(X&amp; &amp;&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	Do(static_cast&lt;X&amp; &amp;&amp;&gt;(t));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>折叠后：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void Forward(X&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	Do(static_cast&lt;X&amp;&gt;(t));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的static_cast看起来似乎是没有必要，而它实际上是为右值引用准备的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void Forward(X&amp;&amp; &amp;&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	Do(static_cast&lt;X&amp;&amp; &amp;&amp;&gt;(t));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>折叠后：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void Forward(X&amp;&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	Do(static_cast&lt;X&amp;&amp;&gt;(t));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>前面提到过，可以接收右值的右值引用本身却是个左值，因为它具名并且可以取值。因此在<code>Forward(X&amp;&amp; t)</code>中，参数t已经是一个左值了，此时我们需要将其转换为它本身传入的类型，即为右值。由于static_cast中引用折叠的存在，我们总能还原参数本来的类型。</p>
<p>在C++11中，<code>static_cast&lt;T&amp;&amp;&gt;(t)</code> 可以通过 <code>std::forward&lt;T&gt;(t)</code> 来替代，<code>std::forward</code>是C++11用于实现完美转发的一个函数，它和<code>std::move</code>一样，都通过static_cast来实现。我们的Forward函数最终变成了：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">template&lt;typename T&gt;</span><br><span class="line">void Forward(T&amp;&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	Do(std::forward&lt;T&gt;(t));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以通过如下代码来测试：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">void Do(int&amp; i)       &#123; cout &lt;&lt; &quot;左值引用&quot;    &lt;&lt; endl; &#125;</span><br><span class="line">void Do(int&amp;&amp; i)      &#123; cout &lt;&lt; &quot;右值引用&quot;    &lt;&lt; endl; &#125;</span><br><span class="line">void Do(const int&amp; i)  &#123; cout &lt;&lt; &quot;常量左值引用&quot; &lt;&lt; endl; &#125;</span><br><span class="line">void Do(const int&amp;&amp; i) &#123; cout &lt;&lt; &quot;常量右值引用&quot; &lt;&lt; endl; &#125;</span><br><span class="line"></span><br><span class="line">template&lt;typename T&gt;</span><br><span class="line">void PerfectForward(T&amp;&amp; t)&#123; Do(forward&lt;T&gt;(t)); &#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	int a;</span><br><span class="line">	const int b;</span><br><span class="line">	</span><br><span class="line">	PerfectForward(a);			&#x2F;&#x2F; 左值引用</span><br><span class="line">	PerfectForward(move(a));		&#x2F;&#x2F; 右值引用</span><br><span class="line">	PerfectForward(b);			&#x2F;&#x2F; 常量左值引用</span><br><span class="line">	PerfectForward(move(b));		&#x2F;&#x2F; 常量右值引用</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="四-附注"><a href="#四-附注" class="headerlink" title="四. 附注"></a>四. 附注</h2><p>左值和左值引用，右值和右值引用都是同一个东西，引用不是一个新的类型，仅仅是一个别名。这一点对于理解模板推导很重要。对于以下两个函数<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">template&lt;typename T&gt;</span><br><span class="line">void Fun(T t)</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F; do something...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">template&lt;typename T&gt;</span><br><span class="line">void Fun(T&amp; t)</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F; do otherthing...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><code>Fun(T t)</code>和<code>Fun(T&amp; t)</code>他们都能接受左值(引用)，它们的区别在于对参数作不同的语义，前者执行拷贝语义，后者只是取个新的别名。因此调用<code>Fun(a)</code>编译器会报错，因为它不知道你要对a执行何种语义。另外，对于<code>Fun(T t)</code>来说，由于它执行拷贝语义，因此它还能接受右值。因此调用<code>Fun(5)</code>不会报错，因为左值引用无法引用到右值，因此只有<code>Fun(T t)</code>能执行拷贝。</p>
<p>最后，附上VS中 <code>std::move</code> 和 <code>std::forward</code> 的源码:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F; move</span><br><span class="line">template&lt;class _Ty&gt; </span><br><span class="line">inline typename remove_reference&lt;_Ty&gt;::type&amp;&amp; move(_Ty&amp;&amp; _Arg) _NOEXCEPT</span><br><span class="line">&#123;	</span><br><span class="line">	return ((typename remove_reference&lt;_Ty&gt;::type&amp;&amp;)_Arg);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; forward</span><br><span class="line">template&lt;class _Ty&gt; </span><br><span class="line">inline _Ty&amp;&amp; forward(typename remove_reference&lt;_Ty&gt;::type&amp; _Arg)</span><br><span class="line">&#123;	&#x2F;&#x2F; forward an lvalue</span><br><span class="line">	return (static_cast&lt;_Ty&amp;&amp;&gt;(_Arg));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">template&lt;class _Ty&gt; </span><br><span class="line">inline 	_Ty&amp;&amp; forward(typename remove_reference&lt;_Ty&gt;::type&amp;&amp; _Arg) _NOEXCEPT</span><br><span class="line">&#123;	&#x2F;&#x2F; forward anything</span><br><span class="line">	static_assert(!is_lvalue_reference&lt;_Ty&gt;::value, &quot;bad forward call&quot;);</span><br><span class="line">	return (static_cast&lt;_Ty&amp;&amp;&gt;(_Arg));</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>c/c++</category>
      </categories>
      <tags>
        <tag>c/c++</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ 编译模型</title>
    <url>/2015/03/cpp-compile-model/</url>
    <content><![CDATA[<p>C++继承了C的编译模型，而C是一门古老的语言，它的编译链接模型受限于当时的硬件条件限制，并且该模型也足够用于简洁的C。而C++继承了这些机制之后，引发了更为复杂的一些问题。</p>
<h2 id="C-编译模型"><a href="#C-编译模型" class="headerlink" title="C 编译模型"></a>C 编译模型</h2><p>首先简要介绍一下C的编译模型：</p>
<p>限于当时的硬件条件，C编译器不能够在内存里一次性地装载所有程序代码，而需要将代码分为多个源文件，并且分别编译。并且由于内存限制，编译器本身也不能太大，因此需要分为多个可执行文件，进行分阶段的编译。在早期一共包括7个可执行文件：cc(调用其它可执行文件)，cpp(预处理器)，c0(生成中间文件)，c1(生成汇编文件)，c2(优化，可选)，as(汇编器，生成目标文件)，ld(链接器)。</p>
<h3 id="1-隐式函数声明"><a href="#1-隐式函数声明" class="headerlink" title="1. 隐式函数声明"></a>1. 隐式函数声明</h3><p>为了在减少内存使用的情况下实现分离编译，C语言还支持”隐式函数声明”，即代码在使用前文未定义的函数时，编译器不会检查函数原型，编译器假定该函数存在并且被正确调用，还假定该函数返回int，并且为该函数生成汇编代码。此时唯一不确定的，只是该函数的函数地址。这由链接器来完成。如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	printf(&quot;ok\n&quot;);</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在gcc上会给出隐式函数声明的警告，但能编译运行通过。因为在链接时，链接器在libc中找到了printf符号的定义，并将其地址填到编译阶段留下的空白中。PS：用g++编译则会生成错误：<code>use of undeclared identifier &#39;printf&#39;</code>。而如果使用的是未经定义的函数，如上面的printf函数改为print，得到的将是链接错误，而不是编译错误。</p>
<span id="more"></span>
<h3 id="2-头文件"><a href="#2-头文件" class="headerlink" title="2. 头文件"></a>2. 头文件</h3><p>有了隐式函数声明，编译器在编译时应该就不需要头文件了，编译器可以按函数调用时的代码生成汇编代码，并且假定函数返回int。而C头文件的最初目的是用于方便文件之间共享数据结构定义，外部变量，常量宏。早期的头文件里，也只包含这三样东西。注意，没有提到函数声明。</p>
<p>而如今在引入将函数声明放入头文件这一做法后，带来了哪些便利和缺陷：</p>
<p>优点：</p>
<ul>
<li>项目不同的文件之间共享接口。</li>
<li>头文件为第三方库提供了接口说明。</li>
</ul>
<p>缺点：</p>
<ul>
<li>效率性：为了使用一个简单的库函数，编译器可能要parse成千上万行预处理之后的头文件源码。</li>
<li>传递性：头文件具有传递性。在头文件传递链中任一头文件变动，都将导致包含该头文件的所有源文件重新编译。哪怕改动无关紧要(没有源文件使用被改动的接口)。</li>
<li>差异性：头文件在编译时使用，动态库在运行时使用，二者有可能因为版本不一致造成二进制兼容问题。</li>
<li>一致性：头文件函数声明和源文件函数实现的参数名无需一致。这将可能导致函数声明的意思，和函数具体实现不一致。如声明为 <code>void draw(int height, int width)</code> 实现为 <code>void draw(int width, int height)</code>。</li>
</ul>
<h3 id="3-单遍编译-One-Pass"><a href="#3-单遍编译-One-Pass" class="headerlink" title="3. 单遍编译( One Pass )"></a>3. 单遍编译( One Pass )</h3><p>由于当时的编译器并不能将整个源文件的语法树保存在内存中，因此编译器实际上是”单遍编译”。即编译器从头到尾地编译源文件，一边解析，一边即刻生成目标代码，在单遍编译时，编译器只能看到已经解析过的部分。 意味着：</p>
<ul>
<li>C语言结构体需要先定义，才能访问。因为编译器需要知道结构体定义，才知道结构体成员类型和偏移量，并生成目标代码。</li>
<li>局部变量必须先定义，再使用。编译器需要知道局部变量的类型和在栈中的位置。</li>
<li>外部变量(全局变量)，编译器只需要知道它的类型和名字，不需要知道它的地址，就能生成目标代码。而外部变量的地址将留给连接器去填。</li>
<li>对于函数，根据隐式函数声明，编译器可以立即生成目标代码，并假定函数返回int，留下空白函数地址交给连接器去填。</li>
</ul>
<p>C语言早期的头文件就是用来提供结构体定义和外部变量声明的，而外部符号(函数或外部变量)的决议则交给链接器去做。</p>
<p>单遍编译结合隐式函数声明，将引出一个有趣的例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void bar()</span><br><span class="line">&#123;</span><br><span class="line">	foo(&#39;a&#39;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int foo(char a)</span><br><span class="line">&#123;</span><br><span class="line">	printf(&quot;foobar\n&quot;);</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	bar();</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>gcc编译上面的代码，得到如下错误：</p>
<pre><code>test.c:16:6: error: conflicting types for &#39;foo&#39;
void foo(char a)
 ^
test.c:12:2: note: previous implicit declaration is here
    foo(&#39;a&#39;);
</code></pre><p>这是因为当编译器在bar()中遇到foo调用时，编译器并不能看到后面近在咫尺的foo函数定义。它只能根据隐式函数声明，生成<code>int foo(int)</code>的函数调用代码，注意隐式生成的函数参数为int而不是char，这应该是编译器做的一个向上转换，向int靠齐。在编译器解析到更为适合的<code>int foo(char)</code>时，它可不会认错，它会认为foo定义和编译器隐式生成的foo声明不一致，得到编译错误。将上面的foo函数替换为 <code>void foo(int a)</code>也会得到类似的编译错误，C语言严格要求一个符号只能有一种定义，包括函数返回值也要一致。</p>
<p>而将foo定义放于bar之前，就编译运行OK了。</p>
<h2 id="C-编译模型-1"><a href="#C-编译模型-1" class="headerlink" title="C++ 编译模型"></a>C++ 编译模型</h2><p>到目前为止，我们提到的3点关于C编译模型的特性，对C语言来说，都是利多于弊的，因为C语言足够简单。而当C++试图兼容这些特性时(C++没有隐式函数声明)，加之C++本身独有的重载，类，模板等特性，使得C++更加难以理解。</p>
<h3 id="1-单遍编译"><a href="#1-单遍编译" class="headerlink" title="1. 单遍编译"></a>1. 单遍编译</h3><p>C++没有隐式函数声明，但它仍然遵循单遍编译，至少看起来是这样，单遍编译语义给C++带来的影响主要是重载决议和名字解析。</p>
<h4 id="1-1-重载决议"><a href="#1-1-重载决议" class="headerlink" title="1.1 重载决议"></a>1.1 重载决议</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">void foo(int a)</span><br><span class="line">&#123;</span><br><span class="line">	printf(&quot;foo(int)\n&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void bar()</span><br><span class="line">&#123;</span><br><span class="line">	foo(&#39;a&#39;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void foo(char a)</span><br><span class="line">&#123;</span><br><span class="line">	printf(&quot;foo(char)\n&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	bar();</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上代码通过g++编译运行结果为：<code>foo(int)</code>。尽管后面有更合适的函数原型，但C++在解析bar()时，只看到了<code>void foo(int)</code>。</p>
<p>这是C++重载结合单遍编译造成的困惑之一，即使现在C++并非真的单遍编译(想一下前向声明)，但它要和C兼容语义，因此不得不”装傻”。对于C++类是个例外，编译器会先扫描类的定义，再解析成员函数，因此类中所有同名函数都能参加重载决议。</p>
<p>关于重载还有一点就是C的隐式类型转换也给重载带来了麻烦：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; Case 1</span><br><span class="line">void f(int)&#123;&#125;</span><br><span class="line">void f(unsigned int)&#123;&#125;</span><br><span class="line">void test() &#123; f(5); &#125; &#x2F;&#x2F; call f(int)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Case 2</span><br><span class="line">void f(int)&#123;&#125;</span><br><span class="line">void f(long)&#123;&#125;</span><br><span class="line">void test() &#123; f(5); &#125; &#x2F;&#x2F; call f(int)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Case 3</span><br><span class="line">void f(unsigned int)&#123;&#125;</span><br><span class="line">void f(long)&#123;&#125;</span><br><span class="line">void test() &#123; f(5); &#125; &#x2F;&#x2F; error. 编译器也不知道你要干啥</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Case 4</span><br><span class="line">void f(unsigned int)&#123;&#125;</span><br><span class="line">void test&#123; f(5); &#125; &#x2F;&#x2F; call f(unsigned int)...</span><br><span class="line">void f(long)&#123;&#125;</span><br></pre></td></tr></table></figure>
<p>再加上C++子类到父类的隐式转换，转换运算符的重载… 你必须费劲心思，才能确保编译器按你预想的去做。</p>
<h4 id="1-2-名字查找"><a href="#1-2-名字查找" class="headerlink" title="1.2 名字查找"></a>1.2 名字查找</h4><p>单遍编译给C++造成的另一个影响是名字查找，C++只能通过源码来了解名字的含义，比如 <code>AA BB(CC)</code>，这句话即可以是声明函数，也可以是定义变量。编译器需要结合它解析过的所有源代码，来判断这句话的确切含义。当结合了C++ template之后，这种难度几何攀升。因此不经意地改动头文件，或修改头文件包含顺序，都可能改变语句语义和代码的含义。</p>
<h3 id="2-头文件-1"><a href="#2-头文件-1" class="headerlink" title="2. 头文件"></a>2. 头文件</h3><p>在初学C++时，函数声明放在.h文件，函数实现放在.cpp文件，似乎已经成了共识。C++没有C的隐式函数声明，也没有其它高级语言的包机制，因此，同一个项目中，头文件已经成了模块与模块之间，类与类之间，共享接口的主要方式。</p>
<p>C中的效率性，传递性，差异性，一致性，C++都一个不落地继承了。除此之外，C++头文件还带来如下麻烦：</p>
<h4 id="2-1-顺序性"><a href="#2-1-顺序性" class="headerlink" title="2.1 顺序性"></a>2.1 顺序性</h4><p>由于C++头文件包含更多的内容：template, typedef, #define, #pragma, class,等等，不同的头文件包含顺序，将可能导致完全不同的语义。或者直接导致编译错误。</p>
<h4 id="2-2-又见重载"><a href="#2-2-又见重载" class="headerlink" title="2.2 又见重载"></a>2.2 又见重载</h4><p>由于C++支持重载，因此如果头文件中的函数声明和源文件中函数实现不一致(如参数个数，const属性等)，将可能构成重载，这个时候”聪明”的C++编译器不错报错，它将该函数的调用地址交给链接器去填，而源文件中写错了的实现将被认定为一个全新的重载。从而到链接阶段才报错。这一点在C中会得到编译错误，因为C没有重载，也就没有名字改编(name mangling)，将会在编译时得到符号冲突。</p>
<h4 id="2-3-重复包含"><a href="#2-3-重复包含" class="headerlink" title="2.3 重复包含"></a>2.3 重复包含</h4><p>由于头文件的传递性，有可能造成某上层头文件的重复包含。重复包含的头文件在展开后，将可能导致符号重定义，如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; common.h</span><br><span class="line">class Common</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F; ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; h1.h</span><br><span class="line">#include &quot;common.h&quot;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; h2.h</span><br><span class="line">#include &quot;common.h&quot;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; test.cpp</span><br><span class="line">#include &quot;h1.h&quot;</span><br><span class="line">#include &quot;h2.h&quot;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果common.h中，有函数定义，结构体定义，类声明，外部变量定义等等。test.cpp中将展开两份common.h，编译时得到符号重定义的错误。而如果common.h中只有外部函数声明，则OK，因为<strong>函数可在多处声明，但只能在一处定义</strong>。关于类声明，C++类保持了C结构体语义，因此叫做”类定义”更为适合。始终记得，<strong>头文件只是一个公共代码的整合，这些代码会在预编译期替换到源文件中</strong>。</p>
<p>为了解决重复包含，C++头文件常用 <code>#ifndef #define #endif</code>或<code>#pragma once</code>来保证头文件不被重复包含。</p>
<h4 id="2-4-交叉包含"><a href="#2-4-交叉包含" class="headerlink" title="2.4 交叉包含"></a>2.4 交叉包含</h4><p>C++中的类出现相互引用时，就会出现交叉包含的情况。如Parent包含一个Child对象，而Child类包含Parent的引用。因此相互包含对方的头文件，编译器展开Child.h需要展开Parent.h，展开Parent.h又要展开Child.h，如此无限循环，最终g++给出：<code>error: #include nested too deeply</code>的编译错误。</p>
<p>解决这个问题的方案是前向声明，在Child类定义前面加上 <code>class Parent;</code> 声明Parent类，而无需包含其头文件。前向声明不止可以用于类，还可以用于函数(即显式的函数声明)。<strong>前向声明应该被大量使用，它可以解决头文件带来的绝大多数问题，如效率性，传递性，重复包含，交叉包含等等。</strong>这一点有点像包(package)机制，需要什么，就声明(导入)什么。<strong>前向声明也有局限：仅当编译器无需知道目标类完整定义时</strong>。如下情形，类A可使用 <code>class B;</code>：</p>
<ul>
<li>类A中使用B声明引用或指针；</li>
<li>类A使用B作为函数参数类型或返回类型，而不使用该对象，即无需知道其构造函数和析构函数或成员函数；</li>
</ul>
<h4 id="2-5-如何使用头文件"><a href="#2-5-如何使用头文件" class="headerlink" title="2.5 如何使用头文件"></a>2.5 如何使用头文件</h4><p>关于头文件使用的建议：</p>
<ul>
<li>降低将文件间的编译依赖(如使用前向声明)；</li>
<li>将头文件归类，按照特定顺序包含，如C语言系统头文件，C++系统头文件，项目基础头文件，项目头文件；</li>
<li>防止头文件重复编译(#ifndef or #pragma)；</li>
<li>确保头文件和源文件的一致；</li>
</ul>
<hr>
<h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h3><p>C语言本身一些比较简单的特性，放在C++中却引起了很多麻烦，主要是因为C++复杂的语言特性：类，模板，各种宏… 举个例子来说，对于一个类A，它有一个私有函数，需要用到类B，而这个私有函数必须出现在类定义即头文件中，因此就增加了A头文件对B的不必要引用。这是因为C++类遵循C结构体的语义，所有类成员都必须出现在类定义中，”属于这个类的一部分”。这不仅在定义上造成不便，也在容易在语义上造成误解，事实上，C++类的成员函数不属于对象，它更像普通函数(虚函数除外)。</p>
<p>而在C中，没有”类的捆绑”，实现起来就要简单多了，将该函数放在A.c中，函数不在A.h中声明。由A.c包含B.h，解除了A.h和B.h之间的关联，这也是C将数据和操作分离的优势之一。</p>
<p>最后，看看其它语言是如何避免这些”坑”的：</p>
<ul>
<li>对于解释型语言，import的时候直接将对应模块的源文件解析一遍，而不是将文件包含进来；</li>
<li>对于编译型语言，编译后的目标文件中包含了足够的元数据，不需要读取源文件(也就没有头文件一说了)；</li>
</ul>
<p>它们都避免了定义和声明不一致的问题，并且在这些语言里面，定义和声明是一体的。import机制可以确保只到处必要的名字符号，不会有多余的符号加进来。</p>
]]></content>
      <categories>
        <category>c/c++</category>
      </categories>
      <tags>
        <tag>c/c++</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang mnesia</title>
    <url>/2015/04/erlang-mnesia/</url>
    <content><![CDATA[<p>mnesia是基于Erlang的分布式数据库管理系统，是Erlang OTP的重要组件。</p>
<h2 id="基础特性"><a href="#基础特性" class="headerlink" title="基础特性"></a>基础特性</h2><h3 id="1-分布式的ets"><a href="#1-分布式的ets" class="headerlink" title="1. 分布式的ets"></a>1. 分布式的ets</h3><p>mnesia数据库被组织为一个表的集合，每个表由记录(通常被定义为Erlang Record)构成，表本身也包含一些属性，如类型，位置和持久性。这种表集合和记录的概念，和ets表很类似。事实上，mnesia中的数据在节点内就是以ets表存储的。因此，mnesia实际上是一个分布式的ets。</p>
<h3 id="2-表的存储形式"><a href="#2-表的存储形式" class="headerlink" title="2. 表的存储形式"></a>2. 表的存储形式</h3><p>mnesia中的表在节点内有三种存储形式：</p>
<ul>
<li><code>ram_copies</code>: 表仅存储于内存，可通过<code>mnesia:dump_tables(TabList)</code>来将数据导入到硬盘。</li>
<li><code>disc_copies</code>: 表存储于内存中，但同时拥有磁盘备份，对表的写操作会分为两步：1.将写操作写入日志文件 2. 对内存中的表执行写操作</li>
<li><code>disc_only_copies</code>: 表仅存储于磁盘中，对表的读写将会更慢，但是不会占用内存</li>
</ul>
<p>表的存储形式可以在表的创建中指出，默认为ram_copies。也可以在创建表后通过<code>mnesia:change_table_copy_type/3</code>来修改。</p>
<span id="more"></span>
<h3 id="3-表的重要属性"><a href="#3-表的重要属性" class="headerlink" title="3. 表的重要属性"></a>3. 表的重要属性</h3><p>表的属性由<code>mnesia:create_table(Name, TableDef)</code>中的TableDef指定，TableDef是一个Tuple List，其中比较重要的属性有：</p>
<ul>
<li><code>type</code>: 表的类型，主要有set, ordered_set和bag三种。前两者要求key唯一，bag不要求key唯一，但要求至少有一个字段不同。另外set和bag通过哈希表实现，而ordered_set则使用其它数据结构(如红黑树)以对key排序。type属性默认为set。</li>
<li><code>attributes</code>: 表中条目的字段，通常由record_info(fields, myrecord)得出，而myrecord一般则用作表名。</li>
<li><code>local_content</code>: 标识该表是否为本地表，local_content属性为true的表将仅本地可见，不会共享到集群中。local_content默认为false。</li>
<li><code>index</code>: 表的索引。</li>
<li><code>ram_copies</code>: 指名该表在哪些节点上存储为ram_copies。默认值为[node()]。即新建表默认都存储为ram_copies。</li>
<li><code>disc_copies</code>: 该表在哪些节点上存储为disc_copies。默认为[]。</li>
<li><code>disc_only_copies</code>: 该表在哪些节点上存储为disc_only_copies。默认为[]。</li>
</ul>
<h3 id="4-schema表"><a href="#4-schema表" class="headerlink" title="4. schema表"></a>4. schema表</h3><p>schema表是mnesia数据库一张特殊的表，又叫模式表。它记录数据库中其它表的信息，schema表只能有ram_copies或disc_copies两种存储形式。并且一旦schema表存储为ram_copies，那么该节点上的其它表，也将只能存储为ram_copies。</p>
<p>mnesia需要schema表的初始化自身，可在mnesia启动前，通过<code>mnesia:create_schema/1</code>来创建一个disc_copies类型的schema表，如果不调用<code>mnesia:create_schema/1</code>，直接启动<code>mnesia:start/0</code>，默认生成一个ram_copies类型的schema表，此时我们称该mnesia节点为”无盘节点”，因为其所有表都不能存储于磁盘中。</p>
<h3 id="5-单节点使用示例"><a href="#5-单节点使用示例" class="headerlink" title="5. 单节点使用示例"></a>5. 单节点使用示例</h3><pre><code>➜  ~  erl -mnesia dir &#39;&quot;Tmp/ErlDB/test&quot;&#39;

Erlang/OTP 17 [erts-6.3.1] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]

Eshell V6.3.1  (abort with ^G)
# 创建disc_copies存储类型的schema表 但其它表的默认存储类型仍然为ram_copies
1&gt; mnesia:create_schema([node()]).
ok
2&gt; mnesia:start().
ok
3&gt; rd(person, &#123;name, sex, age&#125;).
person
# 创建disc_copies存储类型的table，table的fields即为person记录的fields
4&gt; mnesia:create_table(person, [&#123;disc_copies, [node()]&#125;, &#123;attributes, record_info(fields, person)&#125;]).
&#123;atomic,ok&#125;
# 等价于mnesia:dirty_write(&#123;person, &quot;wdj&quot;, undefined, 3&#125;)
5&gt; mnesia:dirty_write(#person&#123;name=&quot;wdj&quot;, age=3&#125;).
ok
6&gt; mnesia:dirty_read(person, &quot;wdj&quot;).
[#person&#123;name = &quot;wdj&quot;,sex = undefined,age = 3&#125;]
</code></pre><p><code>record_info(fileds, person)</code>返回<code>[name,sex,age]</code>，<code>mnesia:create_table/2</code>默认将attributes属性中的第一个field作为key，即name。</p>
<p>mnesia:read, mnesia:write, mnesia:select等API均不能直接调用，需要封装在事务（transaction）中使用：</p>
<pre><code>F = fun() -&gt;  
    Rec = #person&#123;name=&quot;BigBen&quot;, sex=1, age=99&#125;,  
    mnesia:write(Rec)  
end,  
mnesia:transaction(F). 
</code></pre><p>而对应的<code>mnesia:dirty_read</code>，<code>mnesia:dirty_write</code>，即”脏操作”，无需事务保护，也就没有锁，事务管理器等。dirty版本的读写一般要比事务性读写快十倍以上。但是失去了原子性和隔离性。</p>
<h3 id="6-表名与记录名"><a href="#6-表名与记录名" class="headerlink" title="6. 表名与记录名"></a>6. 表名与记录名</h3><p>mnesia表由记录组成，记录第一个元素为是记录名，第二个元素为标识记录的键。{表名，键}可以唯一标识表中特定记录，又称为记录的对象标识(Oid)。</p>
<p>mnesia要求表中所有的记录必须为同一个record的实例，前面的例子中，表名即为记录名，表字段则为记录的域。而实际上，记录名可以是但不一定是表名，记录名可通过record_name属性指出，没有指定table_name则记录名默认为create_table第一参数指定的表名。</p>
<pre><code>mnesia:dirty_write(Record) -&gt;
    Tab = element(1, Record), 
    mnesia:dirty_write(Tab, Record). % 这里提取出表名，表名和表中记录原型实际上是分离的
</code></pre><p>表名和记录名不一致使我们可以定义多个以同一record的原型的table。</p>
<h2 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h2><pre><code>% 创建集群 需要各节点的mnesia都未启动
mnesia:create_schema([&#39;node1@host,&#39;node2@host&#39;])
% 创建表 指明在各节点上的存储类型 如果没指定，则为remote类型
mnesia:create_table(person, [&#123;ram_copies,[&#39;node1@host&#39;]&#125;])
% 删除表的所有备份
mnesia:delete_table(person)
% 删除整个schema和表数据(包含持久化文件)
mnesia:delete_table([&#39;node1@host,&#39;node2@host&#39;])

% 集群动态配置能力
% 动态加入集群(等价于启动参数：-mnesia extra_db_nodes NodeList)
mnesia:change_config(extra_db_nodes, [&#39;node3@host&#39;])
% 动态修改表的存储类型
mnesia:change_table_copy_type(person, node(), disc_copies)
% 添加远程表的本地备份
mnesia:add_table_copy(person, &#39;node3@host&#39;, ram_copies)
% 迁移表备份 表存储类型不变
mnesia:move_table_copy(person, &#39;node3@host&#39;, &#39;node4host&#39;)
% 删除表的本节点备份
mnesia:del_table_copy(person, &#39;node3@host&#39;)
% 对表的元数据和所有记录进行热升级
mnesia:transform_table(Tab, Fun, NewAttributeList, NewRecordName)
</code></pre><ul>
<li><a href="http://veniceweb.googlecode.com/svn/trunk/public/daily_tech_doc/erlang_faq_20091125.txt">这篇FAQ</a>中归纳了mnesia集群的大多数问题</li>
<li>在新节点动态加入集群的过程中，如果新节点mnesia已经启动，启动的节点会尝试将其表定义与其它节点带来的表定义合并。这也应用于模式表自身的定义</li>
<li>mnesia会同步集群中节点上所有的表信息，如果某节点需要自己本地维护一张表而不希望共享该表，可以在创建表时指定<code>local_content</code>属性。该类型的表表名对mnesia可见，但每个节点写入的数据不会被同步，即每个节点都只能看到自己写入的数据</li>
<li>mnesia后台同步时，会形成一个全联通网络(即使集群节点都是hidden节点)</li>
<li>如果新加入节点和已有集群的schema表都是disc_copies，则会merge schema failed</li>
</ul>
<h2 id="特性总结"><a href="#特性总结" class="headerlink" title="特性总结"></a>特性总结</h2><p>mneisa的优势:</p>
<ul>
<li>与Erlang的完美契合，记录字段可以是任意Erlang Term，具备强大的描述能力</li>
<li>和传统数据库一样，支持事务，索引，分片等特性</li>
<li>分布式特性，表的存储类型和位置对应用透明，支持分布式事务</li>
<li>强大的动态配置能力，包括集群的动态伸缩，表的动态配置，增删，转移，升级等</li>
</ul>
<p>mnesia缺点：</p>
<ul>
<li>多节点事务带来的开销，尽可能少使用事务(在逻辑上配合做处理)</li>
<li>mnesia全联通网络的维护开销，在使用时需要控制集群节点数量</li>
<li>不适合存储大量数据，这会带来网络负载</li>
</ul>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul>
<li><a href="http://www.erlang.org/doc/man/mnesia.html" title="erlang mnesia">Erlang Mnesia Man Page</a></li>
<li><a href="http://www.erlang.org/doc/apps/mnesia/Mnesia_chap3.html" title="building a mnesia database">Building A Mnesia Database</a></li>
<li><a href="http://www.hitb.com.cn/c/document_library/get_file?p_l_id=10190&amp;folderId=11012&amp;name=DLFE-1103.pdf" title="mnesia用户手册">Mnesia 中文版 用户手册</a></li>
</ul>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang 热更新</title>
    <url>/2015/04/erlang-hotcode/</url>
    <content><![CDATA[<p>erlang 热更是指在erlang系统不停止运行的情况下，对模块代码进行更新的特性，这也是erlang最神奇的特性之一。特别适用于游戏服务器，做活动更新，漏洞修复等。</p>
<h2 id="一-简单示例"><a href="#一-简单示例" class="headerlink" title="一. 简单示例"></a>一. 简单示例</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%% 示例一 </span><br><span class="line">-module(test).</span><br><span class="line"></span><br><span class="line">-export([start&#x2F;0, run&#x2F;0]).</span><br><span class="line"></span><br><span class="line">f() -&gt;</span><br><span class="line">	io:format(&quot;this is old code~n&quot;).</span><br><span class="line"></span><br><span class="line">run() -&gt;</span><br><span class="line">	f(),</span><br><span class="line">	timer:sleep(5000),</span><br><span class="line">	?MODULE:run().</span><br><span class="line"></span><br><span class="line">start() -&gt;</span><br><span class="line">	spawn(fun() -&gt; run() end).</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<ol>
<li><p>在erl shell中运行test:</p>
<pre><code> Eshell V6.3.1  (abort with ^G)
 1&gt; c(test).
 &#123;ok,test&#125;
 2&gt; test:start().
 this is old code
 &lt;0.39.0&gt;
 this is old code
 this is old code
</code></pre></li>
<li><p>修改test.erl代码，将f()输出改为 <code>io:format(&quot;this is new code~n&quot;).</code>。</p>
</li>
<li><p>在erl shell中，<strong>重新编译并加载</strong>test模块。</p>
<p> 可通过<code>erlc test.erl</code>完成模块编译，然后在erl shell中通过<code>l(test).</code>完成加载。也可直接在erl shell 中通过<code>c(test).</code>单步完成编译和加载。</p>
<pre><code> 3&gt; c(test).
 &#123;ok,test&#125;
</code></pre></li>
<li><p>观察完整<code>test:run()</code>运行结果：</p>
<pre><code> 1&gt; c(test).
 &#123;ok,test&#125;
 2&gt; test:run().
 this is old code
 &lt;0.39.0&gt;
 this is old code
 this is old code
 3&gt; c(test).
 &#123;ok,test&#125;
 this is new code
 this is new code
 ...
</code></pre></li>
</ol>
<h2 id="二-热更原理"><a href="#二-热更原理" class="headerlink" title="二. 热更原理"></a>二. 热更原理</h2><h3 id="2-1-两个条件"><a href="#2-1-两个条件" class="headerlink" title="2.1 两个条件"></a>2.1 两个条件</h3><p>Erlang代码热更需要两个基本条件：</p>
<ul>
<li>将修改后的代码重新编译并加载</li>
<li>只有外部调用(完全限定方式调用)才会使用新版本的代码</li>
</ul>
<p>第一个条件在上面示例中已经做过，要注意的是，使用erlc命令行工具编译.erl源文件后，需要在erl shell中加载模块，才能将新模块代码更新到erlang虚拟机中。而我们平时通过erlc编译，然后直接进入erl shell使用模块，事实上是Erlang虚拟机自动在系统路径中查找并加载了对应模块。</p>
<p>第二个条件所谓的外部调用(external calls)，即 <code>Mod:Func(Arg)</code> 形式的调用。而对应的本地调用是指 <code>Func(Arg)</code>。本地调用的函数比外部调用更快，并且调用的函数无需导出。erlang热更新只会对外部调用应用最新的模块代码，而对于本地调用则会一直使用旧版本的代码。</p>
<p>在上面的例子中，我们在尾递归中使用<code>?MODULE:run()</code>实现了外部调用，因此每一次都会检查并应用最新的模块代码。而如果将该调用其改为run()。则将一直使用当前版本的代码，始终输出<code>this is old code</code>。</p>
<p>需要注意的是，<strong>erlang更新虽然以模块为单位，但却执行”部分更新”，即对于某外部调用f()，运行时系统仅更新f()函数所引用的代码，即f()函数和其依赖的函数(无论何种调用形式)的代码。</strong>比如示例一中，对run函数的外部调用，完成了对f()函数的代码更新，因为run()函数依赖f()函数。</p>
<p>而反过来，对f()的外部调用，不会更新run()的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%% 示例二</span><br><span class="line">-module(test2).</span><br><span class="line">-export([start&#x2F;0, f&#x2F;0]).</span><br><span class="line"></span><br><span class="line">f() -&gt;</span><br><span class="line">    io:format(&quot;this is old code~n&quot;).</span><br><span class="line"></span><br><span class="line">run() -&gt;</span><br><span class="line">    ?MODULE:f(),</span><br><span class="line">    timer:sleep(5000),</span><br><span class="line">    run().</span><br><span class="line"></span><br><span class="line">start() -&gt;</span><br><span class="line">    spawn(fun() -&gt; run() end).</span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>编译并运行，再修改test2.erl:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%% 示例二 新版本代码</span><br><span class="line">-module(test2).</span><br><span class="line">-export([start&#x2F;0, f&#x2F;0]).</span><br><span class="line"></span><br><span class="line">f() -&gt;</span><br><span class="line">	io:format(&quot;this is new code~n&quot;).</span><br><span class="line"></span><br><span class="line">run() -&gt;</span><br><span class="line">	io:format(&quot;say hello~n&quot;),</span><br><span class="line">	?MODULE:f(),</span><br><span class="line">	timer:sleep(5000),</span><br><span class="line">	run().</span><br><span class="line"></span><br><span class="line">start() -&gt;</span><br><span class="line">	spawn(fun() -&gt; run() end).</span><br></pre></td></tr></table></figure>
<p>编译并加载新模块代码，得到的输出将和示例一类似，而不会打印出”say hello”。</p>
<h3 id="2-2-新旧更迭"><a href="#2-2-新旧更迭" class="headerlink" title="2.2 新旧更迭"></a>2.2 新旧更迭</h3><p>当模块有新版本的代码被载入时，之后对该模块执行的外部调用将依次加载模块最新代码，其它没有更新模块代码的进程仍然可以使用模块的当前版本(现在已经是旧版本)代码。erlang系统中同一模块最多可以存在两个版本的代码同时运行。</p>
<p>如果有进程一直在执行旧版本代码，没有更新，也没有结束，那么当模块代码需要再次更新时，erlang将kill掉仍在执行旧版本代码的进程，然后再执行本次更新。</p>
<h3 id="2-3-更新策略"><a href="#2-3-更新策略" class="headerlink" title="2.3 更新策略"></a>2.3 更新策略</h3><p>erlang中的热更是通过code_server模块来实现的，code_server模块是kernel的一部分，它的职责是将已经编译好的模块加载到运行时环境。code_server有两种启动策略，embedded和interactive(默认)两种模式：</p>
<ul>
<li>embeded模式：指模块加载顺序需要预先定义好，code_server会严格按照加载顺序来加载模块</li>
<li>interactive模式：模块只有在被引用到时才会被加载</li>
</ul>
<h2 id="三-控制更新"><a href="#三-控制更新" class="headerlink" title="三. 控制更新"></a>三. 控制更新</h2><p>如果要在模块代码中实现对更新机制的控制，比如代码希望处理完某个逻辑流程之后，检查并应用更新。可以如下这样：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%% 示例三</span><br><span class="line">-module(hotfix).</span><br><span class="line">-export([server&#x2F;1, upgrade&#x2F;1, start&#x2F;0]).</span><br><span class="line"> </span><br><span class="line">-record(state, &#123;version, data&#125;).</span><br><span class="line"></span><br><span class="line">server(State) -&gt;</span><br><span class="line">	receive</span><br><span class="line">		update -&gt;</span><br><span class="line">			NewState &#x3D; ?MODULE:upgrade(State),</span><br><span class="line">			io:format(&quot;Upgrade Completed. Now verson: ~p~n&quot;, [NewState#state.version]),</span><br><span class="line">			?MODULE:server(NewState);  %% loop in the new version of the module</span><br><span class="line">		_SomeMessage -&gt;</span><br><span class="line">			%% do something here</span><br><span class="line">			io:format(&quot;Stay Old~n&quot;),</span><br><span class="line">			server(State)  %% stay in the same version no matter what.</span><br><span class="line">	end.</span><br><span class="line"></span><br><span class="line">upgrade(State) -&gt;</span><br><span class="line">	%% transform and return the state here.</span><br><span class="line">	io:format(&quot;Upgrading Code~n&quot;),</span><br><span class="line">	NewState &#x3D; State#state&#123;version&#x3D;2.0&#125;,</span><br><span class="line">	NewState.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">start() -&gt;</span><br><span class="line">	spawn(fun() -&gt; server(#state&#123;version&#x3D;1.0&#125;) end).</span><br></pre></td></tr></table></figure>
<p>示例三中，main loop 只有在收到update消息后，才会执行更新，否则通过本地调用，始终执行当前版本的代码。而发送update消息的时机可以由程序灵活控制。</p>
<p>在执行更新时，代码通过<code>?MODULE:upgrade(State)</code>来预热代码，对数据结构进行更新处理，upgrade函数由本次代码更新者提供，因此能够非常安全地进行版本过渡。之后再调用<code>?MODULE:server(NewState)</code>来进行主循环代码的更新。</p>
<p>测试一下(这里并没真正修改代码)：</p>
<pre><code>Eshell V6.3.1  (abort with ^G)
1&gt; c(hotfix).
&#123;ok,hotfix&#125;
2&gt; Pid = hotfix:start().
&lt;0.39.0&gt;
3&gt; Pid ! hello.
Stay Old
hello
4&gt; Pid ! update.
Upgrading Code
Upgrade Completed. Now verson: 2.0
update
</code></pre><h2 id="四-参考"><a href="#四-参考" class="headerlink" title="四. 参考"></a>四. 参考</h2><ul>
<li><a href="http://learnyousomeerlang.com/designing-a-concurrent-application#hot-code-loving">http://learnyousomeerlang.com/designing-a-concurrent-application#hot-code-loving</a></li>
<li><a href="http://www.erlang.org/doc/reference_manual/code_loading.html#id86381">http://www.erlang.org/doc/reference_manual/code_loading.html#id86381</a></li>
</ul>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang 随想</title>
    <url>/2015/04/erlang-thinking/</url>
    <content><![CDATA[<p>接触Erlang不到两个月时间，之前一直用C++开发。Erlang这门语言确实带给我更多的思考。</p>
<h3 id="并发模型"><a href="#并发模型" class="headerlink" title="并发模型"></a>并发模型</h3><p>在C++游戏服务器中，我们想要实现一个logger，支持多线程调用。因此该日志系统必须是线程安全的(c++标准输出<code>std::cout</code>不是线程安全的)。对应的主要有两种实现策略：</p>
<h4 id="1-共享资源"><a href="#1-共享资源" class="headerlink" title="1.共享资源"></a>1.共享资源</h4><p>常规的思维是，为了实现这个功能，去定义一个接口(函数或类)，可提供给所有用户(线程)使用。但由于多个用户共享一个IO设备资源，因此需要在接口内部通过锁或其它同步方式来实现对资源的访问控制。而锁的设计与调试历来是并发程序中最耗费精力的一部分，并且由于代码在调用线程的上下文中执行，因此接口内部发生故障也会影响到调用线程，如死循环，内存越界等。即隔离性差(包括线程之间的隔离，和模块之间的解耦)。</p>
<span id="more"></span>
<h4 id="2-消息传递"><a href="#2-消息传递" class="headerlink" title="2.消息传递"></a>2.消息传递</h4><p>另一种方式是，将logger抽象为一个单独的执行体，它可以是一个单独的线程，由它来独占IO设备资源，其它线程想要使用IO设备，都需要通知(发送消息)logger线程，由logger线程来操作IO。这样就不会出现资源访问控制的问题。当然你需要自己实现一个线程安全的消息队列，但这毕竟是公共设施，是属于框架层的。<a href="https://github.com/wudaijun/NGServer">NGServer</a>和<a href="https://github.com/cloudwu/skynet">skynet</a>就是这么做的。消息传递方式的瓶颈在于消息拷贝。</p>
<p>再举一个例子，针对于排行榜系统，玩家需要不定期的读取排行榜，而其它玩家的数据变动也会影响到排行榜数据，如果使用共享内存的方式，你可能会使用读写锁，双缓冲，share_ptr copy on write，等多种方式来优化线程之间的同步问题。但仍然是如履薄冰，因为某一次死锁或出错，都可能造成整个游戏服务器宕机。事实上排行榜系统并不是很重要，我们宁愿它无法正常服务，也不应该影响到游戏的正常逻辑。</p>
<p>通过将排行榜独立为一个服务，利用消息传递进行读取于写入，可以很大程度减轻服务之间相互影响的可能性，但往往游戏中的这一类系统太多，一是不能很好地控制和管理这些服务，二是服务之间的消息协议会越来越繁多和复杂，skynet设计者云风也<a href="http://blog.codingnow.com/2012/09/the_design_of_skynet.html">提到了这一点</a>。</p>
<hr>
<h3 id="Erlang"><a href="#Erlang" class="headerlink" title="Erlang"></a>Erlang</h3><p>终于主角出场了，Erlang是消息传递的忠实拥护者，并且构建了大量的基础设施来更好支持这一特性。我觉得Erlang的精髓在于<strong>面向进程</strong>和<strong>变量不可变语义</strong>。</p>
<h4 id="1-面向进程"><a href="#1-面向进程" class="headerlink" title="1.面向进程"></a>1.面向进程</h4><p>Erlang中的服务就是进程，Erlang中的进程比C++的线程更轻量，可以轻易数万数十万级别。Erlang进程相关的基础设施，包括消息队列，调度算法，消息编码都已经千锤百炼，拿来即用。加之工业级的OTP，消息分发和回调也完成了大半，并且更好地支持了容错和热更等机制。</p>
<p>Erlang中将逻辑抽象成进程，而不是对象，Erlang不支持面向对象。上面提到的日志和排行榜，都可以抽象成一个Erlang进程，让它来负责相关的处理。不需要锁，同时也增加了隔离性，<strong>Erlang进程封装了状态</strong>。</p>
<h4 id="2-变量不可变"><a href="#2-变量不可变" class="headerlink" title="2.变量不可变"></a>2.变量不可变</h4><p>Erlang是函数式编程语言，遵循变量不可变语义，一个变量自绑定值起，就一直代表某个值。这种语义刚开始虽然会带来一些不便，但是附带的好处却是巨大的：变量不可变进一步降低了Erlang进程之间相互影响的可能性。例如在NGServer中，你可以通过在线程之间传递指针共享信息，这样做虽通常是为了效率起见，而缺点在于线程之前的关联度增加，并且指针本身的管理和释放也并非易事。在Erlang中，所有的消息都执行拷贝，并且不存在指针引用，因此进程中拿到的消息都是独立的，不变的，这样大幅度降低了犯错的可能性。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang 服务器落地机制</title>
    <url>/2015/05/erlang-gameserver-persistence/</url>
    <content><![CDATA[<p>游戏服务器中用得最多的就是gen_server，比如游戏中的Player进程，由于gen_server提供的完善的进程设施，我们无需过多地担心进程崩溃而造成的数据丢失的问题(至少还有个terminate用于做善后工作)。因此在进行数据写回时，可以通过定时写回的机制来减轻数据库负担。这一点也是C服务器望尘莫及的。</p>
<h2 id="落地流程"><a href="#落地流程" class="headerlink" title="落地流程"></a>落地流程</h2><p>落地时机应由PlayerManager触发，PlayerManager管理所有的Player进程，每隔一段时间进行数据落地。为了避免同时对所有玩家落地造成的热点，可以将Player进程简单分区，每次对其中一个区进行落地，如此轮流。</p>
<p>落地操作交由Player进程，因为我们的绝大部分关于Player的数据都是放在进程字典中的。</p>
<p>Player进程首先遍历其相关的所有Model，取出其中变化的数据，然后更新数据库。</p>
<span id="more"></span>
<p>为了模块化，将相关模块描述为：</p>
<ul>
<li>player: 玩家进程，玩家主要业务逻辑处理，消息分发</li>
<li>player_model: 业务逻辑与数据层的中间模块，负责数据初始化和落地</li>
<li>state: 辅助管理所在进程的进程字典，跟踪数据变化。提供查询和更改进程字典，获取进程字典变化数据的接口。</li>
<li>model: 数据层，负责和数据库交互，提供insert, update等基本接口</li>
</ul>
<h2 id="实现机制"><a href="#实现机制" class="headerlink" title="实现机制"></a>实现机制</h2><p>落地实现最核心的两个模块是 player_model 和 state，前者负责Player所有数据的初始化和落地，后者负责管理Player进程字典数据，并且追踪数据的变更状态。</p>
<h3 id="player-model"><a href="#player-model" class="headerlink" title="player_model"></a>player_model</h3><p>player_model 建立了业务层到模型层的映射，它仅提供两个最重要的接口：init(PlayerId) 和 save(PlayerId)，分别负责Player所有模块的初始化(数据库 -&gt; 进程字典)和落地(进程字典 -&gt; 数据库)。</p>
<p>在player_model中，有所有Model的相关信息，包括名字，类型和所在模块等等。</p>
<pre><code>module_map() -&gt;
  [
   &#123;player_info, &#123;?INFO_STATE, single&#125;, 
    model_user, ?model_record(db_user_info)&#125;,

    .....
    %&#123;业务逻辑模块, 进程字典中的Key和存储类型 single or list&#125;,
    %&#123;数据存储模块, 数据存储字段&#125;
  ]
</code></pre><p>这样业务逻辑层和Model层被关联起来，对于save来说，最重要的是第二个字段和第三个字段，分别代表该Model在进程字典的状态，以及Model名。save流程主要如下：</p>
<ol>
<li>遍历module_map()，获取各个Model数据在进程字典中变更数据</li>
<li>根据变更状态调用对应Model接口 完成回写</li>
<li>回写完成之后，再重置各个Model的变更状态</li>
</ol>
<p>注意：</p>
<ul>
<li>1，2步是事务性的，所有Model的回写要么都成功，要么都失败，以免各个模块数据之间的数据相关性造成数据不一致的问题。在写入成功后，再次遍历module_map()，重置各个Model的状态。</li>
<li>对于list 和 single两种类型的Model需要分开处理，它们获取变更数据和回写的接口不一样，这可能还需要Model层的支持。这一点在下面state模块介绍中会提到。</li>
</ul>
<p>关于获取Model在进程字典中状态管理，通过state模块来管理。</p>
<h3 id="state"><a href="#state" class="headerlink" title="state"></a>state</h3><p>state模块管理进程字典中的数据，进程字典虽然为简单的Key-Value，但对于我们的Model来说，Value可能为单个记录(如玩家信息)或列表(如玩家建筑列表)。</p>
<p>最简单的情况是，我们单独用一个进程字典，如{Name, state}来获取Model的数据状态，数据状态可分为 origin(初始化) new(创建未保存)， update(更新) delete(删除) 在数据更新时，修改状态，在每次落地同步时，取出所有被修改的Model，并且进行落地同步。之后将数据的状态重置为origin。</p>
<p>然而这种做法对于list类型的Model效率太低，一是业务逻辑上的每次更改都需要改动每个数组，典型的例子是任务列表，玩家对某个任务领奖，导致整个任务列表的拷贝，还可能产生不必要的查找过程。更不可忍受的是，数据落地时，也将重写整个任务列表到数据库。</p>
<p>因此还有另一种方案：将list Model中的记录分开存放，并且分别标记状态，提高查找和回写效率：</p>
<pre><code>%% ------ list Model ----------

% 存放list中各个key的状态
&#123;Name, list&#125; -&gt; [&#123;key1, update&#125;, &#123;key2, delete&#125;, ...]

% 存放列表中各元素的实际数据
&#123;Name, Key&#125; -&gt;    Data

% 存放被删除的元素列表(将不能通过&#123;Name, Key&#125;找到)
&#123;Name, delete&#125; -&gt; [DeleteData1, DeleteData2, ....]

%% ------- single Model -------

% 通过 Name 存取
Name -&gt; Value

% 存放Model的更改状态
&#123;Name, state&#125; -&gt; State
</code></pre><p>如此便对Model进行了高效灵活的管理，大大减少了回写数据量。</p>
<p>state封装了进程字典的增删查改操作，并维护进程字典状态。</p>
<p>读取直接通过<code>erlang:get(Name, Key)</code>，对于任务列表来说，这个Key通常是任务ID</p>
<p>更新时：</p>
<p>对于列表:</p>
<ol>
<li>通过{Name, list}检查更新Key的状态</li>
<li>对{Name, Key}执行修改</li>
<li>对于删除操作，还需要将删除的数据放入{Name, delete}中</li>
</ol>
<p>对于单值:</p>
<ol>
<li>通过{Name, state}检查修改状态</li>
<li>对Name执行修改</li>
</ol>
<p>落地相关接口：</p>
<pre><code>% 获取list Model中的变更数据
% 返回: &#123;InsertList, UpdateList, DeleteList&#125;
get_list_changed(Name)

% 获取single Model中的数据状态
% 返回: &#123;State, Value&#125;
get_single_changed(Name)

% 重置list Model中的数据状态为origin 并且删除所有状态为delete的数据
reset_list(Name)

% 重置single Model
reset_single(Name)
</code></pre><p>player_mode根据module_map中的条目依次获取变更数据，在使用model模块更新时，可让model模块也提供对single和list两种类型回写的支持。提供各个Model的特殊化处理，如有些Model可以忽略删除列表。</p>
<h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><p>最后再谈谈关于这套框架的数据加载，player_model提供一个init(PlayerId)完成数据的加载，module_map中业务逻辑模块到数据Model层的映射，也是为此准备的。</p>
<p>player_model遍历module_map，调用Model:get(PlayerId)，取出各个Model的数据，然后通过module_map找到对应的业务逻辑模块，回调业务逻辑层初始化函数，该函数可默认指定，比如叫init_callback，每个module_map中的业务逻辑模块都需要提供init_callback进行初始化处理，如同步客户端等等，之后也由init_callback决定是否将数据存往进程字典(通过state模块)。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>WordPress搭建历程</title>
    <url>/2015/05/wordpress-setup/</url>
    <content><![CDATA[<p>记录一下搭建wordpress博客的过程，做备忘之用，仅供参考。</p>
<h3 id="一-前期准备"><a href="#一-前期准备" class="headerlink" title="一. 前期准备"></a>一. 前期准备</h3><p>一台云服务器和一个域名(可选)。国内的服务器搭建网站需要备案，国外的话推荐linode，目前linode tokyo服务器应该是国内访问最快的，但是已经缺货了，而新开的singapore服务器线路优化又不是很好(ping 300+)，后来又换成了fremont，速度总算稳定了一些，ping值 210 左右。</p>
<span id="more"></span>
<h3 id="二-部署wordpress"><a href="#二-部署wordpress" class="headerlink" title="二. 部署wordpress"></a>二. 部署wordpress</h3><p>我的环境是 Ubuntu 14.04 LTS。</p>
<h4 id="1-安装-apache2-php5-mysql-server"><a href="#1-安装-apache2-php5-mysql-server" class="headerlink" title="1.安装 apache2 + php5 + mysql-server"></a>1.安装 apache2 + php5 + mysql-server</h4><pre><code>// apache
sudo apt-get install apache2 // 安装完成后，在本地打开浏览器 http://云服务器IP地址 测试

// php5
sudo apt-get install php5      
sudo apt-get install libapache2-mod-php5

// mysql
sudo apt-get install mysql-server
sudo apt-get install libapache2-mod-auth-mysql
sudo apt-get install php5-mysql

// 重启apache 如果遇到 ServerName 警告，可在/etc/apache2/apache2.conf 中，
// 添加一行: ServerName localhost
/etc/init.d/apache2 restart 
</code></pre><h4 id="2-下载解压-wordpress"><a href="#2-下载解压-wordpress" class="headerlink" title="2.下载解压 wordpress"></a>2.下载解压 wordpress</h4><pre><code>wget https://cn.wordpress.org/wordpress-4.2-zh_CN.tar.gz // 可去cn.wordpress.org获取最新版
tar zxvf wordpress-4.2-zh_CN.tar.gz
</code></pre><h4 id="3-为wordpress-准备-mysql"><a href="#3-为wordpress-准备-mysql" class="headerlink" title="3.为wordpress 准备 mysql"></a>3.为wordpress 准备 mysql</h4><pre><code>mysql -uroot -p
mysql&gt; CREATE DATABASE 网站数据库名
mysql&gt; GRANT ALL PRIVILEGES ON 网站数据库名.* to 用户名@localhost identified by &#39;密码&#39;
mysql&gt; exit
</code></pre><h4 id="4-配置-wordpress"><a href="#4-配置-wordpress" class="headerlink" title="4.配置 wordpress"></a>4.配置 wordpress</h4><pre><code>// 配置前面为wordpress准备的mysql数据库和用户
cd wordpress
mv wp-config-sample.php wp-config.php
vim wp-config.php #在配置文件中，配置DB_NAME DB_USER DB_PASSWORD三项
</code></pre><h4 id="5-添加-wordpress-到-apache"><a href="#5-添加-wordpress-到-apache" class="headerlink" title="5.添加 wordpress 到 apache"></a>5.添加 wordpress 到 apache</h4><pre><code>// 将wordpress中所有内容移动到 /var/www/html下
// /var/www/html是apache的默认根目录
sudo mv wordpress/* /var/www/html    
</code></pre><h4 id="6-安装wordpress"><a href="#6-安装wordpress" class="headerlink" title="6. 安装wordpress"></a>6. 安装wordpress</h4><p>本地浏览器中，输入 <a href="http://云服务器地址/wp-admin/install.php">http://云服务器地址/wp-admin/install.php</a></p>
<p>安装向导提供网站管理的用户名密码等信息。即可完成安装</p>
<h3 id="三-完善wordpress"><a href="#三-完善wordpress" class="headerlink" title="三. 完善wordpress"></a>三. 完善wordpress</h3><h4 id="1-修改网站根目录"><a href="#1-修改网站根目录" class="headerlink" title="1. 修改网站根目录"></a>1. 修改网站根目录</h4><p>apache2默认目录为 /var/www/html，如果要更改到/var/www:</p>
<pre><code>1. 修改/etc/apache2/sites-available/000-default.conf，将其中的 DocumentRoot 改为 /var/www
2. 执行: sudo mv /var/www/html/* /var/www/
3. 重启: service apache2 restart
</code></pre><h4 id="2-制作固定链接"><a href="#2-制作固定链接" class="headerlink" title="2. 制作固定链接"></a>2. 制作固定链接</h4><p>要求: </p>
<pre><code>1. Apache web server，安装了mod_rewrite模块:
操作:
    sudo a2enmod rewrite
    或: sudo ln -s /etc/apache2/mods-available/rewrite.load /etc/apache2/mods-enabled/rewrite.load

2. 在WordPress的home目录:
     FollowSymLinks option enabled 
     FileInfo directives允许 (如 AllowOverride FileInfo 或 AllowOverride All) 
操作:
    在/etc/apache2/apache2.conf中，找到&lt;Directory /var/www/&gt;标签，将其改为:
    &lt;Directory /var/www/&gt;
    Options Indexes FollowSymLinks
    AllowOverride All
    Require all granted
    &lt;/Directory&gt;

3. .htaccess文件 (如果找不到，当你激活漂亮固定链接时WordPress会尝试创建它) 如果你希望WordPress自动更新.htaccess，WordPress需要有这个文件的写权限。
操作:
    在你的网站根目录(wordpress文件目录)中:
    sudo touch .htaccess
    sudo chmod 777 .htaccess //最粗暴的方式，方便wordpress自动写入
</code></pre><p>准备就绪后，在wordpress <code>管理页面-&gt;设置-&gt;固定链接</code>中可设置固定链接格式，地址为<code>http://xxx/wp-admin/options-permalink.php</code>。选定固定链接后，wordpress会自动尝试写入规则，如果写入失败，则会在最下方给出提示，让你尝试手动添加规则。</p>
<p>完成之后，固定连接就生效了。</p>
<h4 id="3-更换主题"><a href="#3-更换主题" class="headerlink" title="3. 更换主题"></a>3. 更换主题</h4><p>在wordpress中自带更换主题的功能，但默认需要FTP用户名和密码，因为web访问的用户不具有对服务器wordpress文件夹的相关操作权限。由于安装方式不一样，解决方案不一样。我最后找到比较有用的是<a href="http://www.piaoyi.org/php/Wordpress-To-perform-the-requested-action.html">这里</a>提供的一些思路：</p>
<pre><code>// 先将wordpress相关文件全部改为 777
sudo chmod 777 -R /var/www/wp*
// 然后通过wordpress管理界面，主题能够安装成功了
// 此时观察 wp-content/themes的写入者为www-data
// 改回权限:
sudo chmod 755 -R /var/www/wp*
chown -R www-data /var/www/wp*
</code></pre><p>另外，推荐一个wordpress中文主题下载网站: <a href="http://www.wopus.org">http://www.wopus.org</a></p>
<h4 id="4-关于主页"><a href="#4-关于主页" class="headerlink" title="4. 关于主页"></a>4. 关于主页</h4><p>到目前为止，如果在本地浏览器直接输入<code>http://云服务器地址</code> 得到的将是apache的it works页面，这也是服务器上/var/www/index.html页面。而我们想使用的是/var/www/index.php作为我们的主页。此时删掉/var/www/index.html即可。</p>
<h4 id="5-域名绑定"><a href="#5-域名绑定" class="headerlink" title="5. 域名绑定"></a>5. 域名绑定</h4><p>这个比较简单，在你的域名提供商中修改DNS指向为你的云服务器IP地址，然后在wordpress管理-&gt;设置 中修改站点地址为你的域名，就可以了。</p>
<h3 id="四-参考文档"><a href="#四-参考文档" class="headerlink" title="四. 参考文档:"></a>四. 参考文档:</h3><ol>
<li><a href="http://codex.wordpress.org/zh-cn:%E5%AE%89%E8%A3%85WordPress">官方安装教程</a></li>
<li><a href="http://blog.csdn.net/shineflowers/article/details/40979927">网友安装教程</a></li>
<li><a href="https://codex.wordpress.org/zh-cn:Main_Page">官方使用文档</a></li>
</ol>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>Firefly 学习(一)</title>
    <url>/2015/05/firefly-study1/</url>
    <content><![CDATA[<h2 id="一-简介"><a href="#一-简介" class="headerlink" title="一. 简介"></a>一. 简介</h2><p><a href="https://github.com/9miao/firefly">firefly</a>是一款python开发的开源游戏服务器框架，基于分布式，底层使用twisted。</p>
<p>firefly采用多进程方案，节点之间通过网络通信(当然你也可以创建单节点，独立完成大部分功能)，具有很好的可扩展性。</p>
<h2 id="二-使用"><a href="#二-使用" class="headerlink" title="二. 使用"></a>二. 使用</h2><p>作为一个Python初学者，下面只谈一些自己对firefly的一些肤浅认识。上面的途径可以获取到更完整和深入的资料。</p>
<p>下面的Demo的源代码可在<a href="demo_github">我的Github</a>上下载。</p>
<h3 id="1-流程"><a href="#1-流程" class="headerlink" title="1. 流程"></a>1. 流程</h3><p>总体上看，如果你要使用firefly，所需要做的事就是：</p>
<ul>
<li>通过配置文件定义所有节点，节点配置，节点实现文件，以及节点和节点之间的联系(通过网络端口)</li>
<li>定义节点实现文件</li>
<li>启动主节点</li>
</ul>
<p>firefly通过配置文件来设定你的分布式服务器，然后你只需创建和启动master节点，master服务器会启动配置文件中的各个子节点：</p>
<span id="more"></span>
<pre><code>if __name__==&quot;__main__&quot;:
    from firefly.master.master import Master
    master = Master()
    master.config(&#39;config.json&#39;,&#39;appmain.py&#39;)
    master.start()
</code></pre><p>config.json定义你的分布式服务，appmain.py是你的子节点公共入口，master节点已在master.start()中启动。</p>
<h3 id="2-配置文件"><a href="#2-配置文件" class="headerlink" title="2. 配置文件"></a>2. 配置文件</h3><p>下面是一份 config.json 实例，该配置文件配置了一个无盘节点，即没有使用数据库:</p>
<pre><code>&#123;
&quot;master&quot;:&#123;&quot;rootport&quot;:9999,&quot;webport&quot;:9998&#125;,
&quot;servers&quot;:&#123;
    &quot;gate&quot;:&#123;&quot;name&quot;:&quot;gate&quot;, &quot;rootport&quot;:10000, &quot;app&quot;:&quot;app.gateserver&quot;&#125;,
    &quot;net&quot;:&#123;&quot;name&quot;:&quot;net&quot;, &quot;netport&quot;:10001, &quot;name&quot;:&quot;net&quot;, &quot;remoteport&quot;:[&#123;&quot;rootport&quot;:10000, &quot;rootname&quot;:&quot;gate&quot;&#125;], &quot;app&quot;:&quot;app.netserver&quot;&#125;,
    &quot;game1&quot;:&#123;&quot;name&quot;:&quot;game1&quot;, &quot;remoteport&quot;:[&#123;&quot;rootport&quot;:10000, &quot;rootname&quot;:&quot;gate&quot;&#125;], &quot;app&quot;:&quot;app.game1server&quot;&#125;
&#125;
&#125;
</code></pre><p>通过配置文件已经能够很清楚地看懂该服务器的整个分布式情况：</p>
<p><img src="/assets/image/201505/firefly_nodes.png" alt="" title="firefly的分布式节点"></p>
<h4 id="master节点"><a href="#master节点" class="headerlink" title="master节点"></a>master节点</h4><p>master节点管理所有的节点，它有两个端口rootport和webport，顾名思义，rootport用于和和服务器中其它节点通信，webport用于后台管理，如关闭和重启所有子节点。调用master.start()后，框架会自动创建master节点并监听rootport和webport端口，后者通过<a href="flask">Flask</a>实现。</p>
<h4 id="分布式节点"><a href="#分布式节点" class="headerlink" title="分布式节点"></a>分布式节点</h4><p>如果将master节点称为整个服务器的根节点，那么servers中定义的节点即为分布式节点，样例config中定义了四个分布式节点，gate, dbfront, net, game1。每个节点都可以定义自己的父节点(通过remoteport，可有多个父节点)，并且关联节点的实现文件(位于config所在目录 app/*.py)。其中gate是net和game1的父节点，意味着如果有网络消息需要game1节点处理，那么消息将由net-&gt;gate-&gt;game1，同理消息响应途径为：game1-&gt;gate-&gt;net。</p>
<h3 id="3-公共入口"><a href="#3-公共入口" class="headerlink" title="3. 公共入口"></a>3. 公共入口</h3><p>appmain是我们定义的节点公共入口，它会由firefly通过<code>python appmain.py 节点名 配置路径</code>调用，节点名即为gate, dbfront, net, game1之一，配置路径即为 config.json。该入口允许我们对各分布式节点做一些预先特殊处理，在Demo的appmain.py中，仅仅是读取必须配置，通过一个firefly导出的统一节点类来启动节点:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#coding:utf8</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">本模块在启动master时作为参数传入</span><br><span class="line">firefly会在每个Server(除了master)启动时都调用该模块:</span><br><span class="line">    cmds &#x3D; &#39;python %s %s %s&#39;%(self.mainpath, sername, self.configpath) [位于master&#x2F;master.py, 其中self.mainpath即为本模块] </span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import os</span><br><span class="line">import json, sys</span><br><span class="line">from firefly.server.server import FFServer</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    args &#x3D; sys.argv</span><br><span class="line">    servername &#x3D; None</span><br><span class="line">    config &#x3D; None</span><br><span class="line">    if len(args) &gt; 2:</span><br><span class="line">        servername &#x3D; servername &#x3D; args[1]</span><br><span class="line">        config &#x3D; json.load(open(args[2], &#39;r&#39;))</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError</span><br><span class="line"></span><br><span class="line">    dbconf &#x3D; config.get(&#39;db&#39;, &#123;&#125;)</span><br><span class="line">    memconf &#x3D; config.get(&#39;memcached&#39;, &#123;&#125;)</span><br><span class="line">    servsconf &#x3D; config.get(&#39;servers&#39;, &#123;&#125;)</span><br><span class="line">    masterconf &#x3D; config.get(&#39;master&#39;,&#123;&#125;)</span><br><span class="line">    serverconf &#x3D; servsconf.get(servername)</span><br><span class="line">    server &#x3D; FFServer()</span><br><span class="line">    server.config(serverconf, dbconfig&#x3D;dbconf, memconfig&#x3D;memconf, masterconf&#x3D;masterconf)</span><br><span class="line">    print servername, &#39;start&#39;</span><br><span class="line">    server.start()</span><br><span class="line">    print servername, &#39;stop&#39;</span><br></pre></td></tr></table></figure>
<p>appmain.py通过firefly的FFServer来启动节点，这里先不管FFServer如何区分各个节点。至此，我们的分布式服务器就算是启动了。</p>
<h3 id="4-节点实现"><a href="#4-节点实现" class="headerlink" title="4. 节点实现"></a>4. 节点实现</h3><p>最后需要我们关心的，就是节点实现了，不用多说，FFServer会根据你传入的节点实现文件，来实现节点的功能。而实际上我们需要做的事情是很少的，因为启动服务器，监听端口，节点间通信，甚至网络消息编解码等等这些功能，FFServer都帮你做了，后面会提到它如何区分和实现这些功能。</p>
<p>而我们要做的，就是通过装饰器响应消息就OK了，并且节点之间的消息转发也很方便：</p>
<p><strong>netserver实现</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#coding:utf8</span><br><span class="line"></span><br><span class="line">from firefly.server.globalobject import GlobalObject, netserviceHandle</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">netservice 默认是 CommandService:</span><br><span class="line">    netservice &#x3D; services.CommandService(&quot;netservice&quot;)  [位于server&#x2F;server.py]</span><br><span class="line">    CommandService 的消息响应函数格式为: HandleName_CommandID(conn, data)</span><br><span class="line">    CommandService 会通过&#39;_&#39;解析出CommandID并注册HandleName_CommandId为其消息响应函数</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">@netserviceHandle</span><br><span class="line">def netHandle_100(_conn, data):</span><br><span class="line">    print &quot;netHandle_100: &quot;, data</span><br><span class="line">    return &quot;netHandle_100 completed&quot;</span><br><span class="line"></span><br><span class="line">@netserviceHandle</span><br><span class="line">def netHandle_200(_conn, data):</span><br><span class="line">    print &quot;netHandle_200: &quot;, data, &quot;forward to gate&quot;</span><br><span class="line">    # 转发到 gateserver.gateHandle1</span><br><span class="line">    # 通过 GlobalObject().remote[父节点名]来得到父节点的远程调用对象</span><br><span class="line">    return GlobalObject().remote[&#39;gate&#39;].callRemote(&#39;gateHandle1&#39;, data)</span><br><span class="line"></span><br><span class="line">@netserviceHandle</span><br><span class="line">def netHandle_300(_conn, data):</span><br><span class="line">    print &quot;netHandle_300: &quot;, data, &quot;forward to gate&quot;</span><br><span class="line">    return GlobalObject().remote[&#39;gate&#39;].callRemote(&#39;gateHandle2&#39;, data)</span><br></pre></td></tr></table></figure>
<p><strong>gateserver实现</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#coding:utf-8</span><br><span class="line"></span><br><span class="line">from firefly.server.globalobject import GlobalObject, rootserviceHandle</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@rootserviceHandle</span><br><span class="line">def gateHandle1(data):</span><br><span class="line">    print &quot;gateHandle: &quot;, data</span><br><span class="line">    return &quot;gateHandle Completed&quot;</span><br><span class="line"></span><br><span class="line">@rootserviceHandle</span><br><span class="line">def gateHandle2(data):</span><br><span class="line">    print &quot;gateHandle2: &quot;, data, &quot;forward to game1: &quot;</span><br><span class="line">    # 转发到 game1.game1Handle</span><br><span class="line">    # 通过 GlobalObject().root.callChild(节点名，节点函数，参数)远程调用孩子节点</span><br><span class="line">    return GlobalObject().root.callChild(&quot;game1&quot;, &quot;game1Handle&quot;, data)</span><br></pre></td></tr></table></figure>
<p><strong>game1server实现</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from firefly.server.globalobject import GlobalObject, remoteserviceHandle</span><br><span class="line"></span><br><span class="line">@remoteserviceHandle(&quot;gate&quot;)</span><br><span class="line">def game1Handle(data):</span><br><span class="line">    print &quot;game1Handle: &quot;, data</span><br><span class="line">    return &quot;game1Handle completed&quot;</span><br></pre></td></tr></table></figure>
<p>运行Demo，启动测试客户端，得到结果:</p>
<p>Server端: </p>
<pre><code>[firefly.netconnect.protoc.LiberateFactory] Client 0 login in.[127.0.0.1,61752]
[LiberateProtocol,0,127.0.0.1] call method netHandle_100 on service[single]
[LiberateProtocol,0,127.0.0.1] netHandle_100:  msgdata
[LiberateProtocol,0,127.0.0.1] call method netHandle_200 on service[single]
[LiberateProtocol,0,127.0.0.1] netHandle_200:  msgdata forward to gate
[BilateralBroker,0,127.0.0.1] call method gateHandle1 on service[single]
[BilateralBroker,0,127.0.0.1] gateHandle:  msgdata
[LiberateProtocol,0,127.0.0.1] call method netHandle_300 on service[single]
[LiberateProtocol,0,127.0.0.1] netHandle_300:  msgdata forward to gate
[BilateralBroker,0,127.0.0.1] call method gateHandle2 on service[single]
[BilateralBroker,0,127.0.0.1] gateHandle2:  msgdata forward to game1:
[Broker,client] call method game1Handle on service[single]
[Broker,client] game1Handle:  msgdata
[LiberateProtocol,0,127.0.0.1] Client 0 login out.
</code></pre><p>Client端:</p>
<pre><code>----------------
send commandId: 100
netHandle_100 completed
----------------
send commandId: 200
gateHandle Completed
----------------
send commandId: 300
game1Handle completed
</code></pre><h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h3><p>看起来，使用firefly确实很简单，通过配置文件即可完成强大的分布式部署，节点之间的通信协议，节点间消息以及网络消息的编解码，甚至重连机制框架都已经帮你完成。你只需通过python装饰器，来实现自己的请求响应逻辑即可。</p>
<h2 id="三-实现原理"><a href="#三-实现原理" class="headerlink" title="三. 实现原理"></a>三. 实现原理</h2><p>简单梳理一下firefly内部替我们完成的事。</p>
<h3 id="1-master启动"><a href="#1-master启动" class="headerlink" title="1.master启动"></a>1.master启动</h3><p>在我们的app入口文件中，通过master.start()启动服务器，master.start()完成了:</p>
<ul>
<li>创建一个PBRoot 在rootport监听其它节点连接</li>
<li>创建一个Flask  在webport 监听管理员命令</li>
<li>遍历配置中的servers 通过<code>python appmain.py 节点名 配置文件</code>启动各个分布式节点，appmain.py由使用者编写和提供</li>
</ul>
<h3 id="2-FFServer"><a href="#2-FFServer" class="headerlink" title="2.FFServer"></a>2.FFServer</h3><p>在appmain.py中，通过FFServer来创建和启动一个节点，firefly FFServer抽象一个服务进程，前面曾提到过，由于所有非master节点都通过FFServer启动，那么FFServer如何区分各节点功能和通讯协议？ 答案很简单，FFServer检查节点各项配置，为各项配置创建对应的组件，其中比较重要的有:</p>
<ul>
<li>webport 代表该节点希望提供web服务，FFServer通过Flask启动一个简单的web server</li>
<li>rootport 代表该节点是一个父节点，创建并启动PBRoot类(master也有一个PBRoot成员)来监听其它节点的连接 </li>
<li>netport 代表该节点希望接收客户端网络数据，FFServer创建LiberateFactory并监听netport，LiberateFactory中包含对网络数据的解码</li>
<li>db 若该配置为true，FFServer会根据config中的db配置连接到DB</li>
<li>mem 若该配置为true，FFServer会根据config中的memcached配置连接到memchache</li>
<li>remoteport, FFServer为每个父节点创建RemoteObject，并保存remote[name] -&gt; RemoteObject 映射</li>
</ul>
<p>这样，一个节点可以灵活分配一个或多个职责，并且每份职责通过独立的类来处理内部逻辑和通信协议等。除此之外，FFServer还做了两件事：</p>
<ul>
<li>import 节点关联的实现文件，该实现文件通过装饰器可以导入消息回调函数。</li>
<li>连接master节点</li>
</ul>
<h3 id="3-待续"><a href="#3-待续" class="headerlink" title="3. 待续"></a>3. 待续</h3>]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>firefly</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Twisted</title>
    <url>/2015/05/twisted/</url>
    <content><![CDATA[<p>前几天学习firefly游戏服务器框架，其底层用twisted实现，twisted是一个比较出名的python异步回调框架，将reactor回调模式运用到极致，并且也对传统回调所面临的一些问题提出了很好的解决方案。</p>
<p>我的twisted学习主要是基于<a href="http://turtlerbender007.appspot.com/twisted/index.html">Dave的系列博客</a>的，英文原版在<a href="http://krondo.com/blog/?page_id=1327">这里</a>，看了前面比较基础的几章，根据这些文章做个阶段性总结。顺便附上<a href="http://twistedmatrix.com/documents/current/core/howto/index.html">官方文档</a>。</p>
<h3 id="一-reactor"><a href="#一-reactor" class="headerlink" title="一. reactor"></a>一. reactor</h3><p>twisted的核心是reactor，而提到reactor不可避免的是同步/异步，阻塞/非阻塞，在Dave的第一章概念性介绍中，对同步/异步的界限有点模糊，关于同步/异步，阻塞/非阻塞可参见<a href="http://www.zhihu.com/question/19732473">知乎讨论</a>。而关于proactor(主动器)和reactor(反应堆)，这里有一篇<a href="http://www.cnblogs.com/me115/p/4452801.html">推荐博客</a>有比较详细的介绍。</p>
<p>就reactor模式的网络IO而言，应该是同步IO而不是异步IO。而Dave第一章中提到的异步，核心在于：<strong>显式地放弃对任务的控制权而不是被操作系统随机地停止，程序员必须将任务组织成序列来交替的小步完成。因此，若其中一个任务用到另外一个任务的输出，则依赖的任务（即接收输出的任务）需要被设计成为要接收系列比特或分片而不是一下全部接收。</strong></p>
<p>显式主动地放弃任务的控制权有点类似协程的思考方式，reactor可看作协程的调度器。reactor是一个事件循环，我们可以向reactor注册自己感兴趣的事件(如套接字可读/可写)和处理器(如执行读写操作)，reactor会在事件发生时回调我们的处理器，处理器执行完成之后，相当于协程挂起(yield)，回到reactor的事件循环中，等待下一个事件来临并回调。reactor本身有一个同步事件多路分解器(Synchronous Event Demultiplexer)，可用select/epoll等机制实现，当然twisted reactor的事件触发不一定是基于IO，也可以由定时器等其它机制触发。</p>
<p>reactor的回调机制如下:</p>
<span id="more"></span>
<p><img src="/assets/image/201505/reactor_loop.png" alt=""></p>
<p>twisted的reactor无需我们主动注册事件和回调函数，而是通过多态(继承特定类，并实现所关心的事件接口，然后传给twisted reactor)来实现。关于twisted的reactor，有几个需要注意的地方：</p>
<ul>
<li>twisted.internet.reactor是单例模式，每个程序只能有一个reactor；</li>
<li>尽量在reactor回调函数尽快完成操作，不要执行阻塞任务，reactor本质是单线程，用户回调代码与twisted代码运行在同一个上下文，某个回调函数中阻塞，会导致reactor整个事件循环阻塞；</li>
<li>reactor会一直运行，除非通过reactor.stop()显示停止它，但一般调用reactor.stop()，也就意味着应用程序结束；</li>
</ul>
<h3 id="二-twisted简单使用"><a href="#二-twisted简单使用" class="headerlink" title="二. twisted简单使用"></a>二. twisted简单使用</h3><p>twisted的本质是reactor，我们可以使用twisted的底层API(避开twisted便利的高层抽象)来使用reactor:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 示例一 twisted底层API的使用</span><br><span class="line">from twisted.internet import reacto</span><br><span class="line">from twisted.internet import main</span><br><span class="line">from twisted.internet.interfaces import IReadDescriptor</span><br><span class="line">import socket</span><br><span class="line"></span><br><span class="line">class MySocket(IReadDescriptor):</span><br><span class="line">    def __init__(self, address):</span><br><span class="line">        # 连接服务器</span><br><span class="line">        self.address &#x3D; address</span><br><span class="line">        self.sock &#x3D; socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">        self.sock.connect(address)</span><br><span class="line">        self.sock.setblocking(0)</span><br><span class="line"></span><br><span class="line">        # tell the Twisted reactor to monitor this socket for reading</span><br><span class="line">        reactor.addReader(self)</span><br><span class="line">	</span><br><span class="line">	# 接口: 告诉reactor 监听的套接字描述符</span><br><span class="line">    def fileno(self):</span><br><span class="line">        try:</span><br><span class="line">            return self.sock.fileno()</span><br><span class="line">        except socket.error:</span><br><span class="line">            return -1</span><br><span class="line">            </span><br><span class="line">	# 接口: 在连接断开时的回调</span><br><span class="line">    def connectionLost(self, reason):</span><br><span class="line">        self.sock.close()</span><br><span class="line"></span><br><span class="line">        reactor.removeReader(self)</span><br><span class="line">		</span><br><span class="line">		# 当应用程序需要终止时 调用:</span><br><span class="line">        # reactor.stop()</span><br><span class="line"></span><br><span class="line">	# 接口: 当套接字描述符有数据可读时</span><br><span class="line">    def doRead(self):</span><br><span class="line">        bytes &#x3D; &#39;&#39;</span><br><span class="line"></span><br><span class="line">		# 尽可能多的读取数据</span><br><span class="line">        while True:</span><br><span class="line">            try:</span><br><span class="line">                bytesread &#x3D; self.sock.recv(1024)</span><br><span class="line">                if not bytesread:</span><br><span class="line">                    break</span><br><span class="line">                else:</span><br><span class="line">                    bytes +&#x3D; bytesread</span><br><span class="line">            except socket.error, e:</span><br><span class="line">                if e.args[0] &#x3D;&#x3D; errno.EWOULDBLOCK:</span><br><span class="line">                    break</span><br><span class="line">                return main.CONNECTION_LOST</span><br><span class="line"></span><br><span class="line">        if not bytes: </span><br><span class="line">            return main.CONNECTION_DONE</span><br><span class="line">        else:</span><br><span class="line">            # 在这里解析协议并处理数据</span><br><span class="line">            print bytes</span><br></pre></td></tr></table></figure>
<p>示例一可以很清晰的看到twisted的reactor本质：添加监听描述符，监听可读/可写事件，当事件来临时回调函数，回调完成之后继续监听事件。</p>
<p>需要注意：</p>
<ul>
<li>套接字为非阻塞，如果为阻塞则失去了reactor的意义</li>
<li>我们通过继承IReadDescriptor来提供reactor所需要的接口</li>
<li>通过reactor.addReader将套接字类加入reactor的监听对象中</li>
<li>main.CONNECTION_LOST是twisted预定义的值，通过这些值它我们可以一定程度控制下一步回调(类似于模拟一个事件)</li>
</ul>
<p>但是上面的MySocket类不够好，主要有以下缺点：</p>
<ul>
<li>需要我们自己去读取数据，而不是框架帮我们读好，并处理异常</li>
<li>网络IO和数据处理混为一块，没有剥离开来</li>
</ul>
<h3 id="三-twisted抽象"><a href="#三-twisted抽象" class="headerlink" title="三. twisted抽象"></a>三. twisted抽象</h3><p>twisted在reactor的基础上，建立了更高的抽象，对一个网络连接而言，twisted建立了如下三个概念:</p>
<ul>
<li>Transports：网络连接层，仅负责网络连接和读/写字节数据</li>
<li>Protocols： 协议层，服务业务相关的网络协议，将字节流转换成应用所需数据</li>
<li>Protocol Factories：协议工厂，负责创建Protocols，每个网络连接都有一个Protocols对象(因为要保存协议解析状态)</li>
</ul>
<p>twisted的这些概念和erlang中的<a href="https://github.com/ninenines/ranch">ranch</a>网络框架很像，ranch框架也抽象了Transports和Protocols概念，在有新的网络连接时，ranch自动创建Transports和Protocols，其中Protocols由用户在启动ranch时传入，是一个实现了ranch_protocol behaviour的模块，Protocols初始化时，会收到该连接对应的Transports，如此我们可以在Protocols中处理字节流数据，按照我们的协议解析并处理数据。同时可通过Transports来发送数据(ranch已经帮你读取了字节流数据了)。</p>
<p>和ranch类似，twisted也会在新连接到达时创建Protocols并且将Transport传入，twisted会帮我们读取字节流数据，我们只需在<code>dataReceived(self, data)</code>接口中处理字节流数据即可。此时的twisted在网络IO上可以算是真正的异步了，它帮我们处理了网络IO和可能遇到的异常，并且将网络IO和数据处理剥离开来，抽象为Transports和Protocols，提高了程序的清晰性和健壮性。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 示例二 twisted抽象的使用</span><br><span class="line">from twisted.internet import reactor</span><br><span class="line">from twisted.internet.protocol import Protocol, ClientFactory</span><br><span class="line">class MyProtocol(Protocol):</span><br><span class="line">	</span><br><span class="line">	# 接口: Protocols初始化时调用，并传入Transports</span><br><span class="line">	# 另外 twisted会自动将Protocols的factory对象成员设为ProtocolsFactory实例的引用</span><br><span class="line">	# 	   如此就可以通过factory来与MyProtocolFactory交互</span><br><span class="line">    def makeConnection(self,trans):</span><br><span class="line">        print &#39;make connection: get transport: &#39;, trans</span><br><span class="line">        print &#39;my factory is: &#39;, self.factory</span><br><span class="line">        </span><br><span class="line">	# 接口: 有数据到达</span><br><span class="line">    def dataReceived(self, data):</span><br><span class="line">        self.poem +&#x3D; data</span><br><span class="line">        msg &#x3D; &#39;Task %d: got %d bytes of poetry from %s&#39;</span><br><span class="line">        print  msg % (self.task_num, len(data), self.transport.getPeer())</span><br><span class="line"> </span><br><span class="line">	# 接口: 连接断开</span><br><span class="line">    def connectionLost(self, reason):</span><br><span class="line">        # 连接断开的处理</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyProtocolFactory(ClientFactory):</span><br><span class="line"></span><br><span class="line">	# 接口: 通过protocol类成员指出需要创建的Protocols</span><br><span class="line">    protocol &#x3D; PoetryProtocol # tell base class what proto to build</span><br><span class="line"></span><br><span class="line">    def __init__(self, address):</span><br><span class="line">        self.poetry_count &#x3D; poetry_count</span><br><span class="line">        self.poems &#x3D; &#123;&#125; # task num -&gt; poem</span><br><span class="line">        </span><br><span class="line">	# 接口: 在创建Protocols的回调</span><br><span class="line">    def buildProtocol(self, address):</span><br><span class="line">        proto &#x3D; ClientFactory.buildProtocol(self, address)</span><br><span class="line">        # 在这里对proto做一些初始化....</span><br><span class="line">        return proto</span><br><span class="line">       </span><br><span class="line">	# 接口: 连接Server失败时的回调</span><br><span class="line">    def clientConnectionFailed(self, connector, reason):</span><br><span class="line">        print &#39;Failed to connect to:&#39;, connector.getDestination()</span><br><span class="line">        </span><br><span class="line">def main(address):</span><br><span class="line">	factory &#x3D; MyClientFactory(address)</span><br><span class="line">    host, port &#x3D; address</span><br><span class="line">    # 连接服务端时传入ProtocolsFactory</span><br><span class="line">    reactor.connectTCP(host, port, factory) </span><br><span class="line">    reactor.run()</span><br><span class="line">        </span><br></pre></td></tr></table></figure>
<p>示例二要比示例一要简单清晰很多，因为它无需处理网络IO，并且逻辑上更为清晰，实际上ClientFactory和Protocol提供了更多的接口用于实现更灵活强大的逻辑控制，具体的接口可参见<a href="https://github.com/twisted/twisted/tree/trunk/twisted">twisted源代码</a>。</p>
<h3 id="四-twisted-Deferred"><a href="#四-twisted-Deferred" class="headerlink" title="四. twisted Deferred"></a>四. twisted Deferred</h3><p>twisted Deferred对象用于解决这样的问题：有时候我们需要在ProtocolsFactory中嵌入自己的回调，以便Protocols中发生某个事件(如所有Protocols都处理完成)时，回调我们指定的函数(如TaskFinished)。如果我们自己来实现回调，需要处理几个问题:</p>
<ul>
<li>如何区分回调的正确返回和错误返回?(我们在使用异步调用时，要尤其注意错误返回的重要性)</li>
<li>如果我们的正确返回和错误返回都需要执行一个公共函数(如关闭连接)呢?</li>
<li>如果保证该回调只被调用一次?</li>
</ul>
<p>Deferred对象便用于解决这种问题，它提供两个回调链，分别对应于正确返回和错误返回，在正确返回或错误返回时，它会依次调用对应链中的函数，并且保证回调的唯一性。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">d &#x3D; Deferred()</span><br><span class="line"># 添加正确回调和错误回调</span><br><span class="line">d.addCallbacks(your_ok_callback, your_err_callback)</span><br><span class="line"># 添加公共回调函数</span><br><span class="line">d.addBoth(your_common_callback)</span><br><span class="line"></span><br><span class="line"># 正确返回 将依次调用 your_ok_callback(Res) -&gt; common_callback(Res)</span><br><span class="line">d.callback(Res)</span><br><span class="line"># 错误返回 将依次调用 your_err_callback(Err) -&gt; common_callback(Err)</span><br><span class="line">d.errback(Err)</span><br><span class="line"></span><br><span class="line"># 注意，对同一个Defered对象，只能返回一次，尝试多次返回将会报错</span><br></pre></td></tr></table></figure>
<p>暂时就这么多了，又可以回去看Firefly了。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Firefly 学习(二)</title>
    <url>/2015/06/firefly-study2/</url>
    <content><![CDATA[<h2 id="一-GlobalObject"><a href="#一-GlobalObject" class="headerlink" title="一. GlobalObject"></a>一. GlobalObject</h2><p>每个节点(即一个FFServer)对应一个GlobalObject，存放该节点的节点信息和分布式信息。GlobalObject中包含多种组件，FFServer根据节点配置信息决定为节点创建哪些组件。这样分布式配置更为灵活，一个节点可以单一职责，也可以多种职责。GlobalObject包含的组件主要有：</p>
<ul>
<li>netfactory: 前端节点，对应netport字段，监听和管理客户端连接。</li>
<li>root: 分布式根节点，对应字段rootport</li>
<li>remote: 分布式子节点，对应字段remoteport</li>
<li>db: 数据库节点</li>
</ul>
<p>简单介绍一下netfactory, root, remote 这三个组件，已经远程调用的实现机制。</p>
<span id="more"></span>
<h3 id="1-前端节点netfactory："><a href="#1-前端节点netfactory：" class="headerlink" title="1. 前端节点netfactory："></a>1. 前端节点netfactory：</h3><p>前端节点netfactory为LibrateFactory(netconnect/protoc.py)，firefly网络层使用twisted，LibrateFactory即为twisted的协议工厂，同时也是网络层到逻辑层的纽带。LibrateFactory有如下成员：</p>
<ul>
<li>connmanager: <ul>
<li>功能: 管理所有Connection，建立ConnID(transport.sessionno)到Conn的映射。</li>
<li>实现: ConnectionManager(netconnection/manager.py)</li>
</ul>
</li>
<li>dataprotocl: <ul>
<li>功能: 消息编解码器，完成消息的编解码，提供pack/unpack/getHeadlength等接口。</li>
<li>实现: DataPackProtoc(netconnection/datapack.py)</li>
</ul>
</li>
<li>protocol: <ul>
<li>功能: 负责处理收到的字节数据，解决粘包半包问题等，通过DataPackProtoc拿到消息ID(command)和消息数据(request)，调用<code>factory.doDataReceived(self, command, requeset)</code>将消息传给netfactory统一处理。</li>
<li>实现: LibrateProtocol(netconnection/protoc.py)</li>
</ul>
</li>
<li>service:<ul>
<li>功能: netfactory上挂载的Service，也就是从网络层到逻辑层的入口，逻辑层在这个Service通道中注册响应函数，netfactory会在收到消息(<code>doDataReceived</code>)时，通过<code>service.callTarget(commandID, conn, data)</code>将消息交由service处理。 </li>
<li>实现: 目前的netfactory上挂载的是netservice，netservice默认为CommandService(utils/services.py)</li>
</ul>
</li>
</ul>
<p>值得一提的是，LibrateProtocol在处理收到的字节流时(<code>dataHandleCoroutine</code>)，利用yield机制非常简洁高效地完成消息解码工作，使解码函数看起来只是在一个<code>while True</code>循环中，无需多次调用，也自然无需保存状态。当外部数据到达时，通过<code>send(data)</code>即可将数据送入dataHandleCoroutine，后者yield返回即可拿到data继续工作了。</p>
<p>另外，LibrateProtocol解析完一条消息后，通过调用<code>factory.doDataReceived</code>将消息交给netfactory，也就是交给逻辑层，由于LibrateProtocol并不知道逻辑层何时返回，因此<code>factory.doDataReceived</code>是一个异步调用，它返回一个Deffer对象，LibrateProtocol注册callback为写回函数<code>safeToWriteData</code>，当逻辑层返回处理结果时，即可将数据线程安全地响应给客户端。这个Deffer对象可以是响应函数(如netservice:handle_100)返回的，如果响应函数没有返回Deffer而是直接返回的响应数据response，将由<code>service.callTarget</code>创建一个Deffer，并且回调deffer.callback(response)，如果响应函数返回None，那么表示这个请求消息没有响应，<code>service.callTarget</code>直接返回None，LibrateProtocol也无需再为其注册<code>safeToWriteData</code>函数了。</p>
<p>注意，整个过程都是在单线程中跑的(reactor)，firefly中的每个节点都使用一个reactor，netfactory在FFServer(server/server.py)中传给reactor（如果该节点配置了netport），在FFServer启动时会启动reactor。</p>
<h3 id="2-分布式根节点root"><a href="#2-分布式根节点root" class="headerlink" title="2. 分布式根节点root"></a>2. 分布式根节点root</h3><p>firefly使用twisted透明代理(Perspective Broker, 简称PB, 参见<a href="1">twisted官方文档</a>)，屏蔽了分布式节点之间的通信机制和细节。在FFServer中，firefly为每一个根节点(具备rootport字段)创建一个PBRoot对象，PBRoot代表分布式根节点，它包含两个构件:</p>
<ul>
<li><p>childmanager:</p>
<ul>
<li>功能: 管理该根节点下面的所有子节点对象(Child对象)，Child主要包含子节点名和子节点的远程调用对象的引用(通过它调用<code>callRemote(函数名，参数)</code>即可调用子节点函数，剩下的细节将由twisted透明代理来完成)。</li>
<li>实现: ChildManager(distributed/manager.py)</li>
</ul>
</li>
<li><p>service:</p>
<ul>
<li>功能: 和netfactory一样，service用于挂载本节点提供的接口(用于其它节点调用)，firefly所有的节点都抽象出一个service用于管理本节点的接口，除了netfactory的netservice以外，其它节点的service均为Service对象，Service对象根据函数名而不是commandID来调用接口。</li>
<li>实现: Service(utils/services.py) </li>
</ul>
</li>
</ul>
<p>子节点在连接到根节点时，由子节点发起一个takeProxy的远程调用，参数为子节点名和其远程调用对象(继承自twisted.spread.pb.Referenceble)，触发PBRoot的remote_takeProxy，该函数记录该子节点和其远程调用对象)。之后根节点PBRoot可通过<code>callChild(子节点名，函数名，参数)</code>调用子节点函数。关键代码如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class PBRoot(pb.Root):</span><br><span class="line">    </span><br><span class="line">    def __init__(self,dnsmanager &#x3D; ChildsManager()):</span><br><span class="line">        self.service &#x3D; None</span><br><span class="line">        self.childsmanager &#x3D; dnsmanager</span><br><span class="line">    </span><br><span class="line">    # 远程调用: 初始化子节点</span><br><span class="line">    def remote_takeProxy(self,name,transport):</span><br><span class="line">        log.msg(&#39;node [%s] takeProxy ready&#39;%name)</span><br><span class="line">        child &#x3D; Child(name,name)</span><br><span class="line">        self.childsmanager.addChild(child)</span><br><span class="line">        child.setTransport(transport)</span><br><span class="line">        self.doChildConnect(name, transport)</span><br><span class="line">        </span><br><span class="line">    # 远程调用: 调用本节点上实现的响应函数    </span><br><span class="line">    def remote_callTarget(self,command,*args,**kw):</span><br><span class="line">        data &#x3D; self.service.callTarget(command,*args,**kw)</span><br><span class="line">        return data</span><br><span class="line">        </span><br><span class="line">    # 调用子节点方法</span><br><span class="line">    def callChild(self,key,*args,**kw):</span><br><span class="line">        return self.childsmanager.callChild(key,*args,**kw)</span><br><span class="line">        </span><br></pre></td></tr></table></figure>
<h4 id="3-分布式子节点remote"><a href="#3-分布式子节点remote" class="headerlink" title="3. 分布式子节点remote"></a>3. 分布式子节点remote</h4><p>FFServer为每一个子节点(具备remoteport字段)创建N个RemoteObject对象(N为其根节点个数，即remoteport字段的元素个数)，globalobject.remote是一个map，通过remote[根节点名]可以得到连接到指定根节点的RemoteObject。为每一个根节点都创建一个RemoteObject的好处是：同样一个子节点，可以对不同的根节点提供不同的接口。</p>
<p>RemoteObject包含如下构件:</p>
<ul>
<li>_reference:<ul>
<li>功能: 这就是前面提到的远程调用对象，继承自<code>twisted.spread.pb.Referenceble</code>，因此它支持远程调用，即callRemote方法。前提是要将该对象传给根节点。</li>
<li>实现: ProxyReference(distributed/reference.py)</li>
</ul>
</li>
<li>_factory: PBClientFactory实例，用于获取跟节点的远程调用对象(getRootOBject)</li>
<li>_name: 节点名字</li>
</ul>
<p>在<code>RemoteObject.connect(self, addr)</code>中，子节点连接到根节点时，需要先远程调用根节点的takeProxy函数，并将_reference和_name传给该函数作为参数，如此根节点的childmanager会记下该子节点及其远程调用对象。关键代码如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class RemoteObject(object):</span><br><span class="line">    &#39;&#39;&#39;远程调用对象&#39;&#39;&#39;</span><br><span class="line">    </span><br><span class="line">    def __init__(self,name):</span><br><span class="line">        self._name &#x3D; name</span><br><span class="line">        self._factory &#x3D; pb.PBClientFactory()</span><br><span class="line">        self._reference &#x3D; ProxyReference()</span><br><span class="line">        self._addr &#x3D; None</span><br><span class="line">        </span><br><span class="line">    def connect(self,addr):</span><br><span class="line">        &#39;&#39;&#39;初始化远程调用对象&#39;&#39;&#39;</span><br><span class="line">        self._addr &#x3D; addr</span><br><span class="line">        reactor.connectTCP(addr[0], addr[1], self._factory)</span><br><span class="line">        self.takeProxy()</span><br><span class="line">        </span><br><span class="line">    def reconnect(self):</span><br><span class="line">        &#39;&#39;&#39;重新连接&#39;&#39;&#39;</span><br><span class="line">        self.connect(self._addr)</span><br><span class="line">        </span><br><span class="line">    def addServiceChannel(self,service):</span><br><span class="line">        &#39;&#39;&#39;设置引用对象&#39;&#39;&#39;</span><br><span class="line">        self._reference.addService(service)</span><br><span class="line">        </span><br><span class="line">    def takeProxy(self):</span><br><span class="line">        &#39;&#39;&#39;向远程服务端发送代理通道对象</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        deferedRemote &#x3D; self._factory.getRootObject()</span><br><span class="line">        deferedRemote.addCallback(callRemote,&#39;takeProxy&#39;,self._name,self._reference)</span><br><span class="line">    </span><br><span class="line">    def callRemote(self,commandId,*args,**kw):</span><br><span class="line">        &#39;&#39;&#39;远程调用&#39;&#39;&#39;</span><br><span class="line">        deferedRemote &#x3D; self._factory.getRootObject()</span><br><span class="line">        return deferedRemote.addCallback(callRemote,&#39;callTarget&#39;,commandId,*args,**kw)</span><br></pre></td></tr></table></figure>
<h2 id="二-Service装饰器"><a href="#二-Service装饰器" class="headerlink" title="二. Service装饰器"></a>二. Service装饰器</h2><p>至此，除了db和master节点之外，普通分布式节点已经能够正常通讯并且实现远程调用，由于netfactory, root, remote每个组件都抽离出了service用于挂载响应函数，因此firefly在server/globalobject.py中，实现了几个简单的装饰器：netserviceHandle remoteserviceHandle rootserviceHandle，分别用于挂载netfactory，root，remote的响应函数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def netserviceHandle(target):</span><br><span class="line">    GlobalObject().netfactory.service.mapTarget(target)</span><br><span class="line">        </span><br><span class="line">def rootserviceHandle(target):</span><br><span class="line">    GlobalObject().root.service.mapTarget(target)</span><br><span class="line"></span><br><span class="line">class remoteserviceHandle:</span><br><span class="line">	&#39;&#39;&#39; remoteserviceHandle装饰器需要一个参数，指出该接口提供给哪一个根节点使用</span><br><span class="line">    def __init__(self,remotename):</span><br><span class="line">        self.remotename &#x3D; remotename</span><br><span class="line">        </span><br><span class="line">   	def __call__(self,target):</span><br><span class="line">       GlobalObject().remote[self.remotename]._reference._service.mapTarget(target)</span><br></pre></td></tr></table></figure>
<p>这样客户端不用再知道关于globalobject的实现细节，用起来就像上一篇博客中的例子一样简单，暴露给用户globalobject组件只有root和remote，用于实现子节点和父节点之间的远程调用。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>firefly</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang supervisor</title>
    <url>/2015/07/erlang-superviosr/</url>
    <content><![CDATA[<h3 id="一-简介"><a href="#一-简介" class="headerlink" title="一. 简介"></a>一. 简介</h3><p>Supervisor(监督者)用于监督一个或多个Erlang OTP子进程，Supervisor本身是个behaviour，仅有一个Callback: <code>init/1</code>，该函数返回{ok, {ChildSpecList, RestartStrategy}}。ChildSpecs是ChildSpec列表，</p>
<p><strong>ChildSpec(子进程规范)</strong>：</p>
<p>指定要监控的子进程的所在模块，启动函数，启动参数，进程类型等等。格式为:</p>
<span id="more"></span>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">child_spec() &#x3D; &#123;id &#x3D;&gt; child_id(),	   	  % 一般为Child所在Module名</span><br><span class="line">               start &#x3D;&gt; mfargs(),     	% &#123;Module, StartFunc, Arg&#125;</span><br><span class="line">               restart &#x3D;&gt; restart(),  	% permanent:任何原因导致进程终止都重启 | transiend:意外终止时重启 | temporary:永不重启 </span><br><span class="line">               shutdown &#x3D;&gt; shutdown(),	% 终止子进程时给子进程预留的时间(毫秒) | brutal_kill 立即终止 | infinity 无限等待 用于Child也是supervisor的情况</span><br><span class="line">               type &#x3D;&gt; worker(),      	% 子进程类型 worker:工作者 | supervisor:监督者</span><br><span class="line">               modules &#x3D;&gt; modules()&#125;  	% 子进程所依赖的模块，用于定义热更新时的模块升级顺序，一般只列出子进程所在模块</span><br></pre></td></tr></table></figure>
<p><strong>RestartStrategy(重启策略)</strong>:</p>
<p>定义子进程的重启方式，为三元组{How, Max, Within}:</p>
<pre><code>How:     one_for_one:          仅对终止的子进程进行重启，不会影响到其他进程
        one_for_all:          一旦有某个子进程退出，讲终止该监督者下其它所有子进程，并进行全部重启
        rest_for_one:          按照ChildSpecList子进程规范列表中的定义顺序，所在在终止子进程之后的子进程将被终止，并按照顺序重启
        simple_one_for_one:   这是一种特殊的监督者，它管理多个同种类型的子进程，并且所有子进程都通过start_child接口动态添加并启动，在监督者启动时，不会启动任何子进程。

Max:    在Within时间片内，最多重启的次数

Within:  时间片，以秒为单位    
</code></pre><h3 id="二-重启机制"><a href="#二-重启机制" class="headerlink" title="二. 重启机制"></a>二. 重启机制</h3><p>子进程终止时，监督者会重启子进程，那么此时我们关心的是我们的State数据(假设我们的子进程是gen_server)，对于simple_one_for_one类型的监督者，经测试，监督者在重启Child的时候，会传入start_child时的初始化参数(该参数分为两部分，一部分是子进程规范中Arg指定的默认参数，以及<code>supervisor:start_child</code>传入的参数，将这两部分合并即为StartFunc最终收到的参数)。也就是说子进程终止时，我们的State数据丢失了。</p>
<p>考虑Player进程，它使用simple_one_for_one类型的监督者Player_sup，假设启动参数为PlayerId，在Player进程处理逻辑挂掉时，我们在terminate中将PlayerData落地，并做一些其它处理，如通知Agent。Player_sup在重启该Player进程时，会传入其上次传入的参数，即PlayerId，因此我们可以在init中重新加载玩家数据并通知Agent(Player进程重启后Pid会变化)。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>rebar的热更</title>
    <url>/2015/07/rebar-hotcode/</url>
    <content><![CDATA[<p>由于项目开发中早早地用到了<a href="https://github.com/basho/rebar">rebar</a>，虽然rebar在很多方面都比自己构建原生OTP应用更方便，但是每一次修改，都需要重新编译，发布，启动，非常耗费时间，而rebar本身的<a href="https://github.com/rebar/rebar/wiki/Upgrades">upgrade</a>又比较麻烦，是针对于版本发布的，不适合开发测试使用。</p>
<p>因此找到了一种基于.beam文件更新加载的方法，借鉴自<a href="https://github.com/mochi/mochiweb/blob/master/src/reloader.erl">mochiweb reloader</a>。</p>
<p>mochiweb reloader每隔一秒检查一次已加载的所有模块(<code>code:all_loaded()</code>)，遍历模块列表，检查其所在路径的变更状况，若模块在一秒内有变动，则通过<code>code:load_file(Module)</code>加载模块到运行时系统，执行热更。整个过程需要我们做的就是，将编译好的beam文件放到rebar rel对应的发布版本目录下，可通过<code>code:all_loaded()</code>查看各lib或app所在的发布路径，该发布路径是具有版本号的，但是由于我们在开发测试中暂时无需版本号控制，因此直接通过makefile将编译好的beam文件放到发布路径即可。</p>
<span id="more"></span>
<p>mochiweb reloader在加载Module后，会执行Module:test函数(如果该函数已导出)，可通过导出该函数完成一些升级时的处理。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>C链接模型_符号解析</title>
    <url>/2015/07/c-linker-model/</url>
    <content><![CDATA[<p>链接器的工作主要分为两个阶段：符号解析和重定位。本文简单介绍符号解析过程。</p>
<p>符号解析的功能是将每个模块符号引用绑定到一个确切的符号定义。</p>
<h3 id="1-符号分类"><a href="#1-符号分类" class="headerlink" title="1. 符号分类"></a>1. 符号分类</h3><ul>
<li>全局符号：非静态全局变量，非静态函数</li>
<li>外部符号：定义于其它模块，而被本模块引用的全局变量和函数</li>
<li>本地符号：静态变量(包括全局和局部)，静态函数</li>
</ul>
<span id="more"></span>
<p>对于静态局部变量，编译器会为其生成唯一的名字。如x.fun1，x.fun2。本地符号对链接器来说是不可见的。</p>
<h3 id="2-符号决议"><a href="#2-符号决议" class="headerlink" title="2. 符号决议"></a>2. 符号决议</h3><p>当编译器遇到一个不是本模块定义的符号时，会假设该函数由其它模块定义，并生成一个链接器符号表条目，交由链接器处理。如果链接器在它的任何输入模块都没有找到该符号，会给出一个类似<code>undefined reference to &#39;xxx&#39;</code>的链接错误。而如果链接器在输入模块中找到了一个以上的外部符号定义，这个时候就需要链接器进行符号决议，链接器对多个外部符号定义可能并不报错甚至警告，而是按照它的规则去选择其中一个符号定义。</p>
<p>链接器将各个模块输出的全局符号，分类为<strong>强符号</strong>和<strong>弱符号</strong>：</p>
<ul>
<li>强符号：函数和已初始化的全局变量</li>
<li>弱符号：为初始化全局变量</li>
</ul>
<p>根据强弱符号的定义，链接器按照下面的规则处理多重定义的符号：</p>
<ul>
<li>规则1：不允许有多个强符号定义</li>
<li>规则2：如果有一个强符号和多个弱符号，那么选择强符号</li>
<li>规则3：如果有多个弱符号，那么从这些弱符号中选择sizeof大的那个，如果大小相同，则选择先链接的那个</li>
</ul>
<p>上面的规则是很多链接错误的根源，因为编译器在决议时可能默默地替你作出了决定，你并不知晓。根据上面的规则，可以引出下面几个经典例子：</p>
<p>例1：</p>
<pre><code>// in lib1.c
int x;
void f()
&#123;
    x = 1235;
&#125;

// in main1.c
#include&lt;stdio.h&gt;
void f(void);

int x = 1234;

int main(void)
&#123;
    f();
    printf(&quot;x=%d\n&quot;, x);
    return 0;
&#125;
</code></pre><p>上面的代码中，main函数printf输出： <code>x=1235</code>。因为链接器通过规则2决议符号x的定义为main.c中的强符号定义，而lib.c的作者并不知情，他对x的使用和修改影响到了main.c。这种交互修改，相互影响将会很复杂，因为大家都以为自己在做对的事情，在用对的变量。而整个决议过程，链接器悄无声息地完成了。</p>
<p>例2：</p>
<pre><code>// in lib2.c
double x;
void f()
&#123;
    x = -0.0;
&#125;

// in main2.c
#include&lt;stdio.h&gt;
void f(void);

int x = 1234;
int y = 1235;

int main()
&#123;
    f();
    printf(&quot;x=0x%x y=0x%x \n&quot;, x, y);
    return 0;
&#125;
</code></pre><p>这种情况下，程序得到输出： <code>x=0x0 y=0x80000000</code>，而链接器(gcc ld)也终于给出一条警告：</p>
<p><code>ld: warning: tentative definition of &#39;_x&#39; with size 8 from &#39;obj/Debug/lib2.o&#39; is being replaced by real definition of smaller size 4 from &#39;obj/Debug/main2.o&#39;</code></p>
<p>链接器决议的是符号地址，而相邻的全局变量可能在.data段中的内存地址也相邻，因此也就引发了更复杂的问题。这一点和栈溢出很像，但是比栈溢出更复杂，因为问题出在多个模块之间，而不是在一个函数内部。</p>
<p>例3：</p>
<pre><code>// in lib3.c
struct
&#123;
    int a;
    int b;
&#125; x;

void f()
&#123;
    x.a = 123;
    x.b = 456;
    printf(&quot;in f(): sizeof(x)=%d, (&amp;x)=0x%08x\n&quot;, sizeof(x), &amp;x);
&#125;

// in main3.c
#include&lt;stdio.h&gt;
void f(void);

int x;
int y;

int main()
&#123;
    f();
    printf(&quot;in main(): sizeof(x)=%d, (&amp;x)=0x%08x, (&amp;x)=0x%08x, x=%d,y=%d \n&quot;, sizeof(x), &amp;x, &amp;y, x, y);
    return 0;
&#125;
</code></pre><p>程序输出：</p>
<pre><code>in f(): sizeof(x)=8, (&amp;x)=0x02489018
in main(): sizeof(x)=4, (&amp;x)=0x02489018, (&amp;y)=0x02489020, x=123,y=0
</code></pre><p>始终记住，外部符号决议的是地址，因此无论lib3.c和main3.c中，符号x地址都是唯一的，无论其被定义了几次。其次sizeof是编译器决议，与链接无关，编译器只看得到本模块的定义或声明。最后，由于符号x决议到lib3.c中的x，其size是8，因此main3.c中的y的地址比x大8，这是由链接器将lib3.o和main3.o合并后填入可执行文件的.data段的。因此y是无关变量，被初始化为0，注意和例2的区别。</p>
<h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h3><p>由于符号决议容易引发的种种问题，我们在写C的时候应注意：</p>
<ul>
<li>尽量用static属性隐藏变量和函数在模块内的声明，就像在C++中尽量用private保护类私有成员一样。</li>
<li>少定义弱符号，尽量初始化全局变量，这样链接器会根据规则1给出多个符号定义的错误。</li>
<li>为链接器设置必要选项，如gcc的 -fno-common，这样在遇到多重符号定义时，链接器会给出警告。</li>
</ul>
<h3 id="4-C-的符号决议"><a href="#4-C-的符号决议" class="headerlink" title="4. C++的符号决议"></a>4. C++的符号决议</h3><p>C++并不支持强弱符号同时存在，所有符号都只能有一个定义(函数重载通过改写函数符号来确保其唯一)，因此在很大程度上避免了C中的链接器困扰。</p>
]]></content>
      <categories>
        <category>c/c++</category>
      </categories>
      <tags>
        <tag>c/c++</tag>
      </tags>
  </entry>
  <entry>
    <title>kbengine 源码导读(一) 网络底层</title>
    <url>/2015/07/kbengine-study1/</url>
    <content><![CDATA[<h2 id="一-network部分"><a href="#一-network部分" class="headerlink" title="一. network部分"></a>一. network部分</h2><p><strong>EndPoint:</strong></p>
<p>抽象一个Socket及其相关操作，隔离平台相关性。</p>
<p><strong>TcpPacket:</strong></p>
<p>代表一个TCP包，这个包只是recv收到的字节流，并不是上层协议中的消息(Message)。</p>
<p><strong>MsgHandlers:</strong></p>
<p>每个MessageHandler类对应一个消息的处理。MsgHanders维护MsgId -&gt; MsgHandler的映射。</p>
<span id="more"></span>
<p><strong>Channel:</strong></p>
<p>抽象一个Socket连接，每个EndPoint都有其对应的Channel，它代表和维护一个Socket连接，如缓冲Packet，统计连接状态等。<br>提供一个ProcessPackets(MsgHanders* handers)接口处理该Channel上所有待处理数据。</p>
<p><strong>EventPoller:</strong></p>
<p>用于注册和回调网络事件，具体的网络事件由其子类实现processPendingEvents产生，目前EventPoller有两个子类: EpollPoller和SelectorPoller，分别针对于Linux和Windows。<br>通过bool registerForRead(int fd, InputNotificationHandler * handler);注册套接字的可读事件，回调类需实现InputNotificationHandler接口。</p>
<p><strong>EventDispatcher:</strong></p>
<p>核心类，管理和分发所有事件，包括网络事件，定时器事件，任务队列，统计信息等等。<br>它包含 EventPoller Tasks  Timers64 三个组件，在每次处理时，依次在这三个组件中取出事件或任务进行处理。</p>
<p><strong>ListenerReceiver/PacketReceiver:</strong></p>
<p>继承自InputNotificationHandler，分别用于处理监听套接字和客户端套接字的可读事件，通过bool registerReadFileDescriptor(int fd, InputNotificationHandler * handler); 注册可读事件。</p>
<p><strong>NetworkInterface:</strong></p>
<p>维护管理监听套接字，创建监听套接字对应的ListenerReceiver，并且通过一个EndPoint -&gt; Channel的Map管理所有已连接套接字，提供一个processChannels(MsgHandlers* handers)接口处理所有Channel上的待处理数据。这一点上，有点像NGServer:ServiceManager。</p>
<h2 id="二-LoginApp-启动流程"><a href="#二-LoginApp-启动流程" class="headerlink" title="二. LoginApp 启动流程"></a>二. LoginApp 启动流程</h2><p><strong>main:</strong></p>
<p>所有App都有一致的main函数，生成组件唯一ID，读取配置等，转到kbeMainT<LoginApp></p>
<p><strong>kbeMainT:</strong></p>
<ol>
<li>生成公钥私钥，调试相关初始化</li>
<li>创建单例EventDispatcher和NetworkInterface</li>
<li>创建LoginApp，并传入EventDispatcher和NetworkInterface</li>
<li>调用LoginApp:run()</li>
</ol>
<p><strong>LoginApp:run():</strong></p>
<p>调用基类ServerApp:run()，后者调用 EventDispatcher:processUntilBreak() 开始处理各种事件</p>
<p><strong>LoginAppInterface:</strong></p>
<p>存放和注册LoginApp响应的所有消息的消息回调，参见loginapp_interface.h。<br>通过LoginAppInterface::messageHandlers即可导出消息处理类</p>
<p><strong>细节流程:</strong></p>
<ol>
<li>NetworkInterface构造函数中，创建ListenSocket和ListenerReceiver，注册到EventDispatcher</li>
<li>当有新连接到达时，EventDispatcher触发ListenerReceiver:handleInputNotification</li>
<li>handleInputNotification创建新套接字的Channel，并将Channel注册到NetworkInterface</li>
<li>新Channel初始化时，创建新套接字对应的PacketReceiver，并注册到EventDispatcher</li>
<li>在LoginApp::initializeEnd中，添加了一个TIMEOUT_CHECK_STATUS Timer 该Timer触发时，会最终调用networkInterface().processChannels() 处理各Channel的消息，目前该Timer是20mss</li>
</ol>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>kbengine</tag>
      </tags>
  </entry>
  <entry>
    <title>kbengine 源码导读(二) 加载流程</title>
    <url>/2015/07/kbengine-study2/</url>
    <content><![CDATA[<h2 id="一-登录流程"><a href="#一-登录流程" class="headerlink" title="一. 登录流程"></a>一. 登录流程</h2><p><strong>注册</strong></p>
<pre><code>Unity3d:CreateAccount
Loginapp:reqCreateAccount 
-&gt; dbmgr:reqCreateAccount 
-&gt; Loginapp:onReqCreateAccountResult 
-&gt; Client:onReqCreateAccountResult
</code></pre><span id="more"></span>
<p><strong>登录 Step1</strong></p>
<pre><code>Unity3d:login
Loginapp:login 
-&gt; dbmgr:onAccountLogin     //检查登录 将登录结果返回给Loginapp
-&gt; Loginapp:onLoginAccountQueryResultFromDbmgr //转发给BaseappMgr分配Baseapp
-&gt; BaseappMgr:registerPendingAccountToBaseapp //将客户端分配到当前负载最低的Baseapp上 并返回该Baseapp的Ip Port
-&gt; onLoginAccountQueryBaseappAddrFromBaseappmgr //将Baseapp的Ip Port转发给客户端
-&gt; Client:onLoginSuccessfully
</code></pre><p><strong>登录 Step2</strong></p>
<pre><code>Unity3d:loginGateway      //尝试在指定Baseapp上登录
Baseapp:loginGateway    //检查登录 处理重复登录 向数据库查询账号详细信息
dbmgr:queryAccount        //查询账号详细信息 返回给Baseapp
Baseapp:onQueryAccountCBFromDbmgr    //创建账号的Proxy并传入客户端的mailbox(用于和客户端交互)，Demo中的Account.py即继承于KBEngine.Proxy。
</code></pre><p><strong>获角 选角 创角</strong></p>
<p>Unity3d的<code>reqAvatarList</code> <code>selectAvatarGame</code> <code>reqCreateAvatar</code> 都将直接转到Account.py中对应的相应函数上，KBEngine.Proxy已经封装了和客户端通讯的方法(通过Mailbox)。</p>
<h2 id="二-地图创建"><a href="#二-地图创建" class="headerlink" title="二. 地图创建"></a>二. 地图创建</h2><ol>
<li>Baseapp启动，会回调到Python脚本层的onBaseAppReady(base/kbengine.py)</li>
<li>第一个Baseapp启动时，在本Baseapp上创建世界管理器spaces Entity(Baseapp:createBaseLocally) 定义于spaces.py</li>
<li>spaces读取配置文件data/d_spaces.py，为每一个Space Entity创建一个SpaceAlloc，通过定时器分批次调用SpaceAlloc.init创建Space Entity(一秒回调创建一个)</li>
<li>SpaceAlloc.init通过KBEngine.CreateSpaceAnyWhere()完成</li>
<li>Baseapp:CreateSpaceAnyWhere()会转发给BaseappMgr，最终落在当前负载最轻的Baseapp上，通过CreateEntity完成Space Entity创建</li>
<li>创建完成后，回调到发起方Baseapp:CreateSpaceAnywhereCallback() 最终回调到Python层SpaceAlloc.py:onSpaceCreatedCB()<br>注意，上面提到的Space Entity并不是真正的Space，而是Baseapp用于操作Space的一个句柄，真正的Sapce需要挂在Cellapp上，在srcipts/base/Space.py中完成真正的Space创建：</li>
<li>Space.py:_<em>init_</em>()中，通过Baseapp:CreateInNewSpace()创建真正的Space，之后读取该Space上需创建的所有 Entity(配置在scripts/data/d_spaces_spawns中)，等待其上面的Entity被创建</li>
<li>Baseapp:CreateInNewSpace()将请求转发给CellappMgr，后者会将请求分发到当前负载最轻的Cellapp上，Cellapp:onCreateInNewSpaceFromBaseapp()完成Space创建，回调Baseapp:OnEntityGetCell()</li>
<li>注意，此时cell/Space.py:_<em>init_</em>()被调用，开始加载真正的几何数据和寻路相关，回调到Baseapp:OnEntityGetCell()</li>
<li>Baseapp:OnEntityGetCell()判断该Entity是否是客户端，如果是则需要通知客户端(Baseapp::onClientEntityEnterWorld)，之后回调脚本Space.py:OnGetCell()</li>
</ol>
<p>至此，地图创建完成。</p>
<h2 id="三-生成NPC-Monster"><a href="#三-生成NPC-Monster" class="headerlink" title="三. 生成NPC/Monster"></a>三. 生成NPC/Monster</h2><p>对于NPC/Monster，是先创建其出生点，再由出生点创建真正的NPC/Monster</p>
<ol>
<li>接上面Space的Cell和Base部分均创建完成后，base/Space.py:OnGetCell()中，注册一个定时器，开始创建该Space上面的所有NPC/Monster的SpawnPoint，每0.1秒创建一个</li>
<li>base/SpawnPoint.py中，创建其Cell部分</li>
<li>cell/SpawnPoint.py中，通过createEntity创建其对应的真正的NPC/Monster</li>
</ol>
<h2 id="四-Entity-实体"><a href="#四-Entity-实体" class="headerlink" title="四. Entity (实体)"></a>四. Entity (实体)</h2><p>Entity是服务器与客户端交互的一切实体的总称，包括：账号，角色，NCP，Monster，公会，等等。Entity通过 <Entity>.def 来定义自己的属性和方法，指定属性和方法的作用域，即(Base, Cell, Client)的访问权限。因此C/S之间的消息协议实际上只是针对于Entity的远程调用。所以KBEngine本身没有消息协议一说，所有业务逻辑都围绕着Entity展开，通过<Entity>.def来维护。</p>
<p>参见：</p>
<p><a href="http://kbengine.org/cn/docs/programming/entitydef.html">http://kbengine.org/cn/docs/programming/entitydef.html</a><br><a href="http://kbengine.org/cn/docs/configuration/entities.html">http://kbengine.org/cn/docs/configuration/entities.html</a></p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>kbengine</tag>
      </tags>
  </entry>
  <entry>
    <title>开发笔记(1) cluster server</title>
    <url>/2015/08/erlang-server-design1-cluster-server/</url>
    <content><![CDATA[<h3 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h3><p>在游戏服务器中，通常有一些功能本身非常内聚，甚至是无状态的，在这种时候，我们应该将其单独地做成一个服务，而不是嵌入到GameServer中，这种思想就是所谓的服务(<a href="http://martinfowler.com/articles/microservices.html#MicroservicesAndSoa">microservice</a>)思想。</p>
<p>服务发现本身可以看做是一个业务独立的”特殊服务”，它用于逻辑服务的注册/查找/配置信息共享。通常由如下三部分组成：</p>
<ul>
<li>一个强一致，高可用的服务存储</li>
<li>提供服务注册和服务健康状态监控的能力</li>
<li>提供查找服务，连接服务的能力</li>
</ul>
<p>在分布式领域中，服务发现是一个非常实用和通用的组件，并且已经有一些比较成熟的组件，如<a href="https://zookeeper.apache.org/">zookeeper</a>，<a href="https://github.com/coreos/etcd">etcd</a>等。服务发现组件的好处有很多：微服理念，为负载均衡，灾难恢复提供基础。更多应用场景，可参见etcd的<a href="http://www.infoq.com/cn/articles/etcd-interpretation-application-scenario-implement-principle">这篇文章</a>。</p>
<span id="more"></span>
<h3 id="cluster-server"><a href="#cluster-server" class="headerlink" title="cluster_server"></a>cluster_server</h3><p>先来谈谈我们的集群划分，基于我们的服务器设计，整个集群由N个node组成，node可根据其职责来划分，如player_node，master_node，pvp_node，每个node上跑对应类型的进程，每种node可有多个。其中master_node负责监控/管理所有业务逻辑node，新加入的node只需和master_node连接，这种粒度的划分本身是有利弊的，我们在之后的开发中对它进行了<a href="http://wudaijun.com/2016/01/erlang-server-design5-server-node/">改进</a>，就我们本身cluster_server的设计初衷而言，本质职责是没变的。</p>
<p>在GS中，我们在查找某个服务时，如某个PlayerId对应的player_server，我无需知道这个player_server位于哪个player_node上，甚至无需知道是否在本台物理机上，我只需获取到这个player_server的Pid，即可与其通信。显然地，为了将服务的使用者和服务本身解耦，我们需要维护这样一个 PlayerId -&gt; player_server Pid 的映射表，并且这个表是集群共同访问的，这也就是服务发现的基本需求。</p>
<h4 id="服务注册-查找，状态共享"><a href="#服务注册-查找，状态共享" class="headerlink" title="服务注册/查找，状态共享"></a>服务注册/查找，状态共享</h4><p>在Erlang中，我们的服务本身通常是一个进程，即Pid，我们可以用分布式数据库mnesia实现一个简易的cluster_server，它处理的一件事是：根据不同Key值(Erlang Term)取出对应服务的Pid。cluster_server本身是节点唯一的进程，用于和mnesia交互，实现服务注册/服务查找。为了方便使用，我将Key定义为一个type加一个id，表的初步定义如下：</p>
<pre><code>-record(cluster_(TYPE)_process, &#123;id, node, pid, share&#125;).  % TYPE: pvp player 等  share: 用于状态共享
</code></pre><p>基于这张mnesia表，可以实现如下功能：</p>
<ol>
<li>服务注册：通过事务保证写入的原子性，将不同类型的服务写入对应的表中</li>
<li>服务查找：根据不同的类型访问不同的表，用mnesia的ram_copies来优化读取，使读取像本地ets一样快</li>
<li>服务注销：在服务不可用或被终止时，通过事务删除对应表条目</li>
<li>状态共享：通过share字段可以获知服务的当前状态或配置</li>
</ol>
<h4 id="服务创建，负载均衡"><a href="#服务创建，负载均衡" class="headerlink" title="服务创建，负载均衡"></a>服务创建，负载均衡</h4><p>上面实现了最简单的服务注册/查找机制，服务本身的创建和维护由服务提供者管理，在GS集群中，通常我们是希望所有的服务被统一监控和管理，比如某个服务节点挂了，那么上面的所有服务将被注销(主动注销/失联注销)，这个时候应该允许使用者或master重启该服务，将该服务分配到其它可用节点上。</p>
<p>因此我们还需要维护可用节点表，用于服务创建：</p>
<pre><code>-record(cluster_(type)_process, &#123;id, node, pid, share&#125;).
</code></pre><p>通过share字段，可以获取到节点当前的状态信息，比如当前负载，这样做负载均衡就比较容易了，将服务创建的任务分发到当前负载较轻的节点即可。</p>
<h4 id="服务监控，灾难恢复"><a href="#服务监控，灾难恢复" class="headerlink" title="服务监控，灾难恢复"></a>服务监控，灾难恢复</h4><p>对于关键的服务或者是无状态的服务，可以通过master来监控其状态，在其不可用时，对其进行选择性恢复。比如当某服务所在物理机断电或断网，此时上面的服务都来不及注销自己，通过<code>monitor_node/2</code>，master会在数次心跳检测失败后，收到<code>nodedown</code>消息，此时master节点可以代为注销失联结节点上所有服务，并且决定这些服务是否需要重建在其它节点上。</p>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><h4 id="一致性问题"><a href="#一致性问题" class="headerlink" title="一致性问题"></a>一致性问题</h4><ul>
<li>如果不使用事务，服务A可能覆写/误删服务B</li>
<li>服务注册信息同步到其它节点的时间差，可能导致的不同步(服务的写入者无论是服务的发起方还是服务本身，都会存在这个问题)。</li>
</ul>
<p>解决方案：</p>
<ol>
<li><p>使用事务</p>
<p> 这是最”简单”的方案，主要是性能问题，特别是游戏的波峰时段，这种延迟会扩散</p>
</li>
<li><p>串行化服务管理</p>
<p> 将服务的查找或者是注册/注销，交由一个Proxy来做(经由某种分组规则ServerId)，则可使用脏读写，避免一致性问题。但是会有单点，并且弱化了分布式的特性。</p>
</li>
<li><p>服务查询</p>
<p> 将表不添加本地拷贝，直接使用remote类型表进行访问(事务)，在本节点对Pid进行保存，采用某种机制来确保缓存Pid的正确性(如monitor)</p>
</li>
<li><p>退化ETS</p>
<p> 将一些频繁访问和使用的服务退化为ETS(特别是player和agent)，主要目的是减轻mnesia压力(28原则)，使mnesia可以安全的使用事务。但这部分服务也失去了使用mnesia的优势，个人觉得不如方案3。</p>
</li>
</ol>
<h4 id="全联通问题"><a href="#全联通问题" class="headerlink" title="全联通问题"></a>全联通问题</h4><p>mnesia必须建立在全联通网络上，在节点数量超过10个时，就需要关注这个问题了。</p>
<p>解决方案：</p>
<p>可为节点分组(如5个一组)，设定代理节点，由代理节点组成mnesia集群。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang Ports</title>
    <url>/2015/08/erlang-port/</url>
    <content><![CDATA[<h3 id="OverView"><a href="#OverView" class="headerlink" title="OverView"></a>OverView</h3><p>Erlang外部调用的几种方式：</p>
<p>外部接入(OS进程级)：</p>
<ul>
<li><a href="http://erlang.org/doc/tutorial/c_port.html">Ports</a>: 用C实现的可执行程序，以Port的方式与Erlang交互。</li>
<li><a href="http://erlang.org/doc/tutorial/cnode.html">C Nodes</a>: 用C模拟Erlang Node行为实现的可执行程序。</li>
<li><a href="http://erlang.org/doc/apps/jinterface/jinterface_users_guide.html">Jinterface</a>: Java和Erlang的通讯接口。</li>
<li>Network: 通过自定义序列化格式与Erlang节点网络交互，如<a href="http://bert-rpc.org/">bert-rpc</a></li>
</ul>
<p>内部接入(和虚拟机在同一个OS进程内)：</p>
<ul>
<li>BIF: Erlang大部分BIF用C实现，如erlang:now，lists:reverse等</li>
<li><a href="http://erlang.org/doc/tutorial/c_portdriver.html)">Port Driver</a>: 以链接库方式将Port嵌入虚拟机，也叫Linkin Driver</li>
<li><a href="http://www.erlang.org/doc/tutorial/nif.html">NIF</a>: 虚拟机直接调用C原生代码</li>
</ul>
<p>下面主要理解常用的三种：Ports, Port Driver, NIF。</p>
<span id="more"></span>
<h3 id="Ports"><a href="#Ports" class="headerlink" title="Ports"></a>Ports</h3><p><img src="/assets/image/201508/Erlang_Port.png" alt="" title="普通端口"></p>
<p>图一. Ports 通信模型</p>
<p>Port是连接外部程序进程和Erlang虚拟机的桥梁，外部进程通过标准输入输出与Erlang虚拟机交互，并运行于独立的地址空间。</p>
<p>从操作系统的角度看，外部程序和Erlang虚拟机都是独立允许的进程，只不过外部程序的标准输入输出与Erlang虚拟机对接在了一起而已。因此外部程序可以通过<code>read(0, req_buf, len)</code>来获取虚拟机发出的指令，也可通过<code>write(1, ack_buf, len)</code>来发出响应。当外部程序崩溃了，Erlang虚拟机可以检测到，可以选择重启等对应策略。由于两者在不同的地址空间，通过标准IO交互，因此外部程序的崩溃不会影响到Erlang虚拟机本身的正常运行。</p>
<p>每个Port都有一个owner进程，通常为创建Port的进程，当owner进程终止时，Port也将被自动关闭。Ports使用示例参考<a href="http://erlang.org/doc/tutorial/c_port.html">Ports</a>。</p>
<p>Port的优势在于隔离性和安全性，因为外部程序的任何异常都不会导致虚拟机崩溃，并且Erlang层通过<code>receive</code>来实现同步调用等待外部程序响应时，是不会影响Erlang虚拟机调度的。至于Port的缺点，主要是效率低，由于传递的是字节流数据，因此需要对数据进行序列化反序列化，Erlang本身针对C和Java提供了对应的编解码库ei和Jinterface。</p>
<h3 id="Port-Driver"><a href="#Port-Driver" class="headerlink" title="Port Driver"></a>Port Driver</h3><p><img src="/assets/image/201508/Erlang_Port_Driver.png" alt="" title="端口驱动"></p>
<p>图二. Port Driver 通信模型</p>
<p>从Erlang层来看，端口驱动和普通端口所体现的行为模式一样，收发消息，注册名字，并且共用一套Port API。但是端口驱动本身是作为一个链接库运行于Erlang虚拟机中的，也就是和Erlang虚拟机共享一个操作系统进程。</p>
<p>Port Driver分为静态链接和动态链接两种，前者和虚拟机一起编译，在虚拟机启动时被加载，后者通过动态链接库的方式嵌入到虚拟机。出于灵活性和易用性的原因，通常使用后者。</p>
<p>虚拟机和Port Driver的交互方式与Port一样，Port和Port Driver在Erlang层表现的语义一致。</p>
<p>Port Driver通过一个<a href="http://erlang.org/doc/man/driver_entry.html">driver_entry</a>结构体与虚拟机交互，该结构体注册了driver针对各种虚拟机事件的响应函数。<a href="http://wudaijun.com/2015/01/skynet-c-module/">skynet挂接service</a>的思想大概也继承于此。driver_entry结构体主要成员如下：</p>
<pre><code>typedef struct erl_drv_entry &#123;
// 当链接库被加载(erl_ddll:load_driver/2)时调用，同一个链接库的多个driver实例来说，只调用一次
int (*init)(void);

// 当Erlang层调用erlang:open_port/2时调用，每个driver实例执行一次
ErlDrvData (*start)(ErlDrvPort port, char *command);

// 当Port Driver被关闭(erlang:port_close/1,owner进程终止,虚拟机停止等)时执行
void (*stop)(ErlDrvData drv_data);

// 收到Erlang进程发来的消息(Port ! &#123;PortOwner, &#123;command, Data&#125;&#125; or erlang:port_command(Port, Data))
void (*output)(ErlDrvData drv_data, char *buf, ErlDrvSizeT len);

// 用于基于事件的异步Driver 通过erl_driver:driver_select函数进行事件(socket,pipe,Event等)监听
void (*ready_input)(ErlDrvData drv_data, ErlDrvEvent event);
void (*ready_output)(ErlDrvData drv_data, ErlDrvEvent event);

// Driver名字 用于open_port/2
char *driver_name;

// 当Driver被卸载时调用(erl_ddll:unload_driver/1)，和init对应。仅针对动态链接Driver
void (*finish)(void);

// 被erlang:port_control/3(类似ioctl)触发
ErlDrvSSizeT (*control)(ErlDrvData drv_data, unsigned int command,
                        char *buf, ErlDrvSizeT len,
            char **rbuf, ErlDrvSizeT rlen);

// Driver定义的超时回调，通过erl_driver:driver_set_timer设置
void (*timeout)(ErlDrvData drv_data);

// output的高级版本，通过ErlIOVec避免了数据拷贝，更高效
void (*outputv)(ErlDrvData drv_data, ErlIOVec *ev);

// 用于基于线程池的异步Driver(erl_driver:driver_async) 当线程池中的的任务执行完成时，由虚拟机调度线程回调该函数                       
void (*ready_async)(ErlDrvData drv_data, ErlDrvThreadData thread_data);

// 当Driver即将关闭时，在stop之前调用 用于清理Driver队列中的数据(?)
void (*flush)(ErlDrvData drv_data);

// 被erlang:port_call/3触发 和port_control类似，但使用ei库编码ETerm
ErlDrvSSizeT (*call)(ErlDrvData drv_data, unsigned int command,
                     char *buf, ErlDrvSizeT len,
         char **rbuf, ErlDrvSizeT rlen, unsigned int *flags);

// Driver 监听的进程退出信号(erl_driver:driver_monitor_process)
void (*process_exit)(ErlDrvData drv_data, ErlDrvMonitor *monitor);
&#125; ErlDrvEntry;
</code></pre><p>该结构体比较复杂，主要原因是Erlang Port Driver支持多种运行方式：</p>
<ol>
<li>运行于虚拟机调度线程的基本模式</li>
<li>基于select事件触发的异步Driver</li>
<li>基于异步线程池的异步Driver</li>
</ol>
<p>三种模式的示例参考<a href="http://erlang.org/doc/tutorial/c_portdriver.html)">Port Driver</a>，<a href="(http://erlang.org/doc/apps/erts/driver.html)">How to Implement a Driver</a>，Driver API接口文档：<a href="http://erlang.org/doc/man/erl_driver.html">erl_driver</a>。Erlang虚拟机提供的异步线程池可通过<code>+A</code>选项设置。</p>
<p>端口驱动的主要优势是效率高，但是缺点是链入的动态链接库本身出现内测泄露或异常，将影响虚拟机的正常运行甚至导致虚拟机崩溃。将外部模块的问题带入了虚拟机本身。对于耗时较长或阻塞的任务，应该通过异步方式设计，避免影响虚拟机调度。</p>
<h3 id="NIF"><a href="#NIF" class="headerlink" title="NIF"></a>NIF</h3><p>NIF是Erlang调用C代码最简单高效的方案，对Erlang层来说，调用NIF就像调用普通函数一样，只不过这个函数是由C实现的。NIF是同步语义的，运行于调度线程中，无需上下文切换，因此效率很高。但也引出一个问题，对于执行时间长的NIF，在NIF返回之前，调度线程不能做别的事情，影响了虚拟机的公平调度，甚至会影响调度线程之间的协作。因此NIF是把双刃剑，在使用的时候要尤其小心。</p>
<p>Erlang建议的NIF执行时间不要超过1ms，针对于执行时间长的NIF，有如下几种方案：</p>
<ol>
<li>分割任务，将单次长时间调用切分为多次短时间调用，再合并结果。这种方案显然不通用</li>
<li>让NIF参与调度。在NIF中恰当时机通过<code>enif_consume_timeslice</code>汇报消耗的时间片，让虚拟机确定是否放弃控制权并通过返回值通知NIF(做上下文保存等)</li>
<li>使用脏调度器，让NIF在非调度线程中执行</li>
</ol>
<p>Erlang默认并未启用脏调度器，通过<code>--enable-dirty-schedulers</code>选项重新编译虚拟机可打开脏调度器，目前脏调度器只能被NIF使用。</p>
<p>关于脏调度器，NIF测试与调优，参考：</p>
<ol>
<li><a href="http://www.cnblogs.com/zhengsyao/p/dirty_scheduler_otp_17rc1.html">siyao blog</a></li>
<li><a href="https://github.com/slfritchie/nifwait/tree/md5">nifwait</a></li>
<li><a href="https://github.com/vinoski/bitwise/">bitwise</a>(<a href="https://github.com/vinoski/bitwise/blob/master/vinoski-opt-native-code.pdf">其中的PDF</a>质量很高)</li>
</ol>
<p>Port Driver和NIF与虚拟机调度密切相关，想要在实践中用好它们，还是要加深对Erlang虚拟机调度的理解，如公平调度，进程规约，调度器协同等。再来理解异步线程池，脏调度器的存在的意义以及适用场景。另外，Port Driver和NIF还有一种用法是自己创建新的线程或线程池(Driver和NIF也提供了线程操作API)，我们项目组也这么用过，这基本是费力不讨好的一种方案，还极易出错。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>开发笔记(2) 服务器Lua战斗</title>
    <url>/2015/09/erlang-server-design2-erlang-lua-battle/</url>
    <content><![CDATA[<p>服务器战斗系统是自动战斗的，没有玩家实际操作，因此实际上是一份客户端的Lua战斗代码，这里讨论如何在Erlang中植入Lua代码。</p>
<span id="more"></span>
<h3 id="1-Port-Driver"><a href="#1-Port-Driver" class="headerlink" title="1. Port Driver"></a>1. Port Driver</h3><p>最开始，出于简单考虑，我使用Port Driver的方式来挂接战斗模块，使用<a href="https://github.com/Motiejus/erlualib">erlualib</a>库，通过<code>luam:one_call</code>执行调用，进行了简单的时间统计，其中new_state&lt;1ms，dostring: 600ms，call: 20-300ms。</p>
<p>由于是3D+NvN的战斗，整个Lua代码跑起来还是很耗时的，跑一场战斗需要接近1s的时间。由于Port Driver中的Lua代码是在虚拟机调度线程上下文中执行的，而Erlang虚拟机无法对原生代码进行公平调度，这会使在Lua代码执行期间，该调度器上其它任务都被挂起，得不到正常调度。</p>
<h3 id="2-异步nif"><a href="#2-异步nif" class="headerlink" title="2. 异步nif"></a>2. 异步nif</h3><p>为了避免阻塞调度，Port driver是行不通的，我们还剩两种方案：</p>
<ol>
<li>用Ports，将战斗独立为一个操作系统进程</li>
<li>异步nif</li>
</ol>
<p>考虑到尽量利用Erlang Node以及以后手动PVP的可能性，我选择了方案二，而刚好同事写了一个<a href="https://github.com/zhuoyikang/elua">异步nif库</a>，也就拿来测试了。所谓异步nif，就是在nif内部提供一个C原生线程池，来做nif实际的工作，而Erlang虚拟机内只需要receive阻塞等待结果即可，Erlang层面的阻塞是可被调度的，也就是不会影响到节点上其它进程的公平调度。</p>
<p>简单介绍一下elua，elua内部提供一个线程池，每个线程都有自己的任务队列，同一个lua state上的操作将会被推送到同一个线程的任务队列中(通过简单hash)，以保证lua state不被并发。elua使用和定制都非常灵活，可以很轻松地添加nif接口和自定义数据类型的序列化。</p>
<h3 id="3-序列化数据"><a href="#3-序列化数据" class="headerlink" title="3. 序列化数据"></a>3. 序列化数据</h3><p>在erlualib中，数据序列化是在erlang层完成的，erlang层通过<code>lua:push_xxx</code>来将基本数据(bool,integer,atom)一个个压入Lua栈，每一次push操作，都是一次port_command，而战斗入口的数据是比较繁杂的，英雄成长，技能，装备属性等等，涉及很多key-value，一来是序列化效率低，二来是这种数据结构不能兼容于客户端。同一套战斗入口数据，最好能同时用于服务器和客户端的战斗模块。</p>
<p>因此在elua中，我选择使用protobuf，通过二进制传输战斗入口数据，这个二进制流也可以传输给客户端，用于支持重放。</p>
<h3 id="4-进程池"><a href="#4-进程池" class="headerlink" title="4. 进程池"></a>4. 进程池</h3><p>由于每场战斗是独立的，原则上对lua state是没有依赖的，事先分配一个lua state池，将耗时的dostring操作提前完成，每场战斗取出一个可用的lua state，然后spawn一个battle_worker进程来跑战斗，跑完之后将战斗结果cast回逻辑进程，进行后续逻辑处理。这样receive阻塞放在battle_worker中，实际Lua代码执行由elua线程池完成，对逻辑进程来说，是完全异步的。</p>
<p>受限于elua内部的C线程(称为worker)和CPU核心数的多少，并不是erlang process越多，战斗就跑得越快，当战斗请求过多时，请求被阻塞在elua内部各个worker的任务队列中。并且spawn的process不够健壮，也没有重启机制。显然我们应该让worker process常驻，并且通过gen_server+sup实现，worker process的个数可以刚好等于elua worker的个数，这样process和worker可以直接保持一对一的关系，修改elua任务分配hash算法，让process[i]的战斗请求将分发到worker[i]的任务队列。这样我们只需把process的分配调度做好，elua即可高效地利用起来。每个process持有一个lua state，保证lua state不被并发。当战斗请求过多时，消息将阻塞在process的消息队列中，而不是elua worker的任务队列中。</p>
<p>另外，如果战斗模块负荷较重，可以将elua线程池的大小设为Erlang虚拟机可用的CPU个数-1，这样即使elua所有线程忙碌，也不会占用全部的CPU，进一步保证节点其它进程得到调度。</p>
<h3 id="5-无状态服务"><a href="#5-无状态服务" class="headerlink" title="5. 无状态服务"></a>5. 无状态服务</h3><p>到这里，我们讨论的都是如何将Lua代码嵌入在逻辑服务器中，如pvp_server，这样做实际上还有两点隐患：</p>
<ol>
<li>多个pvp_server不能有效地利用同一个pvp_node资源，因为它们具有各自的worker proces pool</li>
<li>我们都假设elua和Lua战斗代码是足够健壮的，虽然Lua代码本身的异常可以通过<code>lua_pcall</code>捕获，但是Lua虚拟机本身的状态异常，如内存增长，仍然是不稳定的因素，可能会影响到整个pvp_node的逻辑处理</li>
</ol>
<p>因此，将所有Lua战斗相关的东西，抽象到一个battle_node上，才是最好的方案，battle_node本身没有状态，可以为来自不同ServerId，不同模块的战斗请求提供服务，battle_node上有唯一的battle_server，动态管理该节点上的battle_worker process，并且分发任务，battle_server本身不属于任何一个ServerId。battle_worker由sup监控，并且在启动和挂掉时，都向battle_server注册/注销自己。</p>
<p>battle_server仍然需要向cluster_server注册自己，只不过不是以逻辑Server：{NodeType,ServerId,Node,Pid}的方式，而是以服务的方式：{ServiceName,_,Node,ServicePid}注册自己，cluster_server需要为Service提供一套筛选机制，在某个服务的所有注册节点中，选出一个可用节点:<code>cluster_server:get_service(ServiceName)</code>。</p>
<p>再来看看整个异常处理流程：</p>
<ul>
<li>lua代码错误: lua_pcall捕获 -&gt; Erlang逻辑层的battle_error</li>
<li>battle_worker crash: 向battle_server注销自己 -&gt; battle_worker_sup重启 -&gt; 重建lua state -&gt; 向battle_server重新注册自己</li>
<li>battle_server crash: 终止所有battle_worker -&gt; 向cluster_server注销自己 -&gt; battle_server_sup重启 -&gt; 重新创建所有battle_worker -&gt; 向cluster_server重新注册</li>
<li>elua crash: battle_node crash -&gt; 该节点不可用 -&gt; 外部请求仍然可能路由到该节点 -&gt; 战斗超时 -&gt; cluster_server检测到(节点心跳机制)该节点不可响应 -&gt; 在集群中删除该节点 -&gt; 外部请求路由到其它可用节点</li>
</ul>
<p>并且整个战斗系统的伸缩性很强，可以通过简单添加机器来缓解服务器战斗压力。</p>
<h3 id="6-Lua代码热更"><a href="#6-Lua代码热更" class="headerlink" title="6. Lua代码热更"></a>6. Lua代码热更</h3><p>这个是Lua的强项，直接通过elua再次dofile Lua入口文件即可，但是要保证该Lua入口不具备副作用，如对一些全局符号进行了改写，否则下一次直接dofile，将叠加这种副作用从而导致代码异常。如果有一些全局初始化操作，应该单独抽离出来，放在另一个Lua文件中，只在创建Lua虚拟机时执行。</p>
<p>另一种热更方案是，每次都重新创建一个Lua虚拟机，这样可以保证每次热更后的Lua虚拟机状态都得以重置恢复。</p>
<p>最重要的是，这一切，所有外部请求来说，都是透明的。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>博客开始使用Hexo</title>
    <url>/2015/09/use-hexo-rebuild-blog/</url>
    <content><![CDATA[<p>最近又开始想在博客上实现自己一直想要的摘要功能，然后倒腾jekyll，本来也没有前端基础，就博客系统而言，对我来说，简单就好，能专注写东西。但是发现jekyll偏离了这个宗旨，缺乏成熟的主题机制，可定制性太强，学习成本高。然后发现了这个<a href="https://github.com/pengloo53/Hexo-theme-light_cn">Hexo主题</a>，觉得就是自己想要的功能。最终抛弃了jekyll，投向Hexo。</p>
<span id="more"></span>
<p>关于Hexo的安装和使用说明，参看<a href="https://hexo.io/zh-cn/docs/index.html">官方中文文档</a>。</p>
<p>Hexo由node.js编写，不像jekyll被Github原生支持，因此它需要本地生成html文件后，再上传到Github。不像jekyll，你的md文件，生成的html，jekyll配置，都在一个仓库中，用起来省心。Hexo在Git上存放的只是生成好的页面，像我经常切换电脑写博客，因此还需要维护：</p>
<ol>
<li>Hexo主题：Hexo的主题像vim一样，都是插件式的，因此独立出来维护完善</li>
<li>source目录：原始的md文件和资源文件，以便随时随地都可以编辑文档</li>
<li>其它文件: 如我将资源文件都放在assets目录下，因此需要生成时通过脚本将assets拷贝到public下</li>
</ol>
<p>现在我是直接把整个Hexo放在Git上，只能说懒人有懒办法了。</p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>ranch</title>
    <url>/2015/09/erlang-ranch/</url>
    <content><![CDATA[<h3 id="一-简介"><a href="#一-简介" class="headerlink" title="一. 简介"></a>一. 简介</h3><p><a href="https://github.com/ninenines/ranch">ranch</a>是erlang的一个开源网络库，提供一个高效的监听进程池，并且将数据传输和数据处理分离开来。使用起来非常简单，灵活。关于ranch的更多介绍和使用，参见<a href="https://github.com/ninenines/ranch/tree/master/doc/src">官方文档</a>。<br><span id="more"></span></p>
<h3 id="二-功能"><a href="#二-功能" class="headerlink" title="二. 功能"></a>二. 功能</h3><p>ranch将网络连接分为传输层(transport)和协议层(protocol)，传输层是底层数据的传输方式，如tcp, udp, ssl等。协议层负责数据在业务逻辑上的处理，是开发者真正需要关心的部分。而ranch的一个目标就是将传输层和逻辑层很好的分离开来。</p>
<p>对服务器端来说，传输层需要负责管理监听套接字和连接套接字。ranch提供一个可设置的进程池，用于高效地接受新连接，将新连接套接字交予用户定义的连接进程，进行业务逻辑上的处理。</p>
<p>ranch做了什么：</p>
<ul>
<li>允许多个应用同时使用，即可有多个listener，每个listener通过名字标识</li>
<li>每个listenr可单独设置acceptor进程池的大小和其它选项</li>
<li>可设置最大连接数，并且可动态改变其大小</li>
<li>到达最大连接数时，后续连接(已经accept的连接)进程将被阻塞，待负载降下来或最大连接数变大后被唤醒</li>
<li>提供安全的网络退出方式</li>
</ul>
<h3 id="三-使用"><a href="#三-使用" class="headerlink" title="三. 使用"></a>三. 使用</h3><pre><code>ok = application:start(ranch).

&#123;ok, _&#125; = ranch:start_listener(tcp_echo, 100, % 监听器名字和监听进程池大小
    ranch_tcp, [&#123;port, 5555&#125;],        % 定义底层transport handler及其选项 ranch_tcp由ranch提供，底层使用gen_tcp
    echo_protocol, []                % 自定义的protocol handler进程所在模块，及其选项
).
</code></pre><p>之后我们需要做的，就是定义echo_protocol，ranch会在每个新连接到达时，调用<code>echo_protocol:start_link/4</code>，生成我们的协议处理进程。参见<a href="https://github.com/ninenines/ranch/blob/master/examples/tcp_echo/src/echo_protocol.erl">官网示例</a>。使用起来非常简单。</p>
<h3 id="四-结构"><a href="#四-结构" class="headerlink" title="四. 结构"></a>四. 结构</h3><p>ranch的进程结构如下：</p>
<p><img src="/assets/image/201509/erlang_ranch.png" alt="" title="ranch进程结构"></p>
<h4 id="ranch-server"><a href="#ranch-server" class="headerlink" title="ranch_server:"></a>ranch_server:</h4><p>维护全局配置信息，整个ranch_app唯一，由多个listener共享。通过ets维护一些配置信息和核心进程的Pid信息，格式<code>\&#123;\&#123;Opt, Ref\&#125;, OptValue\&#125;</code>，Ref是listener名字。</p>
<h4 id="ranch-listener-sup"><a href="#ranch-listener-sup" class="headerlink" title="ranch_listener_sup:"></a>ranch_listener_sup:</h4><p>由<code>ranch:start_listener/6</code>启动，其子进程有ranch_conns_sup和ranch_acceptors_sup，以<code>rest_for_one</code>策略启动，亦即一旦ranch_conns_sup挂了，ranch_acceptors_sup也将被终止，然后再依次重启。</p>
<h4 id="ranch-acceptors-sup"><a href="#ranch-acceptors-sup" class="headerlink" title="ranch_acceptors_sup:"></a>ranch_acceptors_sup:</h4><p>由它创建监听套接字，并启动N个ranch_accepter执行accept操作(<code>gen_tcp:accept</code>本身支持多process执行)。</p>
<h4 id="ranch-acceptor"><a href="#ranch-acceptor" class="headerlink" title="ranch_acceptor:"></a>ranch_acceptor:</h4><p>执行loop，不断执行accept操作，将新conn socket的所属权交给ranch_conns_sup(<code>gen_tcp:controlling_process</code>)，通知其启动新protocol handle进行处理，并阻塞等待ranch_conns_sup返回。</p>
<h4 id="ranch-conns-sup"><a href="#ranch-conns-sup" class="headerlink" title="ranch_conns_sup:"></a>ranch_conns_sup:</h4><p>维护当前所有连接，当新连接到达时，调用<code>your_protocol:start_link/4</code>创建新进程，之后将conn socket所属权交给新连接进程。当连接到达上限时，阻塞前来通知开启新连接的Acceptor进程。直到阀值提高，或有其它连接断开，再唤醒这些Acceptor。ranch的实际最大连接数 = max_conns + NAcceptor。</p>
<h4 id="your-protocol"><a href="#your-protocol" class="headerlink" title="your_protocol"></a>your_protocol</h4><p>开发者定义protocol，当有新连接到达时，将调用<code>your_protocol:start_link/4</code>启动新进程，之后的处理交予开发者。</p>
<h3 id="五-其它"><a href="#五-其它" class="headerlink" title="五. 其它"></a>五. 其它</h3><ul>
<li>对于不需要接收其它进程消息的进程，应该定义通过receive清理进程信箱，避免意料之外的消息一直堆积在信箱中。见<a href="https://github.com/ninenines/ranch/blob/master/src/ranch_acceptor.erl">ranch_accepter.erl</a>。</li>
<li>rest_for_one，实现更加强大灵活的监督者。</li>
<li>ranch将网络的退出方式(brutal_kill，Timeout，infinity等)，交给开发者定制，而不放在框架中。</li>
<li>注意套接字所属权的转移：<code>ranch_acceptor</code> -&gt; <code>ranch_conns_sup</code> -&gt; <code>your_protocol</code>。</li>
</ul>
<h4 id="proc-lib"><a href="#proc-lib" class="headerlink" title="proc_lib"></a>proc_lib</h4><p>ranch中多处用到了proc_lib启动进程，proc_lib是OTP进程的基石，所有OTP behaviour进程都通过proc_lib来创建新进程。</p>
<p>proc_lib的使用方法：</p>
<ol>
<li><code>proc_lib:start_link(M, F, A)</code>启动一个符合OTP规范的进程</li>
<li>在<code>M:F(A)</code>中，通过<code>proc_lib:init_ack(Parent, Ret)</code>来告诉父进程自身已经初始化完成，此时<code>proc_lib:start_link/3</code>方才返回</li>
<li>如果进程本身为OTP进程，此时可通过<code>gen_server:enter_loop(Module, Opts, State)</code>来进入OTP进程的主循环</li>
</ol>
<p>proc_lib使用情形：</p>
<ol>
<li>为了让非OTP进程，能够以OTP规范启动，这样才能融入监督树中并被正确重启。如<code>gen_server:start_link</code>最终也通过<code>proc_lib:start_link</code>来启动进程。见<a href="https://github.com/ninenines/ranch/blob/master/src/ranch_conns_sup.erl">ranch_conns_sup.erl</a>。</li>
<li>让OTP进程在<code>init()</code>中进行消息处理，本来在init未返回之前，进程还未初始化完成，这个时候进程处理消息，会陷入死锁，但通过<code>proc_lib:init_ack/2</code>可以先让本进程伪初始化完成，然后进行消息处理，最后通过<code>gen_server:enter_loop</code>进入gen_server主循环。</li>
</ol>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>【译】进程和错误</title>
    <url>/2015/09/erlang-process-links/</url>
    <content><![CDATA[<p><a href="http://learnyousomeerlang.com/content">learn some erlang</a>上很喜欢的一个章节，主要阐述进程，链接，监视，信号捕获等。花了两天的时间才翻译完(- -)。第一次翻译文章，真心不是件容易的事。但也受益匪浅，平时一晃而过的地方，现在却要字字推敲。这是初稿，后续慢慢校正。原文地址：<a href="http://learnyousomeerlang.com/errors-and-processes">http://learnyousomeerlang.com/errors-and-processes</a></p>
<hr>
<span id="more"></span>
<h3 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h3><p>链接(link)是两个进程之间的一种特殊的关系。一旦这种关系建立，如果任意一端的进程发生异常，错误，或退出(参见<a href="http://learnyousomeerlang.com/errors-and-exceptions">Errors and Exceptions</a>)，链接的另一端进程将一并退出。</p>
<p>这是个很有用的概念，源自于Erlang的原则”鼓励崩溃”：如果发生错误的进程崩溃了而那些依赖它的进程不受影响，那么之后所有这些依赖进程都需要处理这种依赖缺失。让它们都退出再重启整组进程通常是一个可行的方案。链接正提供了这种方案所需。</p>
<p>要为两个进程设置链接，Erlang提供了基础函数<code>link/1</code>，它接收一个Pid作为参数。这个函数将在当前进程和Pid进程之前创建一个链接。要取消链接，可使用<code>ulink/1</code>。当链接的一个进程崩溃，将发送一个特殊的消息，该消息描述了哪个进程出于什么原因而发送故障。如果进程正常退出(如正常执行完其主函数)，这类消息将不会被发送。我将首先介绍这个新函数，它是<a href="http://learnyousomeerlang.com/static/erlang/linkmon.erl">linkmon.erl</a>的一部分：</p>
<pre><code>myproc() -&gt;
    timer:sleep(5000),
    exit(reason).
</code></pre><p>如果你尝试下面的调用(并且在两次spawn操作之间等待5秒钟)，你就能看到shell只有在两个进程之间设置了链接时，才会因<code>reason</code>而崩溃。</p>
<pre><code>1&gt; c(linkmon).
&#123;ok,linkmon&#125;
2&gt; spawn(fun linkmon:myproc/0).
&lt;0.52.0&gt;
3&gt; link(spawn(fun linkmon:myproc/0)).
true
** exception error: reason    % 译注：此时Shell Process已经崩溃，只是立即被重启了。通过self()查看前后的Pid是不同的
</code></pre><p>或者，我们可以用图片来阐述：</p>
<p><img src="/assets/image/201509/process_link_exit.png" alt=""></p>
<p>然后，这个<code>&#123;&#39;EXIT&#39;, B, Reason&#125;</code>消息并不能被<code>try ... catch</code>捕获。我们需要通过其它机制来实现这点，我们将在后面看到。</p>
<p>值得注意的是，链接通常被用来建立一个需要一起退出的进程组：</p>
<pre><code>chain(0) -&gt;
    receive
        _ -&gt; ok
    after 2000 -&gt;
        exit(&quot;chain dies here&quot;)
    end;
chain(N) -&gt;
    Pid = spawn(fun() -&gt; chain(N-1) end),
    link(Pid),
    receive
        _ -&gt; ok
    end.
</code></pre><p><code>chain</code>函数接收一个整型参数N，创建N个依次相互链接的进程。为了能够将N-1参数传递给下一个<code>chain</code>进程(也就是<code>spawn/1</code>)，我将函数调用放在了一个匿名函数中，因此它不再需要参数。调用<code>spawn(?MODULE, chain, [N-1])</code>能达到同样的效果。</p>
<p>这里，我将有一条链式的进程组，并且随着它们的后继者退出而退出：</p>
<pre><code>4&gt; c(linkmon).              
&#123;ok,linkmon&#125;
5&gt; link(spawn(linkmon, chain, [3])).
true
** exception error: &quot;chain dies here&quot;
</code></pre><p>正如你所看到的，Shell将从其它进程收到死亡信号。这幅图阐述产生的进程依次链接：</p>
<pre><code>[shell] == [3] == [2] == [1] == [0]
[shell] == [3] == [2] == [1] == *dead*
[shell] == [3] == [2] == *dead*
[shell] == [3] == *dead*
[shell] == *dead*
*dead, error message shown*
[shell] &lt;-- restarted
</code></pre><p>在执行<code>linkmon:chain(0)</code>的进程死掉之后，错误消息沿着链接链依次传播，直播Shell进程也因此崩溃。崩溃可能发生在任何已经链接的进程中，因为链接是双向的，你只需要令其中一个死亡，其它进程都会随之死亡。</p>
<pre><code>注意：如果你想要通过Shell杀掉其它进程，你可以使用`exit/2`函数，如：`exit(Pid, Reason)`。你可以试试。

链接操作无法被累加，如果你在同样的一对进程上调用`link/1`15次，也只会实际存在一个链接，并且只需要一次`unlink/1`调用就可以解除链接。
</code></pre><p>注意，<code>link(spawn(Function))</code>或<code>link(spawn(M,F,A))</code>是通过多步实现的。在一些情况下，可能进程在被链接之前就死掉了，这样引发了未知行为。出于这个原因，Erlang添加了<code>spawn_link/1-3</code>函数，它和<code>spawn/1-3</code>接收同样的参数，创建一个进程并且相<code>link/1</code>一样建立链接，但是它是一个原子操作(这个操作混合了多个指令，它可能成功或失败，但不会有其它未期望行为)。着通常更安全，并且你也省去了一堆圆括号。</p>
<h3 id="信号捕获"><a href="#信号捕获" class="headerlink" title="信号捕获"></a>信号捕获</h3><p>现在回到链接和进程故障。错误在进程之间向消息那样传递，这类特殊的消息叫做信号。退出信号是自动作用于进程的”秘密消息”，它会立即杀死进程。</p>
<p>我之前提到过很多次，为了高可靠性，应用程序需要能够很快的杀掉和重启进程。现在，链接很好地完成了杀死进程的任务，还差进程重启。</p>
<p>为了重启一个进程，我们首先需要一种方式来知道有进程挂了。这可以通过在链接之上封装一层叫系统进程的概念来完成。系统进程其实就是普通进程，只不过他们可以将退出信号转换为普通消息。在一个运行进程上执行<code>precess_floag(trap_exit, true)</code>可以<br>将其转换为系统进程。没什么比例子更具有说服力了，我们来试试。我首先在一个系统进程上将重演chain例子：</p>
<pre><code>1&gt; process_flag(trap_exit, true).
true
2&gt; spawn_link(fun() -&gt; linkmon:chain(3) end).
&lt;0.49.0&gt;
3&gt; receive X -&gt; X end.
&#123;&#39;EXIT&#39;,&lt;0.49.0&gt;,&quot;chain dies here&quot;&#125;
</code></pre><p>现在事情变得有趣了，回到我们的图例中，现在发生的是这样：</p>
<pre><code>[shell] == [3] == [2] == [1] == [0]
[shell] == [3] == [2] == [1] == *dead*
[shell] == [3] == [2] == *dead*
[shell] == [3] == *dead*
[shell] &lt;-- &#123;&#39;EXIT,Pid,&quot;chain dies here&quot;&#125; -- *dead*
[shell] &lt;-- still alive!
</code></pre><p>这就是让我们可以快速重启进程的机制。通过在程序中使用系统进程，创建一个只负责检查进程崩溃并且在任意时间都能重启故障进程的进程变得很简单。我将在下一章真正用到了这项技术时，更详细地阐述这点。</p>
<p>现在，我想回到我们在<a href="http://learnyousomeerlang.com/errors-and-exceptions">exceptions</a>这一章看到的异常函数，并且展示它在设置了<code>trap exit</code>的进程上有何种行为。我们首先试验没有系统进程的情况。我连续地在相邻的进程上展示了未被捕获的异常，错误，和退出所造成的结果：</p>
<pre><code>Exception source:    spawn_link(fun() -&gt; ok end)
Untrapped Result:    - nothing - 
Trapped      Result:    &#123;&#39;EXIT&#39;, &lt;0.61.0&gt;, normal&#125;
注：进程正常退出，没有任何故障。这有点像`catch exit(normal)`的结果，除了在tuple中添加了Pid以知晓是哪个进程退出了。

Exception source:    spawn_link(fun() -&gt; exit(reason) end)
Untrapped Result:    ** exception exit: reason
Trapped   Result:    &#123;&#39;EXIT&#39;, &lt;0.55.0&gt;, reason&#125;
注：进程由于客观原因而终止，在这种情况下，如果没有捕获退出信号(trap exit)，当前进程被终止，否则你将收到以上消息。

Exception source：    spawn_link(fun() -&gt; exit(normal) end)
Untrapped Result:    - nothing -
Trapped   Result:    &#123;&#39;EXIT&#39;, &lt;0.58.0&gt;, normal&#125;
注：这相当于模仿进程正常终止。在一些情况下，你可能希望像正常流程一样杀掉进程，不需要任何异常流出。

Exception source:    spawn_link(fun() -&gt; 1/0 end)
Untrapped Result:    Error in process &lt;0.44.0&gt; with exit value: &#123;badarith, [&#123;erlang, &#39;/&#39;, [1,0]&#125;]&#125;
Trapped   Result:    &#123;&#39;EXIT&#39;, &lt;0.52.0&gt;, &#123;badarith, [&#123;erlang, &#39;/&#39;, [1,0]&#125;]&#125;&#125;
注：&#123;badarith, Reason&#125;不会被try ... catch捕获，继而转换为&#39;EXIT&#39;消息。这一点上来看，它的行为很像exit(reason)，但是有调用堆栈，可以了解到更多的信息。

Exception source:    spawn_link(fun() -&gt; erlang:error(reason) end)
Untrapped Result:    Error in process &lt;0.47.0&gt; with exit value: &#123;reason, [&#123;erlang, apply, 2&#125;]&#125;
Trapped   Result:    &#123;&#39;EXIT&#39;, &lt;0.74.0&gt;, &#123;reason, [&#123;erlang, apply, 2&#125;]&#125;&#125;
注：和1/0的情况很像，这是正常的，erlang:error/1 就是为了让你可以做到这一点。

Exception source:    spawn_link(fun() -&gt; throw(rocks) end)
Untrapped Result:    Error in process &lt;0.51.0&gt; with exit value: &#123;&#123;nocatch, rocks&#125;, [&#123;erlang, apply, 2&#125;]&#125;
	Trapped   Result:	&#123;'EXIT', <0.79.0>, &#123;&#123;nocatch, rocks&#125;, [&#123;erlang, apply, 2&#125;]&#125;&#125;
注：由于抛出的异常没有被try ... catch捕获，它向上转换为一个nocatch错误，然后再转换为`EXIT`消息。如果没有捕获退出信号，当前进程当终止，否则工作正常。
</code></pre><p>这些都是一般异常。通常情况下：一切都工作得很好。当异常发生：进程死亡，不同的信号被发送出去。</p>
<p>然后来介绍<code>exit/2</code>，它在Erlang进程中就相当于一把枪。它可以让一个进程杀掉远端另一个进程。以下是一些可能的调用情况：</p>
<pre><code>Exception source:     exit(self(), normal)
Untrapped Result:     ** exception exit: normal
Trapped   Result:     &#123;&#39;EXIT&#39;, &lt;0.31.0&gt;, normal&#125;    注：当没有捕获退出信号时，exit(self(), normal)和exit(normal)作用一样。否则你将收到一条和链接进程挂掉一样格式的消息。(译注：如果忽略了&#123;&#39;EXIT&#39;, self(), normal&#125;，将不能通过exit(self(), normal)的方式杀掉自己。而exit(normal)则可以在任何情况结束自己。)

Exception source:     exit(spawn_link(fun() -&gt; timer:sleep(50000) end), normal)
Untrapped Result:     - nothing -
Trapped   Result:     - nothing -
注：这基本上等于调用exit(Pid, normal)。这条命令基本没有做任何有用的事情，因为进程不能以normal的方式来杀掉远端进程。(译注：通过normal的方式kill远端进程是无效的)。

Exception source:     exit(spawn_link(fun() -&gt; timer:sleep(50000) end), reason)
Untrapped Result:     ** exception exit: reason
Trapped   Result:     &#123;&#39;EXIT&#39;, &lt;0.52.0&gt;, reason&#125;
注：外部进程通过reason终止，看起来效果和在外部进程本身执行exit(reason)一样。

Exception source:     exit(spawn_link(fun() -&gt; timer:sleep(50000) end), kill)
Untrapped Result:     ** exception exit: killed
Trapped   Result:     &#123;&#39;EXIT&#39;, &lt;0.58.0&gt;, killed&#125;
注：出乎意料地，消息在从终止进程传向根源进程(译注：调用spawn的进程)时，发生了变化。根源进程收到killed而不是kill。这是因为kill是一个特殊的信号，更多的细节将在后面提到。

Exception source:     exit(self(), kill)
Untrapped Result:     ** exception exit: killed
Trapped   Result:     ** exception exit: killed
注：看起来这种情况不能够被正确地捕捉到，让我们来检查一下。

Exception source:     spawn_link(fun() -&gt; exit(kill) end)
Untrapped Result:     ** exception exit: killed
Trapped   Result:     &#123;&#39;EXIT&#39;, &lt;0.67.0&gt;, kill&#125;
注：现在看起来更加困惑了。当其它进程通过exit(kill)杀掉自己，并且我们不捕获退出信号，我们自己的进程退出原因为killed。然而，当我们捕获退出信号，却不再是killed。
</code></pre><p>你可以捕获大部分的退出原因，在有些情况下，你可能想要残忍地谋杀进程：也许它捕获了退出信号，但是陷入了死循环，不能再读取任何消息。kill是一种不能被捕获的特殊信号。这一点确保了任何你想要杀掉的进程都将被终止。通常，当所有其它办法都试尽之后，kill是最后的杀手锏。</p>
<p>由于kill退出原因不能够捕获，因此当其它进程收到该消息时，需要转换为killed。如果不以这种方式作出改变，所有其它链接到被kill进程的进程都将相继以相同的kill原因被终止，并且继续扩散到与它们链接的进程。随之而来的是一场死亡的雪崩效应。</p>
<p>这也解释了为什么<code>exit(kill)</code>在被其它链接进程收到时转换成了killed(信号被修改了，这样才不会发生雪崩效应)，但是在本地捕获时(译注：这里我也没搞清楚，本地是指被kill的进程，还是指发出kill命令的进程)，仍然是kill。</p>
<p>如果你对这一切感到困惑，不用担心，很多程序员都为此困惑。退出信号是一头有趣的野兽。幸运的是，上面已经提及几乎所有特殊情况。一旦你明白了这些，你就可以轻松明白大多数的Erlang并发错误管理机制。</p>
<h3 id="监视器"><a href="#监视器" class="headerlink" title="监视器"></a>监视器</h3><p>那么，也许谋杀掉一个进程并不是你想要的，也许你并不想将你死亡的消息通告四周，也许你应该更像一个追踪者。在这种情况下，监视器就是你想要的。</p>
<p>严格意义上说，监视器是一种特殊类型的链接。它与链接有两处不同：</p>
<ul>
<li>监视器是单向的</li>
<li>监视可以被叠加</li>
</ul>
<p>监视器可以让一个进程知道另一个进程上发生了什么，但是它们对彼此来说都不是必不可少的。</p>
<p>另一点，像上面所列出的一样，监视引用是可以被叠加的。乍一看这并没什么用，但是这对写需要统计其它进程情况的库很有帮助。</p>
<p>正如你所了解的，链接更像是一种组织结构。当你在架构你的应用程序时，你需要决定每个进程做什么，依赖于什么。一些进程将被用来监督其它进程，一些进程不能没有其兄弟进程而独立存在，等等。这种结构通常是固定的，并且事先决定好的。链接对于这种情况是非常适用的，但除此之外，一般并没有使用它的必要。</p>
<p>但是当你在使用两三个不同的库，而它们都需要知道其它进程存活与否，这种情况会发送什么？如果你尝试使用链接，那么当你尝试解除链接的时候，就会很快遇到问题。因为链接是不可叠加的，一旦取消了其中一个，你就取消了所有(译注：调用库时，仍然是在当前进程)在此之上的链接，也就破坏了其它库的所有假设。这很糟糕。因此你需要可叠加的链接，监视器就是你的解决方案。它们可以被单独地移除。另外，单向特性在库中也是很有用的，因为其它进程不应该关心上述库。</p>
<p>那么监视器看起来是什么样子？很简单，让我们来设置一个。相关函数是<code>erlang:monitor/2</code>，第一个参数是原子<code>process</code>，第二个参数是进程Pid：</p>
<pre><code>1&gt; erlang:monitor(process, spawn(fun() -&gt; timer:sleep(500) end)).
#Ref&lt;0.0.0.77&gt;
2&gt; flush().
Shell got &#123;&#39;DOWN&#39;,#Ref&lt;0.0.0.77&gt;,process,&lt;0.63.0&gt;,normal&#125;
ok
</code></pre><p>每当你监视的进程挂掉时，你都会收到类似消息。消息格式为<code>&#123;&#39;DOWN&#39;, MonitorReference, process, Pid, Reason&#125;</code>。引用被用来取消监视，记住，监视是可以叠加的，所以可能不止一个。引用允许你以独特的方式追踪它们。还要注意，和链接一样，有一个原子函数可以在创建进程的同时监控它，<code>spawn_monitor/3</code>：</p>
<pre><code>3&gt; &#123;Pid, Ref&#125; = spawn_monitor(fun() -&gt; receive _ -&gt; exit(boom) end end).
&#123;&lt;0.73.0&gt;,#Ref&lt;0.0.0.100&gt;&#125;
4&gt; erlang:demonitor(Ref).
true
5&gt; Pid ! die.
die
6&gt; flush().
ok
</code></pre><p>在这个例子中，我们在进程崩溃之前取消了监视，因此我们没有追踪到它的死亡。函数<code>demonitor/2</code>也存在，并且给出了更多信息，第二个参数是一个选项列表。目前只有两个选项，<code>info</code>和<code>flush</code>：</p>
<pre><code>7&gt; f().
ok
8&gt; &#123;Pid, Ref&#125; = spawn_monitor(fun() -&gt; receive _ -&gt; exit(boom) end end).
&#123;&lt;0.35.0&gt;,#Ref&lt;0.0.0.35&gt;&#125;
9&gt; Pid ! die.
die
10&gt; erlang:demonitor(Ref, [flush, info]).
false
11&gt; flush().
ok
</code></pre><p><code>info</code>选项将告诉你在你取消监视的时候监视是否存在，因此第10行返回false。使用<code>flush</code>选项将移除信箱中的<code>DOWN</code>消息(译注：其它消息不受影响)，导致<code>flush()</code>操作没有在当前进程信箱中取得任何消息。</p>
<h3 id="命名的进程"><a href="#命名的进程" class="headerlink" title="命名的进程"></a>命名的进程</h3><p>理解了链接和监视之后，还有一个问题需要解决。我们使用<a href="http://learnyousomeerlang.com/static/erlang/linkmon.erl">linkmon.erl</a>模块的以下函数：</p>
<pre><code>start_critic() -&gt;
    spawn(?MODULE, critic, []).

judge(Pid, Band, Album) -&gt;
    Pid ! &#123;self(), &#123;Band, Album&#125;&#125;,
    receive
        &#123;Pid, Criticism&#125; -&gt; Criticism
    after 2000 -&gt;
        timeout
    end.

critic() -&gt;
    receive
        &#123;From, &#123;&quot;Rage Against the Turing Machine&quot;, &quot;Unit Testify&quot;&#125;&#125; -&gt;
            From ! &#123;self(), &quot;They are great!&quot;&#125;;
        &#123;From, &#123;&quot;System of a Downtime&quot;, &quot;Memoize&quot;&#125;&#125; -&gt;
            From ! &#123;self(), &quot;They&#39;re not Johnny Crash but they&#39;re good.&quot;&#125;;
        &#123;From, &#123;&quot;Johnny Crash&quot;, &quot;The Token Ring of Fire&quot;&#125;&#125; -&gt;
            From ! &#123;self(), &quot;Simply incredible.&quot;&#125;;
        &#123;From, &#123;_Band, _Album&#125;&#125; -&gt;
            From ! &#123;self(), &quot;They are terrible!&quot;&#125;
    end,
    critic().
</code></pre><p>现在假设我们在商店购买唱片。这里有一些听起来很有趣的专辑，但是我们不是很确定。你决定打电话给你的朋友<code>ctritic</code>(译注：后文称”鉴定家”)。</p>
<pre><code>1&gt; c(linkmon).                        
    &#123;ok,linkmon&#125;
2&gt; Critic = linkmon:start_critic().
    &lt;0.47.0&gt;
3&gt; linkmon:judge(Critic, &quot;Genesis&quot;, &quot;The Lambda Lies Down on Broadway&quot;).
    &quot;They are terrible!&quot;
</code></pre><p>烦人的是，我们不久后就不能再得到唱片的评论了。为了保持鉴定家一直存活，我们将写一个基本的监督者进程，它的唯一职责就是在鉴定家挂掉之后重启它。</p>
<pre><code>start_critic2() -&gt;
    spawn(?MODULE, restarter, []).

restarter() -&gt;
    process_flag(trap_exit, true),
    Pid = spawn_link(?MODULE, critic, []),
    receive
        &#123;&#39;EXIT&#39;, Pid, normal&#125; -&gt; % not a crash
            ok;
        &#123;&#39;EXIT&#39;, Pid, shutdown&#125; -&gt; % manual termination, not a crash
            ok;
        &#123;&#39;EXIT&#39;, Pid, _&#125; -&gt;
            restarter()
    end.
</code></pre><p>这里，重启者就是它自己持有的进程。它会轮流启动鉴定家进程，并且一旦它异常退出，<code>restarter/0</code>将循环创建新的鉴定家。注意我添加了<code>&#123;&#39;EXIT&#39;, Pid, shudown&#125;</code>条目，这是为了让我们在必要时，可以手动杀掉鉴定家进程。</p>
<p>我们这个方法的问题是，我们没有办法获得鉴定家进程的Pid，因此我们不能调用它并获得它的评论。Erlang解决这种问题的一个解决方案是为进程取一个名字。</p>
<p>为进程取名字的作用是允许你用一个原子代替不可预测的Pid。之后这个原子可以像Pid一样用来发送消息。<code>erlang:register/2</code>被用来为进程取名。如果进程死亡，它会自动失去它的名字，你也可以使用<code>unregister/1</code>手动取消名字。你可以通过<code>register/0</code>获得一个所有注册了名字的进程列表，或者通过shell命令<code>reg()</code>获得更为详尽的信息。现在我们可以像下面这样重写<code>restarter/0</code>函数：</p>
<pre><code>restarter() -&gt;
    process_flag(trap_exit, true),
    Pid = spawn_link(?MODULE, critic, []),
    register(critic, Pid),
    receive
        &#123;&#39;EXIT&#39;, Pid, normal&#125; -&gt; % not a crash
            ok;
        &#123;&#39;EXIT&#39;, Pid, shutdown&#125; -&gt; % manual termination, not a crash
            ok;
        &#123;&#39;EXIT&#39;, Pid, _&#125; -&gt;
            restarter()
    end.
</code></pre><p>正如你所看到的，不管鉴定家进程的Pid是什么，<code>register/2</code>将总是为其取名为<code>critic</code>。我们还需要做的是从抽象函数中替换需要传递Pid的地方。让我们试试：</p>
<pre><code>judge2(Band, Album) -&gt;
    critic ! &#123;self(), &#123;Band, Album&#125;&#125;,
    Pid = whereis(critic),
    receive
        &#123;Pid, Criticism&#125; -&gt; Criticism
    after 2000 -&gt;
        timeout
    end.
</code></pre><p>这里，为了能在<code>receive</code>语句中进行模式匹配，<code>Pid = whereis(critic)</code>被用来查找鉴定家进程的Pid。我们需要这个Pid来确定我们能匹配到正确的消息(在我们说话的时候，它的信箱可能有500条消息！)。这可能是问题的来源。上面的代码假设了鉴定家进程在函数的前两行将保持一致。然而，下面的情况是完全有可能发生的：</p>
<pre><code>1. critic ! Message
                                   2. critic receives
                                   3. critic replies
                                   4. critic dies
5. whereis fails
                                6. critic is restarted
7. code crashes

当然，还有一种情况可能发生：

1. critic ! Message
                                   2. critic receives
                                   3. critic replies
                                  4. critic dies
                                  5. critic is restarted
6. whereis picks up
   wrong pid
7. message never matches
</code></pre><p>如果我们不处理好的话，在一个进程中出错将可能导致另一个进程错误。在这种情况下，原子<code>critic</code>代表的值可能被多个进程看到。这就说所谓的共享状态。这里的问题是，<code>critic</code>的值可以在几乎同一时间被多个进程获取和修改，导致不一致的信息和软件错误。这类情况的通用术语为<strong>竞态</strong>。竞态是特别危险的，因为其依赖于事件时序。在几乎所有的并发和并行语言中，这种时序依赖于很多不可预测的因素，比如处理器有多忙，进程执行到哪了，以及你的程序在处理哪些数据。</p>
<pre><code>别麻醉了自己

你可能听说过Erlang通常是没有竞态或死锁的，这令并行代码更安全。这在很多情况下都是对的，但是永远不要认为你的代码真的那样安全。命名进程只是并行代码可能出错的多种情况之一。

其它例子还包括计算机访问文件(并修改它们)，多个不同的进程更新相同的数据库记录，等等。
</code></pre><p>对我们来说幸运的是，如果我们不假设命名进程保持不变的话，修复上面的代码是比较容易的。取而代之地，我们将使用引用(通过<code>make_ref()</code>创建)作为一个唯一的值来标识消息。我们需要重写<code>critic/0</code>为<code>critic/2</code>，<code>judge/3</code>为<code>judge2/2</code>：</p>
<pre><code>judge2(Band, Album) -&gt;
    Ref = make_ref(),
critic ! &#123;self(), Ref, &#123;Band, Album&#125;&#125;,
    receive
        &#123;Ref, Criticism&#125; -&gt; Criticism
    after 2000 -&gt;
        timeout
    end.

critic2() -&gt;
    receive
        &#123;From, Ref, &#123;&quot;Rage Against the Turing Machine&quot;, &quot;Unit Testify&quot;&#125;&#125; -&gt;
            From ! &#123;Ref, &quot;They are great!&quot;&#125;;
        &#123;From, Ref, &#123;&quot;System of a Downtime&quot;, &quot;Memoize&quot;&#125;&#125; -&gt;
            From ! &#123;Ref, &quot;They&#39;re not Johnny Crash but they&#39;re good.&quot;&#125;;
        &#123;From, Ref, &#123;&quot;Johnny Crash&quot;, &quot;The Token Ring of Fire&quot;&#125;&#125; -&gt;
            From ! &#123;Ref, &quot;Simply incredible.&quot;&#125;;
        &#123;From, Ref, &#123;_Band, _Album&#125;&#125; -&gt;
            From ! &#123;Ref, &quot;They are terrible!&quot;&#125;
    end,
    critic2().
</code></pre><p>并且随之改变<code>restarter/0</code>，让它通过<code>critic2/0</code>而不是<code>critic/0</code>来产生新进程。其它函数应该能保持正常工作。用户并不能察觉到变化。好吧，他们能察觉到，因为我们改变了函数名和函数参数个数，但是他们并不知道实现细节的改变和为什么这些改变如此重要。他们能看到的是他们的代码更简单了，并且不在需要Pid来调用函数了：</p>
<pre><code>6&gt; c(linkmon).
&#123;ok,linkmon&#125;
7&gt; linkmon:start_critic2().
&lt;0.55.0&gt;
8&gt; linkmon:judge2(&quot;The Doors&quot;, &quot;Light my Firewall&quot;).
&quot;They are terrible!&quot;
9&gt; exit(whereis(critic), kill).
true
10&gt; linkmon:judge2(&quot;Rage Against the Turing Machine&quot;, &quot;Unit Testify&quot;).    
&quot;They are great!&quot;
</code></pre><p>现在，即使我们杀掉了critic，马上会有一个新的回来解决我们的问题。这就是命名进程的作用。如果你试图通过没有注册的进程调用<code>linkmon:judge2/2</code>，一个<code>bad argument</code>错误将会被函数内的<code>!</code>操作符抛出，确保依赖于命名进程的进程，将不能在没有命名进程的情况下而运行。</p>
<pre><code>注意：如果你还记得之前的文章，原子可用的数量有限(尽管很高)。你不应该动态地创建原子。这意味着命名进程应该保留给一些虚拟机上唯一的伴随整个应用程序周期的重要的服务。

如果你需要为进程命名，但是它们不是常驻进程或者它们都不是虚拟机上唯一的，那可能意味着它们需要表示为一组，链接它们，并在它们崩溃后重启可能是一个理智的选择，而不是尝试为他们动态命名。
</code></pre>]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>Unity 动画系统小记</title>
    <url>/2015/10/unity-mecanim/</url>
    <content><![CDATA[<h3 id="动画系统"><a href="#动画系统" class="headerlink" title="动画系统"></a>动画系统</h3><p>如果动画包含多层，要在初始化时设置动画层权重。</p>
<p>通常情况下，在我们操作角色时，脚本根据玩家输入，设置动画的行进速度(可平滑过度)，由动画的Blend Tree来做到角色走和跑之间的平滑过渡，并且将动画的实际位移作用于角色模型上。也就是说，由动画控制前进(走，跑)，脚本直接控制转向(<code>rigidbody.MoveRotation</code>)。模型只需提供<code>Walk</code>和<code>Run</code>两个动画片段即可，但需要导入位移信息。</p>
<p>Animator有个比较有用的选项，用于通过脚本而不是动画来控制模型移动。</p>
<p><code>Apply Root Motion</code>：是否将动画的位移，转向作用于实际模型之上。即模型的运动(Position，Rotation的变化)是由动画控制还是脚本控制。</p>
<span id="more"></span>
<p>Apply Root Motion的作用示例：</p>
<p><img src="/assets/image/201510/apply_root_motion_demo.gif" alt=""></p>
<p>当取消<code>Apply Root Motion</code>时，动画的转向和移动都将被屏蔽，只显示动画本身的动作。<code>Apply Root Motion</code>在一些场合下很有用，比如当模型自己有AI：</p>
<p>NavMeshAgent: 寻路组件，要使用它，首先要烘培寻路地形(Windows-&gt;Navigation)，然后设置目标位置。NavMeshAgent组件会自动将游戏对象按照当前最佳路径移动至目标位置。默认情况下，Nav会自动控制模型的移动和转向。可通过<code>nav.updateRotation/updatePosition</code>决定NavMeshAgent对游戏对象的控制权，当两者都为False时，角色当原地不动。</p>
<p>在游戏中，敌人或者是小兵通常同时具有Animator和NavMeshAgent，而如果此时我们想实现一些比较灵活的控制：比如敌人在寻路至目标点附近(比如刚好看到目标)时，停止移动(进行远程射击)。</p>
<p>此时有两种做法：</p>
<ol>
<li><p>由NavMeshAgent控制敌人移动</p>
<p> 此时禁用<code>Apply Root Motion</code>，Animator只做表现。在游戏逻辑中，根据当前Nav期望速度(决定前进速度和转向速度分量)，与目标的视角(当视角小于一定角度时，直接<code>LookAt</code>到目标位置方向，避免缓冲时间太慢)，是否已经看到目标(此时停下来，看向目标，开枪)等条件，设置Animator的<code>speed</code>(前进速度)和<code>angularSpeed</code>(转向速度)，此时动画层会作出响应的动作，如走，跑，转向等，但是没有实际运动(位移和转向)。然后在<code>OnAnimatorMove</code>中：</p>
<pre><code> void OnAnimatorMove()
 &#123;
     nav.velocity = anim.deltaPosition / Time.deltaTime;
 &#125;
</code></pre><p> 这样我们可以使得动画层和表现和实际运动基本一致，每帧<code>Update()</code>在<code>OnAnimatorMove()</code>之前调用，所有状态都记录到了Animator中。由于Nav的转向是比较生硬的，我们也可以让动画来控制转向：首先在<code>Awake()</code>中<code>nav.updateRotation = false;</code>不让Nav调整敌人转向，然后在<code>OnAnimatorMove()</code>中添加：<code>transform.rotation = anim.rootRotation;</code>。</p>
</li>
<li><p>由动画控制敌人移动</p>
<p> 逻辑处理不变，取消<code>OnAmimatorMove()</code>，勾选<code>Apply Root Motion</code>，并且同时禁用NavMeshAgent的updateRotation和updatePosition。此时nav的速度矢量仅作为参考，最终速度将设置在动画系统中，并由动画系统作用于实际模型。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>unity</category>
      </categories>
      <tags>
        <tag>unity</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP复习笔记(一) 连接的建立与终止</title>
    <url>/2015/10/tcp-notes-1/</url>
    <content><![CDATA[<h3 id="一-TCP首部"><a href="#一-TCP首部" class="headerlink" title="一. TCP首部"></a>一. TCP首部</h3><p><img src="/assets/image/201510/tcp_head.png" alt=""></p>
<p>首部长度以4字节为单位，4位首部长度最多可表示60字节，其中有20字节的固定长度。由于封装在在一个IP报文中，并且可根据首部长度得到数据起始位置，因此TCP首部没有数据或总长度字段，这和IP首部不一样，IP首部同时有首部长度和总长度字段，前者用于得到数据起始位置，后者用于得到结束位置，因为以太网要求桢的数据部分最小长度为46字节，IP报文小于46字节将在后面添加Padding，因此需要总长度来区分哪些是数据，哪些是Padding。这一点对TCP来说不存在，因为得到IP报文数据的结束位置，也就得到了TCP数据的结束位置：</p>
<span id="more"></span>
<p><img src="/assets/image/201510/ip_tcp_makeup.png" alt=""></p>
<p>首部中的序号对传输字节进行计数，在建立连接时，SYN置1，此时序号字段为该主机选择的初始序列号(ISN)。另外，SYN和FIN分别占用一个序列号，这样才能唯一标识一个SYN或FIN包，用于确认或超时重传。</p>
<h3 id="二-连接建立与终止"><a href="#二-连接建立与终止" class="headerlink" title="二. 连接建立与终止"></a>二. 连接建立与终止</h3><p><img src="/assets/image/201510/tcp_establish_close.png" alt=""></p>
<h4 id="2-1-MSS"><a href="#2-1-MSS" class="headerlink" title="2.1 MSS"></a>2.1 MSS</h4><p>在建立连接时，双方会在TCP首部加入MSS选项用于通告己方能接收的最大报文段长度(不包括TCP和IP首部)，MSS只能出现在SYN报文中，如果没有指明，则默认为536(实际上是576的IP报文长度)。在发送SYN报文时，根据<code>MSS=MTU-固定的IP首部-固定的TCP首部长度</code>来确定MSS大小，对于以太网，理想的MSS为<code>1500-20-20=1460</code>，而实际上大部分的MSS为1024，因为许多BSD的实现版本需要MSS为512的倍数。</p>
<p>通告双方的MSS主要是为了避免分段。分段(分片)发生在IP层，由于物理链路层限制了每次发送的数据帧最大长度，因此IP层会在必要的时候对数据进行分段，并在到达目的地时重组，这一切对传输层的TCP是透明的，因此TCP可以认为它的每份交给IP的字节流，都会以正确的形式到达目的地。</p>
<p>避免分片主要有两个好处：</p>
<ul>
<li>效率更高，因为IP层的分片可能由中间路由器完成</li>
<li>在有IP分片丢失时，将重传整个IP报文(IP报文没有确认重传机制)。基于这一点，TCP避免分片将使得重传更为高效</li>
</ul>
<h4 id="2-2-ISN"><a href="#2-2-ISN" class="headerlink" title="2.2 ISN"></a>2.2 ISN</h4><p>在建立连接的SYN报文中的序列号字段即为初始序列号(ISN)，这个值不能是硬编码的，否则可能会出现重新建立连接后，新连接将旧连接的包误认为是有效包的情况(每次建立连接的ISN是一样的)。ISN的初始化应该是动态的，防止新旧包交叠。RFC的建议是每4微妙ISN加1，这样用完32位需要4.55小时，然后ISN又从0开始。4.55小时远远大于TCP包在网络中的最大生存时间，是比较安全的。</p>
<h4 id="2-3-半关闭"><a href="#2-3-半关闭" class="headerlink" title="2.3 半关闭"></a>2.3 半关闭</h4><p>半关闭是指TCP一端在结束发送后，还能收到来自另一端的数据。半关闭不建议被应用程序利用，但是我们至少应该理解<code>shudown(1)</code>和<code>close()</code>的区别，确保TCP连接得到正确关闭。</p>
<h4 id="2-4-SYN超时"><a href="#2-4-SYN超时" class="headerlink" title="2.4 SYN超时"></a>2.4 SYN超时</h4><p>在尝试主动连接服务器时，如果服务器不可达，客户端将尝试重发SYN包。比如：<code>telnet 11.11.11.11</code>，可通过<code>tcpdump tcp port 23</code>查看重试次数和重试间隔，也可以通过<code>date; telnet 11.11.11.11; date</code>来查看总超时时间。</p>
<h4 id="2-5-SYN-ACK超时"><a href="#2-5-SYN-ACK超时" class="headerlink" title="2.5 SYN-ACK超时"></a>2.5 SYN-ACK超时</h4><p>当服务器收到客户端的SYN包后，会回复SYN-ACK包，如果此时客户端迟迟不回ACK包，那么服务器将超时重发SYN-ACK包，重发次数默认为5次，重发间隔依次为1s,2s,4s,8s,16s,加之最后确认超时的32s,一共是63s。这63秒中，该连接占用了服务器的SYN队列，当SYN队列满时，新的连接请求将不能得到处理。<strong>SYN Flood</strong>攻击就是利用这一点，在发完第一个SYN之后，就下线，耗尽服务器的SYN队列，使其它的正常连接请求得不到处理。</p>
<h3 id="三-状态转变"><a href="#三-状态转变" class="headerlink" title="三. 状态转变"></a>三. 状态转变</h3><p><img src="/assets/image/201510/tcp_establish_close_state.png" alt=""></p>
<p>其中比较重要的状态有：</p>
<h4 id="3-1-TIME-WAIT"><a href="#3-1-TIME-WAIT" class="headerlink" title="3.1 TIME_WAIT"></a>3.1 TIME_WAIT</h4><p>在主动发起关闭的一方，发送完最后一个ACK后，需要等待<code>2MSL</code>的时间，这样做的目的有两个：</p>
<ul>
<li>确保最后一个ACK正确到达，2MSL可让TCP再次发送最后的ACK以防这个ACK丢失(另一端超时重发FIN)</li>
<li>确保在建立新的连接前，任何老的重复报文在网络中超时消失</li>
</ul>
<p>MSL(Maximum Segment Lifetime)：报文最大生存时间，用于限制TCP包在网络中最大留存时间，超过这个时间，包将被丢弃。IP层有个类似的TTL跳数来决定IP报文的去留，MSL和TTL共同限制了TCP包的生存时间。RFC建议MSL为2分钟，而Linux下为30秒。</p>
<p>在2MSL这段时间内，定义这个连接的套接字对将不可用，任何<strong>迟到的报文</strong>都将被丢弃。而在伯克利套接字等实现版本上，有更严格的限制：在2MSL时间内，套接字所使用的本地端口默认情况下都不能再使用。</p>
<p>对于客户端来说，这通常没有什么影响，因为客户端一般都使用临时端口与服务器进行连接。因此客户端主动断开连接并重启后，尽管之前使用的端口会处于TIME_WAIT状态而不能复用(<code>bind()</code>)，但<code>connect()</code>会选择一个新的临时端口。</p>
<p>而对于服务器来说，由于服务器通常使用已知端口(监听端口)，如果我们终止一个已经建立连接的服务器程序，并重启它，服务器程序将不能把这个已知端口赋给新的套接字(<code>bind()</code>)，会得到<code>EADDRINUSE</code>的错误，只有在2MSL之后，端口才能被再次使用。</p>
<p>我们可以使用<code>SO_REUSEADDR</code>选项来重用处于2MSL状态的端口，它的原理是需要新的连接的初始序列号(ISN)大于旧连接的最后序号。这样就可以根据序列号区分哪些是旧连接的迟到报文，哪些的新连接的报文，但是仍然是有遗留风险的。</p>
<h4 id="3-2-FIN-WAIT-2"><a href="#3-2-FIN-WAIT-2" class="headerlink" title="3.2 FIN_WAIT_2"></a>3.2 FIN_WAIT_2</h4><p>在主动发起关闭的的一方发送完FIN并收到另一方的ACK后，进入FIN_WAIT_2状态。此时连接处于半关闭状态，正常情况下，如果我们的应用不利用半关闭这个特性，那么对方的应用层在收到FIN后，也会发送一个FIN关闭另一个方向上的连接。本端收到该FIN后，才进入TIME_WAIT状态。</p>
<p>这意味着主动关闭端将可能永远处于FIN_WAIT_2状态，被动端也一直处于CLOSE_WAIT状态。为了防止这种无限等待，当应用层执行全关闭(<code>close</code>)而不是半关闭(<code>shutdown</code>)时，多数套接字实现会生成一个定时器，定时器超时后，连接将进入CLOSED状态。这也进一步提醒我们应该确保正确关闭TCP连接。</p>
<h3 id="四-TCP状态机"><a href="#四-TCP状态机" class="headerlink" title="四. TCP状态机"></a>四. TCP状态机</h3><p>网络上的传输的没有连接的，TCP的所谓的”连接”是依靠一个状态机来维护当前的连接状态。理解这一点是非常重要的，因为网络是随时会有异常，连接在任何阶段都可能被异常终止。通常情况下，如果状态机收到了意料之外的包，将回复一个RST重置包，对方会据此重置连接状态。具体的状态机如下：</p>
<p><img src="/assets/image/201510/tcp_state_machine.png" alt=""></p>
<ul>
<li>TCP状态机分组丢失：<a href="http://www.cppblog.com/qinqing1984/archive/2015/10/05/211950.html">http://www.cppblog.com/qinqing1984/archive/2015/10/05/211950.html</a></li>
</ul>
]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>tcp/ip</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP复习笔记(二) TCP服务器参见问题和参数设置</title>
    <url>/2015/10/tcp-notes-2/</url>
    <content><![CDATA[<h3 id="TCP核心参数"><a href="#TCP核心参数" class="headerlink" title="TCP核心参数"></a>TCP核心参数</h3><p>关于TCP核心参数，参见：<a href="https://www.frozentux.net/ipsysctl-tutorial/chunkyhtml/tcpvariables.html">https://www.frozentux.net/ipsysctl-tutorial/chunkyhtml/tcpvariables.html</a></p>
<p>其中比较重要的有：</p>
<h4 id="tcp-syn-retries"><a href="#tcp-syn-retries" class="headerlink" title="tcp_syn_retries"></a>tcp_syn_retries</h4><p>三次握手中，发出的SYN未得到响应时，超时重传SYN包的次数</p>
<h4 id="tcp-synack-retries"><a href="#tcp-synack-retries" class="headerlink" title="tcp_synack_retries"></a>tcp_synack_retries</h4><p>三次握手中最后一个ACK未收到时，超时重传SYN-ACK包的次数</p>
<h4 id="tcp-max-syn-backlog"><a href="#tcp-max-syn-backlog" class="headerlink" title="tcp_max_syn_backlog"></a>tcp_max_syn_backlog</h4><p>服务器端SYN队列大小，关于TCP Listener的状态转变，可参考下图:</p>
<p><img src="/assets/image/201510/tcp_listen_queues.png" alt=""></p>
<h4 id="tcp-abort-on-overflow"><a href="#tcp-abort-on-overflow" class="headerlink" title="tcp_abort_on_overflow"></a>tcp_abort_on_overflow</h4><p>当服务器忙不过来时(listen backlog满了)，发送RST包重置连接</p>
<h4 id="tcp-tw-reuse"><a href="#tcp-tw-reuse" class="headerlink" title="tcp_tw_reuse"></a>tcp_tw_reuse</h4><p>复用正在TIME_WAIT状态的端口</p>
<h4 id="tcp-defer-accept"><a href="#tcp-defer-accept" class="headerlink" title="tcp_defer_accept"></a>tcp_defer_accept</h4><p>server端会在接收到最后一个ack之后，并不进入ESTABLISHED状态，而只是将这个socket标记为acked，然后丢掉这个ack。此时server端这个socket还是处于syn_recved，然后接下来就是等待client发送数据， 而由于这个socket还是处于syn_recved,因此此时就会被syn_ack定时器所控制。直到收到客户端第一个包(此时连接才ESTABLISHED)或重传超时(丢掉连接)。</p>
<p>针对客户端发送第一个包(典型地，如HTTP浏览器)的情况下，这个参数可以延迟连接的建立(ESTABLISHED)，在应用层体现为延迟连接服务(进程/线程/Actor)的创建，对某些对最大连接(服务)数有限制的服务器，可以更充分地利用资源。并且由于少了服务的休眠/唤醒，可能在这方面有细微地性能提升。</p>
<span id="more"></span>
<hr>
<p>下面是一些比较危险，通常不建议使用的选项：</p>
<h4 id="tcp-syncookies"><a href="#tcp-syncookies" class="headerlink" title="tcp_syncookies"></a>tcp_syncookies</h4><p> 当SYN队列满时，可通过cookies的方式与客户端建立连接(即使该连接不在SYN队列中)。它违反了TCP三次握手协议，是非正规不严谨的。尽管对防止Syn Flood很有帮助</p>
<h4 id="tcp-tw-recycle"><a href="#tcp-tw-recycle" class="headerlink" title="tcp_tw_recycle"></a>tcp_tw_recycle</h4><p>打开TIME_WAIT状态套接字的快速回收，比tcp_tw_reuse更为激进，慎用</p>
<h4 id="tcp-max-tw-buckets"><a href="#tcp-max-tw-buckets" class="headerlink" title="tcp_max_tw_buckets"></a>tcp_max_tw_buckets</h4><p>处于TIME_WAIT状态的套接字最大数量，超过这个限制的套接字将被销毁</p>
<h3 id="服务器常见问题"><a href="#服务器常见问题" class="headerlink" title="服务器常见问题"></a>服务器常见问题</h3><h4 id="1-SYN-Flood-攻击"><a href="#1-SYN-Flood-攻击" class="headerlink" title="1. SYN Flood 攻击"></a>1. SYN Flood 攻击</h4><p>SYN泛洪攻击是指伪造TCP请求，发送SYN包，被攻击服务器将该连接加入SYN队列中，发送SYN-ACK包，但永远等不到客户端的ACK包，直到超时重传SYN-ACK多次后，这种”半连接”才能正常释放。大量的这种请求会耗尽SYN队列，导致正常连接请求得不到响应。</p>
<p>通过Shell命令： </p>
<pre><code>netstat -n | awk &#39;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&#39; 
</code></pre><p>查看当前所有连接的状态统计。<code>SYN_RECV</code>状态即为服务器端等待客户端ACK的状态，当该状态的连接数量过多时，通常是遭受了SYN Flood攻击。</p>
<p>解决方法：</p>
<ul>
<li>调整<code>tcp_synack_retries</code>，减少超时重发SYN-ACK的次数(默认为5次)</li>
<li>调整<code>tcp_max_syn_backlog</code>，增大”半连接”队列，即SYN队列</li>
<li>不到万不得已不要使用<code>tcp_syncookies</code>选项</li>
</ul>
<p>参考：<a href="http://tech.uc.cn/?p=1790">http://tech.uc.cn/?p=1790</a></p>
<h4 id="2-TIME-WAIT-状态"><a href="#2-TIME-WAIT-状态" class="headerlink" title="2. TIME_WAIT 状态"></a>2. TIME_WAIT 状态</h4><p>前面已经说过这个问题，解决这个问题的方法：</p>
<ul>
<li>尽量让客户端主动断开连接</li>
<li>服务器监听套接字使用<code>SO_REUSEADDR</code>选项</li>
</ul>
<h4 id="3-半打开连接"><a href="#3-半打开连接" class="headerlink" title="3. 半打开连接"></a>3. 半打开连接</h4><p>半打开连接(<code>Half-Open</code>)是指，一方已经关闭或异常终止连接而另一方还不知道。</p>
<p>比如客户端突然异常关机，没有发送FIN，而服务器并不知道客户端已经不存在，仍然维护着这个连接，占用着服务器资源。当客户端重启后，将使用一个新的临时端口，即通过一个新连接与服务器通信，而旧的半打开连接仍然存在(我们假设服务器不会主动向客户端发消息，如果有，参见服务器异常关闭的情况)。</p>
<p>而如果服务器异常关闭了，客户端仍然维护着这个连接，在服务器重启后，客户端尝试给服务器发消息，此时服务器将返回一个RST包，导致连接复位。</p>
<p>解决方法：</p>
<ul>
<li>应用层保活定时器：心跳机制</li>
<li>TCP层包括定时器：TCP的keepalive</li>
</ul>
<h4 id="4-半关闭连接"><a href="#4-半关闭连接" class="headerlink" title="4. 半关闭连接"></a>4. 半关闭连接</h4><p>半关闭连接是指一方结束了它的发送行为，但是还能够收到来自另一方的数据。即只关闭了一个方向上的通道。这可能是应用利用半关闭特性来做一些事情(尽管并不建议这么做)，也可能是应用忘了关闭另一个方向上的通道。</p>
<p>通过上面的Shell命令统计出状态结果，其中状态FIN_WAIT2，即为半关闭状态。这通常也是服务器端需要注意的。</p>
]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>tcp/ip</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP复习笔记(三) TCP套接字</title>
    <url>/2015/10/tcp-notes-3/</url>
    <content><![CDATA[<h3 id="主要流程"><a href="#主要流程" class="headerlink" title="主要流程"></a>主要流程</h3><p>服务器端套接字的主要流程：</p>
<ol>
<li><code>socket()</code>：创建一个主动套接字</li>
<li><code>bind()</code>：为套接字绑定一个本地协议地址和端口(这一步不是必须)</li>
<li><code>listen()</code>：将套接字改为被动套接字，如果套接字没有绑定端口，为套接字选择一个临时端口，此时TCP状态机等待<code>SYN</code>包的到达</li>
<li><code>accept()</code>：从listen backlog队列中取出一个<code>已经建立</code>(已完成三次握手)的连接</li>
</ol>
<p>而对于客户端来说，只需要知道服务器IP,Port，直接<code>connect()</code>即可，客户端一般无需主动调用<code>bind()</code>绑定端口，因为客户端不关心它的本地端口，<code>connect()</code>会为其选择一个临时端口。</p>
<span id="more"></span>
<h3 id="套接字API"><a href="#套接字API" class="headerlink" title="套接字API"></a>套接字API</h3><h4 id="socket"><a href="#socket" class="headerlink" title="socket()"></a><code>socket()</code></h4><p>创建一个指定协议簇和套接字类型套接字，对于IPv4 TCP套接字，通常创建方式为<code>socket(AF_INET, SOCKET_STREAM, 0)</code>，该函数创建的TCP套接字默认是主动套接字。</p>
<h4 id="bind"><a href="#bind" class="headerlink" title="bind()"></a><code>bind()</code></h4><p>为指定套接字分配一个本地协议地址，该地址根据套接字类型而定。对于TCP套接字来说，调用bind()函数可以为套接字指定一个IP地址和本地端口，IP地址必须是本机的一个接口。</p>
<p>对于服务器套接字来说，绑定一个固定端口一般是必要的，因为客户端需要指定这个端口才能找到对应服务器进程。而对于IP地址，通常服务器可能不止一个IP，而绑定了一个固定IP意味着套接字只能接收那些目的地为此IP的连接。因此一般我们指定绑定地址为INADDR_ANY，意味着让内核来选择IP地址，内核的做法是：将客户端SYN包的目的IP地址，作为服务器的源IP地址。</p>
<p>如前面所说，客户端一般是不需要调用bind函数的，在调用connect()时，由内核选定一个本地IP地址和临时端口。</p>
<h4 id="listen"><a href="#listen" class="headerlink" title="listen()"></a><code>listen()</code></h4><p>通过socket()函数创建的套接字为主动套接字，调用listen()将使该套接字变为被动套接字，这意味着内核应接收该套接字上的连接请求(SYN包)，listen()使套接字从CLOSED状态变为LISTEN状态。</p>
<p>由于TCP三次握手，客户端与服务器建立连接需要两步：</p>
<ol>
<li>在客户端SYN包到达时，服务端回复SYN-ACK包，此时套接字处于SYN_RECV状态</li>
<li>客户端ACK包到达，此时服务器套接字从SYN_RECV变为ESTABLISH状态，之后等待被accept()取出</li>
</ol>
<p>因此，针对这两种状态的套接字的管理，有两种方案：</p>
<ol>
<li>维护一个队列，里面包括SYN_RECV和ESTABLISH两种状态的套接字，当客户端三次握手最后一个ACK到达时，将对应套接字状态由SYN_RECV改为ESTABLISH。而accept()只会取出ESTABLISH状态的套接字。在这种实现中，listen()的backlog参数就是这个队列的最大长度。</li>
<li>维护两个队列，一个未完成连接队列(SYN队列)，存放SYN_RECV状态的套接字。一个已完成连接队列(Accept队列)，存放ESTABLISH状态的套接字。当连接完成(收到客户端的三次握手ACK)后，套接字将从SYN队列移到Accept队列尾部。accept()函数每次从已完成连接队列头部取出一个套接字。这种实现中，backlog参数指的是Accept队列最大长度。</li>
</ol>
<p>历史上两种方案均被不同的套接字实现版本采取过，而目前Linux2.2以上的版本使用的是第二种方案（参见<a href="http://linux.die.net/man/2/listen">Linux listen() man page</a>），意味着backlog限制Accept队列的大小，而SYN队列的大小通过tcp_max_syn_backlog内核参数来控制。那么这里我们有几个问题需要讨论：</p>
<ul>
<li>当SYN队列满时，新客户端再次尝试连接(发送SYN包)，会发生什么？</li>
<li>当Accept队列满时，收到了客户端的握手ACK，需要将套接字从SYN队列移至Accept队列，会发生什么？</li>
<li>客户端发完握手ACK后，对客户端来说，连接已经建立(处于ESTABLISH状态)了，而服务器套接字由于各种原因(如Accept队列满)并未到达ESTABLISH状态，此时客户端向服务器发送数据，会发送什么？</li>
</ul>
<p>当SYN队列满时，通常的TCP实现会忽略SYN包(而不是发送RST包重置连接)，这使得客户端connect()会进行超时重传，等待SYN队列有空闲位置。tcp_syn_retries参数可以控制客户端SYN报文的重试次数。</p>
<p>当Accept队列满时，这通常是由于accept()调用处理不过来，如果这时收到了客户端的握手ACK包，如果内核参数tcp_abort_on_overflow=0，也就是默认情况，Linux实现会忽略该ACK，这将导致服务器会超时重传SYN-ACK包(参数tcp_synack_retries可控制重传次数)，然后客户端收到SYN-ACK包，也会假设之前的ACK包丢失了，仍然会回复ACK，此时服务器再次收到ACK，可能Accept队列就有空闲位置了。而如果tcp_abort_on_overflow=1，服务器在Accept队列满了，处理不过来时，将直接回复一个RST包，这将导致一个客户端connect()错误: ECONNREFUSED。客户端将不会再次重试。在Linux下，当Accept队列满时，内核还会限制SYN包的进入速度，如果太快，有些SYN包将会被丢弃。</p>
<p>站在客户端的角度来说，当它收到SYN-ACK并回复ACK后，连接就已经建立了。此时如果它立即向服务器发送数据，而服务可能由于Accept队列满，忽略了ACK，也就仍然处于SYN_RECV状态，此时客户端发送的数据仍然将被忽略，并且由客户端重传。TCP的慢启动机制确保了连接刚建立时不会发送太多的数据。</p>
<p>最后，在Linux下，backlog指定的大小受限于/proc/sys/net/core/somaxconn。另外，不要将backlog设为0，不能的实现可能对此有不同的解释。</p>
<p>关于listen() backlog更详细的讨论参见：<a href="http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html">http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html</a></p>
<h4 id="accept"><a href="#accept" class="headerlink" title="accept()"></a><code>accept()</code></h4><p>从Accept队列中取出一个已完成连接，若Accept队列为空，则进程睡眠(假设为阻塞方式)。</p>
<p>accept()返回一个新的连接套接字(内核已经为它已经完成三次握手)，之后与客户端套接字的通信均通过该连接套接字来完成。</p>
<h4 id="connect"><a href="#connect" class="headerlink" title="connect()"></a><code>connect()</code></h4><p>向指定地址发送SYN报文，尝试建立连接。如果套接字之前没有调用bind()绑定地址端口，内核会选择源IP地址和一个临时端口。</p>
<p>connect()仅在连接成功或出错时才返回，出错的可能有：</p>
<ul>
<li>没有收到SYN包的响应，尝试超时重发，最后仍无响应。返回ETIMEOUT</li>
<li>如果收到的SYN响应为RST，表明服务器对应端口还没有进程监听(未调用listen并处于LISTEN状态，状态机不能接收SYN报文)，客户端收到RST包立即返回ECONNREFUSED错误</li>
<li>如果客户端发出的SYN引发了目的地不可达的ICMP错误，那么将按第一种情况重试，重试未果最终返回EHOSTUNREACH或ENETUNREACH</li>
</ul>
]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>tcp/ip</tag>
      </tags>
  </entry>
  <entry>
    <title>开发笔记(4) SLG 地图</title>
    <url>/2015/11/erlang-server-design4-slg-map/</url>
    <content><![CDATA[<h3 id="数据组织"><a href="#数据组织" class="headerlink" title="数据组织"></a>数据组织</h3><p>我们将地图上的数据分为动态数据(行军)和静态数据(点数据)，因为行军过程不会对地图上的点造成影响(飞行)，并且不考虑实时碰撞，因此行军的逻辑是非常轻的，将其剥离出地图点数据，处理起来会更简单。也就是说，行军是地图上特殊的一类事件，而不是动态的点。</p>
<span id="more"></span>
<h3 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h3><h4 id="主动拉取"><a href="#主动拉取" class="headerlink" title="主动拉取"></a>主动拉取</h4><p>主动拉取是指玩家在拖动屏幕时，能够看到地图上实时的点信息和行军信息。</p>
<ul>
<li><p>静态数据：最简单的处理，将玩家屏幕的中心点周围一定范围(&gt;=玩家屏幕大小)的点信息，发送给客户端，但这样有一个问题，玩家稍微移动屏幕(中心点变动)，都会导致频繁的请求和数据包，因此我们需要一定程度的”缓冲和限制”来避免频繁的请求。在这个基础上，我们在地图上建立了块(Block)这个概念，一个Block大概可以看做玩家屏幕大小的一个区块，玩家在拖动屏幕中，只有屏幕中心点跨Block了，才发送拉取数据请求，而每次拉取，服务器会将以该Block为中心的九宫格Blocks都发送给客户端，用于客户端平滑过渡。</p>
</li>
<li><p>动态数据：目前只考虑行军，在行军建立时，算出行军所经历的所有Block，将行军这个事件挂在这些Block上，当玩家拉取该Block的数据时，取出这些行军信息，发送客户端。客户端根据行军上面的时间戳等信息，推算出行军当前位置。</p>
</li>
</ul>
<h4 id="实时推送"><a href="#实时推送" class="headerlink" title="实时推送"></a>实时推送</h4><p>实时推送，是指玩家在屏幕上不进行任何操作，也能看到屏幕所在范围地图上发生的实时信息。这是通过视口(ViewPort)来实现的，视口是一个抽象的概念，可以看做玩家屏幕，玩家视口挂在哪个Block上，玩家就能实时收到该Block上的变化通知，默认情况下，玩家的视口挂载在主城所在的位置，随着玩家屏幕拖送，玩家的视口也会挂载在不同Block上。在服务器上，视口可以简单表示为PlayerId。</p>
<ul>
<li>当一个点数据变动时，底层会自动通知它所在Block上所有的玩家(视口)</li>
<li>新建行军时，底层会实时通知相关Block，并且将该事件ID挂在Block事件队列上。当有新视口挂载在这些Block上时，将得到通知</li>
<li>行军结束后，通知相关Block，并且将事件ID从相关Block事件队列上移除</li>
<li>当玩家离开地图后，清除玩家视口信息</li>
</ul>
<h3 id="行军设计"><a href="#行军设计" class="headerlink" title="行军设计"></a>行军设计</h3><p>一个典型的场景是，玩家选定一支队伍，然后派出行军，采矿/战斗/XXX，回城。在这上面，最开始我们的设计是，行军是队伍的一种状态，是队伍信息的一部分，行军抵达，只是队伍状态由行军转换为了采矿/战斗，这样实际上行军和队伍是一个东西。这样后来在分离出其它玩家/NPC的行军信息时就会很困难。</p>
<p>最后我们将行军单独抽了出来，行军可以承载任何类型的可移动单位，行军和可移动单位相互索引，这样行军本身只携带很少量的信息，并且到达目的地之后就会被删除。</p>
<h3 id="模块设计"><a href="#模块设计" class="headerlink" title="模块设计"></a>模块设计</h3><p>两个模块分别用于管理点和行军，外加共用底层模块来管理Block并支撑数据同步。Block模块需要维护三个映射: <code>Player2Blocks</code>，<code>Block2Players</code>，<code>Block2Events</code>，显然，在这套机制上，一个玩家是可以有多个视口的。</p>
<p>由于将数据同步机制做在了底层，因此优化的空间是比较大的。对于操作地图点的API，可以给出一个sync选项，用于标明是否需要底层自动通知，这样上层在操作多个点时，可以在修改完之后一并通知。对于事件信息，可以优先将消息发送给事件相关的玩家(如行军所属玩家和行军的目标玩家)等。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>开发笔记(3) mongodb driver</title>
    <url>/2015/11/erlang-server-design3-mongodb-driver/</url>
    <content><![CDATA[<p>erlang mongodb驱动地址: <a href="https://github.com/comtihon/mongodb-erlang">https://github.com/comtihon/mongodb-erlang</a></p>
<p>先说说mongodb-erlang驱动的一些特性：</p>
<ul>
<li>支持atom和binary作为Key，atom最终是转换为binary进行存储的，而在读取时，驱动并不会将对应binary转换为atom(它也不知道怎么转)</li>
<li>不支持integer，string(对erlang来说是字符串，对mongodb来说是数组)作为Key</li>
<li>支持atom，binary，integer作为值，这三者的存取是透明的，不需要特殊转换，在mongodb中，atom被存为<code>Symbol(xxx)</code></li>
<li>支持string作为值，但实际上存的是字符数组，如果想存字符串，应使用binary</li>
<li>目前最新的mongodb-erlang驱动使用erlang map来存储doc(之前版本用的是bson list)</li>
</ul>
<p>基于游戏服务器的需求，我们希望：</p>
<ul>
<li>mongodb driver能够支持integer作为key</li>
<li>从模型到对象的转换是透明的，无需我们关心</li>
</ul>
<span id="more"></span>
<p>之前我们服务器逻辑中的数据模型是Dict，而mongodb-erlang使用的是bson-list来表示文档，在此之上做了一些比较繁杂转换。自mongodb-erlang支持map之后，我们也将数据结构由dict改为了map(PS: 非直观的是，map的效率不比dict差，参见<a href="https://github.com/wudaijun/Code/blob/master/erlang/map_test.erl">测试代码</a>)，如此我们需要对驱动读取的map的key value做一些类型转换。为了达到以上两点，我们对mongodb-erlang驱动做了些更改：</p>
<ol>
<li><p>修改mongodb-erlang的依赖<a href="https://github.com/comtihon/bson-erlang">bson-erlang</a>，在src/bson_binary.erl中添加对integer key的存储支持：</p>
<pre><code> put_field_accum(Label, Value, Bin) when is_atom(Label) -&gt;
       &lt;&lt;Bin/binary, (put_field(atom_to_binary(Label, utf8), Value))/binary&gt;&gt;;
   % add this line to suport integer key
 put_field_accum(Label, Value, Bin) when is_integer(Label) -&gt;
       &lt;&lt;Bin/binary, (put_field(integer_to_binary(Label), Value))/binary&gt;&gt;;
 put_field_accum(Label, Value, Bin) when is_binary(Label) -&gt;
       &lt;&lt;Bin/binary, (put_field(Label, Value))/binary&gt;&gt;.
</code></pre></li>
<li><p>在读取时，为了支持atom key和integer key的透明转换，我们约定了服务器只使用integer和atom(不能是integer atom，如’123’)作为key，这样我们可以在驱动读取完成后，进行key的自动转换：</p>
<pre><code> % 将Key由二进制串 转为整数或者原子
 convert_map_key(Map) when is_map(Map) -&gt;
   maps:fold(fun(Key, Value, NewMap) -&gt;
     NewKey = case catch binary_to_integer(Key) of
       &#123;&#39;EXIT&#39;, &#123;badarg, _R&#125;&#125; -&gt; binary_to_atom(Key, utf8);
       IntegerKey -&gt; IntegerKey
     end,
     maps:put(NewKey, convert_map_key(Value), NewMap)
   end, maps:new(), Map);

 convert_map_key(List) when is_list(List) -&gt;
   lists:map(fun(Elem) -&gt;
     convert_map_key(Elem)
   end, List);

 convert_map_key(Data) -&gt; Data.
</code></pre></li>
<li>最后还有一个小问题，就是mongodb-erlang的<a href="https://github.com/comtihon/mongodb-erlang/blob/master/src/api/mongo.erl">mongo.erl</a>中，在插入文档时，会自动检查文档是否包含&lt;&lt;”_id”&gt;&gt;键，如果没有，则会为其生成一个ObjectId()作为&lt;&lt;”_id”&gt;&gt;键的值，这里我们需要将其改为检查’_id’原子键，否则我们在逻辑中创建的包含’_id’键的文档，最终存入时，mongodb中的”_id”键的值是驱动自动生成的ObjectId()，而不是我们定义的’_id’键的值：</li>
</ol>
<pre><code>    assign_id(Map) when is_map(Map) -&gt;
      case maps:is_key(&#39;_id&#39;, Map) of
        true -&gt; Map;
        false -&gt; Map#&#123;&#39;_id&#39; =&gt; mongo_id_server:object_id()&#125;
      end;
    assign_id(Doc) -&gt;
      case bson:lookup(&#39;_id&#39;, Doc) of
        &#123;&#125; -&gt; bson:update(&#39;_id&#39;, mongo_id_server:object_id(), Doc);
        _Value -&gt; Doc
      end.
</code></pre><p>现在我们已经支持integer，atom作为key，binary，integer，atom，list作为value，基于这些类型的key/value是无需我们关心模型到对象的映射转换的。对于一个游戏服务器来说，基本上已经能够满足大部分需求了。对于一些极为特殊的模块，再通过设定回调(on_create/on_init/on_save)等方式特殊处理。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang Map映射到Record</title>
    <url>/2015/11/erlang-map2record/</url>
    <content><![CDATA[<p>在游戏服务器中，通常要面临对象到模型的映射，以及对象到协议的映射，前者用于GS和DB交互，后者用于GS和Client交互。我们的项目中做到了<a href="http://wudaijun.com/2015/11/erlang-server-design3-mongodb-driver/">对象到模型的自动映射</a>，这样在开发过程中无需关心GS和DB的交互，很方便。</p>
<p>而现在我们还没有实现对象(map)到协议(record)的自动映射，我觉得这个特性是比较有用的，特别是在同步一些实体数据的时候。无需写一堆Packer函数来将对象数据打包为协议。因此就研究了一下如何将map的数据自动映射到<a href="https://github.com/basho/erlang_protobuffs">protobuffer</a>，也就是转换为record。</p>
<span id="more"></span>
<p>我希望实现一个接口：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">% RecordName: 	type:atom, 协议名字 如hero</span><br><span class="line">% MapData:		type:map,  对象数据</span><br><span class="line">% RecordData:	type:tuple, 被转换后的协议包</span><br><span class="line">map2record(RecodName, MapData) -&gt; RecordData.</span><br><span class="line"></span><br><span class="line">如：</span><br><span class="line">&gt; rd(hero, &#123;id, level, star&#125;).</span><br><span class="line">&gt; HeroMap &#x3D; #&#123;id &#x3D;&gt; 1, level &#x3D;&gt; 2, star &#x3D;&gt; 3&#125;.</span><br><span class="line">&gt; &#123;hero, 1, 2, 3&#125; &#x3D; map2record(hero, HeroMap).</span><br></pre></td></tr></table></figure>
<p>在实际使用中，还应该考虑到protobuffer中的嵌套结构，map2record应该能够实现嵌套结构，repeated字段的自动解析。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><h4 id="1-识别record"><a href="#1-识别record" class="headerlink" title="1. 识别record"></a>1. 识别record</h4><p>由于record类型在erlang运行时并不存在，因此我们无法判断一个原子是否是record，也无法获取它的字段。因此需要实现<code>is_record/1</code>和<code>record_fields/1</code>接口。</p>
<p>在网上找到<a href="http://jixiuf.github.io/erlang/record_info.html">这篇博客</a>为此提供了一个很好的解决方案。它通过<a href="http://www.erlang.org/doc/man/epp.html">erlang epp</a>模块对record定义进行语义级的解析，并且手动生成我们所需要的函数。我只需要其中的<code>record_fields</code>接口，并对<code>is_record</code>接口进行了一些修改，让其判断一个原子是否是一个record名字，而不是判断一个数据是不是record类型。</p>
<h4 id="2-填充record"><a href="#2-填充record" class="headerlink" title="2. 填充record"></a>2. 填充record</h4><p>填充比较简单，参见代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% codeblock lang:erlang %&#125;</span><br><span class="line">-module(map2record).</span><br><span class="line"></span><br><span class="line">-export([auto_transfer&#x2F;2]).</span><br><span class="line"></span><br><span class="line">auto_transfer(RecordName, MapData) -&gt;</span><br><span class="line">  case &#123;myhead_util:is_record(RecordName), is_list(MapData)&#125; of</span><br><span class="line">    &#123;true, true&#125; -&gt;</span><br><span class="line">      lists:map(fun(SubData) -&gt;</span><br><span class="line">        auto_transfer(RecordName, SubData)</span><br><span class="line">      end, MapData);</span><br><span class="line">    &#123;true, false&#125; -&gt;</span><br><span class="line">      Fields &#x3D; myhead_util:fields_info(RecordName),</span><br><span class="line">      Values &#x3D; lists:map(fun(Field) -&gt;</span><br><span class="line">        auto_transfer(Field, maps:get(Field, MapData, undefined))</span><br><span class="line">      end, Fields),</span><br><span class="line">      list_to_tuple([RecordName|Values]);</span><br><span class="line">    &#123;false, _&#125; -&gt;</span><br><span class="line">      MapData </span><br><span class="line">  end.</span><br><span class="line">&#123;% end codeblock %&#125;</span><br></pre></td></tr></table></figure>
<p>整个填充需要满足一些条件，</p>
<ul>
<li>record中的field名字要和map中的key一致</li>
<li>repeated字段，在map中的值，也应该是个list</li>
<li>对于嵌套record，字段名应该为被嵌套的record名字</li>
</ul>
<p>举个例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 协议文件</span><br><span class="line">message hero&#123;</span><br><span class="line">	required int32 id              &#x3D; 1;</span><br><span class="line">	required hero_base hero_base   &#x3D; 2;</span><br><span class="line">	repeated hero_skill hero_skill &#x3D; 3;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 那么内测中的HeroMap应该是这样：</span><br><span class="line">#&#123;	</span><br><span class="line">    id          &#x3D;&gt; 1,</span><br><span class="line">    hero_base   &#x3D;&gt; #&#123; ... &#125;</span><br><span class="line">    hero_skill  &#x3D;&gt; [#&#123;...&#125;, #&#123;...&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>完整代码参见Github: <a href="https://github.com/wudaijun/erl_utils/tree/master/map2record">https://github.com/wudaijun/erl_utils/tree/master/map2record</a></p>
<p>由于我们项目中大部分列表型实体都被组织成了譬如skill_id =&gt; SkillData的map，因此在项目中并没有采用这份方案，也不知具体实践会遇到什么问题。暂时只当个map2record的工具吧。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang 常用数据结构实现</title>
    <url>/2015/12/erlang-datastructures/</url>
    <content><![CDATA[<p>简单介绍一下Erlang常用数据结构的内部实现和特性，主要参考<a href="https://github.com/erlang/otp/tree/maint-18">Erlang OTP 18.0</a>源码，和网上很多优秀博客(参见附录)，整理了一些自己项目中常用到的。</p>
<p>Erlang虚拟机使用一个字(64/32位)来表示所有类型的数据，即Eterm。具体的实施方案通过占用Eterm的后几位作为类型标签，然后根据标签类型来解释剩余位的用途。这个标签是多层级的，最外层占用两位，有三种类型：</p>
<ul>
<li>01: list，剩下62位是指向列表Cons的指针</li>
<li>10: boxed对象，即复杂对象，剩余62位指向boxed对象的对象头。包括元组，大整数，外部Pid/Port等</li>
<li>11: immediate立即数，即可以在一个字中表示的小型对象，包括小整数，本地Pid/Port，Atom，NIL等</li>
</ul>
<p>这三种类型是Erlang类型的大框架，前两者是可以看做是引用类型，立即数相当于是值类型，<strong>但无论对于哪种类型，Erlang Eterm本身只占用一个字</strong>，理解这一点是很重要的。</p>
<span id="more"></span>
<p>对于二三级标签的细分和编码，一般我们无需知道这些具体的底层细节，以下是几种常用的数据结构实现方式。</p>
<h2 id="一-常用类型"><a href="#一-常用类型" class="headerlink" title="一. 常用类型"></a>一. 常用类型</h2><h3 id="1-atom"><a href="#1-atom" class="headerlink" title="1. atom"></a>1. atom</h3><p>atom用立即数表示，在Eterm中保存的是atom在全局atom表中的索引，依赖于高效的哈希和索引表，Erlang的atom比较和匹配像整数一样高效。atom表是不回收的，并且默认最大值为1024*1024，超过这个限制Erlang虚拟机将会崩溃，可通过<code>+t</code>参数调整该上限。</p>
<h3 id="2-Pid-Port"><a href="#2-Pid-Port" class="headerlink" title="2.Pid/Port"></a>2.Pid/Port</h3><pre><code>/*  erts/emulator/beam/erl_term.h

 *
 *  Old pid layout(R9B及之前):
 *  
 *   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 *   |s s s|n n n n n n n n n n n n n n n|N N N N N N N N|c c|0 0|1 1|
 *   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 *
 *  s : serial  每次n到达2^15之后 自增一次 然后n重新从低位开始
 *  n : number  15位, 进程在本地进程表中的索引
 *  c : creation 每次节点重启，该位自增一次
 *  N : node number 节点名字在atom表中索引
 *
 *
 *  PID layout (internal pids):
 *
 *   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 *   |n n n n n n n n n n n n n n n n n n n n n n n n n n n n|0 0|1 1|
 *   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 *
 *  n : number 28位进程Pid
 */
</code></pre><p>在Old Pid表示中(R9B及之前版本)，在32位中表示了整个Pid，包括其节点名字等信息，也就是本地进程和外部进程都可以用Eterm立即数表示，显示格式为<code>&lt;N, n, s&gt;</code>。</p>
<p>在R9B之后，随着进程数量增加和其它因素，Pid只在32位中表示本地Pid(A=0)，将32位中除了4位Tag之外的28位，都可用于进程Pid表示，出于Pid表示的历史原因，仍然保留三段式的显示，本地Pid表示变成了<code>&lt;0, Pid低15位, Pid高13位&gt;</code>。对于外部Pid，采用boxed复合对象表示，在将本地Pid发往其它node时，Erlang会自动将为Pid加上本地节点信息，并打包为一个boxed对象，占用6个字。另外，Erlang需要维护Pid表，每个条目占8个字节，当进程数量过大时，Pid表将占用大量内存，Erlang默认可以使用18位有效位来表示Pid(262144)，可通过+P参数调节，最大值为27位(2^27-1)，此时Pid表占用内存为2G。</p>
<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line">Eshell V8.<span class="number">1</span>  (abort with ^G)</span><br><span class="line">(n1@T4F-MBP-<span class="number">11</span>)<span class="number">1</span>&gt; node().</span><br><span class="line">&#x27;n1@T4F-MBP-<span class="number">11</span>&#x27;</span><br><span class="line"><span class="comment">% 节点名的二进制表示</span></span><br><span class="line">(n1@T4F-MBP-<span class="number">11</span>)<span class="number">2</span>&gt; term_to_binary(node()).</span><br><span class="line">&lt;&lt;<span class="number">131</span>,<span class="number">100</span>,<span class="number">0</span>,<span class="number">13</span>,<span class="number">110</span>,<span class="number">49</span>,<span class="number">64</span>,<span class="number">84</span>,<span class="number">52</span>,<span class="number">70</span>,<span class="number">45</span>,<span class="number">77</span>,<span class="number">66</span>,<span class="number">80</span>,<span class="number">45</span>,<span class="number">49</span>,<span class="number">49</span>&gt;&gt;</span><br><span class="line">(n1@T4F-MBP-<span class="number">11</span>)<span class="number">3</span>&gt; self().</span><br><span class="line">&lt;<span class="number">0.63</span>.<span class="number">0</span>&gt;</span><br><span class="line"><span class="comment">% term_to_binary会将A对应的节点名编码进去</span></span><br><span class="line">(n1@T4F-MBP-<span class="number">11</span>)<span class="number">4</span>&gt; term_to_binary(self()).</span><br><span class="line">&lt;&lt;<span class="number">131</span>,<span class="number">103</span>,<span class="number">100</span>,<span class="number">0</span>,<span class="number">13</span>,<span class="number">110</span>,<span class="number">49</span>,<span class="number">64</span>,<span class="number">84</span>,<span class="number">52</span>,<span class="number">70</span>,<span class="number">45</span>,<span class="number">77</span>,<span class="number">66</span>,<span class="number">80</span>,<span class="number">45</span>,<span class="number">49</span>,</span><br><span class="line">  <span class="number">49</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">63</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>&gt;&gt;</span><br><span class="line">(n1@T4F-MBP-<span class="number">11</span>)<span class="number">5</span>&gt;</span><br></pre></td></tr></table></figure>
<h3 id="3-lists"><a href="#3-lists" class="headerlink" title="3. lists"></a>3. lists</h3><p>列表以标签01标识，剩余62位指向列表的Cons单元，Cons是[Head|Tail]的组合，在内存中体现为两个相邻的Eterm，Head可以是任何类型的Eterm，Tail是列表类型的Eterm。因此形如<code>L2 = [Elem|L1]</code>的操作，实际上构造了一个新的Cons，其中Head是Elem Eterm，Tail是L1 Eterm，然后将L2的Eterm指向了这个新的Cons，因此L2即代表了这个新的列表。对于<code>[Elem|L2] = L1</code>，实际上是提出了L1 Eterm指向的Cons，将Head部分赋给Elem，Tail部分赋给L2，注意Tail本身就是个List的Eterm，因此list是单向列表，并且构造和提取操作是很高效的。需要再次注意的是，Erlang所有类型的Eterm本身只占用一个字大小。这也是诸如list,tuple能够容纳任意类型的基础。</p>
<p>Erlang中进程内对对象的重复引用只需占用一份对象内存(只是Eterm本身一个字的拷贝)，但是在对象跨进程时，对象会被展开，执行速深度拷贝：</p>
<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line">Eshell V7.<span class="number">0.2</span>  (abort with ^G)</span><br><span class="line"><span class="number">1</span>&gt; L1 = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>].</span><br><span class="line">[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="number">2</span>&gt; erts_debug:size(L1).		  </span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">3</span>&gt; L2 = [L1,L1,L1].</span><br><span class="line">[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]</span><br><span class="line"><span class="number">4</span>&gt; erts_debug:size(L2).		  <span class="comment">% 获得L2对象树的大小 3*2+6</span></span><br><span class="line"><span class="number">12</span></span><br><span class="line"><span class="number">5</span>&gt; erts_debug:flat_size(L2). 	<span class="comment">% 获得对象平坦展开后的大小 3*(2+6)</span></span><br><span class="line"><span class="number">24</span></span><br><span class="line"><span class="number">6</span>&gt; P1 = spawn(<span class="keyword">fun</span>() -&gt; <span class="keyword">receive</span> L -&gt; io:format(<span class="string">&quot;~p~n&quot;</span>,[erts_debug:size(L)]) <span class="keyword">end</span> <span class="keyword">end</span>).</span><br><span class="line">&lt;<span class="number">0.45</span>.<span class="number">0</span>&gt;</span><br><span class="line"><span class="number">7</span>&gt; P1 ! L2.					  <span class="comment">% 在跨进程时，对象被展开 执行深度拷贝</span></span><br><span class="line"><span class="number">24</span></span><br><span class="line">[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]</span><br></pre></td></tr></table></figure>
<p>此时L1, L2的内存布局如下：</p>
<p><img src="/assets/image/201512/erlang_lists_sample.png" alt=""></p>
<h3 id="4-tuple"><a href="#4-tuple" class="headerlink" title="4. tuple"></a>4. tuple</h3><p>tuple属于boxed对象的一种，每个boxed对象都有一个对象头(header)，boxed Eterm即指向这个header，这个header里面包含具体的boxed对象类型，如tuple的header末6位为000000，前面的位数为tuple的size：</p>
<p><img src="/assets/image/201512/erlang_tuple_format.png" alt=""></p>
<p>tuple实际上就是一个有头部的数组，其包含的Eterm在内存中紧凑排列，tuple的操作效率和数组是一致的。</p>
<p>list和tuple是erlang中用得最多的数据结构，也是其它一些数据结构的基础，如record，map，摘下几个关于list，tuple操作的常用函数，便于加深对结构的理解：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 位于 $OTP_SRC/erts/emulator/beam/bif.c</span></span><br><span class="line"><span class="function">BIF_RETTYPE <span class="title">tuple_to_list_1</span><span class="params">(BIF_ALIST_1)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Uint n;</span><br><span class="line">    Eterm *tupleptr;</span><br><span class="line">    Eterm <span class="built_in">list</span> = NIL;</span><br><span class="line">    Eterm* hp;</span><br><span class="line">	</span><br><span class="line">    <span class="keyword">if</span> (is_not_tuple(BIF_ARG_1))  &#123;</span><br><span class="line">	BIF_ERROR(BIF_P, BADARG);</span><br><span class="line">    &#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 得到tuple Eterm所指向的tuple对象头</span></span><br><span class="line">    tupleptr = tuple_val(BIF_ARG_1);</span><br><span class="line">    <span class="comment">// 得到对象头中的tuple size		    </span></span><br><span class="line">    n = arityval(*tupleptr);</span><br><span class="line">    hp = HAlloc(BIF_P, <span class="number">2</span> * n);</span><br><span class="line">    tupleptr++;</span><br><span class="line">	</span><br><span class="line">	 <span class="comment">// 倒序遍历 因为list CONS的构造是倒序的</span></span><br><span class="line">    <span class="keyword">while</span>(n--) &#123;</span><br><span class="line">    <span class="comment">// 相当于hp[0]=tupleptr[n]; hp[1] = list; list = make_list(hp);</span></span><br><span class="line">    <span class="comment">// 最后返回的是指向hp的list Eterm</span></span><br><span class="line">	<span class="built_in">list</span> = CONS(hp, tupleptr[n], <span class="built_in">list</span>);</span><br><span class="line">	hp += <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    BIF_RET(<span class="built_in">list</span>);</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="function">BIF_RETTYPE <span class="title">list_to_tuple_1</span><span class="params">(BIF_ALIST_1)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Eterm <span class="built_in">list</span> = BIF_ARG_1;</span><br><span class="line">    Eterm* cons;</span><br><span class="line">    Eterm res;</span><br><span class="line">    Eterm* hp;</span><br><span class="line">    <span class="keyword">int</span> len;</span><br><span class="line">	</span><br><span class="line">    <span class="keyword">if</span> ((len = erts_list_length(<span class="built_in">list</span>)) &lt; <span class="number">0</span> || len &gt; 		ERTS_MAX_TUPLE_SIZE) &#123;</span><br><span class="line">	BIF_ERROR(BIF_P, BADARG);</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 元素个数 + 对象头</span></span><br><span class="line">    hp = HAlloc(BIF_P, len+<span class="number">1</span>);</span><br><span class="line">    res = make_tuple(hp);</span><br><span class="line">    *hp++ = make_arityval(len);</span><br><span class="line">    <span class="keyword">while</span>(is_list(<span class="built_in">list</span>)) &#123;</span><br><span class="line">	cons = list_val(<span class="built_in">list</span>);</span><br><span class="line">	*hp++ = CAR(cons);</span><br><span class="line">	<span class="built_in">list</span> = CDR(cons);</span><br><span class="line">    &#125;</span><br><span class="line">    BIF_RET(res);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到，list，tuple中添加元素，实际上都是在拷贝Eterm本身，Erlang虚拟机会追踪这些引用，并负责垃圾回收。</p>
<h3 id="5-binary"><a href="#5-binary" class="headerlink" title="5. binary"></a>5. binary</h3><p>Erlang binary用于处理字节块，Erlang其它的数据结构(list,tuple,record)都是以Eterm为单位的，用于处理字节块会浪费大量内存，如”abc”占用了7个字(加上ETerm本身)，binary为字节流提供一种操作高效，占用空间少的解决方案。</p>
<p>之前我们介绍的数据结构都存放在Erlang进程堆上，进程内部可以使用对象引用，在对象跨进程传输时，会执行对象拷贝。为了避免大binary跨进程传输时的拷贝开销，Erlang针对binary作出了优化，将binary分为小binary和大binary。</p>
<h4 id="heap-binary"><a href="#heap-binary" class="headerlink" title="heap binary"></a>heap binary</h4><p>小于64字节(定义于erl_binary.h <code>ERL_ONHEAP_BIN_LIMIT</code>宏)的小binary直接创建在进程堆上，称为heap binary，heap binary是一个boxed对象：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">erl_heap_bin</span> &#123;</span></span><br><span class="line">    Eterm thing_word;		<span class="comment">/* Subtag HEAP_BINARY_SUBTAG. */</span></span><br><span class="line">    Uint size;				<span class="comment">/* Binary size in bytes. */</span></span><br><span class="line">    Eterm data[<span class="number">1</span>];			<span class="comment">/* The data in the binary. */</span></span><br><span class="line">&#125; ErlHeapBin;</span><br></pre></td></tr></table></figure>
<h4 id="refc-binary"><a href="#refc-binary" class="headerlink" title="refc binary"></a>refc binary</h4><p>大于64字节的binary将创建在Erlang虚拟机全局堆上，称为refc binary(reference-counted binary)，可被所有Erlang进程共享，这样跨进程传输只需传输引用即可，虚拟机会对binary本身进行引用计数追踪，以便GC。refc binary需要两个部分来描述，位于全局堆的refc binary数据本身和位于进程堆的binary引用(称作proc binary)，这两种数据结构定义于global.h中。下图描述refc binary和proc binary的关系：</p>
<p><img src="/assets/image/201512/erlang_refc_binary.png" alt=""></p>
<p>所有的OffHeap(进程堆之外的数据)被组织为一个单向链表，进程控制块(erl_process.h struct process)中的<code>off_heap</code>字段维护链表头和所有OffHeap对象的总大小，当这个大小超过虚拟机阀值时，将导致一次强制GC。注意，refc binary只是OffHeap对象的一种，以后可扩展其它种类。</p>
<h4 id="sub-binary"><a href="#sub-binary" class="headerlink" title="sub binary"></a>sub binary</h4><p>sub binary是Erlang为了优化binary分割的(如<code>split_binary/2</code>)，由于Erlang变量不可变语义，拷贝分割的binary是效率比较底下的做法，Erlang通过sub binary来复用原有binary。ErlSubBin定义于<code>erl_binary.h</code>，下图描述<code>split_binary(ProBin, size1)</code>返回一个ErlSubBin二元组的过程：</p>
<p><img src="/assets/image/201512/erlang_sub_binary.png" alt=""></p>
<p>ProBin的size可能小于refc binary的size，如上图中的size3，这是因为refc binary通常会通过预分配空间的方式进行优化。</p>
<p>要注意的是，sub binary只引用proc binary(通过orig)，而不直接引用refc binary，因此图中refc binary的refc字段仍然为1。只要sub binary还有效，对应的proc binary便不会被GC，refc binary的计数也就不为0。</p>
<h4 id="bit-string"><a href="#bit-string" class="headerlink" title="bit string"></a>bit string</h4><p>当我们通过如<code>&lt;&lt;2:3,3:6&gt;&gt;</code>的位语法构建binary时，将得到<code>&lt;&lt;65,1:1&gt;&gt;</code>这种非字节对齐的数据，即二进制流，在Erlang中被称为bitstring，Erlang的bitstring基于ErlSubBin结构实现，此时bitsize为最后一个字节的有效位数，size为有效字节数(不包括未填满的最后一个字节)，对虚拟机底层来说，sub bianry和bit string是同一种数据结构。</p>
<h4 id="binary追加构造优化"><a href="#binary追加构造优化" class="headerlink" title="binary追加构造优化"></a>binary追加构造优化</h4><p>在通过<code>C = &lt;&lt;A/binary,B/binary&gt;&gt;</code>追加构造binary时，最自然的做法应当是创建足够空间的C(heap or refc)，再将A和B的数据拷贝进去，但Erlang对binary的优化不止于此，它使用refc binary的预留空间，通过追加的方式提高大binary和频繁追加的效率。</p>
<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line">Bin0 = &lt;&lt;<span class="number">0</span>&gt;&gt;,                    <span class="comment">%% 创建一个heap binary Bin0</span></span><br><span class="line">Bin1 = &lt;&lt;Bin0/binary,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&gt;&gt;,    <span class="comment">%% 追加目标不是refc binary，创建一个refc binary，预留256字节空间，用Bin0初始化，并追加1,2,3</span></span><br><span class="line">Bin2 = &lt;&lt;Bin1/binary,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>&gt;&gt;,    <span class="comment">%% 追加目标为refc binary且有预留空间 直接追加4,5,6</span></span><br><span class="line">Bin3 = &lt;&lt;Bin2/binary,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>&gt;&gt;,    <span class="comment">%% 同样，将7,8,9追加refc binary预留空间</span></span><br><span class="line">Bin4 = &lt;&lt;Bin1/binary,<span class="number">17</span>&gt;&gt;,       <span class="comment">%% 此时不能直接追加，否则会覆盖Bin2内容，虚拟机会通过某种机制发现这一点，然后将Bin1拷贝到新的refc binary，再执行追加</span></span><br><span class="line">&#123;Bin4,Bin3&#125;</span><br><span class="line">	</span><br><span class="line"><span class="comment">% 通过erts_get_internal_state/1可以获取binary状态</span></span><br><span class="line"><span class="comment">% 对应函数源码位于$BEAM_SRC/erl_bif_info.c erts_debug_get_internal_state_1</span></span><br><span class="line"><span class="function"><span class="title">f</span><span class="params">()</span> -&gt;</span></span><br><span class="line">	B0 = &lt;&lt;<span class="number">0</span>&gt;&gt;,</span><br><span class="line">	erts_debug:set_internal_state(available_internal_state,true), <span class="comment">% 打开内部状态获取接口 同一个进程只需执行一次</span></span><br><span class="line">	f2(B0). <span class="comment">% 通过参数传递B0 是为了避免虚拟机优化 直接构造B1为heap binary</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">f2</span><span class="params">(B0)</span> -&gt;</span></span><br><span class="line">  io:format(<span class="string">&quot;B0: ~p~n&quot;</span>, [erts_debug:get_internal_state(&#123;binary_info,B0&#125;)]),</span><br><span class="line">  B1 = &lt;&lt;B0/binary, <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&gt;&gt;,</span><br><span class="line">  io:format(<span class="string">&quot;B1: ~p~n&quot;</span>, [erts_debug:get_internal_state(&#123;binary_info,B1&#125;)]),</span><br><span class="line">  B2 = &lt;&lt;B1/binary, <span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>&gt;&gt;,</span><br><span class="line">  io:format(<span class="string">&quot;B2: ~p~n&quot;</span>, [erts_debug:get_internal_state(&#123;binary_info,B2&#125;)]),</span><br><span class="line">  ok.</span><br><span class="line">	</span><br><span class="line"><span class="comment">% get_internal_state(&#123;binary_info, B&#125;)返回格式:</span></span><br><span class="line"><span class="comment">% proc binary：&#123;refc_binary, pb_size, &#123;binary, orig_size&#125;, pb_flags&#125;</span></span><br><span class="line"><span class="comment">% heap binary：heap_binary</span></span><br><span class="line">B0: heap_binary</span><br><span class="line">B1: &#123;refc_binary,<span class="number">4</span>,&#123;binary,<span class="number">256</span>&#125;,<span class="number">3</span>&#125;</span><br><span class="line">B2: &#123;refc_binary,<span class="number">7</span>,&#123;binary,<span class="number">256</span>&#125;,<span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure>
<p>binary追加实现源码位于<code>$BEAM_SRC/erl_bits.c erts_bs_append</code>，B1和B2本身是sub binary，基于同一个ProcBin，可追加的refc binary只能被一个ProcBin引用，这是因为可追加refc binary可能会在追加过程中重新分配空间，此时要更新ProcBin引用，而refc binary无法快速追踪到其所有ProcBin引用(只能遍历)，另外，多个ProcBin上的sub binary可能对refc binary覆写。</p>
<p>只有最后追加得到的sub binary才可执行快速追加(通过sub binary和对应ProBin flags来判定)，否则会拷贝并分配新的可追加refc binary。所有的sub binary都是指向ProcBin或heap binary的，不会指向sub binary本身。</p>
<p><img src="/assets/image/201512/erlang_binary_append.png" alt=""></p>
<h4 id="binary降级"><a href="#binary降级" class="headerlink" title="binary降级"></a>binary降级</h4><p>Erlang通过追加优化构造出的可追加refc binary通过空间换取了效率，并且这类refc binary只能被一个proc binary引用(多个proc binary上的sub binary会造成覆写，注意，前面的B1，B2是sub binary而不是ProBin)。比如在跨进程传输时，原本只需拷贝ProBin，但对可追加的refc binary来说，不能直接拷贝ProBin，这时需对binary降级，即将可追加refc binary降级为普通refc binary：</p>
<pre><code>bs_emasculate(Bin0) -&gt;
Bin1 = &lt;&lt;Bin0/binary, 1, 2, 3&gt;&gt;,
NewP = spawn(fun() -&gt; receive _ -&gt; ok end end),
io:format(&quot;Bin1 info: ~p~n&quot;, [erts_debug:get_internal_state(&#123;binary_info, Bin1&#125;)]),
NewP ! Bin1,
io:format(&quot;Bin1 info: ~p~n&quot;, [erts_debug:get_internal_state(&#123;binary_info, Bin1&#125;)]),
Bin2 = &lt;&lt;Bin1/binary, 4, 5, 6&gt;&gt;, % Bin1被收缩 这一步会执行refc binary拷贝
io:format(&quot;Bin2 info: ~p~n&quot;, [erts_debug:get_internal_state(&#123;binary_info, Bin2&#125;)]),
Bin2.

% 运行结果
117&gt; bs_emasculate(&lt;&lt;0&gt;&gt;).
Bin1 info: &#123;refc_binary,4,&#123;binary,256&#125;,3&#125;
Bin1 info: &#123;refc_binary,4,&#123;binary,4&#125;,0&#125;
Bin2 info: &#123;refc_binary,7,&#123;binary,256&#125;,3&#125;
&lt;&lt;0,1,2,3,4,5,6&gt;&gt;
</code></pre><p>降级操作会重新创建一个普通的refc binary(原有可追加refc binary会被GC?)，同时，降级操作会将B1的flags置0，这保证基于B1的sub binary在执行追加时，会重新拷贝分配refc binary。</p>
<pre><code>// 降级函数($BEAM_SRC/erl_bits.c)
void erts_emasculate_writable_binary(ProcBin* pb)
&#123;
    Binary* binp;
    Uint unused;

    pb-&gt;flags = 0;
    binp = pb-&gt;val;
    ASSERT(binp-&gt;orig_size &gt;= pb-&gt;size);
    unused = binp-&gt;orig_size - pb-&gt;size;
    /* Our allocators are 8 byte aligned, i.e., shrinking with
       less than 8 bytes will have no real effect */
    if (unused &gt;= 8) &#123;
    // 根据ProBin中的有效字节数，重新创建一个不可追加的refc binary
    binp = erts_bin_realloc(binp, pb-&gt;size);
    pb-&gt;val = binp;
    pb-&gt;bytes = (byte *) binp-&gt;orig_bytes;
    &#125;
&#125;
</code></pre><blockquote>
<blockquote>
<p>Q: ProcBin B1的字段被更新了，那么Erlang上层如何维护变量不可变语义? </p>
<p>A: 变量不可变指的是Erlang虚拟机上层通过底层屏蔽后所能看到的不变语义，而不是变量底层实现，诸如Pid打包，maps hash扩展等，通过底层差异化处理后，对上层体现的语义和接口都没变，因此我们将其理解为”变量不可变”)。</p>
</blockquote>
</blockquote>
<p>另外，全局堆GC也可能会对可追加refc binary的预留空间进行收缩(shrink)，可参考<code>$BEAM_SRC/erl_gc.c sweep_off_heap</code>函数。</p>
<p>以上都是理论的实现，实际上Erlang虚拟机对二进制还做了一些基于上下文的优化，通过<code>bin_opt_info</code>编译选项可以打印出这些优化。关于binary优化的更多细节，参考<a href="http://erlang.org/doc/efficiency_guide/binaryhandling.html">Constructing and Matching Binaries</a>。</p>
<h2 id="二-复合类型"><a href="#二-复合类型" class="headerlink" title="二. 复合类型"></a>二. 复合类型</h2><p>基于list和tuple之上，Erlang还提供了一些其它的数据结构，这里列举几个key/value相关的数据结构，在服务器中会经常用到。</p>
<h3 id="1-record"><a href="#1-record" class="headerlink" title="1. record"></a>1. record</h3><p>这个类型无需过多介绍，它就是一个tuple，所谓record filed在预编译后实际上都是通过数值下标来索引，因此它访问field是O(1)复杂度的。</p>
<h3 id="2-map"><a href="#2-map" class="headerlink" title="2. map"></a>2. map</h3><p>虽然record的语法糖让我们在使用tuple时便利了不少，但是比起真正的key/value结构仍然有许多限制，如key只能是原子，key不能动态添加或删除，record变动对热更的支持很差等。proplists能够一定程度地解决这种问题，但是它适合键值少的情况，通常用来做选项配置，并且不能保证key的唯一。</p>
<p>map是OTP 17引进的数据结构，是一个boxed对象，它支持任意类型的Key，模式匹配，动态增删Key等，并且最新的<a href="https://github.com/comtihon/mongodb-erlang">mongodb-erlang</a>直接支持map。</p>
<p>在<a href="https://github.com/erlang/otp/tree/maint-17">OTP17</a>中，map的内存结构为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//位于 $OTP_SRC/erts/emulator/beam/erl_map.h</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">map_s</span> &#123;</span></span><br><span class="line">    Eterm thing_word;	<span class="comment">// 	boxed对象header</span></span><br><span class="line">    Uint  size;			<span class="comment">// 	map 键值对个数</span></span><br><span class="line">    Eterm keys;      	<span class="comment">// 	keys的tuple</span></span><br><span class="line">&#125; <span class="keyword">map_t</span>;</span><br></pre></td></tr></table></figure>
<p>该结构体之后就是依次存放的Value，因此maps的get操作，需要先遍历keys tuple，找到key所在下标，然后在value中取出该下标偏移对应的值。因此是O(n)复杂度的。详见maps:get源码(<code>$BEAM_SRC/erl_map.c erts_maps_get</code>)。</p>
<p>如此的maps，只能作为record的替用，并不是真正的Key-&gt;Value映射，因此不能存放大量数据。而在OTP18中，maps加入了针对于big map的hash机制，当maps:size &lt; <code>MAP_SMALL_MAP_LIMIT</code>时，使用flatmap结构，也就是上述OTP17中的结构，当maps:size &gt;= <code>MAP_SMALL_MAP_LIMI</code>T时，将自动使用hashmap结构来高效存取数据。<code>MAP_SMALL_MAP_LIMIT</code>在erl_map.h中默认定义为32。</p>
<p>仍然要注意Erlang本身的变量不可变原则，每次执行更新maps，都会导致新开辟一个maps，并且拷贝原maps的keys和values，在这一点上，maps:update比maps:put更高效，因为前者keys数量不会变，因此无需开辟新的keys tuple，拷贝keys tuples ETerm即可。实际使用maps时：</p>
<ol>
<li>更新已有key值时，使用update(:=)而不是put(=&gt;)，不仅可以检错，并且效率更高</li>
<li>当key/value对太多时，对其进行层级划分，保证其拷贝效率</li>
</ol>
<p>实际测试中，OTP18中的maps在存取大量数据时，效率还是比较高的，<a href="https://github.com/wudaijun/Code/blob/master/erlang/map_test.erl">这里</a>有一份maps和dict的简单测试函数，可通过OTP17和OTP18分别运行来查看效率区别。通常情况下，我们应当优先使用maps，比起dict，它在模式匹配，mongodb支持，可读性上都有很大优势。</p>
<h3 id="3-array"><a href="#3-array" class="headerlink" title="3. array"></a>3. array</h3><p>Erlang有个叫array的结构，其名字容易给人误解，它有如下特性：</p>
<ol>
<li>array下标从0开始</li>
<li>array有两种模式，一种固定大小，另一种按需自动增长大小，但不会自动收缩</li>
<li>支持稀疏存储，执行array:set(100,value,array:new())，那么[0,99]都会被设置为默认值(undefined)，该默认值可修改。</li>
</ol>
<p>在实现上，array最外层被包装为一个record:</p>
<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">-record</span><span class="params">(array, &#123;</span></span><br><span class="line"><span class="params">	size :: non_neg_integer(),	<span class="comment">%% number of defined entries</span></span></span><br><span class="line"><span class="params">	max  :: non_neg_integer(),	<span class="comment">%% maximum number of entries</span></span></span><br><span class="line"><span class="params">	default,	<span class="comment">%% the default value (usually &#x27;undefined&#x27;)</span></span></span><br><span class="line"><span class="params">    elements :: elements(_)     <span class="comment">%% the tuple tree</span></span></span><br><span class="line"><span class="params">&#125;)</span>.</span><br></pre></td></tr></table></figure>
<p>elements是一个tuple tree，即用tuple包含tuple的方式组成的树，叶子节点就是元素值，元素默认以10个为一组，亦即完全展开的情况下，是一颗十叉树。但是对于没有赋值的节点，array用其叶子节点数量代替，并不展开：</p>
<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line">Eshell V7.<span class="number">0.2</span>  (abort with ^G)</span><br><span class="line"><span class="number">1</span>&gt; array:set(<span class="number">9</span>,value,array:new()).</span><br><span class="line">&#123;array,<span class="number">10</span>,<span class="number">10</span>,undefined, <span class="comment">% 全部展开</span></span><br><span class="line">       &#123;undefined,undefined,undefined,undefined,undefined,</span><br><span class="line">undefined,undefined,undefined,undefined,value&#125;&#125;</span><br><span class="line">	</span><br><span class="line"><span class="comment">% 只展开了19所在的子树 其它9个节点未展开 </span></span><br><span class="line"><span class="comment">% 注意tuple一共有11个元素，最后一个元素代表本层节点的基数，这主要是出于效率考虑，能够快速检索到元素所在子节点</span></span><br><span class="line"><span class="number">2</span>&gt; array:set(<span class="number">19</span>,value,array:new()).</span><br><span class="line">&#123;array,<span class="number">20</span>,<span class="number">100</span>,undefined,</span><br><span class="line">       &#123;<span class="number">10</span>,		</span><br><span class="line">        &#123;undefined,undefined,undefined,undefined,undefined，	undefined,undefined,undefined,undefined,value&#125;,</span><br><span class="line">        <span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>&#125;&#125;</span><br><span class="line">	</span><br><span class="line"><span class="comment">% 逐级展开了199所在的子树</span></span><br><span class="line"><span class="number">3</span>&gt; array:set(<span class="number">199</span>,value,array:new()).</span><br><span class="line">&#123;array,<span class="number">200</span>,<span class="number">1000</span>,undefined,</span><br><span class="line">       &#123;<span class="number">100</span>,</span><br><span class="line">        &#123;<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,</span><br><span class="line">         &#123;undefined,undefined,undefined,undefined,undefined,</span><br><span class="line"> undefined,undefined,undefined,undefined,value&#125;,</span><br><span class="line">         <span class="number">10</span>&#125;,</span><br><span class="line">        <span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>&#125;&#125;</span><br><span class="line"><span class="number">4</span>&gt;</span><br></pre></td></tr></table></figure>
<p>由于完全展开的tuple tree是一颗完全十叉树，因此实际上array的自动扩容也是以10为基数的。在根据Index查找元素时，通过div/rem逐级算出Index所属节点:</p>
<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line"><span class="comment">%% 位于$OTP_SRC/lib/stdlib/src/array.erl</span></span><br><span class="line"><span class="function"><span class="title">get</span><span class="params">(I, #array&#123;size = N, max = M, elements = E, default = D&#125;)</span></span></span><br><span class="line"><span class="function">  <span class="title">when</span> <span class="title">is_integer</span><span class="params">(I)</span>, I &gt;= 0 -&gt;</span></span><br><span class="line">    <span class="keyword">if</span> I &lt; N -&gt;		<span class="comment">% 有效下标</span></span><br><span class="line">	    get_1(I, E, D);</span><br><span class="line">       M &gt; <span class="number">0</span> -&gt;		<span class="comment">% I&gt;=N 并且 array处于自动扩容模式 直接返回DefaultValue </span></span><br><span class="line">	    D;</span><br><span class="line">       <span class="literal">true</span> -&gt;		<span class="comment">% I&gt;=N 并且 array为固定大小  返回badarg</span></span><br><span class="line">	    erlang:error(badarg)</span><br><span class="line">    <span class="keyword">end</span>;</span><br><span class="line"><span class="function"><span class="title">get</span><span class="params">(_I, _A)</span> -&gt;</span></span><br><span class="line">    erlang:error(badarg).</span><br><span class="line">	</span><br><span class="line"><span class="comment">%% The use of NODEPATTERN(S) to select the right clause is just a hack,</span></span><br><span class="line"><span class="comment">%% but it is the only way to get the maximum speed out of this loop</span></span><br><span class="line"><span class="comment">%% (using the Beam compiler in OTP 11).</span></span><br><span class="line">	</span><br><span class="line"><span class="comment">% -define(NODEPATTERN(S), &#123;_,_,_,_,_,_,_,_,_,_,S&#125;). % NODESIZE+1 elements!</span></span><br><span class="line"><span class="function"><span class="title">get_1</span><span class="params">(I, E=?NODEPATTERN(S)</span>, D) -&gt;</span>		<span class="comment">% 到达已展开的中间节点 向下递归</span></span><br><span class="line">    get_1(I rem S, element(I div S + <span class="number">1</span>, E), D);</span><br><span class="line"><span class="function"><span class="title">get_1</span><span class="params">(_I, E, D)</span> <span class="title">when</span> <span class="title">is_integer</span><span class="params">(E)</span> -&gt;</span>	<span class="comment">% 到达未展开的中间节点 返回默认值</span></span><br><span class="line">    D;</span><br><span class="line"><span class="function"><span class="title">get_1</span><span class="params">(I, E, _D)</span> -&gt;</span>						<span class="comment">% 到达叶子节点层</span></span><br><span class="line">    element(I+<span class="number">1</span>, E).</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">set</span><span class="params">(I, Value, #array&#123;size = N, max = M, default = D, elements = E&#125;=A)</span></span></span><br><span class="line"><span class="function">  <span class="title">when</span> <span class="title">is_integer</span><span class="params">(I)</span>, I &gt;= 0 -&gt;</span></span><br><span class="line">    <span class="keyword">if</span> I &lt; N -&gt;</span><br><span class="line">	    A#array&#123;elements = set_1(I, E, Value, D)&#125;;</span><br><span class="line">       I &lt; M -&gt;		<span class="comment">% 更新size, size的主要作用是让读取更加高效 </span></span><br><span class="line">	    <span class="comment">%% (note that this cannot happen if M == 0, since N &gt;= 0)</span></span><br><span class="line">	    A#array&#123;size = I+<span class="number">1</span>, elements = set_1(I, E, Value, D)&#125;;</span><br><span class="line">       M &gt; <span class="number">0</span> -&gt;		<span class="comment">% 自动扩容</span></span><br><span class="line">	    &#123;E1, M1&#125; = grow(I, E, M),</span><br><span class="line">	    A#array&#123;size = I+<span class="number">1</span>, max = M1,</span><br><span class="line">		    elements = set_1(I, E1, Value, D)&#125;;</span><br><span class="line">       <span class="literal">true</span> -&gt;</span><br><span class="line">	    erlang:error(badarg)</span><br><span class="line">    <span class="keyword">end</span>;</span><br><span class="line"><span class="function"><span class="title">set</span><span class="params">(_I, _V, _A)</span> -&gt;</span></span><br><span class="line">    erlang:error(badarg).</span><br><span class="line">	</span><br><span class="line"><span class="comment">%% See get_1/3 for details about switching and the NODEPATTERN macro.</span></span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="title">set_1</span><span class="params">(I, E=?NODEPATTERN(S)</span>, X, D) -&gt;</span>		<span class="comment">% 所在节点已展开，向下递归</span></span><br><span class="line">    I1 = I <span class="keyword">div</span> S + <span class="number">1</span>,</span><br><span class="line">    setelement(I1, E, set_1(I rem S, element(I1, E), X, D));</span><br><span class="line"><span class="function"><span class="title">set_1</span><span class="params">(I, E, X, D)</span> <span class="title">when</span> <span class="title">is_integer</span><span class="params">(E)</span> -&gt;</span>	<span class="comment">% 所在节点未被展开，递归展开节点 并赋值</span></span><br><span class="line">    expand(I, E, X, D);</span><br><span class="line"><span class="function"><span class="title">set_1</span><span class="params">(I, E, X, _D)</span> -&gt;</span>						<span class="comment">% 到达叶子节点</span></span><br><span class="line">    setelement(I+<span class="number">1</span>, E, X).</span><br></pre></td></tr></table></figure>
<p>更多细节可以参见源码，了解了这些之后，再来看看Erlang array和其它语言数组不一样的地方：</p>
<ul>
<li>索引不是O(1)复杂度，而是O(log10n)</li>
<li>array并不自动收缩</li>
<li>array中的max和size字段，和array具体占用内存没多大关系(节点默认未展开)</li>
<li>array中并没有subarray之类的操作，因为它根本不是线性存储的，而是树形的，因此如果用它来做递归倒序遍历之类的操作，复杂度不是O(n)，而是O(n*log10n)</li>
<li>array中对于没有赋值的元素，给予默认值undefined，这个默认值可以在array:new()中更改，对使用者来说，明确赋值undefined和默认值undefined并无多大区别，但对array内部来说，可能会导致节点展开。</li>
</ul>
<h2 id="三-参考"><a href="#三-参考" class="headerlink" title="三. 参考"></a>三. 参考</h2><ol>
<li>Erlang数据结构实现文章汇总: <a href="http://www.iroowe.com/erlang_eterm_implementation/">http://www.iroowe.com/erlang_eterm_implementation/</a></li>
<li>[zhengsyao] Erlang系列精品博客(文中大部分图片出处): <a href="http://www.cnblogs.com/zhengsyao/category/387871.html">http://www.cnblogs.com/zhengsyao/category/387871.html</a></li>
<li>[坚强2002] Erlang array: <a href="http://www.cnblogs.com/me-sa/archive/2012/06/14/erlang-array.html">http://www.cnblogs.com/me-sa/archive/2012/06/14/erlang-array.html</a></li>
<li>Erlang Effciency Guide: <a href="http://erlang.org/doc/efficiency_guide/introduction.html">http://erlang.org/doc/efficiency_guide/introduction.html</a></li>
</ol>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>开发笔记(5) cluster_server集群优化</title>
    <url>/2016/01/erlang-server-design5-server-node/</url>
    <content><![CDATA[<p>在使用<a href="http://wudaijun.com/2015/08/erlang-server-design1-cluster-server/">cluster_server</a>做gameserver后台集群支撑的过程中，逐步暴露出一些问题，在此记之。</p>
<h4 id="1-节点交互效率低下"><a href="#1-节点交互效率低下" class="headerlink" title="1. 节点交互效率低下"></a>1. 节点交互效率低下</h4><p>我们按照业务职责将集群节点分为，agent，player，map，alliance，battle等，这些节点可以在一台物理机上(操作系统进程间交互)，也有可能部署到不同的物理机上(网络IO交互)，而玩家一个业务逻辑可能涉及到多个节点，形成一个节点交互链：如玩家在大地图上进行一场战斗，按照流程需要走：agent -&gt; player -&gt; map -&gt; battle -&gt; map -&gt; player -&gt; agent。整个过程都是异步的。这种交互是频繁的且低效的。</p>
<span id="more"></span>
<p>反思cluster_server最初的设计：根据业务职责来划分节点，这样做主要优势在于容错(灾)性和负载均衡，在节点调试和调优方面也很方便。但是对于业务逻辑来说，玩家的数据被分散到各个节点，这些节点之间异步交互(我们对call是敏感的)，造成了数据同步和逻辑交互都变得复杂，这种复杂度随节点数量和逻辑复杂程度(涉及到的节点数)还会不断上升。</p>
<p>针对于这些问题，我们首先对集群进行了重整，将同一个server_id下的player，map，pvp，alliance等轻量的进程放在一起，由server进程统一管理，并挂载server_node之上。这样整个集群的节点只剩三个：agent，server，battle，满足了数据局部性原则，业务逻辑交互也更高效(Erlang进程之间)。mnesia集群表仍然保留，用于执行快速的消息路由和进程查找。</p>
<p><img src="/assets/image/201601/cluster_server_server_node.png" alt="" title="Server Node"></p>
<h4 id="2-玩家数据同步"><a href="#2-玩家数据同步" class="headerlink" title="2. 玩家数据同步"></a>2. 玩家数据同步</h4><p>这一直是分布式系统中的一个大问题，玩家的数据被分散在各节点，不同的节点还需要玩家一些基础信息的副本，这部分需要同步的数据很难管理。主要有以下几种方案：</p>
<ol>
<li>玩家跨节点时，将本次处理所需要的信息带上。这种方案只能运用于玩家本身的数据同步。而玩家可能或查看或拉取其它玩家的数据</li>
<li>各节点存有玩家部分数据的副本，玩家对应数据更新时，player通过cast消息到相关节点进行数据更新。这适用于简单的数据同步，如玩家name，level等，复杂的数据，比如玩家的英雄信息，会导致通信量过大</li>
<li>各节点在需要实时玩家信息时，去player身上拉取。这是不可取的：第一，不能call player 第二，目标player进程不一定还在，特别是流失玩家</li>
<li>做一个Cache中心，并且满足单写多读的原则。比如map节点改变了玩家数据，那么它应该将数据变动发给player节点，由player节点来完成数据更新并更新Cache</li>
</ol>
<p>在重构集群之前，我们用的是方案2，主要原因是数据简单，更新实时。要在跨节点同步中，使用Cache中心，可以直接通过mnesia实现，但是这是软实时，对于一些实时性很高的数据，需要使用事务。但在建立了server_node之后，就简单很多了，通过ets即可实现，但仍然要满足只有一个写入者的原则。</p>
<h4 id="3-节点交互链过长"><a href="#3-节点交互链过长" class="headerlink" title="3. 节点交互链过长"></a>3. 节点交互链过长</h4><p>可以在agent消息路由处，将map相关消息直接路由到map，而map业务处理完成之后，如果不需要在玩家身上增减资源，则可以直接将Ack发到玩家对应的agent上，流程得以简化。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>目前服务器的分布式特性：</p>
<ul>
<li>按照ServerId组成一颗大的监督树，一个Server及其所有包含模块，均作为整体部署在一个server_node上。这样Server内部的逻辑与数据得以聚合。而负载均衡将以Server为基本单位</li>
<li>在节点内部，为了方便交互，仍然使用Mnesia作服务注册与发现，但由于Server之间没有隔离，要求服务ID全局唯一</li>
<li>对于单服管理，可能需要一个进程维护一个Server的同类服务(player, alliance)，以进行LRU，全服广播等服务器逻辑</li>
</ul>
<p>可选的优化方案：</p>
<ul>
<li>服务隔离：对各Server之间的服务进行隔离。隔离的好处：一是减轻Mnesia单表压力，二是对Server逻辑有更好的支撑：如全服通知，停服操作。但就Mnesia来说，我目前没有找到好的隔离方案</li>
<li>本地服务：一些服务是否可以优化至单节点读写，这样Mnesia可退化为ETS，换来更好读取速度，并且极大减轻Mnesia压力</li>
<li>控制节点数量：删除不必要的Mnesia节点，通过消息而不是Mnesia来同步服务</li>
</ul>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>3D动画基础</title>
    <url>/2016/02/3d-animation/</url>
    <content><![CDATA[<h3 id="顶点动画"><a href="#顶点动画" class="headerlink" title="顶点动画"></a>顶点动画</h3><p>3D动画本质上是模型的顶点轨迹，因此要记录一段动画，最原始的办法就是记录动画过程中所有的顶点信息。但由于肉眼的识别速度和GPU的处理能力都有限，因此有了桢(frame)的概念，帧是模型特定姿态的一个快照。为了进一步减少动画桢的内存占用，我们可以从动画的轨迹中提出中关键帧，保存每一个关键帧的模型网格信息，由引擎来得到平滑的动画效果(关键帧过渡)，在关键帧之间平滑过渡的帧叫过渡帧或插值桢。<br><span id="more"></span></p>
<h3 id="骨骼动画"><a href="#骨骼动画" class="headerlink" title="骨骼动画"></a>骨骼动画</h3><p>针对于人/动物等具备骨骼特征的模型动画的一种优化，由于人的皮肤相对于其所属骨骼的相对偏移固定不变，因此皮肤顶点的空间位置可由其骨骼位置加上其相对偏移得到，所以我们无需记录皮肤上每个顶点信息，而记录对应的骨骼信息，这样我们实际得到的是一段简化版的”线段动画”，谓之骨骼动画。</p>
<p>由于骨骼与骨骼通常只有相对角度，没有相对位移，比如手掌不会脱离肘，因此我们无需单独记录每个骨骼的位置信息，只需记录骨骼与其父关节的相对角度，比如手掌的父骨骼为肘，肘的父关节为臂等，这样，我们需要为模型指定一个根骨骼(比如人体的脊椎)，根据根骨骼的位置即可以推算出所有骨骼的位置，以完成正确渲染，为模型顶点绑定其内在骨骼的过程叫做蒙皮(skining)，有些顶点可能需要绑定在多个骨骼上，比如关节处的皮肤。</p>
<p>骨骼动画为动画插值运算，逆向运动学得提供了可行性基础。</p>
<p>关于骨骼动画更多参考：<a href="http://www.cnblogs.com/kex1n/archive/2011/10/11/2207546.html">http://www.cnblogs.com/kex1n/archive/2011/10/11/2207546.html</a></p>
<h3 id="动画过渡"><a href="#动画过渡" class="headerlink" title="动画过渡"></a>动画过渡</h3><p>在给定的时间内，从一个动画平滑过渡到另一个动画的过程，叫做动画过渡，如在0.2s内，将动画从A切换到B，若动画A当前帧为FA1，动画B起始帧为FB1，我们用F1(W1)+F2(W2)表示一个插值桢，设过渡桢为10桢，那么这里有两种过渡方案：</p>
<p>首尾插值：动画引擎将随时间调整FA1，FB1的权重，对其插值融合，得到插值帧：FA1(1)+FB1(0),  FA1(0.9)+FB1(0.1) … FA1(0)+FB1(1)。</p>
<p>交叉插值：动画一边过渡一边插值：FA1(1)+FB1(0), FA2(0.9)+FB2(0.1), … FA11(0)+FB11(1)</p>
<h3 id="动画融合"><a href="#动画融合" class="headerlink" title="动画融合"></a>动画融合</h3><p>在美术导入的资源中，只有每个模型的基本的动作，比如走，跑，跳等，而真正运动中需要的远不止这些，比如我们还需要快走，慢跑等，这些动画完全通过美术导出是不切实际的。现在的动画系统提供了一种动画融合机制，即由程序去控制多个动画的权重，插值合成新的动画。比如我们可以通过速度去控制走，跑动画的插值权重，得到我们想要的慢跑动画。另一个例子是CS中的持枪动作，美术可能导出了上下左右前后的持枪动作，对于任意角度，我们可能需要用到1-3个动画，对其进行融合得到对应角度的持枪动作，融合权重由当前角度而定，而如果这时候我们还希望模型能够保持慢跑动作，我们还需要合成下半身的动画，在融合时，模型慢跑动画的上半身动画权重为0，下半身动画权重为1，持枪动画权重相反，这样就得到一个灵活的模型，而美术只导入有限的基础动画即可。</p>
<p>动画过渡和动画融合本质上都用于生成平滑的动画，但前者用于两个动画的平滑切换，通过时间决定动画插值权重，而后者可用于多个动画(融合)，并且动画插值权重由程序控制。</p>
<h3 id="动画层"><a href="#动画层" class="headerlink" title="动画层"></a>动画层</h3><p>前面提到了CS人物模型的动画融合，它需要用到多个动画，对于慢跑动作，其上半身的融合权重通常为0，而对于持枪动作，其下半身的融合权重为0，但是动画系统仍然会去计算这一部分，造成了不必要的GPU/CPU浪费。如今一些动画系统提供了动画层的概念，可以在一个动画控制器里面存在多个动画状态机，并对它们自动融合。每个动画层可以有身体遮罩(Mask)，亦即决定该动画运用于身体的那一部分，禁止哪一部分，被禁止的部分融合权重为0，并且不会参与运算。比如持枪动画层的身体遮罩应禁止下半身。</p>
<h3 id="动画与模型变换"><a href="#动画与模型变换" class="headerlink" title="动画与模型变换"></a>动画与模型变换</h3><p>动画本身可由美术导入位移(Postion)和转向(Rotation)信息，这些变换是模型相对于自身坐标系的，要将这些变换运用于模型在世界坐标系的变换，有两种方式：由程序控制和由动画控制。由程序控制是指，程序控制模型的Transform，然后将Transform信息设置到动画系统，由动画系统去展现当前动作，比如走，跑等，这也是最早的动画交互方式。如此程序需要事先精确匹配动画的变换信息，否则可能出现滑步等现象。另外一种方式为了解决这类问题的：由动画控制模型变换，程序去动画系统拉取模型的变换信息，这虽然在表现层上体验更好，但也有一些问题：让渲染层决定了逻辑层，如果渲染帧卡了，会影响到逻辑帧处理。</p>
<p>Unity关于这方面有更灵活的控制，参见：<a href="http://blog.csdn.net/cubesky/article/details/39478207">http://blog.csdn.net/cubesky/article/details/39478207</a></p>
<h3 id="逆向运动学"><a href="#逆向运动学" class="headerlink" title="逆向运动学"></a>逆向运动学</h3><p>IK(Inverse Kinematic，逆向运动学，也称反向运动学)主要用于骨骼动画，前面提到，骨骼动画通过根骨骼(也叫模型的根节点)出发，根据其子节点的相对位置(角度)推算出子节点的绝对位置，从手臂到肘到手掌到手指，整个推算结构呈树形。而如果我们已知末节点的位置，逐步推算出所有其它节点的合理位置的过程即为IK。比如人物模型用手触碰一个固定物品，我们需要根据物品的位置，决定模型的动作。</p>
]]></content>
      <categories>
        <category>unity</category>
      </categories>
      <tags>
        <tag>unity</tag>
      </tags>
  </entry>
  <entry>
    <title>3D贴图基础</title>
    <url>/2016/03/3d-mapping/</url>
    <content><![CDATA[<h3 id="漫反射贴图-Diffuse-Mapping"><a href="#漫反射贴图-Diffuse-Mapping" class="headerlink" title="漫反射贴图(Diffuse Mapping)"></a>漫反射贴图(Diffuse Mapping)</h3><p>漫反射贴图反映出物体表面在漫反射下的颜色和强度，表现出物体的固有色以及纹理。是物体最基础的贴图。通常也可以直接理解为纹理。</p>
<h3 id="高光贴图-Specular-Mapping"><a href="#高光贴图-Specular-Mapping" class="headerlink" title="高光贴图(Specular Mapping)"></a>高光贴图(Specular Mapping)</h3><p>高光贴图表现物体表面的光照属性，包括镜面反射强度，光泽度，以及菲涅耳衍射强度，决定物体在强光下，表面不同材质(布料，金属，皮肤等)的光照表现。一些高光贴图只包含镜面反射强度信息，每个像素只需要8位，即使用一个通道。</p>
<span id="more"></span>
<h3 id="法线贴图-Normal-Mapping"><a href="#法线贴图-Normal-Mapping" class="headerlink" title="法线贴图(Normal Mapping)"></a>法线贴图(Normal Mapping)</h3><p>法线贴图保存了物体表面每个像素点的法线向量：</p>
<p><img src="/assets/image/201603/normal_map_vector.jpg" alt=""><br><img src="/assets/image/201603/normal_map_vector1.jpg" alt=""></p>
<p>这样，将大小为1的光源向量与法线向量相乘，得到的值越接近于0，表面越暗，越接近于1，表面越亮。要保存所有点的法线向量，需要保存[x,y,z]三元组，这正好可以作为RGB值放到一张图片中，因此就有了法线”贴图”，虽然它表现为一张图片，但实际上只是存放向量信息的载体。</p>
<p>有了法线贴图，我们既避免了复杂模型带来的运算和内存占用，又实现了比较细节的光照效果，突出了模型的细节。</p>
<h3 id="视差贴图-Parallax-Mapping"><a href="#视差贴图-Parallax-Mapping" class="headerlink" title="视差贴图(Parallax Mapping)"></a>视差贴图(Parallax Mapping)</h3><p>视差贴图技术和法线贴图差不多，但它有着不同的原则。和法线贴图一样视差贴图能够极大提升表面细节，使之具有深度感。它根据储存在纹理中的几何信息对顶点进行位移或偏移。但是这种偏移只用于光影表现，不作用于实际模型轮廓。一种实现的方式通过高度贴图(High Mapping)保存纹理中顶点的高度信息。</p>
<p><img src="/assets/image/201603/bump_map.png" alt=""></p>
<h3 id="置换贴图-Displacement-Mapping"><a href="#置换贴图-Displacement-Mapping" class="headerlink" title="置换贴图(Displacement Mapping)"></a>置换贴图(Displacement Mapping)</h3><p>又叫位移贴图，替换贴图可以通过一种向量贴图的方式来实现，这个向量贴图并不像普通贴图那样改变物体表面的颜色，而是改变物体表面点的位置。它不像法线贴图和视差贴图，因为这些技术都是在制造凹凸效果的假象，而位移映射是真正通过贴图的方式制造出凹凸的表面。它必须要配合切面细分算法，增加渲染的多边形数目来制造出细节的效果。因此它是同类贴图中消耗最大的。</p>
<p><img src="/assets/image/201603/displacement_map.jpg" alt=""></p>
<h3 id="环境贴图-Environment-Mapping"><a href="#环境贴图-Environment-Mapping" class="headerlink" title="环境贴图(Environment Mapping)"></a>环境贴图(Environment Mapping)</h3><p>又叫反射贴图，把反射对象当作一个虚拟眼睛，生成一张虚拟的纹理图，然后把该纹理图映射到反射对象上，得到的图像就是该场景的一个影像。反射贴图主要实现的功能是：使物体表面能显示出真实场景的影像，而又无需逐个渲染场景中的物体。环境贴图根据反射对象的不同，主要分为三种：球面环境贴图，立方体环境贴图和双曲面环境贴图。</p>
<p><img src="/assets/image/201603/reflect_map.png" alt=""></p>
<h3 id="光照贴图-Light-Mapping"><a href="#光照贴图-Light-Mapping" class="headerlink" title="光照贴图(Light Mapping)"></a>光照贴图(Light Mapping)</h3><p>光照贴图针对于模型周围光照作用于模型效果的一个快照，以避免实时计算光照效果和阴影效果。这通常用在对静态物体(如墙面，箱子)的渲染优化，如Unity中可通过烘焙得到光照贴图。</p>
<h3 id="实例效果"><a href="#实例效果" class="headerlink" title="实例效果"></a>实例效果</h3><p><img src="/assets/image/201603/diffuse_specular.png" alt="" title="Caption"><br>漫反射+高光贴图</p>
<p><img src="/assets/image/201603/diffuse_env.png" alt="" title="Caption"><br>漫反射+环境贴图</p>
<p><img src="/assets/image/201603/diffuse_normal_env.png" alt="" title="Caption"><br>漫反射+法线+环境贴图</p>
<h3 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h3><ol>
<li>环境贴图：<a href="http://www.twinklingstar.cn/2014/1322/environment-mapping/">http://www.twinklingstar.cn/2014/1322/environment-mapping/</a></li>
<li>Wiki中的各种贴图：<a href="https://zh.wikipedia.org/wiki/%E4%BD%8D%E7%A7%BB%E8%B4%B4%E5%9B%BE">https://zh.wikipedia.org/wiki/%E4%BD%8D%E7%A7%BB%E8%B4%B4%E5%9B%BE</a></li>
<li>Learn OpenGL: <a href="https://learnopengl-cn.readthedocs.org/zh/latest/">https://learnopengl-cn.readthedocs.org/zh/latest/</a></li>
<li>GTA5中的贴图运用：<a href="http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/">http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/</a></li>
</ol>
]]></content>
      <categories>
        <category>unity</category>
      </categories>
      <tags>
        <tag>unity</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang 分布式系统(1)</title>
    <url>/2016/03/erlang-distribution-1/</url>
    <content><![CDATA[<h3 id="一-分布式计算的八大谬论"><a href="#一-分布式计算的八大谬论" class="headerlink" title="一. 分布式计算的八大谬论"></a>一. 分布式计算的八大谬论</h3><h4 id="1-网络总是可靠的"><a href="#1-网络总是可靠的" class="headerlink" title="1. 网络总是可靠的"></a>1. 网络总是可靠的</h4><p>在分布式系统中，你可能最容易犯下的错误就是认为远程节点是永远可用的，尽管这可以通过添加更多的硬件(比如主从)来实现，但这也带来了冗余性。网络可能随时因为断电，硬件故障，自然因素，人为因素等不可用，在这种情况下，保证你的程序能够在远程节点或者第三方服务不可用时，能够正常运行是非常重要的。Erlang除了能够监测到外部服务失去连接(或者不能响应)之外，没有任何的其它措施，毕竟，除了你自己以外，谁也不知道某个组件有多重要。</p>
<p>注意，Erlang跨节点的monitor和link操作是比较危险的，因为一旦远程节点不可用，将触发关于该节点所有的远程monitor和link，这可能会引起一场网络风暴，给系统带来意料之外的高负载。在不可靠的网络上构建可靠的分布式应用，需要你随时准备面临这种突发状况，并且保证系统能够继续正常稳定地工作。</p>
<span id="more"></span>
<h4 id="2-可忽略的延迟"><a href="#2-可忽略的延迟" class="headerlink" title="2. 可忽略的延迟"></a>2. 可忽略的延迟</h4><p>一个好的分布式系统的特性之一就是隐藏函数调用为远程调用的事实，然而这是一把双刃剑，一些本地上执行非常快的函数，通过网络调用时，会与预期大不相同。在这一点上，Erlang的通信模型处理得很好，Erlang的每个进程是孤立的，通过异步消息进行通信，这使得我们考虑超时，以及外部服务不可用的情况。将Erlang程序改造为分布式程序只需要做很少的工作，异步通信模型，超时，监视，链接等都可以保留。因此，Erlang在设计之初，并不忽略延迟的存在。但是作为设计者，在设计上，你需要对此留意。</p>
<h4 id="3-带宽是无限的"><a href="#3-带宽是无限的" class="headerlink" title="3. 带宽是无限的"></a>3. 带宽是无限的</h4><p>尽管现在网络越来越快，每个字节在网络上传输的成本也越来越便宜，但是对网络负载过于乐观的假设仍然是具有风险的。关于这一点的一个小技巧是发送当前的事件，而不是当前的整个状态。如果在一些情况下，你不得不发送大消息，一定要小心，由于Erlang保证两个进程间的消息次序(即使是通过网络)，因此一个大消息可能会阻塞该通道上的其它消息。更糟糕的是，这可能会阻塞节点间的正常心跳，导致节点误以为对方节点无法响应并且断开连接。要避免这种情况发生的唯一方案就是控制消息的大小，这也是一条好的Erlang设计实践。</p>
<h4 id="4-网络是安全的"><a href="#4-网络是安全的" class="headerlink" title="4. 网络是安全的"></a>4. 网络是安全的</h4><p>当你在分布式环境下，信任你所接收到的任何消息是非常危险的，消息可能被刻意伪造或抓包改写，甚至外部节点可能已经完全被其他人控制。遗憾的是，Erlang做了这种假设，Erlang分布式系统的网络安全是非常薄弱的，这和它的历史有关。这意味着Erlang程序很少被部署在不同的数据中心，Erlang也不建议你这么做。你可以将你的系统分为很多小的，相互隔离的节点，并且部署在可靠的地方(一台物理机，或者安全的局域网)。但任何除此之外的东西，都需要开发者自己去实现，例如切换到SSL，或者实现你自己的更高层次的通信协议，或重写节点之间的通信协议等。关于这些主题可以参见<a href="http://erlang.org/doc/apps/erts/alt_dist.html">How to implement an alternative carrier for the Erlang distribution</a>和<a href="http://erlang.org/doc/apps/erts/erl_dist_protocol.html">Distribution Protocol</a>。即使做了更多的安全工作，也要非常小心，因为一旦有人获取了你的远程节点的访问权限，他就可以获取到节点上的一切，并且在该节点上执行任何命令。</p>
<h4 id="5-网络拓扑是不变的"><a href="#5-网络拓扑是不变的" class="headerlink" title="5. 网络拓扑是不变的"></a>5. 网络拓扑是不变的</h4><p>在分布式系统构建之初，你的系统原型可能有指定数量的节点并且确定了它们的网络位置(IP+Port)，但硬件错误，人为部署，负载均衡等，都会导致节点的动态添加和删除，这时集群的网络拓扑结构就会变化，如果你在程序中对集群节点位置有任何依赖，都将很难适应这种变化。在Erlang中，每个节点都有其名字(相当于IP+Port)，如果在程序中对这些节点地址硬编码，将会使程序很难动态扩展。</p>
<h4 id="6-只有一个管理员"><a href="#6-只有一个管理员" class="headerlink" title="6. 只有一个管理员"></a>6. 只有一个管理员</h4><p>这是从系统运维上来说的，你可能只管理着整个系统的一部分，一方面你需要诊断系统问题的工具，这一点上来说，Erlang提供了比较完善的调试诊断系统，并且支持热更。另一方面，你需要做好系统各个部分间的通讯协议，以管理各个子系统的不同版本的兼容问题。</p>
<h4 id="7-数据传输代价为零"><a href="#7-数据传输代价为零" class="headerlink" title="7. 数据传输代价为零"></a>7. 数据传输代价为零</h4><p>这里的代价包括时间代价和金钱代价，前者指数据的序列化和反序列化时间，后者指数据对带宽的占用，从这个角度来看，将消息优化得小而短又一次被证明是很重要的。基于Erlang的历史，Erlang并没有对网络传输数据做任何压缩处理(尽管提供了这样的函数)，Erlang的设计者选择让开发者自己按需实现其通讯协议，减小数据传输的代价。</p>
<h4 id="8-集群是同质的"><a href="#8-集群是同质的" class="headerlink" title="8. 集群是同质的"></a>8. 集群是同质的</h4><p>这里的同质(Homogeneous)指的是同一种语言(或协议)，在分布式集群中，你不能对所有节点都是同质的作出假设，集群中的节点可能由不同的语言实现，或者遵从其它通讯协议。你应该对集群持开放原则而不是封闭原则。对Erlang来说，分布式协议是公开的，但所有的Erlang节点都假设其它节点都是同质的，外部节点想要将自己整合在Erlang集群中，有两种方式：</p>
<p>第一种方式是使自己看起来像Erlang节点，实现Erlang节点的通讯协议，比如<a href="http://erlang.org/doc/tutorial/cnode.html">Erlang C-nodes</a>，这样其它语言实现的节点也能像Erlang节点一样运行于Erlang集群中。</p>
<p>另一种方式是使用其它的数据交换协议，如<a href="http://bert-rpc.org/">BERT-RPC</a>，一种类似于XML或JSON的数据交换格式，但与<a href="http://erlang.org/doc/apps/erts/erl_ext_dist.html">Erlang External Term Format</a>更为契合。</p>
<p>关于以上8点更多请参考：<a href="http://www.rgoarchitects.com/Files/fallacies.pdf">Fallacies of Distributed Computing Explained</a>。</p>
<h3 id="二-节点检活"><a href="#二-节点检活" class="headerlink" title="二. 节点检活"></a>二. 节点检活</h3><p>对于分布式系统来说，其中最让人头疼的事情之一就是当节点不可响应(或网络错误)时的处理流程。一个节点不可响应的因素有很多：网络故障，网络拥塞，硬件错误，应用崩溃，节点忙碌等，几乎没有方式能够对问题节点当时的状态进行确认和诊断，这个时候，其它节点有几种处理方式：继续等待响应，再次发起请求，或者假设问题节点已经挂掉并且继续后续事宜。如果真是问题节点挂掉了，那你可以忽略这个节点，整个集群继续运转。而更差的情况下，问题节点此时仍然运行于孤立的环境中，从该节点的视角来看，其它节点都挂掉了，整个集群只剩自己一个节点。</p>
<p>Erlang集群默认即视不可达的节点为死节点，这是一种悲观的方案，这可以让我们对灾难性故障迅速作出反应。Erlang假设网络故障的概率比硬件或应用故障的概率低，Erlang最初就是这么设计的(为电信通讯平台服务)。另一种乐观的方案(假设失连节点仍然存活)可能或延迟故障恢复相关的处理，因为它假设网络故障的可能性要比硬件或应用故障的可能性更大，因此它会重试等待更长的时间，以便失连节点重返集群。</p>
<p>那么问题来了，在悲观的解决方案中，如果失连节点突然回归集群(比如网络恢复)又会怎么样呢？此时失连节点可能已经运行在孤立的环境数日，有自己的数据，连接，状态等。这个时候想要协调数据和状态的一致性是很困难的，并且你的集群可能已经启动了失连节点的备用节点，而直接忽略节点也不可取，也许该节点已经处理了很多外部请求，甚至向DB写入了数据。总之，会有一些非常奇怪的事情发生。</p>
<p>那么，是否有一个方案可以在节点失连的时候保持应用正常运行，并且不会出现数据丢失或不一致呢？</p>
<h3 id="三-CAP理论"><a href="#三-CAP理论" class="headerlink" title="三. CAP理论"></a>三. CAP理论</h3><p>在CAP理论中，关于上一个问题的答案是”没有”，你没有办法让一个分布式系统在网络断开的时候保持正常运行并且正确地运行。CAP理论在<a href="https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86">Wiki</a>中解释：</p>
<ul>
<li>一致性（Consistence) (等同于所有节点访问同一份最新的数据副本）</li>
<li>可用性（Availability）（对数据更新具备高可用性）</li>
<li>容忍网络分区（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择)</li>
</ul>
<p>根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。</p>
<p>关于CAP理论的另一篇很有意思的文章：<a href="http://www.infoq.com/cn/articles/cap-twelve-years-later-how-the-rules-have-changed">CAP理论十二年回顾：”规则”变了</a>。</p>
<p>从CAP理论来看，我们只有三种选择: CA, CP, AP，通常情况下，CA是我们无需考虑的，除非你可以保证你的网络不会出现故障，抑或集群是部署在同一台主机上。剩下的CP, AP需要根据你自己的系统进行取舍。</p>
<h3 id="四-待续"><a href="#四-待续" class="headerlink" title="四. 待续"></a>四. 待续</h3><p>尽管在Erlang中构建分布式系统是非常Easy的一件事情，但是分布式系统本身的复杂度，需要你根据系统需求，从多个维度去设计，考量和评估整个分布式系统，同时理解分布式系统的常见误区，注重底层细节。本文内容参考：<a href="http://learnyousomeerlang.com/distribunomicon">http://learnyousomeerlang.com/distribunomicon</a></p>
<p>之后可能详细整理一下Erlang本身在分布式方面提供的具体支持，并且评估一下当前项目用到的服务器集群系统。</p>
]]></content>
      <categories>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>erlang</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>技术学习误区</title>
    <url>/2016/04/learning-mistakes/</url>
    <content><![CDATA[<p>前几天看一些Go框架的源码和相关工具，由于之前没有在正式项目中用过Go，看起来是有些吃力的，有一种顾头不顾尾的感觉，到之后仍然是困于其中，不得精髓。这和本人的一些学习习惯有关：迷信源码，觉得只有理解其源码，才能运用自如，不知道是不是部分受于C/C++出身的影响，底层思维根深蒂固。之前看的一些框架(skynet,firefly,kbengine等)也是一样，虽然直接看的源码，但是由于缺少实践，对其运用场景，优缺点没有足够的认识，能够吸收的干货也比较有限。加之工作上开始忙起来，难免急躁，事倍功半。</p>
<span id="more"></span>
<p>于是开始反思自己的学习方法，在游戏服务器这个领域也有两年多了，对这方面的技术细节，常用构件，设计模式等已经非常熟悉了，了解过多种语言设计服务器的特性和方式，因此技术细节和语言障碍对我来说已经问题不大了，如果按照木桶原理来说，我觉得，架构设计，线上经验，解决问题的能力才是木桶的短板，而这一块需要恰巧不是深度而是广度，以问题为出发点，将多种解决方案纵向对比，能够选出一套合适的方案并加以实施，才是正解。换句话说，如果设计一个可靠，易于维护的服务器，才是目前我应该关注的东西。其它的工具，都只是实现这个目标的一种方案。关于广度的学习，我觉得分为三个层级：</p>
<ul>
<li>了解：了解方案的出发点，适用情形，以及别人的经验教训</li>
<li>实践：在项目中实践运用，评估其优缺点，瓶颈</li>
<li>剖析：在必要的时候，通过源码验证自己的想法，并针对于现有问题进行改进/优化</li>
</ul>
<p>如此看来，自己确实是有些本末倒置了，错把技术而不是解决问题当做最终目标，这并不是说技术细节不重要，而是合适的学习方法，能够让你站在一个更高的角度去理解事物的出发点，目标，以及其存在的理由，更高效地学习。另一个重要的点是，技术始终是为产品服务的。</p>
<p>第一篇水文就这样了，引以为诫。</p>
]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
  <entry>
    <title>开发笔记(6) Erlang服务器集群常见问题</title>
    <url>/2016/04/erlang-server-design6-distribution-question/</url>
    <content><![CDATA[<h3 id="集群的安全启动-终止"><a href="#集群的安全启动-终止" class="headerlink" title="集群的安全启动/终止"></a>集群的安全启动/终止</h3><p>典型地，我们需要在GS和各个服务都启动完成之后，再打开网关接入网络连接，这需要通过master节点进行监控，GS和服务也需要向cluster汇报自己的状态(启动中，运行中)，master在关键服务都启动完成并状态正常之后，再通知gateway开放连接。基于cluster中的控制信息，这一点不难做到。集群的终止流程也类似。</p>
<span id="more"></span>
<h3 id="集群OPS管理"><a href="#集群OPS管理" class="headerlink" title="集群OPS管理"></a>集群OPS管理</h3><p>master节点上还可以做一些简单运维工作：</p>
<ul>
<li>监控服务器状态：所有GS和服务是否状态正常</li>
<li>自动开服：统计所有GS的人数，确认是否开新服，并同步到推荐服列表(DB操作)</li>
<li>故障恢复：服务器本身在sup之下，其组件Crash可通过sup重启恢复，而遇上物理机宕机或失联，master会通过心跳检测确认节点不可达，然后代为注销问题节点上所有的服务，之后master将问题节点上的GS重新部署到其它可用节点。比起物理机宕机，更棘手的是网络故障，当失联节点重新回到集群而master可能已经在其它节点重新部署了故障节点上的GS，解决方案之一是，当一个节点与master节点失联时，终止自身。</li>
</ul>
<p>这些工作本质上仍然是，定时监控状态，统计状态，确认下一步操作(开新服，重新部署故障服务器等)。由于OPS监控时间间隔一般至少是分钟级别，master不需要将所监控的表设为ram_copies，减轻mnesia同步的网络负担。</p>
<h3 id="master单点"><a href="#master单点" class="headerlink" title="master单点"></a>master单点</h3><p>由于master负担了一些逻辑和状态(比如监控其它节点)，想要做一个透明过渡的主从是非常困难的，目前虽然有个主从，但应该问题还很多，待后续完善。或者是说，对一个游戏GS来说，master节点的单点是能够容忍的(因为Erlang OTP足够健壮)，遇上物理故障，停止整个集群或许是更好的办法。</p>
<h3 id="多节点写入的安全性"><a href="#多节点写入的安全性" class="headerlink" title="多节点写入的安全性"></a>多节点写入的安全性</h3><p>这在Actor模型中的经典问题，比如当服务进程S需要对玩家进程P上的资源进行操作，分两种情况，需要对资源进行增加时，向P发送资源增量即可，而需要对资源进行扣除时，则要分两步：1.检查资源是否足够，以决定下一步操作，2.向P发送消息扣除资源 ，有多种方案可以检查玩家进程资源是否足够，同步消息，异步消息，公共缓存，数据副本等，<strong>事实上，无论何种方式都不能保证当P进程在收到消息扣除资源时，资源还是S当时检查到的情形</strong>，因为这两步操作之间，P进程可能收到其它消息对资源进行了改动。这里我们选择容忍这种情况，因此一般我选择通过公共缓存或者数据副本来进行同步资源检查，然后通过向P发送消息来进行异步资源改动。注意，玩家资源的变动只能由玩家进程来进行，对缓存数据保证单写入者是减少不一致问题最有效的方式。</p>
<p>如果这类问题在开发中带来很多困扰，那么可以重新考虑一下资源所有权的问题。比如有一种资源A，它只在进程X中增加，在进程Y中扣除，如果这种设计是稳定的，那么我觉得将A挂在Y上更为适合，而如果X和Y都对A有频繁的改动操作的话，是否可以从设计上，将X中的A和Y中的A设计成两种资源，当玩家从X系统进入Y系统时，进行一次资源转换(策划案上可以叫”投放”，”运输”之类的东西)，这样两个系统都独立操作自己的资源，只在玩家选择进程资源转换时，再同步一次。当然，这里只是提供一种思路。</p>
<h3 id="全联通问题"><a href="#全联通问题" class="headerlink" title="全联通问题"></a>全联通问题</h3><p>由于cluster用mnesia来做后台同步，而mnesia后台同步时，会形成一个全联通网络(即使集群节点都是hidden节点)，虽然我们可以通过控制表的属性来避免不要的数据同步，但全联通网络的负载是比较大的，对于几十个节点的规模或许可以忍受，但更大的集群则需要正视这个问题了。由于负载量依赖于单个GS开销和机器性能，因此目前我们暂未考虑这个问题，等上线之后再观察。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang 实践经验</title>
    <url>/2016/05/erlang-practices/</url>
    <content><![CDATA[<h3 id="使用binary而不是lists"><a href="#使用binary而不是lists" class="headerlink" title="使用binary而不是lists"></a>使用binary而不是lists</h3><p>所有能用binary的地方都用binary，配置，协议，DB，网络接口，等等，如果驱动或第三方库不能很好地支持binary，就换一个或者重写接口，如果项目一开始就这么做，会在后期省掉很多麻烦。</p>
<h3 id="不要动态生成-atom"><a href="#不要动态生成-atom" class="headerlink" title="不要动态生成 atom"></a>不要动态生成 atom</h3><p>atom不被Erlang GC，在代码中要时刻警惕诸如<code>list(binary)_to_atom/2</code>和<code>binary_to_term/1</code>等动态生成atom的API，特别是这些API的输入源来自于网络或客户端等不可信源，可用<code>list(binary)_to_existing_atom/2</code>和<code>binary_to_term/2</code>替换之，前者只能转换为已经存在的原子，否则会报错，后者功能类似，确保不会生成新的atom，函数引用，Pid等(这些资源都是不会被GC回收的)。</p>
<p>可通过<code>erlang:memory/0</code>来观察atom内存使用状况。</p>
<span id="more"></span>
<h3 id="保证OTP进程的init-1是安全稳定的"><a href="#保证OTP进程的init-1是安全稳定的" class="headerlink" title="保证OTP进程的init/1是安全稳定的"></a>保证OTP进程的init/1是安全稳定的</h3><p>supervisor的start_link会<strong>同步启动</strong>整个supervisor树，如果某个孩子进程启动失败，supervisor会立即尝试重启，如果重启成功，继续启动下一个孩子进程，否则重试次数到达设定上限后，supervisor启动失败。</p>
<p>在实践中，不要将耗时，依赖外部不稳定服务的操作，放在init/1中，这会导致整个supervisor树启动的不稳定性。特别是对于一些网络连接，数据库读取等操作，应该尽量通过诸如<code>gen_server:cast(self(), reconnect)</code>的形式，将实际初始化延后，并维护好状态(是否已经初始化完成)。在<code>handle_cast(reconnect, State)</code>中处理具体的细节，不管是初始化，还是运行时的网络异常，都可以通过该函数处理。如果一个错误会经常性地出现在日常的操作中，那么是现在出现，还是以后出现是没有区别的，尽量以同样的方法处理它。</p>
<p>通常情况下，我们需要保证OTP进程的init/1是快速，稳定的，如果连启动过程都不是稳定的，那么supervisor的启动也就没有多大意义了(不能将整个系统恢复到已知稳定状态)，并且可能一个进程本身的非关键初始化错误，导致了整个supervisor启动失败。</p>
<blockquote>
<p>initialization与supervision方法的不同之处：在initialization过程中，client的使用者来决定他们能容忍什么程序的错误，而不是client自己本身决定的。在设计容错系统中，这两者区别尤其重要。   — <a href="https://zhongwencool.gitbooks.io/erlang_in_anger/chapter_2_building_open_source_erlang_software/side_effects.html">Erlang In Anger</a></p>
</blockquote>
<h3 id="消息队列膨胀"><a href="#消息队列膨胀" class="headerlink" title="消息队列膨胀"></a>消息队列膨胀</h3><p>Erlang系统最常见的问题是节点内存耗尽，而内存耗尽的主凶之一就是消息队列过长(Erlang消息队列的大小是无限制的)。要查看消息队列膨胀的进程不难，但是难的是找到消息队列膨胀的原因和解决方案。</p>
<p>常见的消息膨胀原因：</p>
<ol>
<li>日志进程：特别是错误日志，重试，重启，链接都是产生大量错误日志消息的原因，解决方案：使用lager</li>
<li>锁和阻塞操作：如网络操作或阻塞等待消息等，解决方案：添加更多进程，化阻塞为异步等</li>
<li>非期望的消息：特别针对于非OTP进程，解决方案：非OTP进程定期flush消息队列，当然，尽量使用OTP进程</li>
<li>系统处理能力不足：解决方案：横向扩展，限制输入，丢弃请求等。</li>
</ol>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang 分布式系统(2)</title>
    <url>/2016/03/erlang-distribution-2/</url>
    <content><![CDATA[<h2 id="一-分布式Erlang"><a href="#一-分布式Erlang" class="headerlink" title="一. 分布式Erlang"></a>一. 分布式Erlang</h2><p>Erlang为分布式提供的基础设施</p>
<ol>
<li>良好的函数式编程语义，为并发而生</li>
<li>异步通信模型，屏蔽底层通讯细节(Erlang进程间/系统进程间/物理机间)，将本地代码扩展为分布式程序非常容易</li>
<li>透明的通信协议，完善的序列化/反序列化支持</li>
<li>完善的监控能力：监督(supervisor), 监视(monitor), 链接(link)等</li>
<li>其它分布式组件：如global,epmd,mnesia等</li>
</ol>
<span id="more"></span>
<h2 id="二-Erlang分布式基础"><a href="#二-Erlang分布式基础" class="headerlink" title="二. Erlang分布式基础"></a>二. Erlang分布式基础</h2><h3 id="1-Erlang-node"><a href="#1-Erlang-node" class="headerlink" title="1. Erlang node"></a>1. Erlang node</h3><p>一个Erlang分布式系统由多个Erlang节点(node)组成，每一个节点即为一个Erlang虚拟机，这些节点可以彼此通信。不同节点节点上Pid之间通信(link,monitor等)，是完全透明的。</p>
<p>集群中每个Erlang节点都有自己的名字，通过<code>-sname</code>或<code>-name</code>设置节点名字，前者在局域网中使用，后者在广域网中使用，两种命名方式的节点不能相互通信。也可在节点启动后通过<code>net_kernel:start/1</code>来将一个独立节点转换为分布式节点。</p>
<p>Erlang节点之间通过TCP/IP建立连接并通信，集群中的节点是松散连接的(loosely connected)，只有当第一次用到其它节点名字时，才会和该节点建立连接(并且校验cookie)。但同时连接也是扩散(transitive)的，比如现有节点A,B相连，C,D相连，此时节点B连接节点C，那么A,B,C,D将两两相连形成一个全联通集群。要关闭Erlang节点的transitive行为，使用虚拟机启动选项<code>-connect_all false</code>。当节点挂掉后，其上所有的连接都会被关闭，也可通过<code>erlang:disconnect_node/1</code>关闭与指定节点的连接。</p>
<h3 id="2-cookie"><a href="#2-cookie" class="headerlink" title="2. cookie"></a>2. cookie</h3><p>cookie是Erlang节点连接时的简单验证机制，只有具有相同cookie的节点才能连接。通过<code>-setcookie</code>选项或<code>erlang:set_cookie/2</code>设置cookie，后者可以为一个节点设置多个cookie，在连接不同的节点时使用不同的cookie，连接到多个集群中。如果没有指定，将使用<code>~/.erlang.cookie</code>中的字符串作为cookie。由于cookie是明文的，并且共享于所有节点，更像是一种分隔集群的方式，而不是一种安全机制。</p>
<h3 id="3-hidden-node"><a href="#3-hidden-node" class="headerlink" title="3. hidden node"></a>3. hidden node</h3><p>通过为节点启动参数<code>-hidden</code>，让一个节点成为hidden节点，hidden节点与其它节点的连接不会扩展，它们必须被显示建立。通过<code>nodes(hidden)</code>或<code>nodes(connected)</code>才能看到与本节点连接的hidden节点。</p>
<h3 id="4-net-kernel"><a href="#4-net-kernel" class="headerlink" title="4. net_kernel"></a>4. net_kernel</h3><p>net_kernel管理节点之间的连接，通过<code>-sname</code>或<code>-name</code>启动参数或在代码中调用<code>net_kernel:start/1</code>可以启动net_kernel进程。net_kernel默认会在引用到其它节点时(如rpc:call/5, spawn/4, link/1等)，自动与该节点建立连接，通过<code>-dist_auto_connect false</code>选项可以关闭这种行为，如此只能通过<code>net_kernel:connect_node/1</code>手动显式地建立连接。</p>
<h3 id="5-epmd"><a href="#5-epmd" class="headerlink" title="5. epmd"></a>5. epmd</h3><p>epmd(Erlang Port Mapper Daemon)是Erlang节点所在主机上的守护进程，它维护本机上所有Erlang节点名到节点地址(Host:Port)的映射。</p>
<p>epmd会在主机上第一个Erlang分布式节点启动时自动后台启动，默认监听4369端口。当分布式节点启动时，VM会监听一个端口(可通过<code>inet_dist_listen_min</code>和<code>inet_dist_listen_max</code>限制端口范围)用于接收其它节点连接请求，之后节点会将节点名(@前半部分)和监听地址发给epmd进程，当节点和epmd进程断开TCP连接后，epmd会注销该节点地址信息。</p>
<p>当节点A(<code>node_a@myhost1</code>)尝试连接节点B(<code>node_b@myhost2</code>)时，节点A会先向myhost2上的empd进程(<code>myhost2:4369</code>)根据节点B名字(nodeb)查询节点监听地址，之后再连接这个监听地址和B节点通信。</p>
<p>默认配置下，epmd在物理机上的监听端口为4369，这意味着：</p>
<ol>
<li>因为是周知端口，所以通过查询目标机器上的4369，就可以知道这个机器上节点的情况。</li>
<li>在同一机器可能会部署不同的Erlang集群，希望不要互相干扰。</li>
<li>防火墙不允许过4369端口，或者不在开放端口之列表。</li>
</ol>
<p>我们可以指定epmd监听端口：</p>
<pre><code>// 单独启动epmd进程
empd -daemon -port 5000
// epmd随分布式节点启动而自动启动时，也可指定epmd的启动方案
erl -name hello -epmd &quot;epmd -port 5001 -daemon&quot; -epmd_port 5001
</code></pre><p>可以在虚拟机启动时，通过<code>-epmd_port</code>(或<code>ERL_EPMD_PORT</code>环境变量)指定要连接的epmd端口：</p>
<pre><code>// 通过启动选项
erl -name hello -epmd_port 5000
// 通过环境变量
ERL_EPMD_PORT=5000 erl -name hello
</code></pre><p>需要注意的是，一旦节点采用定制的epmd port，那么节点在连接其它节点的时候，也将使用定制的epmd端口访问epmd。因此，<strong>同一个集群的epmd端口必须是一致的</strong>。</p>
<p>参考：</p>
<ol>
<li><a href="http://erlang.org/doc/man/epmd.html">http://erlang.org/doc/man/epmd.html</a></li>
<li><a href="http://www.cnblogs.com/me-sa/p/erlang-epmd.html">http://www.cnblogs.com/me-sa/p/erlang-epmd.html</a></li>
<li><a href="http://erlang.org/doc/apps/erts/erl\_dist\_protocol.html">http://erlang.org/doc/apps/erts/erl\_dist\_protocol.html</a></li>
</ol>
<h3 id="6-global"><a href="#6-global" class="headerlink" title="6. global"></a>6. global</h3><p>global模块功能主要通过global_name_server进程完成，该进程在节点启动时启动。global模块主要包含如下功能：</p>
<h4 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h4><p>global模块提供全局锁功能，可以在集群内对某个资源进行访问控制，当某个节点尝试lock某个资源时，global_name_server会muticall集群中所有节点上的global_name_server进程，只要其中一个节点上操作失败，本次lock也会失败，并引发下次重试或整个操作的失败。</p>
<p>global模块会在当前所有known(<code>nodes()</code>)节点中推选出一个Boss节点(简单通过<code>lists:max(Nodes)</code>选出)，在设置全局锁时，会先尝试在Boss节点上上锁，再对其它节点上锁，这样保证全局资源的唯一性，又不需要单独设置中心节点。</p>
<h4 id="全局名字管理"><a href="#全局名字管理" class="headerlink" title="全局名字管理"></a>全局名字管理</h4><p>global_name_server另一个职责是管理集群全局名字信息，global_name_server将全局名字信息缓存在ets，因此对全局名字的解析是非常快的，甚至不走消息流程。但是对名字的注册，需要先上全局锁，再muticall所有的global_name_server，进行本地ets名字更新，整个过程至少要muticall集群所有节点两次，对于这类耗时的操作，global_name_server有一个小技巧：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"> </span><br><span class="line"></span><br><span class="line">% 外部进程（call调用）</span><br><span class="line">gen_server:call(global_server, &#123;something, Args&#125;)</span><br><span class="line"></span><br><span class="line">% global_name_server（任务异步分发）</span><br><span class="line">handle_call(&#123;something Args&#125;, State) -&gt;</span><br><span class="line">	State<span class="meta">#state.worker ! &#123;someting, Args, self()&#125;</span></span><br><span class="line"></span><br><span class="line">% Worker进程（实际任务，通过gen_server:reply手动模拟call返回）</span><br><span class="line">loop_the_worker() -&gt;</span><br><span class="line">    receive </span><br><span class="line">        &#123;do_something, Args, From&#125; -&gt;</span><br><span class="line">            gen_server:reply(From, do_something(Args));</span><br><span class="line">	Other -&gt;</span><br><span class="line">            unexpected_message(Other)</span><br><span class="line">    end,</span><br><span class="line">    loop_the_worker().</span><br><span class="line">   </span><br></pre></td></tr></table></figure>
<h4 id="维护全联通网络"><a href="#维护全联通网络" class="headerlink" title="维护全联通网络"></a>维护全联通网络</h4><p>global的最后一个职责就是维护全联通网络，在global模块的源码注释中可以看到其网络信息同步协议：</p>
<pre><code>%% Suppose nodes A and B connect, and C is connected to A.
%% Here&#39;s the algorithm&#39;s flow:
%%
%% Node A
%% ------
%% &lt;&lt; &#123;nodeup, B&#125;
%%   TheLocker ! &#123;nodeup, ..., Node, ...&#125; (there is one locker per node)
%% B ! &#123;init_connect, ..., &#123;..., TheLockerAtA, ...&#125;&#125;
%% &lt;&lt; &#123;init_connect, TheLockerAtB&#125;
%%   [The lockers try to set the lock]
%% &lt;&lt; &#123;lock_is_set, B, ...&#125;
%%   [Now, lock is set in both partitions]
%% B ! &#123;exchange, A, Names, ...&#125;
%% &lt;&lt; &#123;exchange, B, Names, ...&#125;
%%   [solve conflict]
%% B ! &#123;resolved, A, ResolvedA, KnownAtA, ...&#125;
%% &lt;&lt; &#123;resolved, B, ResolvedB, KnownAtB, ...&#125;
%% C ! &#123;new_nodes, ResolvedAandB, [B]&#125;
%%
%% Node C
%% ------
%% &lt;&lt; &#123;new_nodes, ResolvedOps, NewNodes&#125;
%%   [insert Ops]
%% ping(NewNodes)
%% &lt;&lt; &#123;nodeup, B&#125;
%% &lt;ignore this one&gt;
</code></pre><p>在上面的源码注释中，可以看到global模块的全联通维护机制，集群中被连接的节点(Node A)，会将新加入的节点(Node B)介绍给集群中的其它节点(Node C)。同名字注册一样，global_name_server将全联通集群管理放在另一个Worker中执行。</p>
<p>global模块的名字注册只能在全联通网络下进行，这样才能在任意节点进行信息更新。在非全联通集群中(<code>-connect_all false</code>)，全局锁机制仍然是可用的。</p>
<p>注意到整个同步协议中，nodeup和nodedown消息是由net_kernel进程发布的。</p>
<p>global模块更加具体的实现细节没有细究，待后续详细理解。能够在不可靠的网络上实现一套全局锁和全联通管理方案，本身就是非常复杂的，因此还是值得一读。</p>
<h3 id="7-mnesia"><a href="#7-mnesia" class="headerlink" title="7. mnesia"></a>7. mnesia</h3><p>参见：<a href="http://wudaijun.com/2015/04/erlang-mnesia/">http://wudaijun.com/2015/04/erlang-mnesia/</a></p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang 状态监控</title>
    <url>/2016/05/erlang-debug-online/</url>
    <content><![CDATA[<h2 id="一-接入远程节点"><a href="#一-接入远程节点" class="headerlink" title="一. 接入远程节点"></a>一. 接入远程节点</h2><h3 id="1-JCL"><a href="#1-JCL" class="headerlink" title="1. JCL"></a>1. JCL</h3><pre><code>erl -sname n2 -setcookie 123
(n2@T4F-MBP-11)1&gt;        //^G
User switch command
 --&gt; r &#39;n1@T4F-MBP-11&#39;
 --&gt; c
Eshell V8.1  (abort with ^G)
(n1@T4F-MBP-11)1&gt;
</code></pre><h3 id="2-remsh"><a href="#2-remsh" class="headerlink" title="2. remsh"></a>2. remsh</h3><pre><code>erl -setcookie abc -name node_2@127.0.0.1 -remsh node_1@127.0.0.1
</code></pre><p>和第一种JCL方式是同一个原理，这也是rebar2 remote_console的实现方式。</p>
<h3 id="3-erl-call"><a href="#3-erl-call" class="headerlink" title="3. erl_call"></a>3. <a href="http://erlang.org/doc/man/erl_call.html">erl_call</a></h3><pre><code>    erl_call -s -a &#39;erlang memory &#39; -name node_1@127.0.0.1 -c abc
</code></pre><h3 id="4-run-erl"><a href="#4-run-erl" class="headerlink" title="4. run_erl"></a>4. <a href="http://erlang.org/doc/man/run_erl.html">run_erl</a></h3><pre><code>    run_erl -daemon tmp/ log/ &quot;exec erl -eval &#39;t:start_link().&#39;&quot;
</code></pre><p><code>run_erl</code>是随OTP发布的命令，它通过管道来与Erlang节点交互，仅类Unix系统下可用。上面的命令启动Erlang节点，将tmp/目录设为节点管道目录，之后<code>run_erl</code>会在tmp下创建<code>erlang.pipe.1.r erlang.pipe.1.w</code>两个管道文件，外部系统可通过该管道文件向节点写入/读取数据。可用OTP提供的<code>to_erl</code>命令通过管道连接到节点:</p>
<span id="more"></span>
<pre><code>    to_erl tmp/
    Attaching to tmp/erlang.pipe.1 (^D to exit)
    1&gt; 
</code></pre><p>需要注意的当前你是直接通过Unix管道和节点交互的，并不存在中间代理节点(和remsh方式不同)，因此在这种情况下使用JCL <code>^G+q</code>会终止目标节点。如果要退出attach模式而不影响目标节点，使用<code>^D</code>。</p>
<p><code>run_erl</code>另一个作用是输出重定向，上例中将所有输出(包括虚拟机和nif输出)重定向到log/erlang.log.*，这对多日志渠道(lager,io:format,c,lua等)的混合调试是有所帮助的。</p>
<p>rebar2便通过<code>run_erl</code>实现节点启动，并使用<code>to_erl</code>实现<code>attach</code>命令。</p>
<h3 id="5-ssh"><a href="#5-ssh" class="headerlink" title="5. ssh"></a>5. ssh</h3><pre><code>    ---------- Server:  -----------
    $ mkdir /tmp/ssh
    $ ssh-keygen -t rsa -f /tmp/ssh/ssh_host_rsa_key
    $ ssh-keygen -t rsa1 -f /tmp/ssh/ssh_host_key
    $ ssh-keygen -t dsa -f /tmp/ssh/ssh_host_dsa_key
    $ erl
    1&gt; application:ensure_all_started(ssh).
    &#123;ok,[crypto,asn1,public_key,ssh]&#125;
    2&gt; ssh:daemon(8989, [&#123;system_dir, &quot;/tmp/ssh&quot;&#125;,
    2&gt; &#123;user_dir, &quot;/home/ferd/.ssh&quot;&#125;]).
    &#123;ok,&lt;0.52.0&gt;&#125;

    ---------- Client -------------
    $ ssh -p 8989 ferd@127.0.0.1
    Eshell Vx.x.x (abort with ^G)
    1&gt;
</code></pre><h2 id="二-etop"><a href="#二-etop" class="headerlink" title="二. etop"></a>二. etop</h2><p>etop是Erlang提供的类似于top命令，它的输出格式和功能都与top类似，提供了必要的节点信息和进程信息。常用用法：</p>
<pre><code>% 查看占用CPU最高的进程 每10秒输出一次
&gt; spawn(fun() -&gt; etop:start([&#123;interval,10&#125;, &#123;sort, runtime&#125;]) end). 
% 查看占用内存最高的进程 每10秒输出一次 输出进程数量为20
&gt; spawn(fun() -&gt; etop:start([&#123;interval,10&#125;, &#123;sort, memory&#125;, &#123;lines,20&#125;]) end). 
% 连接远程节点方式一
&gt; erl -name abcd@127.0.0.1 -hidden -s etop -output text -sort memory -lines 20 -node &#39;server_node@127.0.0.1&#39; -setcookie galaxy_server
% 连接远程节点方式二
&gt; erl -name abc@127.0.0.1 -hidden  -setcookie galaxy_server
&gt; etop:start([&#123;node,&#39;server_node@127.0.0.1&#39;&#125;, &#123;output, text&#125;, &#123;lines, 20&#125;,  &#123;sort, memory&#125;]).
% 连接远程节点方式三
&gt; erl -name abc@127.0.0.1 -setcookie galaxy_server
&gt;  rpc:call(&#39;server_node@127.0.0.1&#39;, etop, start, [[&#123;output, text&#125;, &#123;lines, 20&#125;,  &#123;sort, memory&#125;]]).
</code></pre><p>输出样例(截断为前5条)：</p>
<pre><code>========================================================================================
 &#39;def@127.0.0.1&#39;                                                           09:38:01
 Load:  cpu         0               Memory:  total       14212    binary         40
        procs      35                        processes    4398    code         4666
        runq        0                        atom          198    ets           304

Pid            Name or Initial Func    Time    Reds  Memory    MsgQ Current Function
----------------------------------------------------------------------------------------
&lt;6858.7.0&gt;     application_controll     &#39;-&#39;    7830  426552       0 gen_server:loop/6
&lt;6858.12.0&gt;    code_server              &#39;-&#39;  125106  284656       0 code_server:loop/1
&lt;6858.33.0&gt;    erlang:apply/2           &#39;-&#39;   10300  230552       0 shell:get_command1/5
&lt;6858.3.0&gt;     erl_prim_loader          &#39;-&#39;  211750  122040       0 erl_prim_loader:loop
&lt;6858.0.0&gt;     init                     &#39;-&#39;    3775   18600       0 init:loop/1
========================================================================================
</code></pre><p>官方文档：<a href="http://erlang.org/doc/apps/observer/etop_ug.html">http://erlang.org/doc/apps/observer/etop_ug.html</a></p>
<h2 id="三-erlang-API"><a href="#三-erlang-API" class="headerlink" title="三. erlang API"></a>三. erlang API</h2><h3 id="1-内存"><a href="#1-内存" class="headerlink" title="1. 内存"></a>1. 内存</h3><p>通过<code>erlang:memory()</code>可以查看整个Erlang虚拟机的内存使用情况。</p>
<h3 id="2-CPU"><a href="#2-CPU" class="headerlink" title="2. CPU"></a>2. CPU</h3><p>Erlang的CPU使用情况是比较难衡量的，由于Erlang虚拟机内部复杂的调度机制，通过<code>top/htop</code>得到的系统进程级的CPU占用率参考性是有限的，即使一个空闲的Erlang虚拟机，调度线程的忙等也会占用一定的CPU。</p>
<p>因此Erlang内部提供了一些更有用的测量参考，通过<code>erlang:statistics(scheduler_wall_time)</code>可以获得调度器钟表时间：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1&gt; erlang:system_flag(scheduler_wall_time, true).</span><br><span class="line">false</span><br><span class="line">2&gt; erlang:statistics(scheduler_wall_time).</span><br><span class="line">[&#123;&#123;1,166040393363,9269301338549&#125;,</span><br><span class="line"> &#123;2,40587963468,9269301007667&#125;,</span><br><span class="line"> &#123;3,725727980,9269301004304&#125;,</span><br><span class="line"> 4,299688,9269301361357&#125;]</span><br></pre></td></tr></table></figure>
<p>该函数返回<code>[&#123;调度器ID, BusyTime, TotalTime&#125;]</code>，BusyTime是调度器执行进程代码，BIF，NIF，GC等的时间，TotalTime是<code>cheduler_wall_time</code>打开统计以来的总调度器钟表时间，通常，直观地看BusyTime和TotalTIme的数值没有什么参考意义，有意义的是BusyTime/TotalTIme，该值越高，说明调度器利用率越高：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1&gt; Ts0 &#x3D; lists:sort(erlang:statistics(scheduler_wall_time)), ok.</span><br><span class="line">ok	</span><br><span class="line">2&gt; Ts1 &#x3D; lists:sort(erlang:statistics(scheduler_wall_time)), ok.</span><br><span class="line">ok	</span><br><span class="line">3&gt; lists:map(fun(&#123;&#123;I, A0, T0&#125;, &#123;I, A1, T1&#125;&#125;) -&gt; </span><br><span class="line">	&#123;I, (A1 - A0)&#x2F;(T1 - T0)&#125; end, lists:zip(Ts0,Ts1)).</span><br><span class="line">[&#123;1,0.01723977154806915&#125;,	</span><br><span class="line"> &#123;2,8.596423007719012e-5&#125;,	</span><br><span class="line"> &#123;3,2.8416950342830393e-6&#125;,	</span><br><span class="line"> &#123;4,1.3440177144802423e-6&#125;</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure>
<h3 id="3-进程"><a href="#3-进程" class="headerlink" title="3. 进程"></a>3. 进程</h3><p>通过<code>length(processes())</code>/<code>length(ports())</code>统计虚拟机当前进程和端口数量。</p>
<p>关于指定进程的详细信息，都可以通过<code>erlang:process_info(Pid, Key)</code>获得，其中比较有用的Key有：</p>
<ul>
<li>dictionary:             进程字典中所有的数据项</li>
<li>registerd_name:     注册的名字</li>
<li>status:                进程状态</li>
<li>links:                 所有链接进程</li>
<li>monitored_by:        所有监控当前进程的进程</li>
<li>monitors:            所有被当前进程监控的进程</li>
<li>trap_exit:            是否捕获exit信号</li>
<li>current_function:    当前进程执行的函数，{M, F, A}</li>
<li>current_location:    进程在模块中的位置，{M, F, A, [{file, FileName}, {line, Num}]}</li>
<li>current_stacktrace:  以current_location的格式列出堆栈跟踪信息</li>
<li>initial_call:            进程初始入口函数，如spawn时的入口函数，{M, F, A}</li>
<li>memory:            进程占用的内存大小(包含所有堆，栈等)，以bytes为单位</li>
<li>message_queue_len: 进程邮箱中的待处理消息个数</li>
<li>messages:            返回进程邮箱中的所有消息，该调用之前务必通过message_queue_len确认消息条数，否则消息过多时，调用非常危险</li>
<li>reductions:            进程<a href="http://www.cnblogs.com/zhengsyao/p/how_erlang_does_scheduling_translation.html">规约</a>数</li>
</ul>
<p>获取端口信息，可调用<code>erlang:port_info/2</code>。</p>
<p>关于OTP进程，Erlang提供了更为丰富的调试模块，如<a href="http://erlang.org/doc/man/sys.html">sys</a>，其中部分常用函数：</p>
<ul>
<li>sys:log_to_file(Pid, FileName)：    将指定进程收到的所有事件信息打印到指定文件</li>
<li>sys:get_state(Pid)：                获取OTP进程的State</li>
<li>sys:statistics(Pid, Flag):            Flag: true/false/get 打开/关闭/获取进程信息统计</li>
<li>sys:install/remove                可为指定进程动态挂载和卸载通用事件处理函数</li>
<li>sys:suspend/resume:            挂起/恢复指定进程</li>
<li>sys:terminate(Pid, Reason):        向指定进程发消息，终止该进程</li>
</ul>
<h2 id="四-recon"><a href="#四-recon" class="headerlink" title="四. recon"></a>四. recon</h2><p><a href="https://github.com/ferd/recon">recon</a>是<a href="http://learnyousomeerlang.com/">learn you some erlang</a>的作者写的一个非常强大好用的库，将erlang散布在各个模块的调试函数整合起来，以更易用和可读的方式提供给用户，包含了信息统计，健康状态分析，动态追踪调试等一整套解决方案。并且本身只是一系列的API，放入rebar deps即可attach上节点使用，强烈推荐。</p>
<p>下面是我常用的几个函数:</p>
<pre><code>% 找出当前节点Attr属性(如message_queue_len)最大的N个进程
recon:proc_count(Attr, N).
% 对节点进行GC，并返回进程GC前后持有的binary差异最大的N个进程
recon:bin_leak(N).
% process_info的安全增强版本
recon:info/1-2-3-4
% 返回M毫秒内的调度器占用
recon:scheduler_usage(M)
% 强大的动态追踪函数，可用于动态挂载钩子。
% 1. 可挂载模块/函数调用(甚至可对参数匹配/过滤)
% 2. 可对调用进程筛选(指定Pid，限制新建进程等)
% 3. 可限制打印的追踪数量/速率
% 4. 其它功能，如输出重定向，追踪调用结果等
recon_trace:calls/2-3
</code></pre><p>详细用法参见：<a href="http://ferd.github.io/recon/">http://ferd.github.io/recon/</a></p>
<h2 id="五-更多资料"><a href="#五-更多资料" class="headerlink" title="五. 更多资料"></a>五. 更多资料</h2><ul>
<li>Erlang实践红宝书：<a href="http://pan.baidu.com/s/1gfCZBKf">Erlang In Anger</a></li>
</ul>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB 分片</title>
    <url>/2016/06/mongodb-sharding/</url>
    <content><![CDATA[<h2 id="一-什么是分片"><a href="#一-什么是分片" class="headerlink" title="一. 什么是分片"></a>一. 什么是分片</h2><p>分片(shards)是使用多个机器存储数据的方法，MongoDB使用分片以支持巨大的数据存储量和对数据的操作。它将一个很大的集合分割成多个片(shard)，每个分片存储于不同的机器或副本集中，每个分片都是一个独立的数据库。</p>
<p>分片为提高系统吞吐量和大数据的存储提供了方法：</p>
<ul>
<li>使用分片减少了每个分片需要处理的请求数</li>
<li>使用分片减少了每个分片存储的数据量</li>
</ul>
<span id="more"></span>
<h2 id="二-分片的基础设施"><a href="#二-分片的基础设施" class="headerlink" title="二. 分片的基础设施"></a>二. 分片的基础设施</h2><h3 id="1-片键（shard-key）"><a href="#1-片键（shard-key）" class="headerlink" title="1. 片键（shard key）"></a>1. 片键（shard key）</h3><p>MongoDB通过片键将一个集合分为多个部分，它决定了一个集合的文档在不同的分片上的分布。它有如下特性：</p>
<ul>
<li>片键字段可以是单个字段或者是复合字段</li>
<li>片键字段必须被索引(或是索引的前缀)</li>
<li>片键字段不能是多键索引</li>
<li>集合中的每个文档都必须包含片键字段</li>
<li>文档的片键值不可被修改，只能删除文档，并重新插入新片键文档</li>
<li>不同文档的片键可以相同</li>
</ul>
<p>MongoDB的片键有两种：</p>
<h4 id="1-1-基于范围的片键"><a href="#1-1-基于范围的片键" class="headerlink" title="1.1 基于范围的片键"></a>1.1 基于范围的片键</h4><p>如有Person集合，其片键age，有两个分片，那么分片1可能负责存储<code>-∞&lt;=age&lt;20</code>的文档，分片2负责存取<code>20&lt;=age&lt;∞</code>的文档，这里的∞代表MongoDB所有值的最大值，而不仅限于数字。这是最简单的基于范围的片键模型，我们需要手动指定某个范围的片键位于某个分片上，MongoDB的分片机制要比这个要灵活强大得多。</p>
<h4 id="1-2-基于哈希的片键："><a href="#1-2-基于哈希的片键：" class="headerlink" title="1.2 基于哈希的片键："></a>1.2 基于哈希的片键：</h4><p>同样，我们可以基于片键哈希值来进行分片之间的分发，集合片键需要有足够大的基数。</p>
<p>在写入的时候，MongoDB(mongos)会将请求分发到负责该片键的分片上，在查询的时候，如果查询涉及了片键，则和写入一样，MongoDB会将请求分发到对应的片键上(针对性查询)，否则，MongoDB必须将请求发送到所有的分片上，以获取结果。</p>
<p>更多参考：<a href="http://docs.mongoing.com/manual-zh/core/sharding-shard-key.html">http://docs.mongoing.com/manual-zh/core/sharding-shard-key.html</a></p>
<h3 id="2-块分裂（chunk-split）"><a href="#2-块分裂（chunk-split）" class="headerlink" title="2. 块分裂（chunk split）"></a>2. 块分裂（chunk split）</h3><p>随着文档的不断写入，各个分片的集合大小会拉开差距，单个分片的集合大小仍然可能是个问题。MongoDB采用单分片多区间的方式来将片键映射到分片，某个区间片键内的文档被称作”块”(chunk)，当某个块超过设置的块大小(sharding-chunk-size，默认为64M，会动态调整)时，MongoDB会负责将这个<a href="http://docs.mongoing.com/manual-zh/core/sharding-chunk-splitting.html">数据块分割</a>为两个，分裂会改变元信息，但效率很高，对集群的性能也没有影响。</p>
<h3 id="3-块迁移-chunk-migration"><a href="#3-块迁移-chunk-migration" class="headerlink" title="3. 块迁移 (chunk migration)"></a>3. 块迁移 (chunk migration)</h3><p>随着块分裂持续下去，会导致不同分片之间的块数量和压力的不均衡，这个时候，MongoDB会开始一次分片间的<a href="http://docs.mongoing.com/manual-zh/core/sharding-chunk-migration.htmlml">数据块迁移</a>，平衡各个分片的块数量，并调整各个分片的片键区间。MongoDB允许管理员控制块阀值大小，并且可以通过<a href="http://docs.mongoing.com/manual-zh/tutorial/administer-shard-tags.html">标记</a>来直接决定集群分布。</p>
<p>块分裂，块迁移示例图：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>分片</th>
<th>片键</th>
<th>块</th>
</tr>
</thead>
<tbody>
<tr>
<td>分片1</td>
<td>age</td>
<td>(-∞, 20)</td>
</tr>
<tr>
<td>分片2</td>
<td>age</td>
<td>[20, ∞)</td>
</tr>
</tbody>
</table>
</div>
<p>分片2的文档持续增长，导致块分裂：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>分片</th>
<th>片键</th>
<th>块</th>
</tr>
</thead>
<tbody>
<tr>
<td>分片1</td>
<td>age</td>
<td>(-∞, 20)</td>
</tr>
<tr>
<td>分片2</td>
<td>age</td>
<td>[20, 30), [30, 50), [50, ∞)</td>
</tr>
</tbody>
</table>
</div>
<p>当各个分片之间的块数量差距过大时，导致块迁移：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>分片</th>
<th>片键</th>
<th>块</th>
</tr>
</thead>
<tbody>
<tr>
<td>分片1</td>
<td>age</td>
<td>(-∞, 20), [20, 30)</td>
</tr>
<tr>
<td>分片2</td>
<td>age</td>
<td>[30, 50), [50, ∞)</td>
</tr>
</tbody>
</table>
</div>
<p>分块过程是由平衡器(balancer)来控制的，整个分裂和迁移过程都是自动的，块的分裂阀值可设置，如果你想要人为控制块分布，只能关闭平衡器，或者重新选择片键。</p>
<h2 id="三-如何选择片键"><a href="#三-如何选择片键" class="headerlink" title="三. 如何选择片键"></a>三. 如何选择片键</h2><h3 id="1-范围片键-vs-哈希片键"><a href="#1-范围片键-vs-哈希片键" class="headerlink" title="1. 范围片键 vs 哈希片键"></a>1. 范围片键 vs 哈希片键</h3><p>基于范围的分片方式提供了更高效的范围查询，给定一个片键的范围，分发路由可以很简单地确定哪个数据块存储了请求需要的数据，并将请求转发到相应的分片中。</p>
<p>不过,基于范围的分片会导致数据在不同分片上的不均衡，有时候，带来的消极作用会大于查询性能的积极作用。比如，如果片键所在的字段是线性增长的，一定时间内的所有请求都会落到某个固定的数据块中，最终导致分布在同一个分片中。在这种情况下，一小部分分片承载了集群大部分的数据，系统并不能很好地进行扩展。</p>
<p>与此相比,基于哈希的分片方式以范围查询性能的损失为代价，保证了集群中数据的均衡。哈希值的随机性使数据随机分布在每个数据块中,因此也随机分布在不同分片中。但是也正由于随机性，一个范围查询很难确定应该请求哪些分片，通常为了返回需要的结果，需要请求所有分片。</p>
<h3 id="2-哈希片键的选择"><a href="#2-哈希片键的选择" class="headerlink" title="2. 哈希片键的选择"></a>2. 哈希片键的选择</h3><p>哈希片键的选择是比较简单的，片键只需要满足基数够大，通常ObjectId，自增ID，时间戳，都是不错的选择。</p>
<h3 id="3-范围片键选择"><a href="#3-范围片键选择" class="headerlink" title="3. 范围片键选择"></a>3. 范围片键选择</h3><p>范围片键的选择是比较复杂的，但目标是一致的：<strong>读写分离</strong>和<strong>数据局部性</strong>，举几个例子：</p>
<h4 id="a-小基数片键："><a href="#a-小基数片键：" class="headerlink" title="a. 小基数片键："></a>a. 小基数片键：</h4><p>小基数片键随着数据增长和块分裂，单个块的片键范围越来越小，最终可能会形成单个块对应单个片键，此时无法再进行块分裂，从而导致单个块过大，吞吐量也会受到影响。</p>
<p>小基数片键满足数据局部性，并且基于片键的查询效率也很高，但MongoDB不能对数据块进行有效地分割，导致读写不能分离。</p>
<p>解决方案：如果是要基于该小基数片键进行大量的查询，可以选择组合片键，确保第二个字段有足够大的基数。</p>
<h4 id="b-升序片键："><a href="#b-升序片键：" class="headerlink" title="b. 升序片键："></a>b. 升序片键：</h4><p>我们可能会选择ObjectId这类自增Key作为片键，这类Key的问题是可能会造成单一且不可分散的性能单点，因为新数据总是写入最新的数据块，没有做到写分离。</p>
<h4 id="c-随机片键"><a href="#c-随机片键" class="headerlink" title="c. 随机片键"></a>c. 随机片键</h4><p>随机片键的原理有点像哈希片键，比如选择MD5这类Key来做片键，这样能够很好地满足读写分离，文档被随机分布在分片中。但和哈希片键不同的是，哈希片键对片键查询仍然是比较高效的，根据片键算出哈希值，找到指定分片即可。对于随机片键来说，通常我们不会基于随机片键进行查询，而非片键查询需要向所有分片发出请求。因此实际上随机片键相对于哈希片键，在灵活性(哈希函数可以自己设置)，查询效率等方面都是有所不如的。</p>
<p>而无论哈希片键还是随机片键，都存在一个问题，数据过于分散，数据局部性不是很高，可能会导致块迁移时，磁盘IO开销很大(冷数据)。</p>
<h4 id="d-好的片键"><a href="#d-好的片键" class="headerlink" title="d. 好的片键"></a>d. 好的片键</h4><p>由于数据通常满足时间局部性，因此首先我们希望数据大致按照时间排序，但同时，我们希望数据能均匀分布，不要造成性能热点，因此添加一个搜索键作为第二片键。比如<code>&#123;&quot;month&quot;:1, &quot;name&quot;:1&#125;</code>，在3月时，当数据量够大时，MongoDB能够根据name键有效合理地分块，随着时间增长，在4月时，3月的数据开始不再被使用，置换出内存，渐渐成为冷数据，并且由于3月的数据不再写入，因此3月的数据也无需被分裂从而进一步造成块迁移，因此不会造成块迁移磁盘IO开销大的问题。</p>
<p>一般情况下，好的片键可以通过该公式推导：<code>&#123;控制局部化:1, 控制读写分离:1&#125;</code>，控制局部化的键可以是粗粒度时间(考虑一下为什么不是细粒度？)，控制读写分离的键通常是查询键。</p>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB 读写要点</title>
    <url>/2016/06/mongodb-read-write/</url>
    <content><![CDATA[<h2 id="一-查询"><a href="#一-查询" class="headerlink" title="一. 查询"></a>一. 查询</h2><h3 id="1-1-“多段式”查询"><a href="#1-1-“多段式”查询" class="headerlink" title="1.1 “多段式”查询"></a>1.1 “多段式”查询</h3><p>当执行find操作的时候，只是返回一个游标，并不立即查询数据库，这样在执行之前可以给查询附加额外选项。几乎所有游标对象的方法都返回游标本身，因此可以按任意顺序组成方法链。以下查询是等价的：</p>
<pre><code>&gt; var cursor = db.foo.find().sort(&#123;&quot;x&quot;:1&#125;).limit(1).skip(10)
&gt; var cursor = db.foo.find().limit(1).sort(&#123;&quot;x&quot;:1&#125;).skip(10)
&gt; var cursor = db.foo.find().skip(10).limit(1).sort(&#123;&quot;x&quot;:1&#125;)
</code></pre><p>此时，我们只是构造了一个查询，并没有执行实际操作，当我们执行：</p>
<pre><code>&gt; cursor.hasNext()
</code></pre><p>这时，查询被发往服务器，sell立即获取第一个块(前101个文档或前1M数据，取其小者)，这样下次调用next或hasNext时，就不必再次向服务器发起一次查询。客户端用完了第一组结果，shell会再次向服务器获取下一组结果(大小不超过4MB)， 直至结果全部返回。可通过<a href="https://docs.mongodb.com/manual/reference/method/cursor.batchSize/#cursor.batchSize">batchSize</a>设置游标返回的块的文档数量。</p>
<p>注：如果在shell中，没有将返回的游标赋给一个var，shell将自动迭代游标20次，显示出前20调记录。</p>
<span id="more"></span>
<h3 id="1-2-快照查询"><a href="#1-2-快照查询" class="headerlink" title="1.2 快照查询"></a>1.2 快照查询</h3><p>由于find()操作是<strong>多段式</strong>的，集合在游标查询的过程中，文档可能由于大小改变而发生了移动，比如某个文档由于增大，超过了原来分配的空间，导致文档被移动到集合的末尾处，此时使用游标查询可能会再次返回这些被移动的文档。解决方案是对查询进行<a href="https://docs.mongodb.com/manual/reference/method/cursor.snapshot/">快照</a>:</p>
<pre><code>&gt; db.foo.find().snapshot()
</code></pre><h3 id="1-3-游标释放"><a href="#1-3-游标释放" class="headerlink" title="1.3 游标释放"></a>1.3 游标释放</h3><p>前面看到的游标都是客户端游标，每个客户端游标对应一个数据库游标，数据库游标会占用服务器资源，因此合理地尽快地释放游标是有必要的。以下几种情况将会释放数据库游标：</p>
<ul>
<li>客户端主动发起关闭游标请求</li>
<li>游标迭代完匹配结果</li>
<li>客户端游标不在作用域(客户端游标被析构/GC)，会向服务器发送消息销毁对应数据库游标</li>
<li>游标10分钟未被使用，数据库游标会自动销毁，可通过<a href="https://docs.mongodb.com/manual/reference/method/cursor.noCursorTimeout/#cursor.noCursorTimeout">noCursorTimeout</a>(注意和<a href="https://docs.mongodb.com/manual/reference/method/cursor.maxTimeMS/">maxTimeMS</a>的区别)取消游标超时</li>
</ul>
<h3 id="1-4-cursor-explain"><a href="#1-4-cursor-explain" class="headerlink" title="1.4 cursor.explain()"></a>1.4 cursor.explain()</h3><p>游标的另一个很有用的函数是explain()，它能够提供<code>db.collection.find()</code>操作的详尽分析，包括</p>
<ul>
<li>查询方案的决策：使用和何种方案(如使用哪个索引)，查询方向</li>
<li>执行结果分析：扫描了多少文档，多少个索引条目，花费时间等</li>
<li>服务器信息：地址，端口，版本等</li>
<li>分片信息：如果集合使用了分片，还会列出访问了哪个分片，即对应的分片信息</li>
</ul>
<p>这些信息对于开发期间的查询性能分析和索引的对比性测试是非常有帮助的，关于它的详细解释，参见<a href="https://docs.mongodb.com/manual/reference/method/cursor.explain/#cursor.explain">cursor.explain()</a>官方文档。</p>
<h3 id="1-5-读取策略"><a href="#1-5-读取策略" class="headerlink" title="1.5 读取策略"></a>1.5 读取策略</h3><p>在目前最新的MongoDB 3.2版本中，新加了读取策略(<a href="https://docs.mongodb.com/manual/reference/read-concern/">ReadConcern</a>)，支持local和majority两种策略，前者直接读取当前的MongoDB实例，但是可能会读到副本集中不一致的数据，甚至可能回滚。majority策略读取那些已经被副本集大多数成员所认可的数据，因此数据不可能被回滚。目前majority只被<a href="https://docs.mongodb.com/manual/core/WiredTiger/">WiredTiger</a>存储引擎所支持。</p>
<h3 id="1-6-其它查询技巧"><a href="#1-6-其它查询技巧" class="headerlink" title="1.6 其它查询技巧"></a>1.6 其它查询技巧</h3><ol>
<li>不要使用skip()来实现分页，这样每次都会查询所有文档，可利用每页最后一个文档中的key作为查询条件来获取下一页。</li>
<li>获取随机文档，不要先将所有的文档都找出来，然后再随机。而是为所有的文档加一个随机Key，每次查询{“$gte”:randomkey}或{“$lt”:randomkey}即可</li>
<li>MongoDB对内嵌文档的支持非常完善，可通过{“key1.key2”: value2}直接查询内嵌文档，也可以在内嵌文档Key上建立索引</li>
</ol>
<h2 id="二-写入"><a href="#二-写入" class="headerlink" title="二. 写入"></a>二. 写入</h2><h3 id="2-1-写入策略"><a href="#2-1-写入策略" class="headerlink" title="2.1 写入策略"></a>2.1 写入策略</h3><p>MongoDB支持灵活的写入策略(<a href="https://docs.mongodb.com/manual/reference/write-concern/">WriteConcern</a>):</p>
<p>用法：<code>db.collection.insert(&#123;x:1&#125;, &#123;writeConcern:&#123;w:1,j:false&#125;&#125;)</code></p>
<ol>
<li>w: 数据写入到number个节点才向客户端确认<ul>
<li>{w: 0}: 对客户端的写入不需要发送任何确认，适用于性能要求较高，但不关注正确性的场景</li>
<li>{w: 1}: 默认的写入策略，数据写入到Primary就向客户端发送确认</li>
<li>{w: “majority”}: 数据写入到副本集大多数成员后向客户端发送确认，适用于对数据安全性要求高的场景，但会降低写入性能</li>
</ul>
</li>
<li>j: 写入操作的journal持久化后才向客户端确认(需要w选项所指定的节点均已写入journal)，默认为false。</li>
<li>wtimeout: 写入超时时间，仅当w选项的值大于1才有效，当写入过程出现节点故障，无法满足w选项的条件时，超过wtimeout时间，则认定写入失败。</li>
</ol>
<p>关于写入策略的具体实现，参见：<a href="http://www.mongoing.com/archives/2916">http://www.mongoing.com/archives/2916</a></p>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p>MongoDB CURD概念： <a href="https://docs.mongodb.com/manual/core/crud/">https://docs.mongodb.com/manual/core/crud/</a></p>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB 存储引擎</title>
    <url>/2016/06/mongodb-storage-engine/</url>
    <content><![CDATA[<p>MongoDB目前支持三种存储引擎：MMAPv1 Storage Engine，In-Memory Storage Engine, WiredTiger Storage Engine。</p>
<h2 id="MMAPv1-Storage-Engine"><a href="#MMAPv1-Storage-Engine" class="headerlink" title="MMAPv1 Storage Engine"></a>MMAPv1 Storage Engine</h2><p>MongoDB3.2之前版本的默认引擎。</p>
<h3 id="1-存储原理"><a href="#1-存储原理" class="headerlink" title="1. 存储原理"></a>1. 存储原理</h3><p>文档在磁盘中连续存放，文档所占用的磁盘空间包括文档数据所占空间和文档填充(padding)。</p>
<p><img src="/assets/image/201606/MMAPv1_storage_engine.png" alt=""></p>
<p>摘自：MongoDB MMAPv1内部实现：<a href="http://www.mongoing.com/archives/1484">http://www.mongoing.com/archives/1484</a></p>
<span id="more"></span>
<h4 id="1-1-文档移动"><a href="#1-1-文档移动" class="headerlink" title="1.1 文档移动"></a>1.1 文档移动</h4><p>由于文档在磁盘中连续存放，当文档大小增长时，可能需要重新分配文档空间，并更新索引。这会使写入效率降低，因此通常MongoDB为文档分配的record空间会包括document数据和padding空间。这样减少了文档移动的可能性，提高了写入效率。</p>
<h4 id="1-2-padding算法"><a href="#1-2-padding算法" class="headerlink" title="1.2 padding算法"></a>1.2 padding算法</h4><p> 在MongoDB3.0之前，MMAPv1使用填充因子(<a href="http://openmymind.net/Whats-A-Padding-Factor/">padding factor</a>)来决定空间分配，填充因子会根据文档移动的频繁度动态调整(初始时为1.0)，当padding factor = 1.5时，MMAPv1将为文档分配<code>sizeof(record) = 1.5 * sizeof(document)</code>的空间，其中<code>0.5*sizeof(document)</code>用作padding。</p>
<p>padding factor这种方式看起来很智能，但是由于文档的record大小不一，在文档删除或移动之后，文档原来分配的空间很难被再次利用，从而造成了磁盘碎片，这也是MongoDB3.0之前数据占用磁盘空间大的主要原因之一。</p>
<p>因此在MongoDB3.0之后，不再使用padding factor填充机制，而使用<a href="https://docs.mongodb.com/manual/core/mmapv1/#power-of-2-sized-allocations">Power of 2 Sized Allocations</a>，为每个文档分配2的N次方的空间(超过2MB则变为2MB的倍数增长)，这样做既可以减少文档的移动，文档被删除或移动后的空间也可以被有序地组织起来，达成复用(只能被其所在collection的文档复用)。除了Power of 2 Sized Allocations外，MongoDB3.0还提供了<a href="https://docs.mongodb.com/manual/reference/command/collMod/#noPadding">no padding</a>分配策略，即只分配文档实际大小的磁盘空间，但应用程序需要确保文档大小不会增长。</p>
<p>虽然Power of 2 Sized Allocations解决了磁盘碎片的问题，但改进后的MMAPv1引擎仍然在数据库级别分配文件，数据库中的所有集合和索引都混合存储在数据库文件中，并且删除或移动文档后的空间会被保留用以复用，因此磁盘空间无法无法即时自动回收的问题仍然存在(即使drop collection)。</p>
<h3 id="2-并发能力"><a href="#2-并发能力" class="headerlink" title="2.并发能力"></a>2.并发能力</h3><p>在MongoDB3.0之前，只有MMAPv1存储引擎支持，并且只支持Database级的锁，有时候不得不刻意将数据分到多个数据库中提升并发能力。在MongoDB3.0之后，MMAPv1终于支持collection级的并发，并发效率提升了一个档次。参考<a href="https://docs.mongodb.com/manual/faq/concurrency/">MongoDB concurrency FAQ</a>。</p>
<h3 id="3-故障恢复"><a href="#3-故障恢复" class="headerlink" title="3. 故障恢复"></a>3. 故障恢复</h3><p>MongoDB默认记录所有的变更操作日志(<a href="https://docs.mongodb.com/manual/core/journaling/#journaling-and-the-mmapv1-storage-engine">journal</a>)并写入磁盘，MongoDB flush变更日志的频率(默认100ms)比flush数据的频率(默认60s)要高，因此journal是MongoDB故障恢复的重要保障。</p>
<h3 id="4-内存占用"><a href="#4-内存占用" class="headerlink" title="4. 内存占用"></a>4. 内存占用</h3><p>由于MMAPv1使用<a href="http://www.cnblogs.com/huxiao-tee/p/4660352.html">mmap</a>来将数据库文件映射到内存中，MongoDB总是尽可能的多吃内存，以映射更多的数据文件。并且页面的换入换出基本交给OS控制(MongoDB不建议<a href="https://docs.mongodb.com/manual/core/mmapv1/#journal">修改</a>flush频率)，因此，将MongoDB部署在更高RAM环境下，是提升性能的最有效的方式之一。</p>
<h3 id="5-遗留问题"><a href="#5-遗留问题" class="headerlink" title="5. 遗留问题"></a>5. 遗留问题</h3><ul>
<li>磁盘占用，运维人员可能需要定期的整理数据库(<a href="https://docs.mongodb.com/manual/reference/command/compact/">compat</a>，<a href="https://docs.mongodb.com/manual/reference/command/repairDatabase/">repairDatabase</a>)</li>
<li>内存占用，基本是有多少吃多少</li>
<li>collection级的并发控制仍然偏弱</li>
</ul>
<h2 id="WiredTiger-Storage-Engine"><a href="#WiredTiger-Storage-Engine" class="headerlink" title="WiredTiger Storage Engine"></a>WiredTiger Storage Engine</h2><p>MongoDB version3.0中引入，在MongoDB3.2中，已将WiredTiger作为默认存储引擎。</p>
<h3 id="1-并发能力"><a href="#1-并发能力" class="headerlink" title="1. 并发能力"></a>1. 并发能力</h3><p>文档级别的并发支持，WiredTiger通过MVCC实现文档级别的并发控制，即文档级别锁。这就允许多个客户端请求同时更新一个集合内存的多个文档。更多MongoDB并发模型，参见<a href="https://docs.mongodb.com/manual/faq/concurrency/">MongoDB concurrency FAQ</a>。</p>
<h3 id="2-故障恢复"><a href="#2-故障恢复" class="headerlink" title="2. 故障恢复"></a>2. 故障恢复</h3><p>支持checkpoint和journal两种方式进行持久化。</p>
<p>checkpoint是数据库某一时刻的快照，每60s或超过2GB的变更日志执行一次，在写最新快照时，上一个快照仍然有效，防止MongoDB在快照落地时挂掉，在快照落地完成后，上一个快照将被删除。</p>
<p>和MMAPv1一样，支持通过变更日志故障恢复，journal可与checkpoint集合使用，提供快速，可靠的数据恢复。可禁用wiredtiger journal，这在一定程度上可以降低系统开支，对于单点MongoDB来说，可能会导致异常关闭时丢失checkpoint之间的数据，对于复制集来说，可靠性稍高一点。在MongoDB3.2之前的版本中，WiredTiger journal默认在日志超过100MB时持久化journal一次，系统宕机最多会丢失100MB journal数据。在3.2版本中，加入了默认50ms时间间隔刷盘条件。参见官方文档<a href="https://docs.mongodb.com/manual/core/journaling/#journaling-wiredtiger">journaling wiredtiger</a>。</p>
<h3 id="3-磁盘占用"><a href="#3-磁盘占用" class="headerlink" title="3. 磁盘占用"></a>3. 磁盘占用</h3><p>不同于MMAPv1在数据库级别分配数据文件，WiredTiger将每个collection的数据和索引单独存放，并且会即时回收文档和集合占用空间。</p>
<p>WiredTiger的另一个两点是支持日志，文档数据块，索引压缩，可配置或关闭压缩算法，大幅度节省了磁盘空间。</p>
<h3 id="4-内存占用-1"><a href="#4-内存占用-1" class="headerlink" title="4. 内存占用"></a>4. 内存占用</h3><p>WiredTiger支持内存使用容量配置，用户可通过<a href="https://docs.mongodb.com/manual/reference/configuration-options/#storage.wiredTiger.engineConfig.cacheSizeGB">WiredTiger CacheSize</a>配置MongoDB WiredTiger所能使用的最大内存，在3.2版本中，该参数默认值为<code>max(60%Ram-1GB, 1GB)</code>。这个内存限制的并不是MongoDB所占用的内存，MongoDB还使用OS文件系统缓存(文件可能是被压缩过的)。</p>
<h3 id="5-遗留问题-1"><a href="#5-遗留问题-1" class="headerlink" title="5. 遗留问题"></a>5. 遗留问题</h3><p>相较于MMAPv1，压缩算法和新的存储机制，极大减少了磁盘空间占用，文档级别的并发控制，在多核上吞吐量有明显提升。MongoDB WiredTiger仍然是个吃内存的家伙，虽然可以配置内存最高占用，但更多的内存确实能带来更好的读写效率。</p>
<h2 id="In-Memory-Storage-Engine"><a href="#In-Memory-Storage-Engine" class="headerlink" title="In-Memory Storage Engine"></a>In-Memory Storage Engine</h2><p>纯内存版的MongoDB，限企业版，64bits。简单介绍一下：</p>
<ul>
<li>不维护任何磁盘数据，包括配置数据，索引，用户证书，等等，Everything In Memory</li>
<li>文档级别的并发支持</li>
<li>在启动时配置最大使用内存，默认1GB，超出使用内存将会报错</li>
<li>不可落地，不可恢复</li>
<li>支持分片，复制集</li>
</ul>
<p>总结：为啥不用Redis？</p>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><ol>
<li>MongoDB Storage Engine: <a href="https://docs.mongodb.com/manual/core/storage-engines/">https://docs.mongodb.com/manual/core/storage-engines/</a></li>
<li>MongoDB Storage FAQ: <a href="https://docs.mongodb.com/manual/faq/storage/">https://docs.mongodb.com/manual/faq/storage/</a></li>
<li>MongoDB MMAPv1内部实现：    <a href="http://www.mongoing.com/archives/1484">http://www.mongoing.com/archives/1484</a></li>
<li>MongoDB WiredTiger内部实现：<a href="http://www.mongoing.com/archives/2540">http://www.mongoing.com/archives/2540</a></li>
<li>MongoDB存储特性与内部原理： <a href="http://shift-alt-ctrl.iteye.com/blog/2255580">http://shift-alt-ctrl.iteye.com/blog/2255580</a></li>
<li>MongoDB3.0官方性能测试报告：<a href="http://www.mongoing.com/archives/862">http://www.mongoing.com/archives/862</a></li>
</ol>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title>虚拟存储器</title>
    <url>/2016/06/virtual-memory/</url>
    <content><![CDATA[<p>前几天又翻了翻《深入理解计算机系统》，相比几年前刚看这本书有了更多的理解，这也许就是一本好书的价值吧。因此尝试提炼和总结出对自己有用的东西，把书读薄。其中也加了一些自己的理解和查阅的相关资料。</p>
<h2 id="虚拟存储器的意义"><a href="#虚拟存储器的意义" class="headerlink" title="虚拟存储器的意义"></a>虚拟存储器的意义</h2><p>虚拟存储器提供了三个重要的能力：</p>
<ul>
<li>将主存看作是存储在磁盘上的高速缓存，并根据需要在磁盘和主存中传送数据，高效地运用主存</li>
<li>为每个进程提供一致性的地址空间，简化了存储器管理</li>
<li>保护每个进程的地址空间不被其它进程破坏</li>
</ul>
<p>下面分别从这三个方面来谈虚拟存储器</p>
<span id="more"></span>
<h3 id="1-内存是磁盘的Cache"><a href="#1-内存是磁盘的Cache" class="headerlink" title="1. 内存是磁盘的Cache"></a>1. 内存是磁盘的Cache</h3><p>虚拟存储器和物理存储器一样，都分页管理，并且页大小是一致的。在任意时刻，虚拟页面(VP)的集合都分为三个不相交的子集：</p>
<ul>
<li>未分配：VM系统还未分配或创建的页，没有任何数据和它们相关联，因此不占用任何磁盘空间</li>
<li>已缓存：当前缓存在物理存储器中的已分配页</li>
<li>未缓存：没有缓存在物理存储器中的已分配页</li>
</ul>
<p>同任何缓存一样，虚拟存储系统必须有某种方法来判定一个虚拟页是否被缓存在主存中，如果是，系统还必须确认这个虚拟页放在哪个物理页中，如果不命中，系统需要判断这个虚拟页存放在磁盘的哪个位置，并且该磁盘对应数据加载到主存中，并且在必要时，选择一个牺牲页(页面调度)。VM通过页表(page table)来维护虚拟页的状态和当前实际地址(主存地址/磁盘地址)：</p>
<p><img src="/assets/image/201606/page-table.png" alt=""></p>
<p>每个进程都有一份页表，页表本身是进程数据的一部分，操作系统负责维护页表的内容，并在磁盘和主存之间来回传送页。CPU通过虚拟地址访问主存时，MMU会先查看页表中该虚拟地址的页表条目：</p>
<ul>
<li>已缓存：如果页表条目标志位为已缓存，MMU则取出对应的物理页面地址，返回给CPU</li>
<li>未缓存：如果页表条目标志位为未缓存，则DRAM缓存不命中，又称为缺页(page fault)，此时会触发一个缺页异常，缺页异常会调用缺页异常处理程序，该程序选择一个牺牲页VP2(如果VP2已经被修改了，则将其写回磁盘)，更新VP2的页表条目为未缓存，之后内核从磁盘拷贝目标页VP1到物理页，更新VP1的页表条目，最后返回。此时，页面置换已经完成，当异常处理程序返回时，会重新发起导致缺页的指令，而此时VP1对应的页表条目状态为已缓存，即按照页命中流程正常处理</li>
<li>未分配：导致非法地址访问，段错误(segment fault)</li>
</ul>
<p>巨大的不命中开销(磁盘读写效率比主存低10000倍)驱动着整个DRAM缓存设计的方方面面，由于磁盘读第一个字节的效率是读连续字节的效率的100000倍，因此页不能太小，通常是在4KB~2MB之间，并且DRAM Cache是全相连的，也就是说任何虚拟页都可以放置在任何的物理页中，而对于不命中的替换算法也更为精密，最后，由于对磁盘的访问时间很长，DRAM缓存总是使用写回，而不是直写。DRAM通常都工作得很好，这是因为程序的局部性(时间局部性和空间局部性)原理，但是如果程序的常驻集(工作集)超过了DRAM的大小，则会导致页面不断被换入换出，也就是页面颠簸。</p>
<p>另外，前面我们讨论的页面调度，都是在不命中发生时，才换入页面，这种策略称为按需页面调度(demand paging)，也可以采用其它方法，比如尝试预测不命中，在页面实际被引用之前就换入页面。目前，所有现代系统使用的都是按需页面调度的方式。</p>
<p><img src="/assets/image/201606/address-translation.png" alt=""></p>
<h3 id="2-虚拟存储器提供的存储器管理"><a href="#2-虚拟存储器提供的存储器管理" class="headerlink" title="2. 虚拟存储器提供的存储器管理"></a>2. 虚拟存储器提供的存储器管理</h3><p>由于每个进程都有独立的页表，因此也提供了一个独立的虚拟地址空间，多个虚拟页面可以映射到同一个共享物理物理上。独立虚拟地址空间和按需调度的结合，对系统中存储器的使用和管理有深远的影响。VM机制简化了链接，加载，代码和数据共享，以及应用程序的存储器分配。</p>
<ul>
<li><p>简化链接：独立的地址空间，允许每个进程的存储器映像使用相同的基本格式，而不管代码和数据实际存放在物理存储器的何处。如Linux系统上每个进程都使用类似的存储器格式(.text,.data)， 这样的一致性极大地简化了链接器的设计与实现，允许链接器生成全链接的可执行文件，这些可执行文件独立于物理存储器中的代码和数据的最终位置。</p>
</li>
<li><p>简化加载：虚拟存储器还可以很容易地实现可执行文件和共享对象文件的加载，要把可执行文件加载到内存中，系统先分配虚拟页的一个连续的块(chunk)，将页表条目指向目标文件中的适当位置，并且标记为未缓存的，即可将可执行文件中的指定节加载到虚拟内存中。需要注意的是，此时文件并未被真正加载到物理内存中，而是要等每个页初次被引用时，才会真正执行页面调入(按需调度)。另外，虽然分配的虚拟内存是连续的，但是具体缓存的物理页面，可以是离散的。</p>
</li>
<li><p>简化存储器分配：虚拟存储器为用户提供一个简单的分配额外存储器的机制，当程序要求额外的堆空间时(如调用malloc)，操作系统分配k个连续的存储器页面，并且将它们映射到物理存储器中的任意位置的k个物理页面。由于页表的存在，存储系统没有必要分配k个连续的物理页，页面可以随机分散在物理存储器中</p>
</li>
</ul>
<h3 id="3-虚拟存储器提供的存储器保护"><a href="#3-虚拟存储器提供的存储器保护" class="headerlink" title="3. 虚拟存储器提供的存储器保护"></a>3. 虚拟存储器提供的存储器保护</h3><p>由于每个进程都有自己的独立虚拟地址空间，因此分离不同进程的私有存储器变得很容易。但进程私有存储器和共享存储器仍然需要访问控制(只读，可写等)，这只需要在页表标志位上加上可读，可写等许可位来控制即可。如果一些指令违反了许可条件，CPU会触发异常，Unix Shell将这种异常报告为”段错误”(segmentation fault)。</p>
<h2 id="虚拟存储器的应用"><a href="#虚拟存储器的应用" class="headerlink" title="虚拟存储器的应用"></a>虚拟存储器的应用</h2><h3 id="1-Linux虚拟存储器系统"><a href="#1-Linux虚拟存储器系统" class="headerlink" title="1. Linux虚拟存储器系统"></a>1. Linux虚拟存储器系统</h3><p><img src="/assets/image/201606/linux-process-vm.png" alt=""></p>
<p>如上，是Linux进程的虚拟存储器，Linux进程虚拟存储器有如下特性：</p>
<h4 id="1-1-分段管理"><a href="#1-1-分段管理" class="headerlink" title="1.1 分段管理"></a>1.1 分段管理</h4><p>Linux将虚拟存储器组织成一些区域(段)的集合，一个区域就是已经分配虚拟存储器的连续片，这些页是以某种方式相关联的。如代码段，数据段，堆，栈，共享库等。该进程每个存在的虚拟页都保存在某个段中，不属于某个段的虚拟页是不存在的，并且不能被进程引用。段的概念很重要，因为它允许虚拟地址空间有间隙，内核不用记录哪些不存在的虚拟页，这样的页也不会占用存储器，磁盘，内核等任何额外资源。(页表中应该还是存在所有虚拟页的条目的)。</p>
<p><img src="/assets/image/201606/linux-process-vm2.png" alt=""></p>
<p>如图，每个task_struct对应一个进程，其中pgd字段为第一级页表(页全局目录)基址，mmap字段则指向进行的虚拟内存结构信息，Linux为每个段分配一个<code>vm_area_struct</code>结构，这个结构是个链表，在对虚拟地址执行地址翻译时，Linux会先遍历vm_area_struct链表，判断VA是否合法，即是否在某个段中。之后根据vm_area_struct中的信息判断进程是否对VA有访问权限。由于遍历vm_area_struct可能带来的开销，Linux还使用AVL树来加速查询。</p>
<h4 id="1-2-数据共享与访问控制"><a href="#1-2-数据共享与访问控制" class="headerlink" title="1.2 数据共享与访问控制"></a>1.2 数据共享与访问控制</h4><p>通过VM提供强大抽象能力，Linux进程可以实现多进程虚拟内存布局的灵活控制，从访问权限来看，进程虚拟存储器包括内核虚拟存储器和进程存储器，从共享/私有来看，所有进程共享内核代码与全局数据结构，并且有自己独立的页表，堆栈段，task_struct结构等。</p>
<p>这里有一些参考：<a href="http://www.cnblogs.com/fuzhe1989/p/3936894.html">Linux进程内存布局</a>，<a href="http://www.ahlinux.com/start/kernel/6876.html">Linux地址翻译</a></p>
<h3 id="2-存储器映射"><a href="#2-存储器映射" class="headerlink" title="2. 存储器映射"></a>2. 存储器映射</h3><p>除了本身的段管理之外，Linux还允许用户手动建立段到磁盘对象之间的映射。虚拟存储器段可以映射到两种类型的文件对象：</p>
<ul>
<li>普通文件：一个段可以映射到普通磁盘文件的连续部分，文件区被分为页大小的片，每一片即为对应虚拟页面的初始内容(剩余部分用0填充)。由于按需页面调度，所有在进行存储器映射时，虚拟页面并没有实际交换如物理存储器，直到CPU第一次引用页面。</li>
<li>匿名文件：匿名文件是由内核创建的，包含的全是二进制0，虚拟存储器段被映射到匿名文件时，当CPU第一次引用到虚拟页，该虚拟页面将被0覆盖。磁盘和存储器之间并没有实际的数据传送。因此，映射到匿名文件的段，也叫做请求二进制0的页。</li>
</ul>
<p>无论在那种情况下，一旦虚拟页面被初始化了，就在一个由内核维护的<a href="http://vod.sjtu.edu.cn/help/Article_Print.asp?ArticleID=1191">交换文件(交换空间)</a>中换来换去，在任何时刻，交换空间都限制这当前运行着的进程能够分配的虚拟页面总数。</p>
<p>一个对象可以以共享对象或私有对象的方式被映射到存储器段，前者对段的写操作其它进程可见，并且会写回到磁盘的原始对象中。后者的改动是私有的，只有自己可见，并且不会被写回。对于私有对象，Linux使用一种叫写时拷贝的机制来高效地执行映射，在执行私有映射时，物理内存在只有一份私有对象拷贝(但却被映射到不同虚拟地址空间中的段)，只有当有进程尝试写私有区域的某个页面时，才会创建拷贝。fork()函数内部就是写时拷贝原理。</p>
<p>内核通过唯一的文件名来判断文件是否已经被加载，从而复用已映射的物理页面，使映射到多个共享区域的对象，在内存中，只需要存放一份拷贝。存储器映射有很多实际应用，如进程快速加载文件，进程间共享文件，动态链接库，execve()等。在Linux下，用户可通过mmap()来手动建立一个映射，这里有一篇不错的[mmap()的用法详解][]。</p>
<h3 id="3-存储器分配"><a href="#3-存储器分配" class="headerlink" title="3. 存储器分配"></a>3. 存储器分配</h3><p>应用程序可通过malloc申请一块连续的虚拟内存，在Linux下，虚拟内存的布局规定了malloc申请位置以及大小，当malloc申请小于<code>MMAP_THRESHOLD</code>(目前为128KB)的内存时，分配的是在堆区，用sbrk()进行对齐生长，而malloc一次性申请大内存(大于128K)时，分配在映射区(位于堆栈之间)，而不是在堆区，glibc会返回一块匿名的mmap内存块。虽然malloc得到的虚拟内存对应用程序来说是连续的，而实际上可以是离散的物理页面，这一点大家都应该很清楚了。</p>
]]></content>
      <categories>
        <category>os</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB 状态监控</title>
    <url>/2016/07/monitor-mongodb/</url>
    <content><![CDATA[<h2 id="一-关键指标"><a href="#一-关键指标" class="headerlink" title="一. 关键指标"></a>一. 关键指标</h2><ul>
<li>慢查询：当MongoDB处理能力不足时，找出系统中的慢查询，分析原因，看能否通过建立索引或重新设计schema改进</li>
<li>内存使用：MongoDB吃内存(特别是MMAPv1)，至少要给MongoDB足够的内存存放索引，最理想的情况是能够存放所有数据。当内存占用过高，或者page faults过高时，考虑能不能给MongoDB预留更多的内存。</li>
<li>磁盘占用：特别是对于MMAPv1，涉及到磁盘占用的因素有很多，不合理的schema(文档频繁移动)或集合/文档的删除都可能会导致磁盘空间利用不足。前期需要设计好schema，后期维护也需要定期整理磁盘数据。</li>
<li>连接数：MongoDB为每个连接分配一个线程，因此连接是占资源的，并且也不是越多连接越好。合理地控制连接数。</li>
<li>索引不命中：查看所有查询的索引不命中情况，尽量让所有查询都通过索引</li>
<li>锁等待：锁等待的原因有很多，连接数过多，操作频繁，慢操作，schema设计过于反范式化等，可从上面的原因针对性解决。</li>
</ul>
<span id="more"></span>
<h2 id="二-监控工具"><a href="#二-监控工具" class="headerlink" title="二. 监控工具"></a>二. 监控工具</h2><h3 id="1-mongostat"><a href="#1-mongostat" class="headerlink" title="1. mongostat"></a>1. mongostat</h3><p>mongodb自带的状态检测工具，按照固定时间间隔(默认1s)获取mongodb的当前运行状态，适用于对临时异常状态的监控：</p>
<pre><code>// from MongoDB 3.0 MMAPv1
▶ mongostat
insert query update delete getmore command flushes mapped vsize    res faults qr|qw ar|aw netIn netOut conn     time
    *0    40      1     *0       0     1|0       0   4.3G 11.1G 150.0M      0   0|0   0|0    2k    12k  201 19:07:04
    *0    20     *0     *0       0     1|0       0   4.3G 11.1G 150.0M      0   0|0   0|0    1k    11k  201 19:07:05
    *0    *0      1     *0       0     1|0       0   4.3G 11.1G 150.0M      0   0|0   0|0  244b    10k  201 19:07:06
    *0    20     *0     *0       0     1|0       0   4.3G 11.1G 150.0M      0   0|0   0|0    1k    11k  201 19:07:07
    *0    20     *0     *0       0     2|0       0   4.3G 11.1G 150.0M      0   0|0   0|0    1k    11k  201 19:07:08
</code></pre><p>具体各列的意义都很简单，见官方文档即可。比较重要的字段有：</p>
<ul>
<li>res:      常驻内存大小</li>
<li>mapped:   通过mmap映射数据所占用虚拟内存大小(只对MMAPv1有效)</li>
<li>vsize:    mongodb进程占用的虚拟内存大小</li>
<li>faults:   page fault次数，如果持续过高，则可以考虑加内存</li>
<li>qr/qw:    读取/写入等待队列的大小，如果队列很大，表示MongoDB处理能力跟不上，可以看看是否存在慢操作，或者减缓请求</li>
<li>conn:     当前连接数，conn也会占用MongoDB资源，合理控制连接数</li>
<li>idx miss: 索引不命中所占百分比 如果太高则要考虑索引是否设计得不合理</li>
<li>flushes:  通常为0或1，对于MMAPv1，表示后台刷盘次数(默认60s)，对于WiredTiger，表示执行checkpoint次数(默认60s或2GB journal日志)</li>
<li>lr/lw:    读取/写入操作等待锁的比例 (New In MongoDB 3.2, Only for MMapv1)</li>
<li>lrt/lwt:  读取/写入锁的平均获取时间(微妙)</li>
</ul>
<p>更多<a href="https://docs.mongodb.com/manual/reference/program/mongostat/">参考</a>。</p>
<h3 id="2-db-serverStatus"><a href="#2-db-serverStatus" class="headerlink" title="2. db.serverStatus()"></a>2. db.serverStatus()</h3><p>返回数据库服务器信息，该命令返回的数据量很大，但执行很快，不会对数据库性能造成影响，其中比较重要的字段有：</p>
<ul>
<li>db.serverStatus().mem: 当前数据库内存使用情况</li>
<li>db.serverStatus().connections: 当前数据库服务器的连接情况</li>
<li>db.serverStatus().extra_info: 在Linux下，包含page fault次数</li>
<li>db.serverStatus().locks: 数据库各种类型锁竞态情况</li>
<li>db.serverStatus().backgroundFlushing: 数据库后台刷盘情况(默认60s)一次，仅针对MMAPv1存储引擎</li>
</ul>
<p>更多<a href="https://docs.mongodb.com/manual/reference/command/serverStatus/">参考</a>。</p>
<h3 id="3-Profiler"><a href="#3-Profiler" class="headerlink" title="3. Profiler"></a>3. Profiler</h3><p>主要用于分析查询性能，默认是关闭的，Profiler获取关于查询/写入/命令等操作的详细执行数据，并将这些分析数据写入system.profile集合。Profiler有三个Level：</p>
<ul>
<li>Level 0: 意味着关闭Profiler，并不收集任何数据，也是mongod的默认配置。注意mongod总是会将”慢操作”(执行时间超过<a href="https://docs.mongodb.com/manual/reference/configuration-options/#operationProfiling.slowOpThresholdMs">slowOpThresholdMs</a>，默认100ms)的操作写入mongod日志(不是system.profile集合)</li>
<li>Level 1: 只收集所有慢操作的信息，慢操作执行时间可通过<a href="https://docs.mongodb.com/manual/tutorial/manage-the-database-profiler/#database-profiling-specify-slowms-threshold">修改slowOpThresholdMs参数</a>指定</li>
<li>Level 2: 收集所有的数据库操作执行信息</li>
</ul>
<p>需要注意，一个操作执行慢，可能是索引不合理，也可能是page fault从磁盘读数据等原因导致。需要进一步分析。</p>
<p>使用示例：</p>
<pre><code>&gt; db.setProfilingLevel(2)
&#123; &quot;was&quot; : 0, &quot;slowms&quot; : 100, &quot;ok&quot; : 1 &#125;
&gt;
&gt; db.getProfilingStatus()
&#123; &quot;was&quot; : 2, &quot;slowms&quot; : 100 &#125;
&gt; db.user.insert(&#123;&quot;name&quot;:&quot;wdj&quot;&#125;)
WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)
&gt; db.system.profile.find()
&#123; &quot;op&quot; : &quot;insert&quot;, &quot;ns&quot; : &quot;test.user&quot;, &quot;query&quot; : &#123; &quot;insert&quot; : &quot;user&quot;, &quot;documents&quot; : [ &#123; &quot;_id&quot; : ObjectId(&quot;577e62991fa7b960bb8bf0af&quot;), &quot;name&quot; : &quot;wdj&quot; &#125; ], &quot;ordered&quot; : true &#125;, &quot;ninserted&quot; : 1, &quot;keyUpdates&quot; : 0, &quot;writeConflicts&quot; : 0, &quot;numYield&quot; : 0, &quot;locks&quot; : &#123; &quot;Global&quot; : &#123; &quot;acquireCount&quot; : &#123; &quot;r&quot; : NumberLong(2), &quot;w&quot; : NumberLong(2) &#125; &#125;, &quot;Database&quot; : &#123; &quot;acquireCount&quot; : &#123; &quot;w&quot; : NumberLong(1), &quot;W&quot; : NumberLong(1) &#125; &#125;, &quot;Collection&quot; : &#123; &quot;acquireCount&quot; : &#123; &quot;w&quot; : NumberLong(1), &quot;W&quot; : NumberLong(1) &#125; &#125; &#125;, &quot;responseLength&quot; : 25, &quot;protocol&quot; : &quot;op_command&quot;, &quot;millis&quot; : 32, &quot;execStats&quot; : &#123;  &#125;, &quot;ts&quot; : ISODate(&quot;2016-07-07T14:09:29.690Z&quot;), &quot;client&quot; : &quot;127.0.0.1&quot;, &quot;allUsers&quot; : [ ], &quot;user&quot; : &quot;&quot; &#125;
&gt;
</code></pre><p>system.profile集合中，关键字段：op(操作类型), ns(操作集合), ts(操作时间)，millis(执行时间ms),query(操作详情)。</p>
<p>更多<a href="https://docs.mongodb.com/manual/tutorial/manage-the-database-profiler/">参考</a>。</p>
<h3 id="4-db-currentOp"><a href="#4-db-currentOp" class="headerlink" title="4. db.currentOp()"></a>4. db.currentOp()</h3><p>当MongoDB比较繁忙或者在执行比较慢的命令时，可能会阻塞之后的操作(视数据库和操作的并发级别而定)。可通过db.currentOp()来获取当前正在进行的操作，并可通过db.killOp()来干掉它。</p>
<p>更多<a href="https://docs.mongodb.com/manual/reference/method/db.currentOp/">参考</a>。</p>
<h3 id="5-db-stats"><a href="#5-db-stats" class="headerlink" title="5. db.stats()"></a>5. db.stats()</h3><p>返回对应数据库的信息，包括集合数量，文档总大小，文档平均大小，索引数量，索引大小等静态信息：</p>
<pre><code>&gt; db.stats()
&#123;
        &quot;db&quot; : &quot;test&quot;,
        &quot;collections&quot; : 2,
        &quot;objects&quot; : 3,
        &quot;avgObjSize&quot; : 430,
        &quot;dataSize&quot; : 1290,
        &quot;storageSize&quot; : 49152,
        &quot;numExtents&quot; : 0,
        &quot;indexes&quot; : 1,
        &quot;indexSize&quot; : 16384,
        &quot;ok&quot; : 1
&#125;
&gt;
</code></pre><p>更多<a href="https://docs.mongodb.com/manual/reference/command/dbStats/">参考</a>。</p>
<h3 id="6-db-collStats"><a href="#6-db-collStats" class="headerlink" title="6. db.collStats()"></a>6. db.collStats()</h3><p>返回集合详细信息.</p>
<p>更多<a href="https://docs.mongodb.com/manual/reference/command/collStats/#dbcmd.collStats">参考</a>。</p>
<h3 id="7-db-enableFreeMonitoring"><a href="#7-db-enableFreeMonitoring" class="headerlink" title="7. db.enableFreeMonitoring"></a>7. db.enableFreeMonitoring</h3><p>Mongo官方提供的免费监视服务，可以脱离altas云服务独立使用，<code>db.enableFreeMonitoring()</code>会返回一个URL地址，上面有包含MongoDB内存，CPU，读写，网络，磁盘等全方位的可视化监控。</p>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title>web 初学笔记</title>
    <url>/2016/08/web-get-started/</url>
    <content><![CDATA[<p>一些简单的web学习笔记，用于在需要时快速搭建一个可用的网站。</p>
<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><ul>
<li>HTML: 通过一套标记标签，定义网页的内容</li>
<li>CSS:  通过选择器和层叠次序，定义网页的布局</li>
<li>JavaScript: 通过可编程的文档对象模型(DOM)和事件响应，定义网页的行为</li>
</ul>
<span id="more"></span>
<h3 id="后端框架"><a href="#后端框架" class="headerlink" title="后端框架"></a>后端框架</h3><p>由于Python的原因，选用了<a href="http://webpy.org/docs/0.3/tutorial">web.py</a>这个非常轻量的框架，之前也看过Rails，用起来觉得很”神奇”，但约定和黑魔法太多，不合个人口味。</p>
<p>web.py是一个web framework，它也提供了http server的功能，但在线上环境，通常需要结合更高效专业的http server(如nginx)。这里有几种结合方案:</p>
<ol>
<li>用nginx做反向代理，将请求路由到后端web.py</li>
<li>将web.py作为CGI/FastCGI程序，挂接到nginx/lighttpd/apache</li>
</ol>
<p>第二种方式需要安装python flup库，它实现了CGI/FastCGI规范，并实现了这些规范的WSGI(定义flup这类服务与web.py这类framework的调用规范)接口。</p>
<h4 id="CGI"><a href="#CGI" class="headerlink" title="CGI"></a>CGI</h4><p>通用网关接口(Common Gateway Interface)，是外部应用程序（CGI程序）与Web服务器之间的接口标准。CGI规范允许Web服务器执行外部程序，并将它们的输出发送给Web浏览器，CGI将Web的一组简单的静态超媒体文档变成一个完整的新的交互式媒体。</p>
<p>我们知道http server提供的内容通常分为静态内容和动态内容，前者通常集成于web server中。而动态内容，需要web server(如nginx)将请求传递给处理程序(如web.py)并获取返回结果。那么web server传递哪些请求内容，如何传递，处理程序如何返回生成的响应内容等细节，就需要一个通信规范，并且这个规范最好抽象于双方的具体实现，这就是CGI存在的意义，CGI程序可以用任何脚本或编程语言实现，只要这种语言具有标准输入输出和环境变量。</p>
<p>CGI规定每次有请求，都会启动一个CGI程序进程(对Shell script来说，就是sh或bash命令，对python等脚本语言来说，通常是对应解释器)，并且通过标准输入输出以及环境变量与CGI程序交互。CGI的缺点是反复进程启动/初始化/关闭比较消耗资源并且效率低下，难以扩展。目前CGI已经逐渐退出历史舞台。</p>
<h4 id="web内置模块"><a href="#web内置模块" class="headerlink" title="web内置模块"></a>web内置模块</h4><p>针对CGI每次初始化进程(脚本解释器)的开销问题，一些web server(如apache)以插件的方式集成了CGI脚本的解释器(如mod_php,mod_perl等)，将这些解释器以模块的方式常驻，web服务器在启动时会启动这些模块，当新的动态请求到达，web服务器可利用解释器模块解析CGI脚本，避免进程fork。这种优化方式主要针对于脚本语言编写的CGI程序。</p>
<h4 id="FastCGI"><a href="#FastCGI" class="headerlink" title="FastCGI"></a>FastCGI</h4><p>FastCGI在CGI进程常驻的前提下，通过进程池，进程管理器进一步提高了CGI的可伸缩性和容错性。web server将动态请求发给FastCGI进程管理器，后者会将请求分发给进程池中的某一个worker进程。</p>
<p>web server和FastCGI管理进程的通信方式有socks(相同主机)和tcp(不同主机)两种，这提高了FastCGI本身的可扩展性。目前FastCGI进程管理器除了web server自带的fastcgi模块之外，还有<code>spawn-fcgi</code>(分离于lighttpd)，<code>php-fpm</code>(仅用于PHP)等可替换的独立模块。</p>
<p>参考：</p>
<ol>
<li><a href="http://hao.jser.com/archive/8184/">什么是CGI、FASTCGI、PHP-CGI、PHP-FPM、SPAWN-FCGI?</a></li>
<li><a href="https://www.douban.com/note/13508388/">WSGI、flup、fastcgi、web.py的关系</a> </li>
<li><a href="http://blog.csdn.net/five3/article/details/7732832">nginx[+spawn-fcgi]+flup+webpy服务搭建</a></li>
<li><a href="http://webpy.org/install.zh-cn">http://webpy.org/install.zh-cn</a></li>
<li><a href="http://webpy.org/cookbook/index.zh-cn">http://webpy.org/cookbook/index.zh-cn</a></li>
</ol>
<h3 id="模板引擎"><a href="#模板引擎" class="headerlink" title="模板引擎"></a>模板引擎</h3><p>模板引擎用于将用户界面和业务数据分离，使用模板语言，来根据业务数据动态生成HTML网页，简化HTML的书写。简单了解了一下Python的模板引擎，<a href="http://docs.jinkan.org/docs/jinja2/">Jinja2</a>似乎是个不错的选择，速度块，语法易懂，文档全面。控制结构，模板继承都很好用。</p>
<h3 id="CSS框架"><a href="#CSS框架" class="headerlink" title="CSS框架"></a>CSS框架</h3><p>前端框架定义一系列可复用，可扩展的CSS样式，常用组件，和JS插件等。让用户在排版样式上少操点心，直接拿来用就行了。目前觉得<a href="http://www.runoob.com/bootstrap/bootstrap-tutorial.html">Bootstrap</a>还不错，社区庞大，稳定，有多套可视化的布局系统。</p>
<h3 id="JS框架"><a href="#JS框架" class="headerlink" title="JS框架"></a>JS框架</h3><p><a href="http://www.runoob.com/jquery/jquery-tutorial.html">JQuery</a>应该是目前最火的前端JS框架了，基于CSS选择器扩展的JQuery选择器，简化了JavaScript的书写，实现脚本与内容分离。</p>
<h3 id="其它类库"><a href="#其它类库" class="headerlink" title="其它类库"></a>其它类库</h3><p>除此之外，可能还需要用到一些第三方的类库，如Python的MongoDB库<a href="https://github.com/mongodb/mongo-python-driver">pymongo</a>，Json的解析和渲染库<a href="https://github.com/warfares/pretty-json">pretty-json</a>等。在开发过程中要善于搜索，提高开发效率。</p>
<h3 id="综合使用"><a href="#综合使用" class="headerlink" title="综合使用"></a>综合使用</h3><p>写了一个简单Demo, 很Low, 没用JS, 只是用来熟悉基本流程:</p>
<p><a href="https://github.com/wudaijun/pyweb">https://github.com/wudaijun/pyweb</a></p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 作业管理</title>
    <url>/2016/08/linux-job-control/</url>
    <content><![CDATA[<h3 id="进程组-会话"><a href="#进程组-会话" class="headerlink" title="进程组/会话"></a>进程组/会话</h3><p>简要概念：</p>
<ul>
<li>进程组：N(N&gt;=1)个进程的集合，通常在同一作业中关联起来(通过管道)。进程组的ID(PGID)即为进程组组长的PID。进程必定且只能属于一个进程组，只有进程组中一个进程存在，进程组就存在，与组长进程终止与否无关。进程组的概念提出主要是为了进程管理与信号分发</li>
<li>会话：N(N&gt;=1)个进程组的集合，创建会话的进程叫会话首进程。会话ID即为会话首进程PID</li>
<li>控制终端：如果会话有控制终端，建立与控制终端连接的会话首进程叫控制进程(通常就是Shell进程)，当前与终端交互的进程组为前台进程组，其余进程组成为后台进程组</li>
<li>无论合适输入终端的退出键，都会将退出信号发送到前台进程组的所有进程</li>
<li>如果控制终端断开连接，则将挂掉信号(SIGHUP)发送至控制进程(会话首进程)，SIGHUP信号默认将导致控制进程终止</li>
</ul>
<span id="more"></span>
<p>例如，打开Bash，输入：<br>          proc1 | proc2 &amp;<br>          proc3 | proc4 | proc5</p>
<p>进程关系如下图所示：</p>
<p><img src="/assets/image/201608/linux-session-process.png" alt="" title="进程组，会话和控制终端"></p>
<h3 id="作业控制信号"><a href="#作业控制信号" class="headerlink" title="作业控制信号"></a>作业控制信号</h3><ul>
<li>SIGCHLD: 子进程终止</li>
<li>SIGTTIN: 后台进程组成员读控制终端</li>
<li>SIGTTOU: 后台进程组写控制终端</li>
<li>SIGCONT:  如果进程已停止，则使其继续运行(fg &amp; bg)</li>
<li>SIGSTOP: 进程停止信号，不能被捕获或忽略</li>
<li>SIGTSTP: 交互式停止信号(Ctrl+Z)</li>
<li>SIGINT: 中断信号(Ctrl+C)</li>
<li>SIGQUIT: 退出信号(Ctrl+)</li>
</ul>
<p>SIGCHILD信号在子进程终止或停止时向父进程发送，系统默认将忽略该信号，如果父进程希望知晓子进程状态变更，应捕获该信号。</p>
<p>对于SIGTTIN和SIGTTOU信号，在后台作业尝试读取控制终端时，终端驱动程序知道它是个后台作业，于是将向改进程发送SIGTTIN信号，该信号默认将导致进程被挂起(停止)：</p>
<pre><code>▶ /usr/local/opt/coreutils/libexec/gnubin/cat &gt; file &amp;                                                                                                                   
[1] 44978
[1]  + 44978 suspended (tty input)  /usr/local/opt/coreutils/libexec/gnubin/cat &gt; file
▶ fg                                                                                                                                                                     
[1]  + 44978 continued  /usr/local/opt/coreutils/libexec/gnubin/cat &gt; file
Hello World! // 重新获得终端 读取输入
[Ctrl+D] // 键入EOF
</code></pre><p>当后台作业尝试写终端时，默认情况下，后台作业的输出将成功输出到控制终端，但我们可以通过stty命令禁止后台作业向控制终端写，此时终端驱动程序向进程发送SIGTTOU信号：</p>
<pre><code>▶ /usr/local/opt/coreutils/libexec/gnubin/cat file &amp;
[1] 46166
Hello World!
[1]  + 46166 done       /usr/local/opt/coreutils/libexec/gnubin/cat file
▶ stty tostop  // 禁止后台作业向控制终端写
▶ /usr/local/opt/coreutils/libexec/gnubin/cat file &amp; 
[1] 46290
[1]  + 46290 suspended (tty output)  /usr/local/opt/coreutils/libexec/gnubin/cat file
▶ fg
[1]  + 46290 continued  /usr/local/opt/coreutils/libexec/gnubin/cat file
Hello World!
</code></pre><p>注意，在MacOS X上，自带的cat程序有BUG，不是interrupt-safe的，在MacOS X上，尝试恢复cat程序的执行将得到<code>cat: stdin: Interrupted system call</code>错误，<a href="http://factor-language.blogspot.com/2010/09/two-things-every-unix-developer-should.html">这篇文章</a>和APUE 9.8节均提到了这个问题，因此我使用的是brew安装的GNU版本cat命令，安装方案参见<a href="https://www.topbug.net/blog/2013/04/14/install-and-use-gnu-command-line-tools-in-mac-os-x/">这里</a>。</p>
<p>关于SIGTSTP和SIGSTOP的区别，前者通常由键盘产生，可被捕获，当通过Ctrl+Z将前台作业放入后台时，前台作业收到该信号，意思是”从哪儿来到哪儿去”。而SIGSTOP通常由kill产生，不可被捕获或忽略，意思是”在那里待着别动”。两者均可由SIGCONT信号恢复运行。</p>
<p>对于键盘输入产生的信号，控制进程将信号发送至前台进程组的所有进程。</p>
<p>作业控制信号间有某些交互，当对一个进程产生四种停止信号(SIGTSTP,SIGSTOP,SIGTTIN,SIGTTOU)中的一种时，对该进程的任意未决SIGCONT信号将被丢弃，同样，当产生SIGCONT信号时，对同一进程的任意停止信号将被丢弃。</p>
<h3 id="作业管理"><a href="#作业管理" class="headerlink" title="作业管理"></a>作业管理</h3><ul>
<li>&amp; 将作业放入后台执行，如果没有进行重定向，数据流仍然会输出到前台</li>
<li>Ctrl+C 强制中断前台当前作业执行</li>
<li>Ctrl+Z 将作业挂到后台</li>
<li>jobs -l 查看所有作业，作业ID和其PID</li>
<li>fg %作业ID 将后台作业拿到前台来处理</li>
<li>bg %作业ID 将后台作业由挂起变为执行</li>
<li>kill -signal %作业ID 向指定作业的所有进程发送信号</li>
</ul>
<p>作业管理的后台不是系统后台，因此，上述的任务管理依旧与终端有关，当远程连接的终端断开连接时，SIGHUP信号默认将导致改会话上所有的任务都会被中断。</p>
<h3 id="脱机管理"><a href="#脱机管理" class="headerlink" title="脱机管理"></a>脱机管理</h3><ul>
<li>nohup: nohup CMD &amp; 将任务放在后台执行，并忽略SIGHUP挂掉信号，但是在人机交互上比较麻烦</li>
<li>screen: 一个可以在多个进程之间多路复用一个物理终端的窗口管理器，在远端服务器上运行screen，开启一个新会话并执行任务，在终端断开后，任务继续执行，下次登录再attach上screen会话即可，Linux发行版自带</li>
<li>tmux: 功能类似于screen，但在分屏切换，配置方面更强大，完全可作为本地终端使用</li>
</ul>
]]></content>
      <categories>
        <category>os</category>
      </categories>
      <tags>
        <tag>os</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>一些GS设计理念</title>
    <url>/2016/08/gs-design-concept/</url>
    <content><![CDATA[<p>关于GS设计的一些体会，纯属个人理解。</p>
<h2 id="一-系统结构"><a href="#一-系统结构" class="headerlink" title="一. 系统结构"></a>一. 系统结构</h2><p>解耦是在做系统设计时，最应该铭记于心的原则，解耦的目的是让<strong>系统组件可以独立变化</strong>，构建易于理解，测试，维护的系统。</p>
<p>解耦的手段通常有如下几种：</p>
<h3 id="1-依赖倒置"><a href="#1-依赖倒置" class="headerlink" title="1. 依赖倒置"></a>1. 依赖倒置</h3><p>依赖倒置的原则：上层模块不应该依赖于下层模块，它们共同依赖于一个抽象。抽象不能依赖于具象，具象依赖于抽象。</p>
<p><a href="https://zh.wikipedia.org/wiki/%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC%E5%8E%9F%E5%88%99">依赖倒置</a>原则的目的是把高层次组件从对低层次组件的依赖中解耦出来，这样使得重用不同层级的组件实现变得可能。如模块A依赖于模块B，那么在A和B之间加一层接口(interface)，A调用(依赖)该接口，B实现(依赖)该接口，这样，只要接口稳定，A，B即可独立变化。</p>
<p>这种依赖抽象的思想，在GOF的设计模式中，有大量宝贵实践，如策略模式，模板方法模式等。</p>
<span id="more"></span>
<h3 id="2-控制反转"><a href="#2-控制反转" class="headerlink" title="2. 控制反转"></a>2. 控制反转</h3><p>依赖倒置描述的是组件之间的依赖关系被倒置，而控制反转更强调的是控制流程，体现了控制流程的依赖倒置。典型的实现方式：</p>
<h4 id="依赖注入"><a href="#依赖注入" class="headerlink" title="依赖注入"></a>依赖注入</h4><p>反转依赖对象的获取，由框架注入组件所依赖的对象(被动接收对象)。</p>
<h4 id="依赖查找"><a href="#依赖查找" class="headerlink" title="依赖查找"></a>依赖查找</h4><p>反转依赖对象的获取，由组件通过框架提供的方法获取所需依赖对象(主动查找对象)。微服务系统中的服务发现(比如我们的<a href="http://wudaijun.com/2015/08/erlang-server-design1-cluster-server/">cluster_server</a>)，就是一种依赖查找机制。</p>
<h4 id="事件发布-订阅"><a href="#事件发布-订阅" class="headerlink" title="事件发布/订阅"></a>事件发布/订阅</h4><p>反转对事件的处理，发布方不再关心有哪些接收方依赖了某个事件，由接收方主动订阅事件并注册处理函数。在GS设计中，经常会用到，如任务系统，通知中心等。</p>
<p>向依赖和耦合宣战，就是和混乱和失控划清界限，解耦也有助于更好地复用代码，在我看来，重复和耦合一样危险。在发现已有系统不能很好地兼容变化时，就应该理清组件依赖，将变化封装起来。这里有一篇关于<a href="http://dotnetfresh.cnblogs.com/archive/2005/06/27/181878.html">依赖导致和控制反转</a>不错的文章，在GOF设计模式中有更全面精辟的实践经验。</p>
<h2 id="二-系统拆分"><a href="#二-系统拆分" class="headerlink" title="二. 系统拆分"></a>二. 系统拆分</h2><p>在系统结构中，更多地去梳理系统内部的结构和对象行为的关系，而系统拆分则尝试从架构设计的角度将系统拆分为多个小系统(服务)，这些服务独立运行(Routine/Actor/进程等)，服务之间遵循某种通信规范(Message/RPC/TCP/Channel等)。不同粒度的服务的优劣各不相同，一方面我们希望服务彼此独立并且无状态，另一方面我们也希望有服务间的通信足够高效(通过缓存，消息，或远程调用)。需要注意的是，这里所说的服务，并不只是微服务，像Erlang中的Actor，Go中的goroutine，都可以叫服务。以下只讨论最基本的服务设计。</p>
<h3 id="1-服务的数据管理"><a href="#1-服务的数据管理" class="headerlink" title="1. 服务的数据管理"></a>1. 服务的数据管理</h3><p>以Erlang为例，GS中存在多种实体(Actor)，玩家，公会，地图等，实体之间的交互产生了一些关联数据，我们需要明确这类数据的归属权和数据的同步方式，制定清晰的数据边界。数据只能由其所属Actor进行更新和同步，并且是数据的唯一正确参照。关于数据同步，此前我们一直严格遵循”通过通讯来共享”，在带来很好的隔离性的同时，也带来更高的复杂度，大量的Actor数据同步通信，非必要的实时性同步，多份数据副本等等。之后开始使用Ets做Cache，数据冗余和逻辑复杂度都小了很多。使用Cache时，需要严格遵守单写入者，即数据的Cache只能由数据所属Actor进行更新。</p>
<h3 id="2-服务发现"><a href="#2-服务发现" class="headerlink" title="2. 服务发现"></a>2. 服务发现</h3><p>前面也提到，服务发现实则是对服务之间的依赖关系的倒置，服务发现是系统具备良好扩展性和容灾性的基础。目前已经有一些成熟的服务发现和配置共享工具，如etcd，zookeeper等。</p>
<h3 id="3-无状态服务"><a href="#3-无状态服务" class="headerlink" title="3. 无状态服务"></a>3. 无状态服务</h3><p>服务应该尽量被设计为无状态的，这样对容错和透明扩展都有巨大好处，在<a href="http://wudaijun.com/2015/09/erlang-server-design2-erlang-lua-battle/">这篇博客</a>中我曾提到到无状态服务的实践。</p>
<h2 id="三-过度设计"><a href="#三-过度设计" class="headerlink" title="三. 过度设计"></a>三. 过度设计</h2><p>在设计系统时，有时候我们会为了设计而设计，过度抽象和封装，这种过度设计会导致：</p>
<ul>
<li>浪费不必要的开发时间和精力在很简单的逻辑上</li>
<li>产生很多不必要的约定和限制，随着项目需求的变更和增长，会成为系统的负担，很可能也并不能满足新需求</li>
</ul>
<p>如何辨别过度设计，我的理解是，首先这个系统是否需要重构，如果系统足够简单，或者足够稳定，那就let it alone。将精力花在核心系统上，并且在必要的时候(已有架构不能满足当前需求(不是YY的需求)或者已经带来大量的复杂度)再进行重构，特别是对于游戏服务器来说，需求迭代很快，提供可靠的服务才是宗旨，不要陷入设计的漩涡。</p>
<h2 id="四-防御式编程"><a href="#四-防御式编程" class="headerlink" title="四. 防御式编程"></a>四. 防御式编程</h2><p>防御是为了隔离错误，而不是为了容忍错误。在实际运用中，API职责不单一，过度防御，都可能将错误隐藏或扩散出去，对系统调试带来麻烦。应该遵循职责单一，语义明确的API设计理念，对Erlang OTP这种高容错的系统，提倡让错误尽早暴露而不是容忍，对于一些严重错误，甚至应该Crash。错误的尽早暴露有利于Debug，找到问题的源头。</p>
<h2 id="五-注重测试"><a href="#五-注重测试" class="headerlink" title="五. 注重测试"></a>五. 注重测试</h2><p>测试分为黑盒和白盒，对后端来说，黑盒相当于模拟客户端，发出请求，并确保得到正确响应。白盒为服务器内部的函数测试，模块测试，数据检查等。</p>
<p>就实现上来说，游戏服务器主要的测试的方式有：</p>
<h3 id="1-测试用例"><a href="#1-测试用例" class="headerlink" title="1. 测试用例"></a>1. 测试用例</h3><p>以逻辑功能为测试单元，模拟客户端请求流程，尽可能多地覆盖正常分支和异常分支。优点是覆盖完善，使用简单，可以检查并暴露出绝大部分问题。缺点是维护麻烦，对上下文环境(配置，流程，协议等)进行了过多地依赖，适用于需求稳定，流程简单的功能模块。</p>
<h3 id="2-测试状态机"><a href="#2-测试状态机" class="headerlink" title="2. 测试状态机"></a>2. 测试状态机</h3><p>状态机是一个独立的Actor，也叫做Robot，通常基于有限状态机，对所有事件(外部命令，服务器消息，内部事件)作出响应。在Erlang中可以用gen_fsm来实现，一般被设计为可扩展的事件处理中心，Robot的优点有很多，灵活，强大，可以对服务器进行压测，针对性测试，以及长期测试。将一些常用的测试模式做成一个Mode集成到状态机中，如大地图测试，登录流程测试等，再结合bash脚本和后台定时任务，一个服务器测试框架的雏形就有了。对于一些来不及写测试用例的功能模块，通过Robot也可以进行快速测试，这也是我们目前主要使用的测试手段。在这方面可以进一步探索的还有很多，比如将测试用例集成到测试状态机中，外部只定义期望的消息交互流程(如发送req1, 期望收到ack1, ack2,发送req2, 期望收到…)，再导入到状态机中进行执行，并判断整个流程是否符合预期。</p>
<h3 id="3-内部测试"><a href="#3-内部测试" class="headerlink" title="3. 内部测试"></a>3. 内部测试</h3><p>前两者更像是黑盒测试，而内部测试更像白盒，针对API，模块进行测试，除此之外，内部测试还包括一些服务器自身的数据逻辑检查，这类检查关注服务器本身的数据和服务的正确性，尽早地暴露问题，及时进行数据修复和调试。比如我们的大地图就有一些数据一致性检查，比如实体状态，实体交互，资源刷新等等，这类检查在开发期间可以直接作为routine让进程定时跑，配合机器人测试，能查出大量问题。</p>
<p>测试的重要性怎么强调也不为过，对服务器开发来说，测试的优点有：</p>
<ul>
<li>节省大量和客户端以及QA的调试和交互时间</li>
<li>确保重构/改动的正确性</li>
<li>进一步理解交互流程</li>
<li>预先暴露问题，并获得更加详尽的错误信息</li>
<li>多种测试并行，加速测试流程</li>
</ul>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
      </tags>
  </entry>
  <entry>
    <title>Go 笔记(2) 顺序编程</title>
    <url>/2016/09/go-notes-2-procedural-programming/</url>
    <content><![CDATA[<h2 id="不定参数-amp-多返回值"><a href="#不定参数-amp-多返回值" class="headerlink" title="不定参数&amp;多返回值"></a>不定参数&amp;多返回值</h2><p>不定参数只能是最后一个参数，它实际上是数组切片参数的语法糖：</p>
<pre><code>// 语法糖 相当于 func myfunc(args []interface&#123;&#125;)
func myfunc(args ...interface&#123;&#125;)&#123;
    for _, arg := range args &#123;
    fmt.Println(arg)
&#125;

// 参数会被打包为 []&#123;arg1,arg2,arg3&#125;
myfunc(arg1,arg2,arg3)
// 要完成可变参数的完美传递 需要用...将Slice打散
func myfunc2(args ...interface&#123;&#125;)
    // 此时args已经是Slice 如果不打散将作为一个参数 不能完美传递
    myfunc(args)
    // 编译器在此处有优化 最终会直接将args传入 不会打散再打包 参考: http://www.jianshu.com/p/94710d8ab691
    myfunc(args...) 
end
</code></pre><p>多返回值为函数提供了更大的便利性，无需传引用或者专门构造返回值结构体，并且在错误处理方面也更简便，在前面的示例代码中已经初尝甜头。</p>
<span id="more"></span>
<pre><code>// 定义多返回值函数时，可以为返回值指定名字
func (file *File) Read(b []byte) (n int, err Error)&#123;
    // n和err在函数开始时，被自动初始化为空
    ...
    ... n = xxx
    ...
    ... err = xxx
    ...
    // 直接执行return时，将返回n和err变量的值
    return
&#125;
</code></pre><p>多返回值的在Plan9 C编译器上的实现是由调用者在其栈上分配n和err的内存，由被调用方修改调用方栈上的n和err的值：</p>
<p><img src="/assets/image/201609/go-func-call.png" alt=""></p>
<h2 id="匿名函数-amp-闭包"><a href="#匿名函数-amp-闭包" class="headerlink" title="匿名函数&amp;闭包"></a>匿名函数&amp;闭包</h2><p>匿名函数允许函数像变量一样被定义，传递，和使用。Go语言支持随时在代码里定义匿名函数。</p>
<pre><code>// 赋给变量
F = func (a, b int) int &#123;
    return a + b
&#125;
F(1,2)
// 直接执行
func (a, b int) int &#123;
    return a + b
&#125;(1,2)
</code></pre><h3 id="1-闭包的概念"><a href="#1-闭包的概念" class="headerlink" title="1. 闭包的概念"></a>1. 闭包的概念</h3><p>闭包是可以包含自由(未绑定到特定对象)变量的代码块，这些变量不在这个代码块内或者任何全局上下文中定义，而是在定义代码块的环境中定义。要执行的代码块(由于自由变量包含在代码块中，所以这些自由变量以及它们所引用的对象没有被释放)为自由变量提供绑定的计算环境(作用域)。</p>
<h3 id="2-闭包的价值"><a href="#2-闭包的价值" class="headerlink" title="2. 闭包的价值"></a>2. 闭包的价值</h3><p>闭包的价值在于可以作为函数对象或者匿名函数，对于类型系统而言，这意味着不仅要表示数据还要表示代码。支持闭包的多数语言都将函数作为第一类对象，就是说这些函数可以存储到变量中作为参数传递给其它函数，最重要的是能够被函数动态创建和返回。</p>
<h3 id="3-Go语言中的闭包"><a href="#3-Go语言中的闭包" class="headerlink" title="3. Go语言中的闭包"></a>3. Go语言中的闭包</h3><p>Go语言中的闭包同样也会引用到函数外的变量，闭包的实现确保只要闭包还被使用，那么闭包引用的变量会一直存在。 </p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> j <span class="keyword">int</span> = <span class="number">5</span></span><br><span class="line">    return_closure := <span class="function"><span class="keyword">func</span><span class="params">()</span><span class="params">(<span class="keyword">func</span>()</span>)</span> &#123;</span><br><span class="line">        <span class="keyword">var</span> i <span class="keyword">int</span> = <span class="number">10</span></span><br><span class="line">        <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">            i = i + <span class="number">1</span></span><br><span class="line">            j = j + <span class="number">1</span></span><br><span class="line">            fmt.Printf(<span class="string">&quot;i, j: %d, %d\n&quot;</span>, i, j)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	</span><br><span class="line">    <span class="comment">// 同一个闭包c1 共享所有外部环境 i, j</span></span><br><span class="line">    c1 := return_closure()</span><br><span class="line">    c1()</span><br><span class="line">    c1()</span><br><span class="line">	</span><br><span class="line">    j = j + <span class="number">1</span></span><br><span class="line">    <span class="comment">// c1 c2 只共享return_closure作用域之外的变量 j</span></span><br><span class="line">    <span class="comment">// return_closure之内定义的变量i将在每次调用时重新生成，因此只对同一个closure有效</span></span><br><span class="line">    c2 := return_closure()</span><br><span class="line">    c2()</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="comment">// 输出：</span></span><br><span class="line">i, j: <span class="number">11</span>, <span class="number">6</span></span><br><span class="line">i, j: <span class="number">12</span>, <span class="number">7</span></span><br><span class="line">i, j: <span class="number">11</span>, <span class="number">9</span></span><br></pre></td></tr></table></figure>
<p>为了实现闭包:</p>
<ul>
<li>Go必须有能力识别闭包函数的引用变量(这里的j)，并将它们分配在堆上而不是栈上(escape analyze技术)</li>
<li>用一个闭包结构体保存函数和其引用环境</li>
</ul>
<p>下面分别阐述这两点：</p>
<h4 id="escape-analyze"><a href="#escape-analyze" class="headerlink" title="escape analyze"></a>escape analyze</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> test</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">F</span><span class="params">()</span> *<span class="title">int</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> i <span class="keyword">int</span></span><br><span class="line">	i = <span class="number">5</span></span><br><span class="line">	<span class="keyword">return</span> &amp;i</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在C语言中，在函数中返回该函数栈上的地址是不被允许的，因为当函数调用完成后函数栈会被回收。Go当然也有函数栈和栈回收的概念，因此它将i分配在堆上而不是栈上，通过<code>go tool compile -S x.go</code>查看汇编代码:</p>
<pre><code>...
0x001d 00029 (tmp.go:3) LEAQ    type.int(SB), AX
0x0024 00036 (tmp.go:3) MOVQ    AX, (SP)
0x0028 00040 (tmp.go:3) PCDATA  $0, $0
0x0028 00040 (tmp.go:3) CALL    runtime.newobject(SB) // 相当于new(int)
0x002d 00045 (tmp.go:3) MOVQ    8(SP), AX // 将i的地址放入AX
0x0032 00050 (tmp.go:4) MOVQ    $5, (AX) // 将AX存放的内存地址值设为5
...
</code></pre><p>也可通过<code>-gcflags=-m</code>选项编译来查看:</p>
<pre><code>▶ go build --gcflags=-m x.go
./tmp.go:2: can inline F
./tmp.go:5: &amp;i escapes to heap
./tmp.go:3: moved to heap: i
</code></pre><p>Go编译器依靠escape analyze来识别局部变量的作用范围，来决定变量分配在堆上还是栈上，这与GC技术是相辅相成的。</p>
<h4 id="闭包结构体"><a href="#闭包结构体" class="headerlink" title="闭包结构体"></a>闭包结构体</h4><p>闭包结构体在src/cmd/compile/internal/gc/closure.go的walkclosure函数生成，具体实现太过复杂，其注释简要地说明了实现方式：</p>
<pre><code>// Create closure in the form of a composite literal.
// supposing the closure captures an int i and a string s
// and has one float64 argument and no results,
// the generated code looks like:
//
//    clos = &amp;struct&#123;.F uintptr; i *int; s *string&#125;&#123;func.1, &amp;i, &amp;s&#125;
//
// The use of the struct provides type information to the garbage
// collector so that it can walk the closure. We could use (in this case)
// [3]unsafe.Pointer instead, but that would leave the gc in the dark.
// The information appears in the binary in the form of type descriptors;
// the struct is unnamed so that closures in multiple packages with the
// same struct type can share the descriptor.
</code></pre><p>比如对我们闭包例子中return_closure生成的闭包，其闭包结构体表示为:</p>
<pre><code>type.struct&#123;
     .F uintptr//闭包调用的函数指针
     j *int// 指向闭包的上下文数据，c1,c2指向不同的堆地址
&#125;
</code></pre><h3 id="3-错误处理"><a href="#3-错误处理" class="headerlink" title="3. 错误处理"></a>3. 错误处理</h3><p>Go的错误处理主要依靠 <code>panic</code>，<code>recover</code>，<code>defer</code>，前两者相当于throw和catch，而defer则是Go又一个让人惊喜的特性，defer确保语句在函数结束(包括异常中断)前执行，更准备地说，<strong>defer语句的执行时机是在返回值赋值之后，函数返回之前</strong>:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f1</span><span class="params">()</span> <span class="params">(r <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		r++</span><br><span class="line">	&#125;()</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* 函数返回: 1</span></span><br><span class="line"><span class="comment">f1等价于:</span></span><br><span class="line"><span class="comment">func f1() (r int)&#123;</span></span><br><span class="line"><span class="comment">	r = 0 // 返回值赋值</span></span><br><span class="line"><span class="comment">	func() &#123; 	 // 执行defer函数</span></span><br><span class="line"><span class="comment">		r++</span></span><br><span class="line"><span class="comment">	&#125;()</span></span><br><span class="line"><span class="comment">	return 	 // 函数返回</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f2</span><span class="params">()</span> <span class="params">(r <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">	t := <span class="number">5</span></span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		t = t + <span class="number">5</span></span><br><span class="line">	&#125;()</span><br><span class="line">	<span class="keyword">return</span> t</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*函数返回: 5</span></span><br><span class="line"><span class="comment">f2等价于:</span></span><br><span class="line"><span class="comment">func f2() (r int) &#123;</span></span><br><span class="line"><span class="comment">	t := 5</span></span><br><span class="line"><span class="comment">	r = t</span></span><br><span class="line"><span class="comment">	func() &#123;</span></span><br><span class="line"><span class="comment">		t = t + 5</span></span><br><span class="line"><span class="comment">	&#125;()</span></span><br><span class="line"><span class="comment">	return</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f3</span><span class="params">()</span> <span class="params">(r <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">(r <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">		r = r + <span class="number">5</span></span><br><span class="line">	&#125;(r)</span><br><span class="line">	<span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*函数返回: 5</span></span><br><span class="line"><span class="comment">f3等价于:</span></span><br><span class="line"><span class="comment">func f3()(r int)&#123;</span></span><br><span class="line"><span class="comment">	r = 1</span></span><br><span class="line"><span class="comment">	func(r int) &#123;</span></span><br><span class="line"><span class="comment">		r = r + 5</span></span><br><span class="line"><span class="comment">	&#125;(r) // 值传参 不会影响返回的r的值</span></span><br><span class="line"><span class="comment">	return</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<p>因此，<code>return x</code>其实不是”原子操作”，在其中会插入defer函数执行，在<a href="https://golang.org/ref/spec#Defer_statements">Go官方文档</a>中也提到了这点。</p>
<p>defer还有如下特性：</p>
<ol>
<li>一个函数可定义多个defer语句</li>
<li>多个defer语句按照先入后出的顺序执行</li>
<li>defer表达式中的变量值在defer表达式定义时就已经明确</li>
<li>defer表达式可以修改函数中的命名返回值</li>
</ol>
<p>defer的作用：</p>
<ol>
<li>简化异常处理(在defetr中recover)，避免异常与控制流程混合(try … catch … finally)</li>
<li>在defer中做环境清理和资源释放</li>
</ol>
<p>更多阅读:</p>
<ol>
<li>多返回值和闭包: <a href="https://www.teakki.com/p/57df64ccda84a0c45338154e">https://www.teakki.com/p/57df64ccda84a0c45338154e</a></li>
</ol>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Go 笔记(3) 面向对象和接口</title>
    <url>/2016/09/go-notes-3-object-oriented/</url>
    <content><![CDATA[<p>探索Go类型扩展，类和继承，以及接口的用法和实现。</p>
<h2 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h2><h3 id="1-类型扩展"><a href="#1-类型扩展" class="headerlink" title="1. 类型扩展"></a>1. 类型扩展</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line">	</span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line">	</span><br><span class="line"><span class="comment">// 定义了一个新类型:Integer，与int不能直接比较/赋值</span></span><br><span class="line"><span class="keyword">type</span> Integer <span class="keyword">int</span></span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(a *Integer)</span> <span class="title">Add</span><span class="params">(b Integer)</span> <span class="title">Integer</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> *a + b</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-类和继承"><a href="#2-类和继承" class="headerlink" title="2. 类和继承"></a>2. 类和继承</h3><p>在Go中，传统意义上的类相当于是对struct的类型扩展：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line">	</span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line">	</span><br><span class="line"><span class="keyword">type</span> Rect <span class="keyword">struct</span>&#123;</span><br><span class="line">    x, y <span class="keyword">float64</span></span><br><span class="line">    w, l <span class="keyword">float64</span></span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r Rect)</span> <span class="title">Area</span><span class="params">()</span> <span class="title">float64</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> r.l * r.w</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    c := Rect&#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>&#125;</span><br><span class="line">    fmt.Println(c.Area())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<!--more->

Go中的继承通过匿名组合实现：

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line">	</span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line">	</span><br><span class="line"><span class="keyword">type</span> Base <span class="keyword">struct</span> &#123;</span><br><span class="line">    Name <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(base *Base)</span> <span class="title">Foo</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;Base Foo()&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(base *Base)</span> <span class="title">Bar</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;Base Bar()&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 以组合的方式 定义继承</span></span><br><span class="line"><span class="comment">// 当derive.xxx在Derive中未找到时，将从基类Base中查找</span></span><br><span class="line"><span class="comment">// 也可通过derive.Base.xxx直接引用基类Base的方法或成员</span></span><br><span class="line"><span class="keyword">type</span> Derive <span class="keyword">struct</span> &#123;</span><br><span class="line">    Base</span><br><span class="line">    age <span class="keyword">int</span> <span class="comment">// 这里的同名成员将覆盖Base中的成员</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 重写基类方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *Derive)</span> <span class="title">Bar</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;Derive Bar()&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    b := Base&#123;<span class="string">&quot;name&quot;</span>&#125;</span><br><span class="line">    d := Derive&#123;b, <span class="number">99</span>&#125;</span><br><span class="line">    d.Foo() <span class="comment">// == d.Base.Foo() 语法糖，Foo()函数的接收者只能是Base*</span></span><br><span class="line">    d.Bar()</span><br><span class="line">    fmt.Println(d.Name,d.age)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>还可以以指针的方式从一个类型派生：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Derive <span class="keyword">struct</span> &#123;</span><br><span class="line">    *Base</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个时候Derive的初始化需要提供一个Base的指针，它存在的意义类似于C++中的虚基类，Go将C++面向对象中一些”黑盒子”放到了台面上来，如this指针(作为一个特殊的参数显现出来)，虚函数表(Go中不允许派生类指针到基类指针的隐式转换，也就无需虚函数表来实现多态)，虚基类(通过显式基类指针，简洁明了的实现了这一需求)。</p>
<p>Go中没有private public等关键字，要使符号对其它包可见，则需要将该符号定义为大写字母开头。如Base中的Name能被其它引用了Base所在包的代码访问到，而Derive中age则不能。Go中没有类级别的访问控制。</p>
<h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>接口(interface)是一系列方法声明的组合，同时它本身也是一个类型。</p>
<h3 id="1-非侵入式接口"><a href="#1-非侵入式接口" class="headerlink" title="1. 非侵入式接口"></a>1. 非侵入式接口</h3><p>侵入式接口是指实现类需要明确声明实现了某个接口，目前C++/Java等语言均为侵入式接口。这类接口的缺点是类的实现方需要知道需求方需要的接口，并提前实现这些接口。这给类设计带来很大困难，因为设计类的时候，你并不知道也不应该关心它会被怎么使用。</p>
<p>GO中的接口是非侵入式的，接口与类分离，类只需要关心它应该有那些功能(函数)，而无需操心其应该满足哪些接口(契约)，<strong>一个类只要实现了某个接口的所有函数，那么它就实现了这个接口</strong>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> IReader <span class="keyword">interface</span>&#123;</span><br><span class="line">    Read(buf []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="keyword">type</span> IWriter <span class="keyword">interface</span>&#123;</span><br><span class="line">    Write(buf []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="keyword">type</span> IFile <span class="keyword">interface</span>&#123;</span><br><span class="line">    Read(buf []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">    Write(buf []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="keyword">type</span> IStream <span class="keyword">interface</span>&#123;</span><br><span class="line">    Read(buf []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">    Write(buf []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="keyword">type</span> IDevice <span class="keyword">interface</span>&#123;</span><br><span class="line">    Name() <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="comment">// File定义无需指定实现接口，直接实现其方法即可</span></span><br><span class="line"><span class="comment">// 根据File类的实现，可以得到：</span></span><br><span class="line"><span class="comment">// File类实现了 IDevice接口</span></span><br><span class="line"><span class="comment">// File*类实现了以上所有接口</span></span><br><span class="line"><span class="keyword">type</span> File <span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *File)</span> <span class="title">Read</span><span class="params">(buf []<span class="keyword">byte</span>)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *File)</span> <span class="title">Write</span><span class="params">(buf []<span class="keyword">byte</span>)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f File)</span> <span class="title">Name</span><span class="params">()</span> <span class="params">(s <span class="keyword">string</span>)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Go的非侵入式接口的意义：</p>
<ol>
<li>Go语言的标准库，没有复杂的继承树，接口与类之间是平坦的，无需绘制类库的继承树图。</li>
<li>实现类的时候，只需要关心自己应该提供哪些方法(自身功能)，不用再纠结实现哪些接口，接口由使用方按需定义，而不用事前规划。</li>
<li>不用为了实现一个接口而导入一个包，因为多引用一个外部的包，就意味着更多的耦合。接口由使用方按自身需求来定义，使用方无需关心是否有其他模块定义过类似的接口。</li>
</ol>
<h3 id="2-接口赋值"><a href="#2-接口赋值" class="headerlink" title="2. 接口赋值"></a>2. 接口赋值</h3><p>由于接口本身是一种类型，因此它可被赋值。接口赋值分为两种：将对象赋值给接口和将接口赋值给接口：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1. 将对象赋值给接口</span></span><br><span class="line"><span class="comment">// 赋值条件：对象需实现该接口</span></span><br><span class="line">f := File&#123;&#125;</span><br><span class="line"><span class="comment">// ok</span></span><br><span class="line"><span class="keyword">var</span> I1 IDevice = f</span><br><span class="line"><span class="comment">// ok. Go会根据 func (f File) Name() 自动生成 func (f *file) Name()方法</span></span><br><span class="line"><span class="keyword">var</span> I2 IDevice = &amp;f</span><br><span class="line"><span class="comment">// error. File类实现的IFile接口中，有函数的接收者为File*</span></span><br><span class="line"><span class="comment">// func (f *File) Read(buf []byte) 不能转化为 func (f File) Read(buf []byte)</span></span><br><span class="line"><span class="comment">// 因为前者可能在函数中改变f，后者不能，可能造成语义上的不一致</span></span><br><span class="line"><span class="keyword">var</span> I3 IFile = f</span><br><span class="line"><span class="comment">// ok</span></span><br><span class="line"><span class="keyword">var</span> I4 IFile = &amp;f</span><br><span class="line"><span class="comment">// 赋值完成之后 可通过接口直接调用对象方法</span></span><br><span class="line">I1.Name()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 将接口赋值给接口</span></span><br><span class="line"><span class="comment">// 赋值条件：左值接口需是右值接口的子集</span></span><br><span class="line"><span class="keyword">var</span> I5 IReader = I1 <span class="comment">// error</span></span><br><span class="line"><span class="keyword">var</span> I6 IFile   = I3 <span class="comment">// ok</span></span><br><span class="line"><span class="keyword">var</span> I7 IReader = I3 <span class="comment">// ok</span></span><br></pre></td></tr></table></figure>
<h3 id="3-接口查询"><a href="#3-接口查询" class="headerlink" title="3. 接口查询"></a>3. 接口查询</h3><p>既然我们可以将对象或者接口赋值给接口，那么也应该有方法能让我们从一个接口查询出其指向对象的类型信息和接口信息：</p>
<pre><code>f := File&#123;&#125;
// 接口查询
var I1 IDevice = f
// 判断接口I1指向的对象是否实现了IFile接口
I2, ok := I1.(IFile) // ok = false File类型没有实现IFile接口 File*类型实现了

// 类型查询
// 方法一 type assertions
f2, ok := I1.(File) // ok = true
// 方法二 type switch
// X.(type)方法只能用在switch语句中
switch(I1.(type))&#123;
    case int:       // 如果I1指向的对象为int
    case File:      // 如果I1指向的对象为File
    ...
&#125;
</code></pre><h3 id="4-接口组合"><a href="#4-接口组合" class="headerlink" title="4. 接口组合"></a>4. 接口组合</h3><p>前面的IFile接口定义等价于：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> IFile <span class="keyword">interface</span>&#123;</span><br><span class="line">    IReader</span><br><span class="line">    IWriter</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接口组合可以以更简便的方式复用接口类似于类继承，只不过没有成员变量。</p>
<h3 id="5-空接口"><a href="#5-空接口" class="headerlink" title="5. 空接口"></a>5. 空接口</h3><p>在Go中的任何对象都满足空接口<code>interface&#123;&#125;</code>，所以<code>interface&#123;&#125;</code>可以指向任何对象：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> v1 <span class="keyword">interface</span>&#123;&#125; = <span class="number">1</span></span><br><span class="line"><span class="keyword">var</span> v2 <span class="keyword">interface</span>&#123;&#125; = <span class="string">&quot;abc&quot;</span></span><br><span class="line"><span class="keyword">var</span> v3 <span class="keyword">interface</span>&#123;&#125; = <span class="keyword">struct</span>&#123; x <span class="keyword">int</span> &#125;&#123;<span class="number">1</span>&#125;</span><br><span class="line"><span class="keyword">var</span> v4 <span class="keyword">interface</span>&#123;&#125; = v3</span><br></pre></td></tr></table></figure>
<p><code>interface&#123;&#125;</code>比C++中的<code>void*</code>更强大，比<code>template&lt;&gt;</code>更灵活，结合接口查询和反射，构建底层代码变得非常容易。</p>
<h3 id="6-反射"><a href="#6-反射" class="headerlink" title="6. 反射"></a>6. 反射</h3><p>简单概括，反射一种检查存储在接口变量(任意类型值)中的“类型-值对”的机制。任何接口变量(包括空接口变量)都包含了其对应的具体类型和值信息：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> f = <span class="built_in">new</span>(File)</span><br><span class="line"><span class="keyword">var</span> r IReader</span><br><span class="line">r = f</span><br><span class="line">fmt.Println(reflect.TypeOf(r), reflect.ValueOf(r))</span><br><span class="line"><span class="comment">// 输出: *main.File &amp;&#123;&#125;</span></span><br><span class="line"><span class="keyword">var</span> w IWriter</span><br><span class="line">w = r.(IWriter)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>IReader接口变量只提供了访问Read方法的能力，但其接口变量仍然保存了有关该值的所有类型信息，因此我们可以通过接口查询得到IWriter接口变量。接口的静态类型决定了哪些方法可以通过接口变量调用，但接口变量本身可能包含更大的方法集。</p>
<p>有了这个机制，我们才能通过反射从任意接口变量，获取对象完整的属性。关于反射的API都在reflect包中提供，通过<code>reflect.TypeOf</code>和<code>reflect.ValueOf</code>获取接口变量的Type和Value，reflect为Type和Value提供了大量的方法，如<code>Type.Kind()</code>,<code>Value.Interface()</code>等。</p>
<p>现在我们尝试通过反射修改接口变量的值：</p>
<pre><code>var x float64 = 3.4
v := reflect.ValueOf(x)
v.Set(4.1) // error: cannot use 4.1 (type float64) as type reflect.Value in argument to v.Set
</code></pre><p>由于在<code>refect.ValueOf(x)</code>中操作的是x的拷贝，因此实际上v.Set即使能操作成功，也不能如我们预期一般修改x的值。因此reflect提供<code>Value.CanSet()</code>来辨别这类不能成功修改的值：</p>
<blockquote>
<blockquote>
<p>CanSet reports whether the value of v can be changed. A Value can be changed only if it is addressable and was not obtained by the use of unexported struct fields. If CanSet returns false, calling Set or any type-specific setter (e.g., SetBool, SetInt) will panic.</p>
</blockquote>
</blockquote>
<p>我们可以通过*float64类型的反射来修改x的值:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> x <span class="keyword">float64</span> = <span class="number">3.4</span></span><br><span class="line">p := reflect.ValueOf(&amp;x)</span><br><span class="line">fmt.Println(<span class="string">&quot;type of p:&quot;</span>, p.Type())</span><br><span class="line">fmt.Println(<span class="string">&quot;CanSet of p:&quot;</span> , p.CanSet())</span><br><span class="line">v := p.Elem()</span><br><span class="line">fmt.Println(<span class="string">&quot;CanSet of v:&quot;</span> , v.CanSet())</span><br><span class="line"><span class="comment">// v的地址是有效的(保存在p.Value()中) 因此可以修改</span></span><br><span class="line">v.SetFloat(<span class="number">7.1</span>)</span><br><span class="line">fmt.Println(v.Interface())</span><br><span class="line">fmt.Println(x)</span><br><span class="line"><span class="comment">// 输出:</span></span><br><span class="line"><span class="comment">// type of p: *float64</span></span><br><span class="line"><span class="comment">// CanSet of p: false</span></span><br><span class="line"><span class="comment">// CanSet of v: true</span></span><br><span class="line"><span class="comment">// 7.1</span></span><br><span class="line"><span class="comment">// 7.1</span></span><br></pre></td></tr></table></figure>
<p>推荐阅读:</p>
<ol>
<li>接口和反射的好文：<a href="https://blog.go-zh.org/laws-of-reflection">https://blog.go-zh.org/laws-of-reflection</a></li>
</ol>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Rebar3 Erlang/OTP构建利器</title>
    <url>/2016/09/erlang-rebar3/</url>
    <content><![CDATA[<h3 id="一-依赖管理"><a href="#一-依赖管理" class="headerlink" title="一. 依赖管理"></a>一. 依赖管理</h3><h4 id="1-包依赖和源码依赖"><a href="#1-包依赖和源码依赖" class="headerlink" title="1. 包依赖和源码依赖"></a>1. 包依赖和源码依赖</h4><p>Rebar3支持两种依赖：</p>
<pre><code>&#123;deps,[
  %% 包依赖
  rebar,
  &#123;rebar,&quot;1.0.0&quot;&#125;,
  &#123;rebar, &#123;pkg, rebar_fork&#125;&#125;, % rebar app under a different pkg name
  &#123;rebar, &quot;1.0.0&quot;, &#123;pkg, rebar_fork&#125;&#125;,
  %% 源码依赖
  &#123;rebar, &#123;git, &quot;git://github.com/erlang/rebar3.git&quot;&#125;&#125;,
  &#123;rebar, &#123;git, &quot;http://github.com/erlang/rebar3.git&quot;&#125;&#125;,
  &#123;rebar, &#123;git, &quot;https://github.com/erlang/rebar3.git&quot;&#125;&#125;,
  &#123;rebar, &#123;git, &quot;git@github.com:erlang/rebar3.git&quot;&#125;&#125;,
  &#123;rebar, &#123;hg, &quot;https://othersite.com/erlang/rebar3&quot;&#125;&#125;,
  &#123;rebar, &#123;git, &quot;git://github.com/erlang/rebar3.git&quot;, &#123;ref, &quot;aef728&quot;&#125;&#125;&#125;,
  &#123;rebar, &#123;git, &quot;git://github.com/erlang/rebar3.git&quot;, &#123;branch, &quot;master&quot;&#125;&#125;&#125;,
  &#123;rebar, &#123;git, &quot;git://github.com/erlang/rebar3.git&quot;, &#123;tag, &quot;3.0.0&quot;&#125;&#125;&#125;
  ]&#125;
</code></pre><span id="more"></span>
<p>Rebar3通过<a href="https://hex.pm">hex.pm</a>来管理包依赖，在使用之前，需要通过<code>rebar3 update</code>从hex.pm更新包索引，并将包索引信息缓存到本地(<code>~/.cache/rebar3/</code>)。之后Rebar3便能正确解析包依赖，对应用程序使用上来说，两者没有明显区别。</p>
<h4 id="2-升级依赖"><a href="#2-升级依赖" class="headerlink" title="2. 升级依赖"></a>2. 升级依赖</h4><p>在使用Rebar2的时候，如果项目依赖一个指向分支的dep，就会出现这种情况：</p>
<ul>
<li>这个dep有远程分支更新时，rebar get-deps不会自动拉取更新，通常你只能进入dep目录执行<code>git pull</code>，或者删除该dep重新执行rebar get-deps。</li>
<li>项目成员各自的工作目录deps版本可能不一致，并且一些很久没更新的依赖可能在你部署新环境时(此时所有依赖都指向最新)出现问题。</li>
</ul>
<p>所以在Rebar2的reabr.config中定义deps，都应该尽量使用tag, commitid来指定，而不是直接指向分支。那么Rebar3是如何解决这个问题的呢？</p>
<p>Rebar3解决此问题的核心在rebar.lock文件，该文件内容如下：</p>
<pre><code>&#123;&quot;1.1.0&quot;,
[&#123;&lt;&lt;&quot;goldrush&quot;&gt;&gt;,&#123;pkg,&lt;&lt;&quot;goldrush&quot;&gt;&gt;,&lt;&lt;&quot;0.1.8&quot;&gt;&gt;&#125;,1&#125;,
 &#123;&lt;&lt;&quot;lager&quot;&gt;&gt;,&#123;pkg,&lt;&lt;&quot;lager&quot;&gt;&gt;,&lt;&lt;&quot;3.2.1&quot;&gt;&gt;&#125;,0&#125;]&#125;.
[
&#123;pkg_hash,[
 &#123;&lt;&lt;&quot;goldrush&quot;&gt;&gt;, &lt;&lt;&quot;2024BA375CEEA47E27EA70E14D2C483B2D8610101B4E852EF7F89163CDB6E649&quot;&gt;&gt;&#125;,
 &#123;&lt;&lt;&quot;lager&quot;&gt;&gt;, &lt;&lt;&quot;EEF4E18B39E4195D37606D9088EA05BF1B745986CF8EC84F01D332456FE88D17&quot;&gt;&gt;&#125;]&#125;
].
</code></pre><p>该文件是项目当前使用依赖库的一个版本快照。当一个依赖被获取和锁定，Rebar3将从依赖中提取版本信息并写入rebar.lock文件中，该文件应该加入GIt仓库，并且由专人维护，这样只要rebar.lock一致，各本地仓库的依赖库版本就是一致的。</p>
<p>依赖升级分为两种，一种是直接通过<code>rebar upgrade [dep]</code>进行源码更新或包更新(只能更新Top Level依赖)。另一种是rebar.config发生变动，比如去除了某个依赖，此时需要<code>rebar unlock [dep]</code>命令来清理rebar.lock文件。</p>
<p>相关命令：</p>
<pre><code>rebar3 update  // 更新包索引
rebar3 pkgs // 列出所有可用的包
rebar3 deps  // 列出所有一级(Top Level)依赖
rebar3 tree  // 以树形结构查看依赖
rebar3 compile // 获取并编译依赖
rebar3 upgrade [dep] // 升级依赖
rebar3 lock [dep] // 锁定依赖
rebar3 unlock [dep] // 解锁依赖
</code></pre><h3 id="二-构建"><a href="#二-构建" class="headerlink" title="二. 构建"></a>二. 构建</h3><pre><code>rebar3 new app [appname]
rebar3 new lib [libname]
</code></pre><p>Rebar3建议应用程序按照OTP规范目录进行组织：</p>
<pre><code>├── LICENSE
├── README.md
├── apps
│   └── myapp
│       └── src
│           ├── myapp.app.src
│           ├── myapp_app.erl
│           └── myapp_sup.erl
├── config
│   ├── sys.config
│   └── vm.args
├── lib
│   └── mylib
│       ├── LICENSE
│       ├── README.md
│       ├── rebar.config
│       └── src
│           ├── mylib.app.src
│           └── mylib.erl
└── rebar.config
</code></pre><p>这样无需在rebar.config中指定sub_dirs，Rebar3会自动将lib和apps作为搜索路径。</p>
<p>Rebar3没有get-deps命令，通过<code>rebar3 compile</code>即可编译项目，并自动获取和编译不存在的依赖，Rebar3将所有编译文件和Release信息都置于<code>_build</code>目录下。默认apps，deps和lib下的应用都被编译到<code>_build/default/lib</code>中。要指定应用目录和输出目录等选项，请参考：<a href="http://www.rebar3.org/docs/configuration">Rebar3配置</a>。</p>
<h3 id="三-发布"><a href="#三-发布" class="headerlink" title="三. 发布"></a>三. 发布</h3><h4 id="1-发布环境"><a href="#1-发布环境" class="headerlink" title="1. 发布环境"></a>1. 发布环境</h4><p>Rebar3放弃了<a href="http://erlang.org/doc/man/reltool.html">reltool</a>而使用<a href="https://github.com/erlware/relx">relx</a>作为发布工具。并且将relx.config内容集成到rebar.config当中，通过<code>rebar new release [appname]</code>可创建一个发布，rebar.config内容如下：</p>
<pre><code>&#123;erl_opts, [debug_info]&#125;.
&#123;deps, []&#125;.

%% 定义默认发布环境(default环境)
&#123;relx, [&#123;release, &#123; myapp, &quot;0.1.0&quot; &#125;,
         [myapp,
          sasl]&#125;,

        &#123;sys_config, &quot;./config/sys.config&quot;&#125;,
        &#123;vm_args, &quot;./config/vm.args&quot;&#125;,

    %% 当dev_mode==true时 _build/default/rel/myapp/lib/目录下的库其实是_build/default/lib目录下对应lib的软链接，这样重新编译后，无需重新发布，重启或热加载代码即可
        &#123;dev_mode, true&#125;,
        %% 是否在发布目录中包含虚拟机 即为一个独立的运行环境
        &#123;include_erts, false&#125;,

        &#123;extended_start_script, true&#125;]
&#125;.

%% 定义其它发布环境
%% 参数使用覆盖(override)机制，即这里面没有定义的参数，将使用默认发布环境(default)配置
&#123;profiles, [&#123;prod, [&#123;relx, [&#123;dev_mode, false&#125;,
                            &#123;include_erts, true&#125;]&#125;]
            &#125;]
&#125;
</code></pre><p>Rebar3中有发布环境(profiles)的概念，如开发环境(default)，生产环境(prod)，它们可以独立定义编译参数(erl_opts)，发布参数(dev_mode, include_erts)，甚至依赖应用(deps)。目前Rebar3支持四种环境定义：</p>
<ul>
<li>default：默认环境，也就是rebar.config中最外部定义的环境</li>
<li>prod：生产环境，通常在此环境下将使用库的完整发布包(而不是软链接)，有更严格的编译选项，并且可能还要包含Erlang运行时所需要的所有环境</li>
<li>native：原生环境，强制使用<a href="http://erlang.org/doc/man/HiPE_app.html">HiPE</a>编译，从而得到更快的编译速度</li>
<li>test：测试环境，将加载一些额外的库(如<a href="https://github.com/eproxus/meck">meck</a>)，打开调试信息，用于跑测试代码</li>
</ul>
<p>不同发布环境将发布在不同的目录下，如prod环境默认将生成在<code>_build/prod/</code>下，无论顶层应用采用何种发布环境，依赖将始终只能使用prod环境发布。并且只有顶层依赖的default环境，可以被保存到rebar.lock中。</p>
<p><code>rebar3 release</code>将按照default环境发布应用，通过<code>rebar3 as prod release</code>可以将应用在生产环境发布。具体环境配置及命令参考<a href="http://www.rebar3.org/docs/profiles">Rebar3环境</a>。</p>
<h4 id="2-发布多个应用"><a href="#2-发布多个应用" class="headerlink" title="2. 发布多个应用"></a>2. 发布多个应用</h4><p>Rebar3支持在rebar.config中定义多个应用的发布，多个应用可以共享配置：</p>
<pre><code>&#123;relx, [&#123;release, &#123;myapp1, &quot;0.0.1&quot;&#125;,
     [myapp1]&#125;,
    &#123;release, &#123;myapp2, &quot;0.1.0&quot;&#125;,
     [myapp2]&#125;,

     % 共用配置
&#123;sys_config, &quot;config/sys.config&quot;&#125;,
&#123;vm_args, &quot;config/vm.args&quot;&#125;,

    &#123;dev_mode, true&#125;,
    &#123;include_erts, false&#125;,
    &#123;extended_start_script, true&#125;]&#125;.
</code></pre><p>也可以独立配置：</p>
<pre><code>&#123;relx, [
    &#123;release, &#123;myapp1, &quot;0.0.1&quot;&#125;,
             [myapp1],
             % 注意配置顺序和格式 各应用的独立配置是一个PropList
             [&#123;sys_config, &quot;config/sys1.config&quot;&#125;,
        &#123;vm_args, &quot;config/vm1.args&quot;&#125;]
    &#125;,
        &#123;release, &#123;myapp2, &quot;0.1.0&quot;&#125;,
             [myapp2],
             [&#123;sys_config, &quot;config/sys1.config&quot;&#125;,
        &#123;vm_args, &quot;config/vm1.args&quot;&#125;,
        &#123;overlay&#125;]
    &#125;,    

    &#123;dev_mode, true&#125;,
    &#123;include_erts, false&#125;,

    &#123;extended_start_script, true&#125;]&#125;.
</code></pre><h4 id="3-应用依赖"><a href="#3-应用依赖" class="headerlink" title="3. 应用依赖"></a>3. 应用依赖</h4><p>定义于rebar.config deps中的依赖被获取后放在<code>_build/default/lib</code>目录下，默认并不会打包到应用的发布目录<code>_build/default/rel/myapp/lib</code>中，你需要在relbar.config的relx中指定应用依赖：</p>
<pre><code>&#123;relx, [&#123;release, &#123; myapp, &quot;0.1.0&quot; &#125;,
         [
         % 指定应用依赖 mylib会先于myapp被启动
         mylib, 
         myapp]
         &#125;,

        &#123;sys_config, &quot;./config/sys.config&quot;&#125;,
        &#123;vm_args, &quot;./config/vm.args&quot;&#125;,

        &#123;dev_mode, true&#125;,
        &#123;include_erts, false&#125;,

        &#123;extended_start_script, true&#125;]
&#125;.
</code></pre><p>那么对于一些辅助lib呢，我们希望它被打包在应用发布目录中，但不希望它们被启动(它们可能根本不能启动)，一种方法是将mylib指定为<code>&#123;mylib, load&#125;</code>(参见<a href="https://github.com/erlware/relx/issues/483">Issue1</a>, <a href="https://github.com/erlware/relx/issues/149">Issue2</a>)，列表中的依赖项默认被relx解释为<code>&#123;mylib, permanent&#125;</code>，即以常驻的方式启动应用。</p>
<h4 id="4-Overlays"><a href="#4-Overlays" class="headerlink" title="4. Overlays"></a>4. Overlays</h4><p>Overlay允许用户定义一些文件模板和部署准备工作，如拷贝文件，创建文件夹等：</p>
<pre><code>&#123;relx, [
    &#123;overlay_vars, &quot;vars.config&quot;&#125;,
    &#123;overlay, [&#123;mkdir, &quot;log/sasl&quot;&#125;,
               &#123;template, &quot;priv/app.config&quot;, &quot;etc/app.config&quot;&#125;，
               % root_dir是relx提供的变量 代表项目根目录
               &#123;copy, &quot;\&#123;\&#123;root_dir\&#125;\&#125;/configures&quot;, &quot;./&quot;&#125;]&#125;
]&#125;.
</code></pre><p>Overlay可以如sys_config和vm_config一样，放在各应用的独立发布配置中。</p>
<p>更多关于Rebar3发布流程，发布配置，以及库升级等，参考<a href="http://www.rebar3.org/v3/docs/releases">Rebar3发布</a>。</p>
<h3 id="四-总结"><a href="#四-总结" class="headerlink" title="四. 总结"></a>四. 总结</h3><p>Rebar3无疑是个好东西，更先进的依赖管理，多节点发布，发布环境的概念，都是Rebar2 + Reltool所不能实现的，当前我们项目就使用的Rebar2.x，用于部署一个多节点的集群，遇到的问题：</p>
<ul>
<li>依赖管理：各本地版本不一致问题，Rebar3的lock为依赖的一致性提供了保证。</li>
<li>多节点部署：Rebar2.x需要为每个节点创建release(create-node)，需要维护N份reltool.config和一份rebar.config。在Rebar3中只需一个rebar.config文件。并且可以灵活定义各节点配置文件(vm.args, sys.config)路径，更有利于项目结构管理和可读性。</li>
<li>开发模式：在本地开发时，Rebar2.x的generate和upgrade太慢了，前者可用二进制发布自己写脚本替代(用erl_call和节点通信)，后者可用reloader实现热更，这样提高了部署速度，却要自己维护节点交互脚本。Rebar3的dev_mode完美解决了这个问题。</li>
<li>环境管理：这一块的用处还有待挖掘和摸索。</li>
</ul>
<p>Rebar3目前主要的缺点，在于relx文档匮乏，提供了很多好东西，但能传达到用户让用户理解和用上的很少。翻遍了<a href="https://github.com/erlware/relx/wiki">relx wiki</a>，也没有找到应用独立配置环境(sys_config, vm_args等)的方法，最后是看了其配置解析模块<a href="hub.com/erlware/relx/blob/master/src/rlx_config.erl">rlx_config.erl</a>才猜出来的格式= =。</p>
<h3 id="五-参考："><a href="#五-参考：" class="headerlink" title="五. 参考："></a>五. 参考：</h3><ol>
<li><a href="http://www.rebar3.org/docs/getting-started">Rebar3文档</a></li>
<li><a href="https://github.com/zyuyou/rebar3_docs">Rebar3文档中文翻译(部分)</a></li>
<li><a href="https://github.com/erlware/relx/wiki">relx wiki</a></li>
<li><a href="http://erlang.org/doc/design_principles/release_structure.html">OTP Release 结构</a></li>
</ol>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>goa - go web框架</title>
    <url>/2016/09/goa-intro/</url>
    <content><![CDATA[<h3 id="一-简介"><a href="#一-简介" class="headerlink" title="一. 简介"></a>一. 简介</h3><p><a href="https://github.com/goadesign/goa">goa</a>是基于微服务的go语言框架，能够有效帮助开发人员快速开发基于微服务的系统。它通过DSL和代码生成器来生成样板代码和辅助套件(如文档，客户端模块，客户端工具等)。这些生成数据均基于服务的设计描述，goa遵循<strong>单一数据源</strong>(Single Source of Truth, SSOT)原则，任何对设计的改变，都将自动反映到系统各处，</p>
<p>goa可以分为三个部分：</p>
<ul>
<li>goa的设计语言是内置DSL，用于描述微服务的设计</li>
<li>goa代码生成器，用于根据DSL描述生成代码模块，辅助工具，和文档等</li>
<li>goa利用生成代码和用户代码来实现一个服务，并提供一个完全可插拨的框架</li>
</ul>
<span id="more"></span>
<p>goa的特点：</p>
<ul>
<li>重视框架设计(Design-Based)，将框架，文档，胶水代码和辅助工具作为一个整体来设计和描述</li>
<li>为用户生成了大量的代码(框架代码，胶水代码，测试代码，客户端工具等等)，上手快速</li>
<li>DSL，代码生成器，用户代码均使用Go语言编写，并且前两者使用plugin实现，可以替换</li>
<li>基于微服务，对<a href="http://www.infoq.com/cn/articles/rest-introduction#anch82429">RESTful</a> API有非常好的支持，方便构建更高效，易于扩展的HTTP服务器</li>
</ul>
<h3 id="二-使用"><a href="#二-使用" class="headerlink" title="二. 使用"></a>二. 使用</h3><h4 id="1-安装"><a href="#1-安装" class="headerlink" title="1. 安装"></a>1. 安装</h4><pre><code>// 获取goa
go get github.com/goadesign/goa
go get github.com/goadesign/goa/goagen
// 安装goagen
go install github.com/goadesign/goa/goagen
</code></pre><h4 id="2-DSL-服务设计"><a href="#2-DSL-服务设计" class="headerlink" title="2. DSL 服务设计"></a>2. DSL 服务设计</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">package</span> design                         <span class="comment">// The convention consists of naming the design</span></span><br><span class="line">                                                   <span class="comment">// package &quot;design&quot;</span></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">        . <span class="string">&quot;github.com/goadesign/goa/design&quot;</span>        <span class="comment">// Use . imports to enable the DSL</span></span><br><span class="line">        . <span class="string">&quot;github.com/goadesign/goa/design/apidsl&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> _ = API(<span class="string">&quot;cellar&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;                     <span class="comment">// API defines the microservice endpoint and</span></span><br><span class="line">        Title(<span class="string">&quot;The virtual wine cellar&quot;</span>)           <span class="comment">// other global properties. There should be one</span></span><br><span class="line">        Description(<span class="string">&quot;A simple goa service&quot;</span>)        <span class="comment">// and exactly one API definition appearing in</span></span><br><span class="line">        Scheme(<span class="string">&quot;http&quot;</span>)                             <span class="comment">// the design.</span></span><br><span class="line">        Host(<span class="string">&quot;localhost:8080&quot;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> _ = Resource(<span class="string">&quot;bottle&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;                <span class="comment">// Resources group related API endpoints</span></span><br><span class="line">        BasePath(<span class="string">&quot;/bottles&quot;</span>)                       <span class="comment">// together. They map to REST resources for REST</span></span><br><span class="line">        DefaultMedia(BottleMedia)                  <span class="comment">// services.</span></span><br><span class="line"></span><br><span class="line">        Action(<span class="string">&quot;show&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;                    <span class="comment">// Actions define a single API endpoint together</span></span><br><span class="line">                Description(<span class="string">&quot;Get bottle by id&quot;</span>)    <span class="comment">// with its path, parameters (both path</span></span><br><span class="line">                Routing(GET(<span class="string">&quot;/:bottleID&quot;</span>))         <span class="comment">// parameters and querystring values) and payload</span></span><br><span class="line">                Params(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;                    <span class="comment">// (shape of the request body).</span></span><br><span class="line">                        Param(<span class="string">&quot;bottleID&quot;</span>, Integer, <span class="string">&quot;Bottle ID&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">()</span></span>&#123;</span><br><span class="line">                                Minimum(<span class="number">0</span>) <span class="comment">// Do not allow for negative values.</span></span><br><span class="line">                        &#125;)</span><br><span class="line">                &#125;)</span><br><span class="line">                Response(OK)                       <span class="comment">// Responses define the shape and status code</span></span><br><span class="line">                Response(NotFound)                 <span class="comment">// of HTTP responses.</span></span><br><span class="line">        &#125;)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// BottleMedia defines the media type used to render bottles.</span></span><br><span class="line"><span class="keyword">var</span> BottleMedia = MediaType(<span class="string">&quot;application/vnd.goa.example.bottle+json&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        Description(<span class="string">&quot;A bottle of wine&quot;</span>)</span><br><span class="line">        Attributes(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;                         <span class="comment">// Attributes define the media type shape.</span></span><br><span class="line">                Attribute(<span class="string">&quot;id&quot;</span>, Integer, <span class="string">&quot;Unique bottle ID&quot;</span>)</span><br><span class="line">                Attribute(<span class="string">&quot;href&quot;</span>, String, <span class="string">&quot;API href for making requests on the bottle&quot;</span>)</span><br><span class="line">                Attribute(<span class="string">&quot;name&quot;</span>, String, <span class="string">&quot;Name of wine&quot;</span>)</span><br><span class="line">                Required(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;href&quot;</span>, <span class="string">&quot;name&quot;</span>)</span><br><span class="line">        &#125;)</span><br><span class="line">        View(<span class="string">&quot;default&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;                    <span class="comment">// View defines a rendering of the media type.</span></span><br><span class="line">                Attribute(<span class="string">&quot;id&quot;</span>)                     <span class="comment">// Media types may have multiple views and must</span></span><br><span class="line">                Attribute(<span class="string">&quot;href&quot;</span>)                   <span class="comment">// have a &quot;default&quot; view.</span></span><br><span class="line">                Attribute(<span class="string">&quot;name&quot;</span>)</span><br><span class="line">        &#125;)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>    
<p>上面的DSL主要用到的接口：</p>
<ul>
<li>API: 描述一个Service及其地址，协议规范等</li>
<li>Resource: 定义一个资源及其一系列相关的操作(Action)，以及这些操作所共用的一些属性</li>
<li>Action: 定义针对于某个资源的操作，包括方法(GET,POST等)，URL(可有多个)，参数(goa自动做类型检查，值检查等)等</li>
<li>Response: 定义一个响应，包括响应模板和承载内容(payload)，在代码中决定调用那个响应模板</li>
<li>MediaType: 定义Response返回的数据结构，一个Media可以有多个View，可在Response中指定返回的View</li>
</ul>
<p>goa本身DSL设计是<a href="http://www.infoq.com/cn/articles/rest-introduction#anch82429">RESTful</a>的，通过Go的匿名函数，提供了非常强大的描述能力，如参数定义，参数检查，传输媒体，响应模板等。goa基于服务提供功能，每个API定义一个服务(Service)，每个服务有若干资源(Resource)，每个资源对应若干操作(Action)，每个操作(Action)有多种响应(Response)，每个响应可能返回不同媒介(Media)的不同视图(View)。当然goa提供了更好的层级控制和继承关系(如上例，Response返回的视图继承于Resource中定义的默认媒介(BottleMedia)的默认视图(default))。更详细的DSL设计文档参考<a href="https://goa.design/design/overview/">goa dsl design</a>和<a href="https://goa.design/reference/goa/design/apidsl">goa dsl api</a>。</p>
<h4 id="3-生成代码"><a href="#3-生成代码" class="headerlink" title="3. 生成代码"></a>3. 生成代码</h4><p>通过goa根据单个DSL文件，即可生成一整套框架代码：</p>
<pre><code>cd src/cellar
goagen bootstrap -d cellar/design
</code></pre><p>goa会生成一堆代码，主要包括四个目录两个文件：</p>
<ul>
<li>app目录: 根据DSL，生成若干类，并将底层的HTTP服务器和DSL中的资源，路由结合起来</li>
<li>client目录:  配套的client包，包含对媒介类型的定义，和对请求响应的编解码</li>
<li>tool目录：根据client包生成的控制台工具，用于模拟客户端发送请求</li>
<li>swagger目录：包含对整个服务(API)的总体描述(Json和Yaml格式)</li>
<li>main.go文件：主文件，挂载资源路由(BottleController)，启动服务</li>
<li>bottle.go文件：bottle资源的逻辑处理，即BottleController的Action实现</li>
</ul>
<p>当改变DSL文件并再次用goagen生成代码时，goagen只会重新生成框架代码(app,client,tool,swagger)，而不会覆盖逻辑代码(main.go和bottle.go以及其它自定义文件)，做到框架与逻辑分离。</p>
<p>得到这些文件之后，我们直接编辑bottle.go，完善bottle资源的Action逻辑即可：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// Show runs the show action.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *BottleController)</span> <span class="title">Show</span><span class="params">(ctx *app.ShowBottleContext)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// BottleController_Show: start_implement</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Put your logic here</span></span><br><span class="line">    <span class="keyword">if</span> ctx.BottleID == <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> ctx.NotFound()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bottle := app.GoaExampleBottle&#123;</span><br><span class="line">        ID : ctx.BottleID,</span><br><span class="line">        Name : fmt.Sprintf(<span class="string">&quot;Bottle #%d&quot;</span>, ctx.BottleID),</span><br><span class="line">        Href : app.BottleHref(ctx.BottleID),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// BottleController_Show: end_implement</span></span><br><span class="line">	<span class="keyword">return</span> ctx.OK(&amp;bottle)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>至此，服务器就已经设计好了，剩下的HTTP Server，消息编解码，参数检查，路由，响应模板，甚至测试工具，gagen都已经为你做好了。</p>
<h4 id="4-运行和测试"><a href="#4-运行和测试" class="headerlink" title="4. 运行和测试"></a>4. 运行和测试</h4><p>运行服务器：</p>
<pre><code>cd src/cellar
go build -o cellar
./cellar
2016/09/20 00:26:41 [INFO] mount ctrl=Bottle action=Show route=GET /bottles/:bottleID
2016/09/20 00:26:41 [INFO] listen transport=http addr=:8080
</code></pre><p>通过curl测试：</p>
<pre><code># 404 NOT FOUND
curl -i localhost:8080/bottles/0
# 200 一个有效的BottleMedia View
curl -i localhost:8080/bottles/1
# 400 无效参数 得到参数检查错误提示
curl -i localhost:8080/bottles/n
</code></pre><p>通过celler-cli工具测试：</p>
<pre><code>cd src/cellar/tool/cellar-cli
go build -o cellar-cli
# 使用帮助
./cellar-cli 
# show bottle 命令的用法
./cellar-cli show bottle
# 发送HTTP请求 cellar-cli中集成了服务的地址信息
./cellar-cli show bottle /bottles/1
</code></pre><p>最终我们只写了几十行的DSL和几行逻辑代码，就得到了一个基于微服务，RESTful风格的HTTP服务器，附以完整的客户端代码，测试工具，甚至服务API描述。更关键的是，这一套环境是SSOT(Single Source of Truth)的，更改一份DSL服务描述文件，整个服务器底层代码，胶水代码，测试环境，甚至API描述都会重新生成(不会影响到已有的逻辑代码)，这让整个服务保持高度一致性和可控性。</p>
<p>最后，以一段<a href="https://github.com/goadesign/goa">goa github</a>上的描述收尾：</p>
<blockquote>
<blockquote>
<p>There are a number of good Go packages for writing modular web services out there so why build another one? Glad you asked! The existing packages tend to focus on providing small and highly modular frameworks that are purposefully narrowly focused. The intent is to keep things simple and to avoid mixing concerns.</p>
<p>This is great when writing simple APIs that tend to change rarely. However there are a number of problems that any non trivial API implementation must address. Things like request validation, response media type definitions or documentation are hard to do in a way that stays consistent and flexible as the API surface evolves.</p>
<p>goa takes a different approach to building these applications: instead of focusing solely on helping with implementation, goa makes it possible to describe the design of an API in an holistic way. goa then uses that description to provide specialized helper code to the implementation and to generate documentation, API clients, tests, even custom artifacts.</p>
</blockquote>
</blockquote>
<p>完整示例参考<a href="https://goa.design/learn/guide/">goa learn guide</a>和<a href="https://github.com/goadesign/goa">goa github</a>。</p>
<h3 id="三-总结"><a href="#三-总结" class="headerlink" title="三. 总结"></a>三. 总结</h3><p>goa的优点：</p>
<ul>
<li>先进的理念：Design-Based, DSL, Micro-Service, RESTful API，Plugins等</li>
<li>DSL，代码生成器，用户代码，辅助工具等一整套环境都用Go实现</li>
<li>一份服务设计(DSL文件)，生成了包括框架代码，辅助(胶水)代码，测试代码，客户端工具等一整套环境(SSOT)</li>
<li>上手简单，功能强大</li>
<li>文档齐全，社区活跃度高</li>
</ul>
<p>后续会继续关注这个框架，尽快拿到实践中用用。</p>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>goa</tag>
      </tags>
  </entry>
  <entry>
    <title>Go 笔记(1) 常用数据结构及实现</title>
    <url>/2016/09/go-notes-1-datastructures/</url>
    <content><![CDATA[<p>学习一下go中常用的几种数据结构，结合源码了解其实现原理。</p>
<h2 id="一-类型系统"><a href="#一-类型系统" class="headerlink" title="一. 类型系统"></a>一. 类型系统</h2><h3 id="1-array"><a href="#1-array" class="headerlink" title="1. array"></a>1. array</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">(x [2]<span class="keyword">int</span>)</span></span>&#123;</span><br><span class="line">	x[<span class="number">1</span>] = <span class="number">9</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	a := [<span class="number">3</span>]<span class="keyword">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;</span><br><span class="line">	b := [<span class="number">2</span>]<span class="keyword">int</span>&#123;<span class="number">4</span>,<span class="number">5</span>&#125;</span><br><span class="line">	f(a) <span class="comment">// error: cannot use a (type [3]int) as type [2]int in argument to f</span></span><br><span class="line">	f(b) <span class="comment">// 数组是值语义 因此f无法改变b中元素内容</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>array的特性:</p>
<ul>
<li>固定大小，且大小为类型的一部分</li>
<li>数组元素在内存中连续存放</li>
<li>值语义: 数组本身(传参会完整拷贝数组)</li>
</ul>
<h3 id="2-slice"><a href="#2-slice" class="headerlink" title="2. slice"></a>2. slice</h3><h4 id="数组切片"><a href="#数组切片" class="headerlink" title="数组切片"></a>数组切片</h4><p>slice(切片)，提供描述array部分连续元素的能力。</p>
<blockquote>
<blockquote>
<p>A slice is a data structure describing a contiguous section of an array stored separately from the slice variable itself. A slice is not an array. A slice describes a piece of an array.</p>
</blockquote>
</blockquote>
<p>slice只持有array的引用，而不会拷贝元素，因此它在实现上只需持有指向array元素的pointer和slice长度length即可。但由于slice的length可以收缩或扩张，因此slice还需要一个字段capacity来保存其最初引用的array的size，当length &gt; capacity时，说明对array的访问越界，触发panic错误。</p>
<p>因此slice一共有三个字段：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> sliceHeader&#123;</span><br><span class="line">	Length 	<span class="keyword">int</span>			<span class="comment">// slice长度</span></span><br><span class="line">	Capacity 	<span class="keyword">int</span> 		<span class="comment">// slice引用的array size</span></span><br><span class="line">	Elem 	 	*ElemType <span class="comment">// 指向slice第一个元素array中的地址</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>比如:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 直接创建slice 等价于:</span></span><br><span class="line"><span class="comment">// tmp := [5]int&#123;2,3,5,7,11&#125;</span></span><br><span class="line"><span class="comment">// a := tmp[0:5]</span></span><br><span class="line">a := []<span class="keyword">int</span>&#123;<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">11</span>&#125;</span><br><span class="line">b := a[<span class="number">1</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<p>此时a,b的sliceHeader示意图为:</p>
<p><img src="/assets/image/201609/go-slice-implement.png" alt=""></p>
<p>由于slice b在slice a中的起始偏移为1，因此 cap(b) = cap(a)-1 = 4。但b只能访问到a[1],a[2]两个元素:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 尝试访问&gt;=length(2)的元素，会触发panic error</span></span><br><span class="line">fmt.Println(b[<span class="number">2</span>])</span><br><span class="line"><span class="comment">// 等价于 c := b[0:len(b)] c和b引用完全相同的数组切片</span></span><br><span class="line">c := b[:]</span><br><span class="line"><span class="comment">// 虽然b只能访问数组[1],[2]两个元素，但d可以在[0,cap(b)]再次切片扩展引用的数组范围</span></span><br><span class="line">d := b[<span class="number">0</span>:<span class="built_in">cap</span>(b)]</span><br><span class="line">fmt.Println(d[<span class="number">3</span>]) <span class="comment">// 11</span></span><br></pre></td></tr></table></figure>
<p>那么slice这种数组切片的概念，究竟带来了什么好处？比如我们有一个操作，要去掉数组的首尾元素，在C中，我们会创建(动态分配)一个新数组，然后将arr[1,n-1)拷贝出来。在C++中，有vector会方便一些，但移除元素会导致后续元素移动拷贝开销。而在Go中，<code>slice = slice[1:len(slice)-1]</code>即可完成操作，这中间不会涉及到内存分配，移动拷贝等，是个非常高效的操作。当然，由于slice是引用的数组元素，因此slice修改数组元素时，对其它引用到该元素的slice也是可见的。</p>
<p>下面来说说slice的值语义。前面提到的sliceHeader，实际就是slice的值语义，我们创建一个slice，在底层就创建了一个sliceHeader结构体。在参数传递时，将会拷贝sliceHeader，但由于sliceHeader中持有指针，因此在调用函数内可修改数组元素，但无法修改sliceHeader结构体的成员值：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Extend</span><span class="params">(slice []<span class="keyword">int</span>, element <span class="keyword">int</span> )</span></span>&#123;</span><br><span class="line">	n := <span class="built_in">len</span>(slice)</span><br><span class="line">	slice = slice[<span class="number">0</span> : n+<span class="number">1</span>] <span class="comment">// 不会影响到传入的slice的length</span></span><br><span class="line">	slice[n] = element <span class="comment">// 修改了数组内容，对传入的slice可见</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再次摘录一段<a href="https://blog.golang.org/slices">golang blog</a>关于slice值语义的描述:</p>
<blockquote>
<blockquote>
<p>It’s important to understand that even though a slice contains a pointer, it is itself a value. Under the covers, it is a struct value holding a pointer and a length. It is not a pointer to a struct.</p>
</blockquote>
</blockquote>
<p>BTW，在Go里面的参数传递都是值传递的，只是针对各种类型，其值语义不同，比如int,array它们的值语义就是数据本身，不包含对外的引用(指针)，因此在传参时会完整拷贝整个数据，当然，这里的拷贝是浅拷贝，比如对指针数组这类结构而言，仍然是有副作用的，但这是应用层的东西，就数组容器本身而言，是值拷贝的。而对slice来说，其值语义中包含对数组的引用，因此在传参时，其引用内容可能被修改，但其值语义(sliceHeader)本身仍然是完整拷贝的。</p>
<h4 id="动态数组"><a href="#动态数组" class="headerlink" title="动态数组"></a>动态数组</h4><p>前面提到slice本质上是数组切片，但slice本身也可以作为动态数组:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	a := [<span class="number">5</span>]<span class="keyword">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;</span><br><span class="line">	s := a[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">	fmt.Println(<span class="string">&quot;cap: &quot;</span>,<span class="built_in">cap</span>(s),<span class="string">&quot;len: &quot;</span>,<span class="built_in">len</span>(s),<span class="string">&quot;slice: &quot;</span>,s,<span class="string">&quot;array: &quot;</span>,a)</span><br><span class="line">	<span class="comment">// len=3 cap=5 capacity足够 无需重新分配 因此修改会作用于a之上</span></span><br><span class="line">	s = <span class="built_in">append</span>(s, <span class="number">6</span>, <span class="number">7</span>)</span><br><span class="line">	fmt.Println(<span class="string">&quot;cap: &quot;</span>,<span class="built_in">cap</span>(s),<span class="string">&quot;len: &quot;</span>,<span class="built_in">len</span>(s),<span class="string">&quot;slice: &quot;</span>,s,<span class="string">&quot;array: &quot;</span>,a)</span><br><span class="line">	<span class="comment">// len=5 cap=5 append通过make()重新分配新的slice 并通过copy()拷贝已有元素</span></span><br><span class="line">	<span class="comment">// 此后s不再指向a 而指向新分配的连续内存空间</span></span><br><span class="line">	s = <span class="built_in">append</span>(s, <span class="number">8</span>)</span><br><span class="line">	fmt.Println(<span class="string">&quot;cap: &quot;</span>,<span class="built_in">cap</span>(s),<span class="string">&quot;len: &quot;</span>,<span class="built_in">len</span>(s),<span class="string">&quot;slice: &quot;</span>,s,<span class="string">&quot;array: &quot;</span>,a)</span><br><span class="line">	<span class="comment">// 对s的修改将不在作用于a上</span></span><br><span class="line">	s[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">	fmt.Println(<span class="string">&quot;cap: &quot;</span>,<span class="built_in">cap</span>(s),<span class="string">&quot;len: &quot;</span>,<span class="built_in">len</span>(s),<span class="string">&quot;slice: &quot;</span>,s,<span class="string">&quot;array: &quot;</span>,a)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出:</span></span><br><span class="line"><span class="built_in">cap</span>:  <span class="number">5</span> <span class="built_in">len</span>:  <span class="number">3</span> slice:  [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>] array:  [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]</span><br><span class="line"><span class="built_in">cap</span>:  <span class="number">5</span> <span class="built_in">len</span>:  <span class="number">5</span> slice:  [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">6</span> <span class="number">7</span>] array:  [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">6</span> <span class="number">7</span>]</span><br><span class="line"><span class="built_in">cap</span>:  <span class="number">10</span> <span class="built_in">len</span>:  <span class="number">6</span> slice:  [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span>] array:  [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">6</span> <span class="number">7</span>]</span><br><span class="line"><span class="built_in">cap</span>:  <span class="number">10</span> <span class="built_in">len</span>:  <span class="number">6</span> slice:  [<span class="number">0</span> <span class="number">2</span> <span class="number">3</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span>] array:  [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">6</span> <span class="number">7</span>]</span><br></pre></td></tr></table></figure>
<p>append会在<strong>len(s)+添加的元素个数&gt;cap(s)时</strong>，重新分配(make)一个slice，拷贝(copy)已有元素，添加新元素，最后返回这个新的slice。在使用append时，需要保存其返回值，因为append传入的是slice的值，也就是sliceHeader结构体，当slice capacity扩展时，append函数内不能修改sliceHeader中的Length和Capacity字段，因此需要返回一个新的sliceHeader。</p>
<p>为了避免混淆，不要像上例一样将slice的切片特性和动态数组特性混用，使用动态数组时，使用空的slice(<code>var s []int</code>)或make(<code>make([]int, len, cap)</code>)初始化一个slice会比较好。</p>
<h3 id="3-string"><a href="#3-string" class="headerlink" title="3. string"></a>3. string</h3><p>Go中的string更像是C中的字符串字面量，而不是字符数组：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">str := <span class="string">&quot;Hello, 世界&quot;</span></span><br><span class="line"><span class="comment">//str[0] = &#x27;X&#x27; // error 不可改变字符串(类似字面常量)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 字符串可通过 + 进行拼接</span></span><br><span class="line">str += <span class="string">&quot; !&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 以ANSI字符遍历 ch是一个byte n=15(每个中文在UTF-8中占3个字节)</span></span><br><span class="line">n := <span class="built_in">len</span>(str)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i&lt; n; i++ &#123;</span><br><span class="line">    ch := str[i]</span><br><span class="line">    fmt.Println(i, ch)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 以Unicode字符遍历 ch是一个rune 而不是byte 此时遍历得到11个Unicode字符</span></span><br><span class="line"><span class="keyword">for</span> i, ch := <span class="keyword">range</span> str&#123;</span><br><span class="line">    fmt.Println(i, ch)                </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在实现上，string是个read-only byte slice，另外，string的”sliceHeader”没有capacity字段：</p>
<p><img src="/assets/image/201609/go-string-implement.png" alt=""></p>
<pre><code>s := &quot;hello&quot;
t := s[2:3] // &quot;l&quot;
v := t[0:2] // 没有capacity字段，无法扩展，触发panic error: out of range
</code></pre><p>由于string的slice特性，len(s)操作非常高效，字符串切割也给代码处理带来很高的灵活度，如官方runtime/string.go的atoi函数是这样写的:</p>
<pre><code>func atoi(s string) int&#123;
    n := 0
       for len(s) &gt; 0 &amp;&amp; &#39;0&#39; &lt;= s[0] &amp;&amp; s[0] &lt;= &#39;9&#39; &#123;
        n = n*10 + int(s[0]) - &#39;0&#39;
        s = s[1:]
    &#125;
    return n
&#125;
</code></pre><p>PS，slice的这种切片特性，与Erlang的<a href="http://wudaijun.com/2015/12/erlang-datastructures/#refc-bianry">refc binary和sub binary</a>实现有相似之处，这种高效的处理方案有个老大难问题，那就是slice string未释放，那么它引用的string本身也不会被GC，哪怕只引用了很小一部分。</p>
<h3 id="4-map"><a href="#4-map" class="headerlink" title="4. map"></a>4. map</h3><p>map通过hash表实现，实现位于runtime/hashmap.go，以下是主要字段:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span>(</span><br><span class="line">	bucketCntBits = <span class="number">3</span></span><br><span class="line">	bucketCnt     = <span class="number">1</span> &lt;&lt; bucketCntBits</span><br><span class="line">)</span><br><span class="line"><span class="keyword">type</span> hmap <span class="keyword">struct</span> &#123;</span><br><span class="line">	count <span class="keyword">int</span> <span class="comment">// # live cells == size of map.  Must be first (used by len() builtin)</span></span><br><span class="line">	flags <span class="keyword">uint8</span></span><br><span class="line">	B     <span class="keyword">uint8</span>  <span class="comment">// log_2 of # of buckets (can hold up to loadFactor * 2^B items)</span></span><br><span class="line"></span><br><span class="line">	buckets    unsafe.Pointer <span class="comment">// array of 2^B Buckets. may be nil if count==0.</span></span><br><span class="line">	oldbuckets unsafe.Pointer <span class="comment">// previous bucket array of half the size, non-nil only when growing</span></span><br><span class="line">	</span><br><span class="line">	evacuate  <span class="keyword">uintptr</span>        <span class="comment">// progress counter for evacuation (buckets less than this have been evacuated)</span></span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="comment">// A bucket for a Go map.</span></span><br><span class="line"><span class="keyword">type</span> bmap <span class="keyword">struct</span> &#123;</span><br><span class="line">	tophash [bucketCnt]<span class="keyword">uint8</span></span><br><span class="line">	<span class="comment">// Followed by bucketCnt keys and then bucketCnt values.</span></span><br><span class="line">	<span class="comment">// Followed by an overflow pointer.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>摘自源码注释：</p>
<blockquote>
<blockquote>
<p>A map is just a hash table.  The data is arranged into an array of buckets.  Each bucket contains up to 8 key/value pairs.  The low-order bits of the hash are used to select a bucket.  Each bucket contains a few high-order bits of each hash to distinguish the entries within a single bucket.</p>
<p>If more than 8 keys hash to a bucket, we chain on extra buckets.</p>
<p>When the hashtable grows, we allocate a new array of buckets twice as big.  Buckets are incrementally copied from the old bucket array to the new bucket array.</p>
</blockquote>
</blockquote>
<p>hmap的buckets数组大小为2^B，通过取余(<code>hash(key)&amp;(1&lt;&lt;B-1)</code>)可得到key对应的bucket在buckets数组中的下标，每个bucket可以容纳2^bucketCntBits=8个key/value对，落到该桶的key个数超过8个时，会在堆上分配一个新的bucket，并挂在链表末，因此go hashmap通过链表(8个元素一组)来解决hash碰撞问题。</p>
<p>go的hash map使用的是可扩展hash算法，在负载因子loadFactor(<code>hmap.count/(1&lt;&lt;B)</code>)大于某个值(这个值太大会导致overflow buckets过多，查找效率降低，过小会浪费存储空间，经源码作者测试确认为6.5)时，进行hash扩展。此时B=B&lt;&lt;1，原有buckets由oldbuckets指向，新的buckets重新分配，此时由于hash表大小变更，部分key得到的buckets下标也会改变，因此需要将oldbuckets中的数据按照新的hash表大小重新迁移(evacuate)，出于效率考虑，这个操作是增量进行的，在hash map每次写入时，都会尝试迁移两个bucket(以及后续overflow bucket)，一个是写入的目标bucket(局部迁移)，一个是hmap.evacuate指向的bucket(增量迁移)，这样兼顾局部性和全局性，同时也能保证在新的buckets loadFacotr到达6.5前，所有迁移工作一定能完成。迁移工作完成后，oldbucket置为nil。PS: hash map通过bucket的tophash[0]来标记bucket的迁移状态，保留的标记值为0-3，key的tophash在这个范围内时，会被+4修正</p>
<p>上述是基于go1.5 hashmap实现，在go1.8中，添加了sameSizeGrow，当overflow buckets的数量超过一定数量(2^B)而负载未大于阀值6.5时，此时可能存在部分空的bucket，即bucket未有效利用，这时会触发sameSizeGrow，即B不变，但走数据迁移流程，将oldbuckets的数据重新紧凑排列提高bucket的利用率。当然在sameSizeGrow过程中，不能触发loadFactorGrow。</p>
<p>下面来看个结构图:</p>
<p><img src="/assets/image/201609/go-map-implement.png" alt=""></p>
<p>再来看Key查找过程(简化版):</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// From go 1.8.1 src/runtime/hashmap.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapaccess1</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span> <span class="title">unsafe</span>.<span class="title">Pointer</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> h == <span class="literal">nil</span> || h.count == <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> unsafe.Pointer(&amp;zeroVal[<span class="number">0</span>])</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 并发检查 go hashmap不支持并发访问</span></span><br><span class="line">	<span class="keyword">if</span> h.flags&amp;hashWriting != <span class="number">0</span> &#123;</span><br><span class="line">		throw(<span class="string">&quot;concurrent map read and map write&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	alg := t.key.alg</span><br><span class="line">	hash := alg.hash(key, <span class="keyword">uintptr</span>(h.hash0))</span><br><span class="line">	m := <span class="keyword">uintptr</span>(<span class="number">1</span>)&lt;&lt;h.B - <span class="number">1</span></span><br><span class="line">	b := (*bmap)(add(h.buckets, (hash&amp;m)*<span class="keyword">uintptr</span>(t.bucketsize)))</span><br><span class="line">	<span class="comment">// step1: 找到bucket</span></span><br><span class="line">	<span class="comment">// 如果oldbuckets未迁移完成 则找打oldbuckets中对应的bucket(低B-1位)</span></span><br><span class="line">	<span class="comment">// 否则为buckets中的bucket(低B位)</span></span><br><span class="line">	<span class="keyword">if</span> c := h.oldbuckets; c != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> !h.sameSizeGrow() &#123;</span><br><span class="line">			m &gt;&gt;= <span class="number">1</span></span><br><span class="line">		&#125;</span><br><span class="line">		oldb := (*bmap)(add(c, (hash&amp;m)*<span class="keyword">uintptr</span>(t.bucketsize)))</span><br><span class="line">		<span class="keyword">if</span> !evacuated(oldb) &#123;</span><br><span class="line">			b = oldb</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	top := <span class="keyword">uint8</span>(hash &gt;&gt; (sys.PtrSize*<span class="number">8</span> - <span class="number">8</span>))</span><br><span class="line">	<span class="keyword">if</span> top &lt; minTopHash &#123;</span><br><span class="line">		top += minTopHash</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// step2: 比较tophash</span></span><br><span class="line">		<span class="keyword">for</span> i := <span class="keyword">uintptr</span>(<span class="number">0</span>); i &lt; bucketCnt; i++ &#123;</span><br><span class="line">			<span class="keyword">if</span> b.tophash[i] != top &#123;</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// dataOffset为key数组在bucket(bmap结构)中的起始偏移</span></span><br><span class="line">			k := add(unsafe.Pointer(b), dataOffset+i*<span class="keyword">uintptr</span>(t.keysize))</span><br><span class="line">			<span class="keyword">if</span> t.indirectkey &#123;</span><br><span class="line">				k = *((*unsafe.Pointer)(k))</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// step3: 比较key</span></span><br><span class="line">			<span class="keyword">if</span> alg.equal(key, k) &#123;</span><br><span class="line">				v := add(unsafe.Pointer(b), dataOffset+bucketCnt*<span class="keyword">uintptr</span>(t.keysize)+i*<span class="keyword">uintptr</span>(t.valuesize))</span><br><span class="line">				<span class="keyword">if</span> t.indirectvalue &#123;</span><br><span class="line">					v = *((*unsafe.Pointer)(v))</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">return</span> v</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		b = b.overflow(t)</span><br><span class="line">		<span class="keyword">if</span> b == <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> unsafe.Pointer(&amp;zeroVal[<span class="number">0</span>])</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>限于理解深度，其它一些细节没有提到，比如对不含pointer的key/value优化，另外，go map还针对常用key类型(如int32,int64,string)进行了特例优化，代码位于src/runtime/hashmap_fast.go。以下是上面已经提到的一些小的优化细节：</p>
<ul>
<li>key value采用k1,k2,..v1,v2,…排列，而不是k1,v1,k2,v2，这是出于内存对齐考虑，节约空间</li>
<li>tophash可用于加快key的查找，同时用于标记key的迁移状态</li>
<li>map大小是2的幂，因此hash值可快速求余: hash(key)&amp;(1&lt;&lt;B-1)</li>
<li>hash map的增量式扩展，sameSizeGrow</li>
</ul>
<p>其它:</p>
<ul>
<li>go map不支持并发</li>
<li>go map目前只有扩展 没有收缩操作(shrink)</li>
<li>go map迁移时，会创建新的bucket，而不会复用oldbucket中的overflow bucket(作者TODO里面)</li>
</ul>
<p>值语义：如hmap结构体所示，buckets为bucket指针数组，那么对key,value的操作都是引用语义的。</p>
<h3 id="5-channel"><a href="#5-channel" class="headerlink" title="5. channel"></a>5. channel</h3><p>channel是goroutine用于数据交互的通道，和Erlang的Actor以通信实体为第一类对象不同(Actor模型)，Go以通信介质作为第一类对象(CSP模型)，channel支持多写入者和读取者，并且可通过缓冲来实现同步/异步(一定数量)通信。</p>
<p>在实现上，channel其实就是个消息队列：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 省略部分字段</span></span><br><span class="line"><span class="keyword">type</span> hchan <span class="keyword">struct</span> &#123;</span><br><span class="line">	qcount   <span class="keyword">uint</span>           <span class="comment">// total data in the queue</span></span><br><span class="line">	dataqsiz <span class="keyword">uint</span>           <span class="comment">// size of the circular queue</span></span><br><span class="line">	buf      unsafe.Pointer <span class="comment">// points to an array of dataqsiz elements</span></span><br><span class="line">	elemsize <span class="keyword">uint16</span></span><br><span class="line">	closed   <span class="keyword">uint32</span></span><br><span class="line">	elemtype *_type <span class="comment">// element type</span></span><br><span class="line">	sendx    <span class="keyword">uint</span>   <span class="comment">// send index</span></span><br><span class="line">	recvx    <span class="keyword">uint</span>   <span class="comment">// receive index</span></span><br><span class="line">	recvq    waitq  <span class="comment">// list of recv waiters</span></span><br><span class="line">	sendq    waitq  <span class="comment">// list of send waiters</span></span><br><span class="line">	lock mutex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下图描述了一个缓冲区大小为5，并阻塞了若干读goroutine的情况:</p>
<p><img src="/assets/image/201609/go-chan-implement.png" alt=""></p>
<p>该图省略了hchan和sudog的部分字段，waitq在实现上是双向链表，虽然实际只会用到单链表语义(FIFO)。</p>
<p>根据上图情形，此时如果有其它goroutine写入channel:</p>
<ol>
<li>从recvq中pop第一个读写者的sudog</li>
<li>将写入channel的数据拷贝到该sudog的elem字段</li>
<li>唤醒该读写者goroutine(sudog.g)</li>
</ol>
<p>当recvq队列为空，此时写入:</p>
<ol>
<li>将写入的数据缓存到buff[sendx]</li>
<li>sendx环形自增，qcount++</li>
</ol>
<p>当buff缓冲区写满(qcount==dataqsiz)，此时写入:</p>
<ol>
<li>为写入者创建一个sudog，并插入到sendq队列末</li>
<li>挂起该写入者goroutine</li>
</ol>
<p>如果此时有goroutine再次读channel:</p>
<ol>
<li>从buf[recvx]读取第一个数据</li>
<li>从sendq中pop第一个阻塞的写入者goroutine(sudog)</li>
<li>将该sudog中的elem字段数据拷贝到buf[recvx]，相当于将elem数据push到buf末尾</li>
<li>recvx++</li>
<li>唤醒该发送者goroutine</li>
</ol>
<p>没有缓冲的channel(dataqsize==0)操作要简单一些，写入时如果recvq-&gt;first!=nil，则直接拷贝数据到读取者的elem字段，否则将写入者挂起。反之，读写过程也类似。</p>
<p>另外，由于一个goroutine读写多个channel，因此go提供语言级别的select，用于处理异步IO问题。这其实本质上仍然是尝试对channel进行读写操作(chanrecv)，只不过由block参数为false表明该读写不阻塞，当读写操作需要挂起时，立即返回false。而select操作本身其实就是个多分支的if-elseif-else表达式:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">src/runtime/<span class="keyword">chan</span>.<span class="keyword">go</span></span><br><span class="line"><span class="comment">// compiler implements</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//	select &#123;</span></span><br><span class="line"><span class="comment">//	case c &lt;- v:</span></span><br><span class="line"><span class="comment">//		... foo</span></span><br><span class="line"><span class="comment">//	default:</span></span><br><span class="line"><span class="comment">//		... bar</span></span><br><span class="line"><span class="comment">//	&#125;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// as</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//	if selectnbsend(c, v) &#123;</span></span><br><span class="line"><span class="comment">//		... foo</span></span><br><span class="line"><span class="comment">//	&#125; else &#123;</span></span><br><span class="line"><span class="comment">//		... bar</span></span><br><span class="line"><span class="comment">//	&#125;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">selectnbsend</span><span class="params">(t *chantype, c *hchan, elem unsafe.Pointer)</span> <span class="params">(selected <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> chansend(t, c, elem, <span class="literal">false</span>, getcallerpc(unsafe.Pointer(&amp;t)))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>select的if-elseif-else语句分支顺序是随机的，在每次执行select时会将所有scase(包含hchan)顺序随机排列。参考src/runtime/select.go hselect和scase结构体。</p>
<p>通过<code>cap(chan)</code>和<code>len(chan)</code>可以获取channel的缓冲区大小(dataqsize)和当前消息数量(qcount)。</p>
<h3 id="6-interface"><a href="#6-interface" class="headerlink" title="6. interface"></a>6. interface</h3><p>interface接口的用法和实现放到<a href="http://wudaijun.com/2016/09/go-notes-3-object-oriented/">go面向对象</a>和<a href="http://wudaijun.com/2018/01/go-interface-implement/">go interface实现</a>中。</p>
<h3 id="7-make-amp-new"><a href="#7-make-amp-new" class="headerlink" title="7. make &amp; new"></a>7. make &amp; new</h3><p>go中有make和new两个关键字用于分配一个对象，简要提一下两者的区别：</p>
<p>内建函数 new 用来分配内存，它的第一个参数是一个类型，不是一个值，它的返回值是一个指向新分配类型<strong>零值</strong>的指针</p>
<p>内建函数 make 用来为 slice，map 或 chan 类型分配内存和<strong>初始化</strong>一个对象(目前只能用于这三种类型)，跟 new 类似，第一个参数也是一个类型而不是一个值，跟 new 不同的是，make 返回类型的引用而不是指针，而返回值也依赖于具体传入的类型，具体使用如下：</p>
<pre><code>// 等价于 a := [capacity]int&#123;&#125;  s := a[0:2]
s := make([]int, length [,capacity])
m := make(map[int]string [,size])
c := make(chan int, [,length])
</code></pre><h3 id="8-常量"><a href="#8-常量" class="headerlink" title="8. 常量"></a>8. 常量</h3><p>Go中的常量是无类型的，字面常量(如：3.14, “ok”)是无类型的，可以赋给任何满在其值域中的类型。Go预定义了三个常量：true, false, iota，其中iota是一个可以被编译器修改的常量，它代表一个整数，在每个const出现时被重置为0，然后iota每出现一次，其所代表的值即自增一次。iota通常用来定义枚举值，这类值应用程序不关心具体数值，只需确保其在同一个const枚举声明中不会冲突即可。</p>
<pre><code>const (
    c0 = iota    // c0 == 0
    c1 = iota    // c1 == 1
    c2 = iota    // c2 == 2
)
// 根据枚举定义相同表达式的缩写，等价于
const (
    c0 = iota    // c0 == 0
    c1            // c1 == 1
    c2            // c2 == 2
)
</code></pre>]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>开发笔记(7) 记线上一次回档BUG</title>
    <url>/2016/10/erlang-server-design7-cluster-bug-note/</url>
    <content><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>有十几个玩家报告被回档，几小时到一两天不等</p>
<h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>在我们的<a href="http://wudaijun.com/2016/01/erlang-server-design5-server-node/">集群架构</a>中，集群有若干GS节点，每个GS节点可部署N个GS服务器，整个集群所有的玩家进程注册于cluster，我们通过为每个服开一个player_mgr来维护单服玩家状态，player_mgr维护{player_id, agent_pid, player_pid}三元组，用户处理多点登录，单服逻辑，离线玩家LRU等。cluster本身只提供服务注册/注销，如果做服务替换(如agent)，确保服务的唯一性(如player)应该由外部逻辑来确保，cluster并不知晓内部各种服务的特性。player进程启动/终止时，会向player_mgr和cluster分别注册/注销自己。</p>
<span id="more"></span>
<h3 id="问题追踪"><a href="#问题追踪" class="headerlink" title="问题追踪"></a>问题追踪</h3><ol>
<li>error日志中出现几十个rewrite player process(重写cluster中player服务)的错误日志，并且这些玩家基本都属于一个公会</li>
<li>所有玩家进程的启动(login, get_fork)均由player_mgr控制，player_mgr确保玩家进程唯一，依赖的是自身的State数据，而不是cluster，问题可能出在player_mgr 和 cluster 状态不一致上</li>
<li>写了个检查脚本，查出仍有有个别玩家存在于cluster而不在player_mgr中，这类玩家在get_fork或login时，player_mgr会重新开一个player进程，导致rewrite player process，此时同一时刻就存在两个player进程(老玩家进程Pid0，新玩家进程Pid1)，已有Agent消息会被重新路由(通过cluster服务查找)到Pid1进程上，而Pid0不在cluster和player_mgr中，不会被终止，但会不断写盘，称第三方进程，这是导致玩家回档的根本原因</li>
<li>现在问题焦点：为什么player_mgr维护的数据和cluster不一致(比cluster少)</li>
<li>在player_mgr LRU剔除玩家进程时，是先在自己State中删除玩家进程，再cast消失让玩家进程终止，最后在player_server:terminate中，再向player_mgr和cluster注销自己。那么存在这样一种情况：player_mgr LRU剔除玩家进程Pid0到 player_server:terminate从cluster中注销自己之间，新的login或get_fork请求到来，此时player_mgr再启动了Pid1，并且rewrite player process，那么当Pid0 terminate时，检查到cluster中当前服务不是自己，不会更新cluster，之后，Pid0还会向player_mgr注销自己，并且没有带上Pid进行Pid检查，因此将Pid1从player_mgr中删除了！至此，player_mgr和cluster出现了不一致，cluster中存在Pid1程，而player_mgr中没有。下一次玩家login或get_fork一个新的Pid2时，Pid1被rewrite，Pid1也就成了第三方进程</li>
<li>上面的概率看起来很小，但由于公会等组逻辑，可能导致N个玩家同时被get_fork起来，而LRU又是player_mgr统一定期(10分钟)清理的，因此如果alliance前后10分钟get_fork两次，问题出现的概率就被放大了，这也是本次出问题的玩家基本都在一个公会的原因</li>
</ol>
<h3 id="问题来源"><a href="#问题来源" class="headerlink" title="问题来源"></a>问题来源</h3><ol>
<li>player_mgr在没有确认玩家进程已经退出时(此时可能还有一堆消息没处理完)，就删除了它</li>
<li>玩家进程在向player_mgr注销自己时，没有做Pid检查，注销了其它进程(没有考虑容错)</li>
</ol>
<h3 id="问题修复"><a href="#问题修复" class="headerlink" title="问题修复"></a>问题修复</h3><p>线上热更的方案：</p>
<ol>
<li>player_mgr和cluster均在player terminate时才确认注销</li>
<li>服务注销时做Pid检查</li>
<li>在玩家进程定期存盘时检查其cluster和player_mgr状态，并stop掉第三方进程</li>
</ol>
<h3 id="问题反思"><a href="#问题反思" class="headerlink" title="问题反思"></a>问题反思</h3><p> 本质上来说，这次的问题源于：</p>
<ol>
<li>数据冗余导致短暂的不一致状态(player_mgr和cluster不一致)</li>
<li>在这种不一致状态下的特定事件(player login/get_fork)，导致不一致的影响被放大(存在第三方玩家进程)</li>
<li>对这种不一致状态缺乏检查和处理，导致BUG(玩家回档)</li>
</ol>
<p>在Code Review的过程中，还发现一些其它并发和异步问题。在多Actor异步交互模型中，调度时序，网络时延都可能导致状态不一致。在分布式系统中，想要从根本上杜绝不一致，是几乎不可能的(我们对同步和事务非常敏感)，因此我们不只是要从问题预防上考虑，还要从错误恢复上着手，让系统具备一定程度的”自愈能力”：</p>
<p>预防：减少不一致的可能性</p>
<ol>
<li>减少数据冗余，将cluster作为数据的第一参照，player_mgr的优先级降低，并只用于全服逻辑</li>
<li>简化player_mgr的功能，如将离线玩家的LRU移到player自身去管理</li>
</ol>
<p>恢复：检查并修复不一致</p>
<ol>
<li>在服务启动/运行/终止时，加上检查和修复机制，并记录日志</li>
<li>跑定时脚本检查player_mgr和cluster的一致性，并予以临时修复和报警</li>
</ol>
<p>最后，总结出的经验是，在分布式系统中，对问题的检查和修复，和问题的预防同样重要。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>erlang</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 学习</title>
    <url>/2016/11/docker-basic/</url>
    <content><![CDATA[<h2 id="一-理解-Docker"><a href="#一-理解-Docker" class="headerlink" title="一. 理解 Docker"></a>一. 理解 Docker</h2><p>Docker是一种轻量级的虚拟化方案，虚拟化本身可以从两个角度来理解：</p>
<ul>
<li>隔离性：可传统的虚拟机类似，资源隔离(进程，网络，文件系统等)可用于更好地利用物理机。Docker本身虚拟化的开销非常小，这也是它相对于传统虚拟机最大的优势</li>
<li>一致性：同样一份虚拟机镜像，可以部署在不同的平台和物理机上，并且内部的环境，文件，配置是一致的，这在当前多样化的平台，日益复杂的配置/部署流程，以及团队和团队间的协作中，有着重要的意义。想象一下，当你用Docker提交代码时，你做的事情跟以前是完全不同的。在以前我们只是把代码提交上去，而在Docker中我们把整台计算机（虚拟机）提交上去。为什么Docker这么火，就是因为它帮助开发者很简单的就让自己的开发环境跟生产环境一致。环境的标准化，意味着目录、路径、配置文件、储存用户名密码的方式、访问权限、域名等种种细节的一致和差异处理的标准化。</li>
</ul>
<span id="more"></span>
<p>Docker和其它虚拟机或容器技术相比，一是轻量，开销很小，二是发展迅速， 平台兼容性增长很快。虽然Docker的应用场景很多，但都是基于虚拟化和容器技术的这两种特性在特定问题下提出的解决方案。</p>
<p>下面来看看Docker的基本概念：</p>
<ol>
<li>Docker是C/S模式的，包括docker CLI和docker daemon两部分，它们之间通过RESTful API交互，Docker CLI就是我们用的docker命令</li>
<li>镜像(Image)：是一个只读的模板，包含了系统和运行程序，是用于创建容器的一系列指令(Dockfile)，相当于一份虚拟机的磁盘文件。</li>
<li>容器(Container)：当镜像启动后就转化为容器，容器是运行着的镜像，在容器内的修改不会影响镜像，程序的写入操作都保存在容器中。容器可被启动，停止和删除，由docker daemon管理。</li>
<li>仓库(Registry)：Docker镜像可通过公有和私有的仓库来进行共享和分发，仓库是存放和分享镜像文件的场所，功能类似于Github。Docker仓库有免费的<a href="http://hub.docker.com/">Docker Hub</a>和付费的<a href="https://store.docker.com/">Docker Store</a>。</li>
</ol>
<h2 id="二-Docker-容器"><a href="#二-Docker-容器" class="headerlink" title="二. Docker 容器"></a>二. Docker 容器</h2><h3 id="1-容器操作"><a href="#1-容器操作" class="headerlink" title="1. 容器操作"></a>1. 容器操作</h3><p>通常我们都使用docker CLI和docker daemon交互完成docker操作，随着docker日渐完善，docker所提供的功能和参数也更复杂，以下只列举几个常用的。</p>
<pre><code>docker run [OPTIONS] IMAGE [COMMAND] [ARG...]
</code></pre><p>从镜像中创建并启动容器，常用Options有：</p>
<ul>
<li><code>-d</code>：后台运行</li>
<li><code>-t</code>：为容器分配一个伪终端，通常于-i一起使用</li>
<li><code>-i</code>：以交互模式运行容器，如果开了-i而没有指定-t，可以通过管道与容器交互</li>
<li><code>-v</code>：为容器挂载目录，冒号前为宿主机目录，其后为容器目录</li>
<li><code>-p</code>： [hip:]hport:cport 端口映射，将容器端口绑定到指定主机端口</li>
<li><code>--name</code>：为容器命名</li>
<li><code>--link</code>：链接到其它容器，之后可通过容器ID或容器名访问该容器(只针对bridge)</li>
<li><code>--ip</code>：指定容器的IP</li>
<li><code>--network</code>：配置容器的网络</li>
<li><code>--rm</code>：当容器退出时，删除容器</li>
</ul>
<p>完整的命令可通过<code>docker run --help</code>查看。</p>
<p>例如：</p>
<pre><code>docker run -it ubuntu:14.04 /bin/bash 
</code></pre><p>我们就以<code>ubuntu:14:04</code>镜像启动了一个容器，并进入到bash交互模式。docker所做的事情为，先在本地查找ubuntu镜像，如果没有，将从<a href="http://hub.docker.com/">Docker Hub</a>中拉取到本地，解析镜像文件，创建容器，并运行<code>/bin/bash</code>命令。</p>
<p>每个容器在创建时，docker daemon都会为其生成一个Container ID，容器在运行结束后，为<code>STOP</code>状态，可以通过Container ID或容器名字再次启动/停止或删除。可通过<code>docker ps</code>来查看容器状态。以下是其它常用的容器管理命令：</p>
<pre><code>// 查看容器， 默认只显示运行中的容器，-a选项可显示所有容器
docker ps [OPTIONS]
// 启动容器
docker start/stop [OPTIONS] CONTAINER [CONTAINER...]
// 停止容器
docker rm CONTAINER
// 把后台容器调到前端
docker attach [OPTIONS] CONTAINER
// 查询容器的详细信息，也可用于镜像
docker inspect [OPTIONS] CONTAINER/IMAGE
// 在容器内执行指定命令 如:  docker exec -it CONTAINER bash
docker exec [OPTIONS] CONTAINER COMMAND [ARG...]
也可使用第三方工具如nsenter来进入容器
</code></pre><h3 id="2-容器持久化"><a href="#2-容器持久化" class="headerlink" title="2. 容器持久化"></a>2. 容器持久化</h3><p>镜像是分层存储的，容器也一样，每一个容器以镜像为基础层，在其上构建一个当前容器的可读可写层，容器对文件的所有更改都基于这一层。容器的可读可写层的生命周期与容器一样，当容器消亡时，容器在可读可写层作出的任何更改都将丢失(容器不能对基础镜像作出任何更改)。</p>
<p>有几种方式可以持久化容器作出的更改:</p>
<ol>
<li>通过<code>docker commit</code>以镜像构建的方式将可读可写层提交为一个新的镜像(<code>docker commit</code>是<code>docker run</code>的逆操作)。这种方式并不推荐，因为手动commit构建的镜像没有Dockerfile说明，是”隐晦”的，使用者并不知道你对镜像作出了何种修改。</li>
<li>在运行容器时指定<code>docker run -v hostdir:containerdir</code>来将宿主机上的某个目录挂载到容器的指定目录下，这样容器对该目录作出的所有更改，都直接写入到宿主机上，效率也更高。这通常用于在容器中导出应用日志和数据，这样容器消亡后，日志和数据信息不会丢失。</li>
<li>通过网络IO，将数据持久化到其它地方，如mongo，redis等。</li>
</ol>
<p>我们在运行容器时，要尽量保证容器的运行是”无状态”的，即容器可以随时被终止而重要数据不会丢失。</p>
<h2 id="三-Docker-镜像"><a href="#三-Docker-镜像" class="headerlink" title="三. Docker 镜像"></a>三. Docker 镜像</h2><h3 id="1-Dockerfile"><a href="#1-Dockerfile" class="headerlink" title="1. Dockerfile"></a>1. Dockerfile</h3><p>Docker的镜像通过一个Dockerfile构建，我们可以通过编Dockerfile来创建自定义镜像：</p>
<pre><code># 这是注释
INSTRUCTION args
</code></pre><p>Dockerfile不区分大小写，但惯例是将指令大写，下面介绍几个Dockerfile中常用的指令：</p>
<h4 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h4><p>FROM命令必须是Dockerfile的第一条指令，用于指明基础镜像(镜像基础层)：</p>
<pre><code># 格式：FROM &lt;image&gt;[:&lt;tag&gt;]
FROM ubuntu:14:04
FROM erlang
</code></pre><h4 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h4><p>在当前镜像的顶层执行命令(比如安装一个软件包)，将执行结果commit到当前镜像层。</p>
<p>RUN有两种格式：</p>
<pre><code># shell 格式，相当于 /bin/sh -c &lt;command&gt;
# 意味着可以访问shell环境变量 如$HOME
RUN &lt;command&gt;
# exec 格式，推荐格式，直接执行命令，不会打开shell
# 这种格式更灵活，强大
RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]
# 以下两种写法完全等价
RUN echo &quot;hello&quot;
RUN [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo hello&quot;]
</code></pre><h4 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h4><p>CMD指令的主要目的是为容器提供默认值，这些默认值可以包含容器执行入口和参数，也可以只指定参数，这种情况下，容器入口由ENTRYPOINT指出。CMD有三种定义方式：</p>
<pre><code># exec 格式 指定了执行入口和参数
# 可被docker run &lt;image&gt;后的参数覆盖
CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]
# 当ENTRYPOINT存在时，exec格式退化为默认参数格式
# 此时CMD提供的参数将被附加到ENTRYPOINT指定的入口上
# 可被docker run &lt;image&gt;后的参数覆盖
CMD [&quot;param1&quot;, &quot;param2&quot;]
# shell 格式 这种格式不能为ENTRYPOINT提供默认参数  只能提供默认执行入口
# 会被ENTRYPOINT或docker run &lt;image&gt;指定的入口覆盖
CMD command param1 param2
</code></pre><p>Dockerfile中只能有一个CMD命令(如果有多个，只有最后一个生效)，如果CMD要作为ENTRYPOINT的默认参数(即第二种定义方式)，那么CMD和ENTRYPOINT都必须以Json数组的方式指定。</p>
<p>CMD和RUN的区别：RUN在<code>docker build</code>构建镜像时执行，将执行结果写入新的镜像层(实际上也是通过容器写入的，详见后面<code>docker build</code>命令)，而CMD在<code>docker run</code>时执行，执行结果不会写入镜像。</p>
<h4 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h4><p>ENTRYPOINT用于设置在容器启动时执行命令，ENTRYPOINT有两种定义方式：</p>
<pre><code># exec格式 推荐格式
ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]
# shell格式 以这种方式定义，CMD和docker run提供的参数均不能附加给command命令参数
ENTRYPOINT command param1 param2
</code></pre><p><code>docker run &lt;image&gt;</code>后面的参数将会附加在ENTRYPOINT指定的入口上，如：</p>
<pre><code>FROM ubuntu:14.04
ENTRYPOINT [&quot;echo&quot;, &quot;hello&quot;]
CMD [&quot;world&quot;]
</code></pre><p>构建镜像<code>docker build -t echo_img .</code>，之后如果我们以<code>docker run --rm echo_img</code>启动容器，CMD指定的默认参数将附加在ENTRYPOINT的入口上，因此相当于执行<code>echo hello world</code>。而如果我们以<code>docker run --rm echo_img wudaijun</code>启动容器，此时<code>docker run</code>提供的参数将覆盖CMD指定的默认参数，相当于执行<code>echo hello wudaijun</code>。</p>
<p>再举个例子：</p>
<pre><code>FROM ubuntu:14.04
CMD [&quot;echo&quot;, &quot;hello&quot;]
</code></pre><p>由于没有指定ENTRYPOINT，因此CMD指定了默认的执行入口<code>echo hello</code>，如果<code>docker run &lt;image&gt;</code>未指定任何参数，则执行<code>echo hello</code>，否则<code>docker run &lt;image&gt;</code>的参数将覆盖CMD指定的执行入口。如果我们再加上Dockerfile中再加一行<code>ENTRYPOINT [&quot;echo&quot;]</code>，并且<code>docker run &lt;image&gt;</code>后未指定参数，那么将执行<code>echo echo hello</code>，输出<code>echo hello</code>。</p>
<p>和CMD一样，ENTRYPOINT在Dockerfile中最多只能生效一个，如果定义了多个，只有最后一个生效，在docker run中可通过<code>docker run --entrypoint</code>覆盖ENTRYPOINT。</p>
<p>CMD和ENTRYPOINT的区别：CMD和ENTRYPOINT都可用于设置容器执行入口，但CMD会被<code>docker run &lt;image&gt;</code>后的参数覆盖；而ENTRYPOINT会将其当成参数附加给其指定的命令（不会对命令覆盖）。另外CMD还可以单独作为ENTRYPOINT的所接命令的可选参数。如果容器是Execuatble的，通常用法是，用ENTRYPOINT定义不常变动的执行入口和参数(exec格式)，用CMD提供额外默认参数(exec格式)，再用<code>docker run &lt;image&gt;</code>提供的参数来覆盖CMD。另外，ENTRYPOINT指定的入口也可以是shell script，用于实现更灵活的容器交互。</p>
<p>ENTRYPOINT，CMD，RUN在定义时，均推荐使用Json数组方式。参见<a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices">Dockerfile Best Practices</a></p>
<h4 id="Exec和Shell区别"><a href="#Exec和Shell区别" class="headerlink" title="Exec和Shell区别"></a>Exec和Shell区别</h4><p>前面提到的RUN, CMD, ENTRYPOINT都有两种定义方式: </p>
<pre><code># Exec定义 相当于直接执行: /bin/echo hello
ENTRYPOINT     echo hello
# Shell定义 相当于执行: /bin/sh -c &quot;echo hello&quot;
ENTRYPOINT     [&quot;echo&quot;, &quot;hello&quot;]
</code></pre><p>这两者除了前面所描述的使用方法的不同之外，本质上的区别是前者(Exec)的容器主进程(Pid=1)为命令本身，而后者(Shell)的容器主进程为/bin/sh，这会导致容器接收信号的进程不同，如<code>docker stop</code>与<code>docker kill</code>会向容器发送SIGTERM和SIGKILL信号，如果使用Shell方式启动命令，命令作为主进程/bin/sh的子进程将不能正确接收到信号。</p>
<p>因此，统一使用Exec是最佳实践，将容器看做一个进程，这个进程即为应用本身。</p>
<h4 id="其它命令"><a href="#其它命令" class="headerlink" title="其它命令"></a>其它命令</h4><pre><code>ENV: 定义环境变量，该变量可被后续其它指令引用，并且在生成的容器中同样有效
ADD: src dst 将本地文件拷贝到镜像，src可以是文件路径或URL，ADD支持自动解压tar文件
COPY: 和ADD类似，但不支持URL并且不能自动解压
EXPOSE: port, 指定容器在运行时监听的端口
WORKDIR: path, 指定容器的工作目录(启动之后的当前目录)
VOLUME: [path], 在容器中设置一个挂载点，用于挂载宿主机或其它容器的目录 
</code></pre><p>关于Dockerfile的语法参考<a href="https://docs.docker.com/engine/reference/builder/">Dockerfile Reference</a>。</p>
<h3 id="2-docker-build-原理"><a href="#2-docker-build-原理" class="headerlink" title="2. docker build 原理"></a>2. docker build 原理</h3><p><code>docker build</code>的核心机制包括<code>docker commit</code>和<code>build cache</code>两部分。</p>
<h4 id="docker-commit"><a href="#docker-commit" class="headerlink" title="docker commit"></a>docker commit</h4><p>写好Dockerfile之后，通过<code>docker build</code>即可构建镜像：</p>
<pre><code>docker build -t 镜像名[:tag]  Dockerfile所在目录或URL
</code></pre><p><code>docker build</code>将按照指令顺序来逐层构建镜像，每一条指令的执行结果将会commit为一个新的镜像层，并用于下一条指令。理解镜像层和commit的概念，是理解Docker镜像构建的关键。</p>
<p>镜像是被一层一层地”commit”上去的，而commit操作本身是由Docker容器执行的。<code>docker build</code>在执行一条指令时，会根据当前镜像层启动一个容器，Docker会在容器的层级文件系统最上层建立一层空的可读可写层(镜像层的内容对于容器来说是readonly的)，之后Docker容器执行指令，将执行结果写入可读可写层(并更新镜像Json文件)，最后再通过<code>docker commit</code>命令将可读可写层提交为一个新的镜像层。</p>
<p>Docker镜像层与镜像层之间是存在层级关系的，<code>docker build</code>会为Dockerfile每一条指令建立(commit)一个镜像层，并最终产生一个带标签(tag)的镜像，之前Dockerfile指令得到的镜像层(不会在构建完成后删除)是这个含标签镜像的祖先镜像。这样做的好处是最大化地复用镜像，不同的镜像之间可以共享镜像层，组成树形的镜像层级关系。</p>
<h4 id="build-cache"><a href="#build-cache" class="headerlink" title="build cache"></a>build cache</h4><p>在<code>docker build</code>过程中，如果发现本地有镜像与即将构建出来的镜像层一致时，则使用已有镜像作为Cache，充当本次构建的结果。从而加快build过程，并且避免构建重复的镜像。</p>
<p>那么docker是如何知道当前尚未构建的镜像的形态，并且与本地镜像进行比较呢？</p>
<p>Docker镜像由镜像文件系统内容和镜像Json文件两部分构成，前者即为<code>docker commit</code>提交的可读可写层，而镜像Json文件的作用为：</p>
<ul>
<li>记录镜像的父子关系，以及父子间的差异信息</li>
<li>弥补镜像本身以及镜像到容器转换所需的额外信息</li>
</ul>
<p>比如镜像Json文件中记录了当前镜像的父镜像，以及当前镜像与父镜像的差异(比如执行了哪条指令)，<code>docker build</code>则在这个基础上进行预测：</p>
<ul>
<li>判断已有镜像和目标镜像(当前正在构建的镜像)是父镜像ID是否相同</li>
<li>评估已有镜像的Json文件(如执行了那条命令，有何变动)，与目标镜像是否匹配</li>
</ul>
<p>如果条件满足，则可将已有镜像作为目标镜像的Cache，当然这种机制是并不完善的，比如当你执行的指令有外部动态依赖，此时可通过<code>docker build --no-cache</code>禁止使用Cache。</p>
<p>另外，基于build cache的机制，我们在写Dockerfile的时候，应该将静态安装，配置命令等尽可能放在Dockerfile前面，这样才能最大程度地利用cache，加快build过程。因为一旦Dockerfile前面有指令更新了并导致新的镜像层生成，那么该指令之后的镜像层cache也就完全失效了(树结构长辈节点更新了，子节点当然就不一样了)。</p>
<h3 id="3-docker-build-示例"><a href="#3-docker-build-示例" class="headerlink" title="3. docker build 示例"></a>3. docker build 示例</h3><p>Dcokerfile:</p>
<pre><code>FROM ubuntu:14.04
# 创建一个100M的文件 /test
RUN dd if=/dev/zero of=/test bs=1M count=100
RUN rm /test
RUN dd if=/dev/zero of=/test bs=1M count=100
# 在根目录统计容器大小
ENTRYPOINT [&quot;du&quot;, &quot;-sh&quot;]
</code></pre><p>build镜像：</p>
<pre><code>▶ docker build . 
Sending build context to Docker daemon   599 kB
Step 1 : FROM ubuntu:14.04
 ---&gt; 1e0c3dd64ccd
Step 2 : RUN dd if=/dev/zero of=/test bs=1M count=100
 ---&gt; Running in d98f674c46f2
100+0 records in
100+0 records out
104857600 bytes (105 MB) copied, 0.0980112 s, 1.1 GB/s
 ---&gt; f3a606172d91
Removing intermediate container d98f674c46f2
Step 3 : RUN rm /test
 ---&gt; Running in 14544c0dc6a0
 ---&gt; 7efc0655e95d
Removing intermediate container 14544c0dc6a0
Step 4 : RUN dd if=/dev/zero of=/test bs=1M count=100
 ---&gt; Running in 387be027ef2f
100+0 records in
100+0 records out
104857600 bytes (105 MB) copied, 0.0852024 s, 1.2 GB/s
 ---&gt; 38e3ea5c1412
Removing intermediate container 387be027ef2f
Step 5 : ENTRYPOINT du -sh
 ---&gt; Running in e190adcbcce2
 ---&gt; baec9103f182
Removing intermediate container e190adcbcce2
Successfully built baec9103f182
</code></pre><p>可以看到build过程为不断基于当前镜像启动中间容器(如d98f674c46f2容器基于1e0c3dd64ccd镜像层执行指令<code>RUN dd if=/dev/zero of=/test bs=1M count=100</code>并提交f3a606172d91镜像层)。通过<code>docker history &lt;image&gt;</code>可查看镜像层级关系：</p>
<pre><code>docker history baec9103f182                                                                                
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
baec9103f182        4 minutes ago       /bin/sh -c #(nop)  ENTRYPOINT [&quot;du&quot; &quot;-sh&quot;]      0 B
38e3ea5c1412        4 minutes ago       /bin/sh -c dd if=/dev/zero of=/test bs=1M cou   104.9 MB
7efc0655e95d        4 minutes ago       /bin/sh -c rm /test                             0 B
f3a606172d91        4 minutes ago       /bin/sh -c dd if=/dev/zero of=/test bs=1M cou   104.9 MB
1e0c3dd64ccd        3 weeks ago         /bin/sh -c #(nop)  CMD [&quot;/bin/bash&quot;]            0 B
&lt;missing&gt;           3 weeks ago         /bin/sh -c mkdir -p /run/systemd &amp;&amp; echo &#39;doc   7 B
&lt;missing&gt;           3 weeks ago         /bin/sh -c sed -i &#39;s/^#\s*\(deb.*universe\)$/   1.895 kB
&lt;missing&gt;           3 weeks ago         /bin/sh -c rm -rf /var/lib/apt/lists/*          0 B
&lt;missing&gt;           3 weeks ago         /bin/sh -c set -xe   &amp;&amp; echo &#39;#!/bin/sh&#39; &gt; /u   194.6 kB
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop) ADD file:bc2e0eb31424a88aad   187.7 MB
</code></pre><p>注意到其中一些镜像层的SIZE为0，这是因为该镜像层执行的命令不会影响到镜像的文件系统大小，这些命令会单独记录在镜像Json文件中。由于镜像的层级原理，Docker在执行<code>RUN rm /test</code>指令时，并没有真正将其当前镜像f3a606172d91中的/test文件真正删掉，而是将rm操作记录在镜像Json文件中(容器只能在其上层的可读写层进行更改操作)，最终我们得到的镜像大小约为400M。</p>
<p>然后我们基于得到镜像启动容器：</p>
<pre><code>docker run --rm baec9103f182
du: cannot access &#39;./proc/1/task/1/fd/4&#39;: No such file or directory
du: cannot access &#39;./proc/1/task/1/fdinfo/4&#39;: No such file or directory
du: cannot access &#39;./proc/1/fd/4&#39;: No such file or directory
du: cannot access &#39;./proc/1/fdinfo/4&#39;: No such file or directory
296M    .
</code></pre><p>我们的容器大小只是近300M，因此Docker镜像的大小和容器中文件系统内容的大小是两个概念。镜像的大小等于其包含的所有镜像层之和，并且由于镜像层共享技术的存在(比如我们再构建一个基于ubuntu14:04的镜像，将直接复用本地已有的ubuntu镜像层)，极大节省了磁盘空间。</p>
<ol>
<li><a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices">Dockerfile Best Practices</a></li>
<li><a href="https://docs.docker.com/engine/reference/builder/">Dockerfile Reference</a></li>
<li><a href="https://docs.docker.com/engine/reference/run/">Docker run Reference</a></li>
<li><a href="https://www.gitbook.com/book/yeasy/docker_practice/details">Docker 从入门到实践</a></li>
</ol>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>探索Docker在Erlang集群中的应用</title>
    <url>/2016/11/docker-erlang/</url>
    <content><![CDATA[<p>接<a href="http://0.0.0.0:4444/2016/11/docker-basic/">上篇</a>，结合Erlang，对Docker的实际应用进一步理解。并探索将Docker应用到Erlang集群的方案。</p>
<h2 id="简单Docker交互"><a href="#简单Docker交互" class="headerlink" title="简单Docker交互"></a>简单Docker交互</h2><p>下面是个简单的echo server：</p>
<pre><code>-module(server_echo).
-export([start/0]).

start() -&gt;
     io:format(&quot;SERVER Trying to bind to port 2345\n&quot;),
     &#123;ok, Listen&#125; = gen_tcp:listen(2345, [ binary
                                         , &#123;packet, 0&#125;
                                         , &#123;reuseaddr, true&#125;
                                         , &#123;active, true&#125;
                                         ]),
     io:format(&quot;SERVER Listening on port 2345\n&quot;),
     accept(Listen).

 accept(Listen) -&gt;
     &#123;ok, Socket&#125; = gen_tcp:accept(Listen),
     WorkerPid = spawn(fun() -&gt; echo(Socket) end),
     gen_tcp:controlling_process(Socket, WorkerPid),
     accept(Listen).

 echo(Socket) -&gt;
     receive
         &#123;tcp, Socket, Bin&#125; -&gt;
             io:format(&quot;SERVER Received: ~p\n&quot;, [Bin]),
             gen_tcp:send(Socket, Bin),
             echo(Socket);
         &#123;tcp_closed, Socket&#125; -&gt;
             io:format(&quot;SERVER: The client closed the connection\n&quot;)
     end.
</code></pre><p>简单起见，我们直接用<code>telnet</code>命令对echo server进行测试。现在，考虑如何在Docker容器中运行echo server。</p>
<span id="more"></span>
<h3 id="容器中运行"><a href="#容器中运行" class="headerlink" title="容器中运行"></a>容器中运行</h3><pre><code>sudo docker run -it --rm -v ~/docker:/code -w /code erlang erl
Erlang/OTP 19 [erts-8.1] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false]

Eshell V8.1  (abort with ^G)
1&gt; c(server_echo).
&#123;ok,server_echo&#125;
2&gt; server_echo:start().
SERVER Trying to bind to port 2345
SERVER Listening on port 2345
</code></pre><p>在<code>docker run</code>中，我们将本地代码路径挂载到容器的/code目录，并且将/code作为容器的工作目录，此后对本地代码的修改，将直接反映在容器中，而无需拷贝。运行容器后会进入erl shell，并且当前路径(/code)即为本地代码路径(~/docker)，之后编译运行server即可。</p>
<h3 id="宿主机访问容器"><a href="#宿主机访问容器" class="headerlink" title="宿主机访问容器"></a>宿主机访问容器</h3><p>如下方案可以让宿主机能访问容器端口：</p>
<ul>
<li>在<code>docker run</code>中指定<code>-p 2345:2345</code>导出2345端口，之后访问宿主机的2345端口等同于访问容器2345端口</li>
<li>在<code>docker run</code>中指定<code>--network host</code>使容器和宿主机共享网络栈，IP和端口</li>
<li>通过<code>docker inspect</code>查询容器IP地址(如:<code>172.17.0.2</code>)，可在宿主机上通过该IP访问容器</li>
</ul>
<h3 id="容器之间访问"><a href="#容器之间访问" class="headerlink" title="容器之间访问"></a>容器之间访问</h3><p>容器间交互方式主要有三种：</p>
<ul>
<li>通过<code>docker inspect</code>得到容器IP地址，通过IP地址进行容器间的交互</li>
<li>通过<code>docker run</code>中指定<code>--network container:&lt;name or id&gt;</code>，将新创建的容器与一个已经存在的容器的共享网络栈，IP和端口</li>
<li>通过<code>docker run</code>的<code>--link &lt;name or id&gt;</code>选项链接两个容器，之后可以将容器名或容器ID作为Hostname来访问容器，注意<code>--link</code>选项仅在<code>--network bridge</code>下有效</li>
</ul>
<h3 id="定义Dockerfile"><a href="#定义Dockerfile" class="headerlink" title="定义Dockerfile"></a>定义Dockerfile</h3><p>前面我是通过挂载目录的方式将本地代码映射到容器中，这种方式在本地开发中比较方便，但是在项目部署或环境配置比较复杂时，我们需要通过Dockerfile来构建自己的镜像(而不是基于官方Erlang镜像)，初始化项目环境，就本例而言，Dockerfile非常简单：</p>
<pre><code>FROM erlang

RUN mkdir code

COPY server_echo.erl code/server_echo.erl

RUN cd code &amp;&amp; erlc server_echo.erl

WORKDIR /code

ENTRYPOINT [&quot;erl&quot;, &quot;-noshell&quot;, &quot;-run&quot;, &quot;server_echo&quot;, &quot;start&quot;]
</code></pre><h2 id="Erlang多节点通信"><a href="#Erlang多节点通信" class="headerlink" title="Erlang多节点通信"></a>Erlang多节点通信</h2><h3 id="再谈Erlang分布式通信"><a href="#再谈Erlang分布式通信" class="headerlink" title="再谈Erlang分布式通信"></a>再谈Erlang分布式通信</h3><p>Erlang的分布式节点有自己的通信机制，这套通信机制对上层用户是透明的，我们只需一个节点名(<code>node@host</code>)，即可访问这个节点，而无需关心这个节点是在本机上还是在其它主机上。在这之上封装的Pid，进一步地屏蔽了节点内进程和跨节点进程的差异。</p>
<p>在<a href="http://wudaijun.com/2016/03/erlang-distribution-2/">Erlang分布式系统(2)</a>中，我提到了Erlang的分布式设施，其中epmd扮演着重要的角色：它维护了本机上所有节点的节点名到节点监听地址的映射，并且由于epmd进程本身的监听端口在集群内是周知的(默认为4369)，因此可以根据节点名<code>node@host</code>得到节点所在主机上epmd的监听地址(<code>host:4369</code>)，进而从epmd进程上查询到节点名<code>node</code>所监听的地址，实现节点间通信。</p>
<h3 id="在同主机不同容器中部署集群"><a href="#在同主机不同容器中部署集群" class="headerlink" title="在同主机不同容器中部署集群"></a>在同主机不同容器中部署集群</h3><p>现在回到Docker，我们先尝试在同一个主机，不同容器上建立集群：</p>
<pre><code># 容器A 启动后通过docker inspect查询得到IP地址: 172.17.0.2
sudo docker run -it erlang /bin/bash
root@4453d880b5a5:/# erl -name n1@172.17.0.2 -setcookie 123
Eshell V8.1  (abort with ^G)
(n1@172.17.0.2)1&gt; 

# 容器B 启动后通过docker inspect查询得到IP地址: 172.17.0.4
sudo docker run -it erlang /bin/bash
root@dd0f30178036:/# erl -name n2@172.17.0.4 -setcookie 123
Eshell V8.1  (abort with ^G)
(n2@172.17.0.4)1&gt; net_kernel:connect_node(&#39;n1@172.17.0.2&#39;).
true
(n2@172.17.0.4)2&gt; nodes().
[&#39;n1@172.17.0.2&#39;]
</code></pre><p>和在宿主机上一样，我们可以直接通过容器IP架设集群。这里使用的是<code>-name node@host</code>指定的longname，而如果使用shortname：</p>
<pre><code># 容器A
root@4453d880b5a5:/# erl -sname n1 -setcookie 123
Eshell V8.1  (abort with ^G)
(n1@4453d880b5a5)1&gt;

# 容器B
root@dd0f30178036:/# erl -sname n2 -setcookie 123
Eshell V8.1  (abort with ^G)
(n2@dd0f30178036)1&gt; net_kernel:connect_node(&#39;n1@4453d880b5a5&#39;).
false
</code></pre><p>在shortname方案中，我们并不能通过nodename访问节点，本质上是因为<code>n2</code>节点不能通过<code>4453d880b5a5:4369</code>访问到<code>n1</code>节点所在主机上的epmd进程。我们测试一下网络环境：</p>
<pre><code># 通过容器A名字ping
ping 4453d880b5a5
ping: unknown host

# 直接ping容器A IP
ping 172.17.0.2
PING 172.17.0.2 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: icmp_seq=0 ttl=64 time=0.099 ms
64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.089 ms
</code></pre><p>发现是hostname解析出了问题，容器链接来解决这个问题：</p>
<pre><code># 重新启动容器B 并链接到容器A
docker run -it --link 4453d880b5a5 erlang /bin/bash
root@7692c8c71218:/# erl -sname n2 -setcookie 123
Eshell V8.1  (abort with ^G)
(n2@dd0f30178036)1&gt; net_kernel:connect_node(&#39;n1@4453d880b5a5&#39;).
true
</code></pre><p>有个有趣的问题是，当容器B link了容器A，那么容器B能通过容器A的Id或名字访问容器B，而反过来，容器A却不能以同样的方式访问容器B。也就是说link是单向的，这同样可以通过ping来验证。</p>
<h3 id="在不同的主机上部署集群"><a href="#在不同的主机上部署集群" class="headerlink" title="在不同的主机上部署集群"></a>在不同的主机上部署集群</h3><p>在不同的主机上部署集群，问题开始变得复杂：</p>
<ol>
<li>不同的主机上的Docker容器处于不同的子网(一台主机对应一个子网)，因此不同主机上的容器不能直接访问，需要先发布(publish)Erlang节点监听端口</li>
<li>Erlang节点在Docker容器中的监听地址是由Erlang VM启动时分配的，因此我们无法在启动容器时就获知Erlang节点监听端口(从而发布该端口)</li>
<li>假定我们预配置了Erlang节点的监听端口xxx，如果我们使用<code>-p xxx:xxx</code>将可能导致端口争用(亦即一台物理机只能运行一个Docker容器)，如果我们使用<code>-p xxx</code>将该端口发布到主机任意一个端口，那么这个发布的主机端口，将只能通过Docker Daemon获取到(命令行下可通过<code>docker port</code>查看)</li>
<li>再来看epmd，每个Docker容器中都会跑一个epmd进程，它记录的是节点名到<strong>节点在容器中的监听地址</strong>，因此，epmd本身返回的地址是不能直接被其它主机上的节点使用的</li>
</ol>
<h4 id="Erlang-In-Docker"><a href="#Erlang-In-Docker" class="headerlink" title="Erlang In Docker"></a>Erlang In Docker</h4><p>基于上面的种种限制，有人给出了一套解决方案：<a href="https://github.com/Random-Liu/Erlang-In-Docker">Erlang In Docker</a>。这套方案对Erlang集群做了如下制约：</p>
<ol>
<li>每个Docker容器只能运行一个Erlang节点</li>
<li>预配置Erlang节点的监听端口</li>
<li>Erlang节点名格式为<code>DockerContainerID@HostIP</code></li>
<li>使用Docker Daemon而不是epmd来获取节点监听端口</li>
</ol>
<p>这套方案的核心思路是用Docker Daemon替换epmd做节点监听的服务发现，原因有二：</p>
<ul>
<li>Docker Daemon运行于主机同级网络中</li>
<li>维护了容器端口和主机端口的映射关系</li>
</ul>
<p>如果节点A想要访问节点B，则节点A需要提供：</p>
<ul>
<li>节点B所在主机地址: Host</li>
<li>节点B所在主机上Docker Daemon的监听端口: DaemonPort</li>
<li>节点B所在容器ID: ContainerID</li>
<li>节点B在所在容器中的监听端口: Port0</li>
</ul>
<p>之后就可以通过Docker Daemon(<code>Host:DaemonPort</code>)查询到<code>ContainerID</code>容器的<code>Port0</code>端口在主机上对应的发布端口<code>Port1</code>，之后节点A即可通过<code>Host:Port1</code>与节点B通信。</p>
<p>然而节点A只有节点B的名字，要在节点B中编码这四条信息是非常困难的，因此Erlang In Docker的做法是，预配置Port0(12345)和DaemonPort(4243)，剩下的主机地址和容器ID则编码在节点名中：<code>DockerContainerID@HostIP</code>。</p>
<p>EID代码并不复杂，得益于Erlang可替换的分布式通信协议，EID只自定义了<code>eid_tcp_dist</code>(替换默认的<code>inet_tcp_dist</code>模块)和dpmd(通过与Docker Daemon交互模拟epmd的功能)两个模块。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>将Erlang应用到Docker上比较困难的主要原因是Erlang已经提供了非常完备的分布式设施(参见<a href="http://wudaijun.com/2016/03/erlang-distribution-2/">Erlang分布式系统(2)</a>)，并且这一套对上层都是透明的。EID这套方案看起来限制很多，但细想也没多大问题，具体还要看在生产环境中的表现，目前我比较顾虑它的通信效率(NAT)和<code>eid_tcp_dist</code>是否足够健壮。</p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang 内存问题诊断</title>
    <url>/2016/12/erlang-memory-debug/</url>
    <content><![CDATA[<p>通过<code>erlang:memory()</code>查看节点内存占用总览，需要通过静态和动态两个维度对内存进行考核：</p>
<ul>
<li>静态: 各类内存占用比例，是否有某种类的内存占用了节点总内存的绝大部分</li>
<li>动态: 各类内存增长特性，如增长速度，或是否长期增长而不回收(atom除外)</li>
</ul>
<p>找出有疑似内存泄露的种类后，再进行下一步分析</p>
<h3 id="atom"><a href="#atom" class="headerlink" title="atom"></a>atom</h3><p>atom不会被GC，这意味着我们应该对atom内存增长更加重视而不是忽略。在编写代码时，尽量避免动态生成atom，因为一旦你的输入源不可靠或受到攻击(特别针对网络消息)，atom内存增长可能导致节点crash。可以考虑将atom生成函数替换为更安全的版本：</p>
<span id="more"></span>
<pre><code>list_to_atom/1 -&gt; list_to_existing_atom/1
binary_to_atom/2 -&gt; binary_to_existing_atom/2
binary_to_term(Bin) -&gt; binary_to_term(Bin,[safe])
</code></pre><h3 id="ets"><a href="#ets" class="headerlink" title="ets"></a>ets</h3><p>ets内存占用通常是由于表过大，通过<code>ets:i().</code>查看ets表条目数，大小，占用内存等。</p>
<h3 id="process"><a href="#process" class="headerlink" title="process"></a>process</h3><p>进程内存占用过高可能有两方面原因，进程数量过大和进程占用内存过高。针对于前者，首先找出那些没有被链接或监控的”孤儿进程”：</p>
<pre><code>[P || P&lt;-processes(),
    [&#123;_,Ls&#125;,&#123;_,Ms&#125;] &lt;- [process_info(P,[links,monitors])],
    []==Ls,[]==Ms].
</code></pre><p>或通过<code>supervisor:count_children/1</code>查看sup下进程数量和状态。</p>
<p>而如果是进程所占内存过高，则可将内存占用最高的几个进程找出来进行检查:</p>
<pre><code>recon:proc_count(memory, 10). % 打印占用内存最高的10个进程
recon:proc_count(message_queue_len, 10). % 打印消息队列最长的10个进程
</code></pre><h3 id="binary"><a href="#binary" class="headerlink" title="binary"></a>binary</h3><p>erlang binary大致上分为两种，heap binary(&lt;=64字节)和refc binary(&gt;64字节)，分别位于进程堆和全局堆上，进程通过ProBin持有refc binary的引用，当refc binary引用计数为0时，被GC。关于binary的详细实现，参考<a href="http://wudaijun.com/2015/12/erlang-datastructures/">Erlang常用数据结构实现</a>。</p>
<p>recon提供的关于binary问题检测的函数有：</p>
<pre><code>% 打印出引用的refc binary内存最高的N个进程
recon:proc_count(binary_memory, N)
% 对所有进程执行GC 打印出GC前后ProcBin个数减少数量最多的N个进程
recon:bin_leak(N)
</code></pre><p>以上两个函数，通常可以找出有问题的进程，然后针对进程的业务逻辑和上下文进行优化。通常来说，针对于refc binary，有如下思路：</p>
<ul>
<li>每过一段时间手动GC(高效，不优雅)</li>
<li>如果只持有大binary中的一小段，用<code>binary:copy/1-2</code>(减少refc binary引用)</li>
<li>将涉及大binary的工作移到临时一次性进程中，做完工作就死亡(变相的手动GC)</li>
<li>对非活动进程使用hibernate调用(该调用将进程挂起，执行GC并清空调用栈，在收到消息时再唤醒)</li>
</ul>
<p>一种典型地binary泄露情形发生在当一个生命周期很长的中间件当作控制和传递大型refc binary消息的请求控制器或消息路由器时，因为ProcBin仅仅只是个引用，因此它们成本很低而且在中间件进程中需要花很长的时间去触发GC，所以即使除了中间件其他所有进程都已经GC了某个refc binary对应的ProcBin，该refc binary也需要保留在共享堆里。因此中间件进程成为了主要的泄漏源。</p>
<p>针对这种情况，有如下解决方案：</p>
<ul>
<li>避免中间件接触到refc binary，由中间件进程返回目标进程的Pid，由原始调用者来进行binary转发</li>
<li>调整中间件进程的GC频率(fullsweep_after)</li>
</ul>
<h3 id="driver-nif"><a href="#driver-nif" class="headerlink" title="driver/nif"></a>driver/nif</h3><p>另一部分非Erlang虚拟机管制的内存通常来自于第三方Driver或NIF，要确认是否是这部分内存出了问题，可通过<code>recon_alloc:memory(allocated).</code>和OS所报告的内存占用进行对比，可以大概得到C Driver或NIF分配的内存，再根据该部分内存的增长情况和占用比例来判断是否出现问题。</p>
<p>如果是纯C，那么内存使用应该是相对稳定并且可预估的，如果还挂接了Lua这类动态语言，调试起来要麻烦一些，在我们的服务器中，Lua部分是无状态的，可以直接重新加载Lua虚拟机。其它的调试手段，则要透过Lua层面的GC机制去解决问题了。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>CSS 笔记</title>
    <url>/2017/01/css-notes/</url>
    <content><![CDATA[<h2 id="一-选择器"><a href="#一-选择器" class="headerlink" title="一. 选择器"></a>一. 选择器</h2><h3 id="1-普通选择器"><a href="#1-普通选择器" class="headerlink" title="1. 普通选择器"></a>1. 普通选择器</h3><div class="table-container">
<table>
<thead>
<tr>
<th>类别</th>
<th>例子</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>标签选择器</td>
<td>div</td>
<td>以HTML 标签类型来选择元素,又叫类型选择器</td>
</tr>
<tr>
<td>类选择器</td>
<td>.span1</td>
<td>以class属性值来选择元素,可在页面中出现多个</td>
</tr>
<tr>
<td>ID选择器</td>
<td>#inst</td>
<td>以id属性值来选择元素,在页面中只能出现一次</td>
</tr>
</tbody>
</table>
</div>
<span id="more"></span>
<h3 id="2-并列选择器"><a href="#2-并列选择器" class="headerlink" title="2. 并列选择器"></a>2. 并列选择器</h3><div class="table-container">
<table>
<thead>
<tr>
<th>类别</th>
<th>例子</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>并列选择器</td>
<td>div1,span1</td>
<td>同时定义多个样式,即该CSS有多个名称,简化CSS书写</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-层级选择器"><a href="#3-层级选择器" class="headerlink" title="3. 层级选择器"></a>3. 层级选择器</h3><div class="table-container">
<table>
<thead>
<tr>
<th>类别</th>
<th>例子</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>后代选择器</td>
<td>body .span1</td>
<td>选择指定祖先元素内的后代元素</td>
</tr>
<tr>
<td>直接子元素选择器</td>
<td>body &gt; .span1</td>
<td>选择指定父元素内的直接子元素</td>
</tr>
</tbody>
</table>
</div>
<p>例子:</p>
<pre><code>/* body .span1 影响元素E1 E2 */
/* body &gt; .span1 只影响元素E2 */ 
&lt;body&gt;
    &lt;span class=&quot;span1&quot;&gt; E1 &lt;/span&gt;
    &lt;div&gt; &lt;span class=&quot;span1&quot;&gt; E2 &lt;/span&gt; &lt;/div&gt;
&lt;/body&gt;
</code></pre><h3 id="4-兄弟选择器"><a href="#4-兄弟选择器" class="headerlink" title="4. 兄弟选择器"></a>4. 兄弟选择器</h3><div class="table-container">
<table>
<thead>
<tr>
<th>类别</th>
<th>例子</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>普通兄弟选择器</td>
<td>div ~ p</td>
<td>选择第一个元素后的兄弟元素,两者拥有相同的父元素</td>
</tr>
<tr>
<td>相邻兄弟选择器</td>
<td>div + p</td>
<td>选择第一个元素后紧跟的元素,两者拥有相同的父元素</td>
</tr>
</tbody>
</table>
</div>
<p>例子:</p>
<pre><code>/* div + p 影响 Three Six */
/* div ~ p 影响 Three Six Seven */
&lt;div&gt;
    &lt;p&gt;One&lt;/p&gt;
    &lt;div&gt;Two&lt;/div&gt;
    &lt;p&gt;Three&lt;/p&gt;
&lt;/div&gt;

&lt;div&gt;
    &lt;div&gt;Four&lt;/div&gt;
    &lt;div&gt;&lt;p&gt;Five&lt;/p&gt;&lt;/div&gt;
    &lt;p&gt;Six&lt;/p&gt;
    &lt;p&gt;Seven&lt;/p&gt;
&lt;/div&gt;
</code></pre><h3 id="5-伪类-伪元素"><a href="#5-伪类-伪元素" class="headerlink" title="5. 伪类/伪元素"></a>5. 伪类/伪元素</h3><ul>
<li>伪类: 用于定义同一样式的不同状态</li>
<li><p>伪元素: 用来添加一些选择器的特殊效果</p>
<pre><code>  /* 常见伪类 */
  a:link &#123;color:#FF0000;&#125; /* 未访问的链接 */
  a:visited &#123;color:#00FF00;&#125; /* 已访问的链接 */
  a:hover &#123;color:#FF00FF;&#125; /* 鼠标划过链接 */
  a:active &#123;color:#0000FF;&#125; /* 已选中的链接 */
  p:first-child&#123;color:blue;&#125; /* 改变当p作为父元素第一个子元素时的样式*/ 

  /* 常见伪元素 */
  h1:before&#123;content:url(smiley.gif);&#125; /* 在元素内容之前插入图片 */
  h1:after&#123;content:url(smiley.gif);&#125; /* 在元素内容之后插入图片 */
  p:first-line &#123;color:#ff0000;&#125; /* 为文本的首行设置特殊样式 */
  p:first-letter &#123;color:#ff0000;&#125; /* 为文本的首字母设置特殊样式 */
</code></pre></li>
</ul>
<h3 id="6-优先级"><a href="#6-优先级" class="headerlink" title="6. 优先级"></a>6. 优先级</h3><p><code>!import</code> &gt; 元素内嵌样式 &gt; ID选择器 &gt; Class选择器 &gt; 类型选择器 &gt; 父元素继承值，如果一个选择器应用的多个样式重复定义了某一属性，则样式在CSS中定义顺序越后面优先级越高。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span></span><br><span class="line">	...</span><br><span class="line"><span class="css">	<span class="selector-tag">h1</span> &#123;<span class="attribute">color</span>: red; &#125;</span></span><br><span class="line"><span class="css">  <span class="selector-class">.pink-text</span> &#123; <span class="attribute">color</span>: pink; &#125;</span></span><br><span class="line"><span class="css">  <span class="selector-class">.blue-text</span> &#123; <span class="attribute">color</span>: blue; &#125;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span> <span class="attr">id</span>=<span class="string">&quot;orange-text&quot;</span> <span class="attr">class</span>=<span class="string">&quot;blue-text pink-text&quot;</span> <span class="attr">style</span>=<span class="string">&quot;color: white&quot;</span>&gt;</span>Hello World!<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line">应用color属性的优先级为: style=&quot;color:white&quot; &gt; .orange-text &gt; .pink-text &gt; blue-text &gt; h1类型选择器 &gt; 从body继承color值</span><br><span class="line"></span><br><span class="line">如果对pink-text的color属性应用了!important，那么应用important的属性优先级将始终最高!</span><br></pre></td></tr></table></figure>
<h2 id="二-内外边距"><a href="#二-内外边距" class="headerlink" title="二. 内外边距"></a>二. 内外边距</h2><h3 id="1-元素结构"><a href="#1-元素结构" class="headerlink" title="1. 元素结构"></a>1. 元素结构</h3><p> <img src="/assets/image/201701/css-padding-margin.gif" alt=""></p>
<h3 id="2-padding"><a href="#2-padding" class="headerlink" title="2. padding"></a>2. padding</h3><p>内边距，定义元素边框和元素内容之间的留白</p>
<ul>
<li>可填充背景</li>
<li>相邻元素的内边距会叠加(15px + 20px=35px)</li>
</ul>
<h3 id="3-margin"><a href="#3-margin" class="headerlink" title="3. margin"></a>3. margin</h3><p>外边距，元素周围生成额外的空白区。“空白区”通常是指其他元素不能出现且父元素背景可见的区域。</p>
<ul>
<li>不可填充背景</li>
<li>边界是完全透明的(父元素背景可见)</li>
<li>相邻元素的边界会被折叠15px + 20px=20px)</li>
</ul>
<p>margin可为负数，当static元素的margin-top/margin-left被赋予负值时，元素将被拉进指定的方向。例如：</p>
<pre><code>/* 元素向上移10px*/
#mydiv1 &#123;margin-top:-10px;&#125;
</code></pre><p>但如果你设置margin-bottom/right为负数，元素并不会如你所想的那样向下/右移动，而是将后续的元素拖拉进来，覆盖本来的元素。</p>
<pre><code>/* #mydiv1后续元素向上移10px, #mydiv1 本身不移动 */
#mydiv1 &#123;margin-bottom:-10px;&#125;
</code></pre><p>关于负margin的更多用法: <a href="https://www.w3cplus.com/css/the-definitive-guide-to-using-negative-margins.html">https://www.w3cplus.com/css/the-definitive-guide-to-using-negative-margins.html</a></p>
<h3 id="4-外边距合并"><a href="#4-外边距合并" class="headerlink" title="4. 外边距合并"></a>4. 外边距合并</h3><p>外边距合并指的是，当两个垂直外边距相遇时，它们将形成一个外边距。合并后的外边距的高度等于两个发生合并的外边距的高度中的较大者。</p>
<p>垂直外边距合并问题常见于第一个子元素的margin-top会顶开父元素与父元素相邻元素的间距。如:</p>
<pre><code>&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;
&lt;head&gt;
&lt;title&gt;垂直外边距合并&lt;/title&gt;
    &lt;style&gt;
        .top&#123;width:160px; height:50px; background:#ccf;&#125;
        .middle&#123;width:160px; background:#cfc;&#125;
        .middle .firstChild&#123;margin-top:20px;&#125;
    &lt;/style&gt;
&lt;/head&gt;

&lt;body&gt;
    &lt;div class=&quot;top&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;middle&quot;&gt;
        &lt;div class=&quot;firstChild&quot;&gt;我其实只是想和我的父元素隔开点距离。&lt;/div&gt;
    &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre><p>原因：根据CSS规范，当一个元素包含在另一个元素中时（假设没有内边距或边框把外边距分隔开），它们的上和/或下外边距会发生合并。因此firstChild和其父元素middle的上外边距重叠，并顶开了middle和top间的外边距。解决方案是为middle定义边框或者内边距。参考<a href="http://www.w3school.com.cn/css/css_margin_collapsing.asp">CSS外边距合并</a>，<a href="http://www.hicss.net/use-margin-or-padding/">padding or margin</a>。</p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>Go 常用命令</title>
    <url>/2017/01/go-command-notes/</url>
    <content><![CDATA[<h3 id="环境管理"><a href="#环境管理" class="headerlink" title="环境管理"></a>环境管理</h3><ul>
<li>Go版本管理: <a href="https://github.com/moovweb/gvm">gvm</a>(go version manager)</li>
<li>GOPATH管理: <a href="https://github.com/pote/gvp">gvp</a>(go version package)</li>
<li>依赖版本管理: <a href="https://github.com/pote/gpm">gpm</a>(go package manager)</li>
</ul>
<h3 id="go-build"><a href="#go-build" class="headerlink" title="go build"></a>go build</h3><p>用于编译指定的源码文件或代码包以及它们的依赖包。</p>
<blockquote>
<p>import导入路径中的最后一个元素是路径名而不是包名，路径名可以和包名不一样，但同一个目录只能定义一个包(包对应的_test测试包除外)</p>
</blockquote>
<span id="more"></span>
<p>编译包:</p>
<pre><code># 当前路径方式
cd src/foo &amp;&amp; go build
# 包导入路径方式
go build foo bar
# 本地代码包路径方式
go build ./src/foo
</code></pre><p>go build 在编译只包含库源码文件的代码包时，只做检查性的编译，不会输出任何结果文件。如果编译的是main包，则会将编译结果放到执行命令的目录下。</p>
<p>编译源码文件:</p>
<pre><code># 指定源码文件使用文件路径
# 指定的多个源码文件必须属于同一个目录(包)
go build src/foo/foo1.go src/foo/foo2.go
</code></pre><p>当执行以上编译时，编译命令在分析参数的时候如果发现第一个参数是Go源码文件而不是代码包时，会在内部生成一个名为“command-line-arguments”的虚拟代码包。也就是当前的foo1.go foo2.go属于”command-line-arguments”包，而不是foo包，因此除了指定的源码文件和它们所依赖的包，其它文件(如foo3.go)不会被编译。</p>
<p>同样，对于库源码文件，build不会输出任何结果文件。对于main包的源文件，go build要求有且只能有一个main函数声明，并将生成结果(与指定的第一个源码文件同名)放在执行该命令的当前目录下。</p>
<p>构建与<code>go build</code>之上的其它命令(如<code>go run</code>，<code>go install</code>)，在编译包或源码文件时，过程和特性是一样的。</p>
<p>常用选项:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>选项</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>-v</td>
<td>打印出那些被编译的代码包的名字。</td>
</tr>
<tr>
<td>-n</td>
<td>打印编译期间所用到的其它命令，但是并不真正执行它们。</td>
</tr>
<tr>
<td>-x</td>
<td>打印编译期间所用到的其它命令。注意它与-n标记的区别。</td>
</tr>
<tr>
<td>-a</td>
<td>强行对所有涉及到的代码包（包含标准库中的代码包）进行重新构建，即使它们已经是最新的了。</td>
</tr>
<tr>
<td>-work</td>
<td>打印出编译时生成的临时工作目录的路径，并在编译结束时保留它。在默认情况下，编译结束时会删除该目录。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="go-run"><a href="#go-run" class="headerlink" title="go run"></a>go run</h3><p>go run编译(通过go build)并运行命令源码文件(main package)，查看过程:</p>
<pre><code>go run -x -work src/main/main.go
# build 临时目录
WORK=/var/folders/n5/j8y6skrx1xn3_ls64gl1lrsmmp53rv/T/go-build979313546
# main.go依赖foo包  先编译foo包
mkdir -p $WORK/foo/_obj/
mkdir -p $WORK/
cd /Users/wudaijun/Work/test/src/foo
/usr/local/Cellar/go/1.7/libexec/pkg/tool/darwin_amd64/compile -o $WORK/foo.a -trimpath $WORK -p foo -complete -buildid cd61b5a9f3c8eba0f3088adca894fc9bf695826b -D _/Users/wudaijun/Work/test/src/foo -I $WORK -pack ./foo.go
# 在虚拟包 command-line-arguments 中编译 main.go
mkdir -p $WORK/command-line-arguments/_obj/
mkdir -p $WORK/command-line-arguments/_obj/exe/
cd /Users/wudaijun/Work/test/src/main
/usr/local/Cellar/go/1.7/libexec/pkg/tool/darwin_amd64/compile -o $WORK/command-line-arguments.a -trimpath $WORK -p main -complete -buildid 9131b7dd9f64a85bb423da7f8a7d408c089a23e8 -D _/Users/wudaijun/Work/test/src/main -I $WORK -I /Users/wudaijun/Work/test/pkg/darwin_amd64 -pack ./main.go
# 链接
cd .
/usr/local/Cellar/go/1.7/libexec/pkg/tool/darwin_amd64/link -o $WORK/command-line-arguments/_obj/exe/main -L $WORK -L /Users/wudaijun/Work/test/pkg/darwin_amd64 -w -extld=clang -buildmode=exe -buildid=9131b7dd9f64a85bb423da7f8a7d408c089a23e8 $WORK/command-line-arguments.a
# 从临时目录运行可执行文件
$WORK/command-line-arguments/_obj/exe/main
Call Foo()
</code></pre><p>可看到<code>go run</code>的执行结果都在WORK临时目录中完成，由于使用了<code>-work</code>选项，因此WORK目录会在<code>go run</code>执行完成后保留。<code>go run</code>只接受命令源文件而不接收包路径作为参数，并且不会在当前目录生成任何文件。</p>
<h3 id="go-install"><a href="#go-install" class="headerlink" title="go install"></a>go install</h3><p><code>go install</code>只比<code>go build</code>多干一件事：安装编译后的结果文件到指定目录。</p>
<h3 id="go-test"><a href="#go-test" class="headerlink" title="go test"></a>go test</h3><h4 id="1-单元测试"><a href="#1-单元测试" class="headerlink" title="1. 单元测试"></a>1. 单元测试</h4><p><code>go test</code>编译指定包或源文件，并执行所在包对应的测试用例。一个符合规范的测试文件指：</p>
<ul>
<li>文件名必须是_test.go结尾的，这样在执行go test的时候才会执行到相应的代码</li>
<li>你必须import testing这个包</li>
<li>所有的测试用例函数必须是Test开头</li>
<li>测试用例会按照源代码中写的顺序依次执行</li>
<li>测试函数TestXxx()的参数是testing.T，我们可以使用该类型来记录错误或者是测试状态</li>
<li>测试格式：<code>func TestXxx (t *testing.T)</code>,Xxx部分可以为任意的字母数字的组合，但是- - 首字母不能是小写字母[a-z]，例如Testingdiv是错误的函数名</li>
<li>函数中通过调用testing.T的Error, Errorf, FailNow, Fatal, FatalIf方法，说明测试不通过，调用Log方法用来记录测试的信息</li>
</ul>
<p>测试分为包内测试和包外测试，即测试源码文件可于被测试源码文件位于同一个包(目录)，或者测试源码文件声明的包名可以是被测试包名+”_test”后缀。</p>
<h4 id="2-基准测试"><a href="#2-基准测试" class="headerlink" title="2. 基准测试"></a>2. 基准测试</h4><p>基准测试也就是跑分测试，写法和单元测试差不多，只不过函数签名为<code>BenchmarkXxx(b *testing.B)</code>，函数内通过 b.N 作为迭代次数，go test会自动调整这个值，得到合适的测试次数，然后算出每次迭代消耗的时间。</p>
<h4 id="3-执行测试"><a href="#3-执行测试" class="headerlink" title="3. 执行测试"></a>3. 执行测试</h4><pre><code># 执行当前目录所在包的单元测试
go test . 
# 执行当前目录所在包的单元测试和基准测试(-bench 后面接正则匹配，&#39;.&#39;通配所有 Benchmark)
go test -bench . . 
# 执行当前目录所在包的 TestAbc 单元测试以及 BenchmarkAbc 基准测试
go test -run TestAbc -bench BenchmarkAbc . 

# 在当前目录生成 battle.test 二进制文件而不执行，支持 go build 的所有参数。如可通过 -o 参数指定输出文件
go test -c ngs/battle 
# 直接执行 test 二进制时，test flag 需要加上 &#39;test.&#39; 前缀
./battle.test -test.bench . 

# 以下两条命令等价 并且实际上，编译器也是分为这两步来做的
go test -bench . -cpuprofile cpu.prof .
go test -c -o my.test . &amp;&amp; my.test -test.bench . -test.cpuprofile cpu.prof

# 如果要在 go test 时传入无需编译器加 &#39;test.&#39; 前缀的 flag，可将 flag 放在 -args 选项后:
go test -v -args -x -v
# 等价于:
pkg.test -test.v -x -v
</code></pre>]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X下的资源限制</title>
    <url>/2017/02/max-osx-ulimit/</url>
    <content><![CDATA[<p>系统的资源是有限的(如CPU，内存，内核所能打开的最大文件数等)，资源限制对针对进程能使用的系统资源设定上限。防止恶意进程无限制地占用系统资源。</p>
<p>资源限制分为两种，硬限制(Hard Limit)和软限制(Soft Limit)，软限制作用于实际进程并且可以修改，但不能超过硬限制，硬限制只有Root权限才能修改。</p>
<h2 id="相关命令"><a href="#相关命令" class="headerlink" title="相关命令"></a>相关命令</h2><p>在Mac OS X下，有如下三个命令与系统资源有关。</p>
<h3 id="launchctl"><a href="#launchctl" class="headerlink" title="launchctl"></a>launchctl</h3><p>launchctl管理OS X的启动脚本，控制启动计算机时需要开启的服务(通过后台进程launchd)。也可以设置定时执行特定任务的脚本，类似Linux cron。</p>
<p>例如，开机时自动启动Apache服务器：</p>
<pre><code>$ sudo launchctl load -w /System/Library/LaunchDaemons/org.apache.httpd.plist
</code></pre><span id="more"></span>
<p>关于launchctl的plist格式和用法参考:</p>
<ol>
<li><a href="https://developer.apple.com/legacy/library/documentation/Darwin/Reference/ManPages/man1/launchctl.1.html">launchctl man page</a></li>
<li><a href="https://developer.apple.com/legacy/library/documentation/Darwin/Reference/ManPages/man5/launchd.plist.5.html">launchd plist man page</a></li>
<li><a href="http://paul.annesley.cc/2012/09/mac-os-x-launchd-is-cool/">mac-os-x-launchd-is-cool</a></li>
<li><a href="https://developer.apple.com/library/content/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/CreatingLaunchdJobs.html">creating launchd jobs</a></li>
</ol>
<p>简单来说，plist文件用类似XML格式定义了一个命令(及启动参数)和该命令的执行方式(定时执行，系统启动执行，用户登录执行等)。我们这里不着重讨论，我们关心launchctl中如何查看/更改系统资源限制。</p>
<pre><code># Usage: launchctl limit [&lt;limit-name&gt; [&lt;both-limits&gt; | &lt;soft-limit&gt; &lt;hard-limit&gt;]
# 查看文件描述符限制
launchctl limit maxfiles
maxfiles    256            unlimited 

# 修改软限制为512 系统重启失效
sudo launchctl limit maxfiles 512 unlimited

# 可将launchctl子命令写入/etc/launchd.conf中
# 在launchd启动时 会执行该文件中的命令
limit maxfiles 512 unlimited
</code></pre><p>通过将更改命令写入plist文件，并在启动时执行，也可永久更改资源限制：</p>
<ol>
<li><p>新建Library/LaunchDaemons/limit.maxfiles.plist文件，写入</p>
<pre><code> &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;  
 &lt;!DOCTYPE plist PUBLIC &quot;-//Apple//DTD PLIST 1.0//EN&quot;  
         &quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&gt;
 &lt;plist version=&quot;1.0&quot;&gt;  
   &lt;dict&gt;
     &lt;key&gt;Label&lt;/key&gt;
     &lt;string&gt;limit.maxfiles&lt;/string&gt;
     &lt;key&gt;ProgramArguments&lt;/key&gt;
     &lt;array&gt;
       &lt;string&gt;launchctl&lt;/string&gt;
       &lt;string&gt;limit&lt;/string&gt;
       &lt;string&gt;maxfiles&lt;/string&gt;
       &lt;string&gt;64000&lt;/string&gt;
       &lt;string&gt;524288&lt;/string&gt;
     &lt;/array&gt;
     &lt;key&gt;RunAtLoad&lt;/key&gt;
     &lt;true/&gt;
     &lt;key&gt;ServiceIPC&lt;/key&gt;
     &lt;false/&gt;
   &lt;/dict&gt;
 &lt;/plist&gt;
</code></pre></li>
<li><p>修改文件权限</p>
<pre><code> sudo chown root:wheel /Library/LaunchDaemons/limit.maxfiles.plist
 sudo chmod 644 /Library/LaunchDaemons/limit.maxfiles.plist
</code></pre></li>
<li><p>加载plist文件(或重启系统后生效 launchd在启动时会自动加载该目录的plist)</p>
<pre><code> sudo launchctl load -w /Library/LaunchDaemons/limit.maxfiles.plist
</code></pre></li>
<li><p>确认更改后的限制</p>
<pre><code> launchctl limit maxfiles
</code></pre></li>
</ol>
<h3 id="sysctl"><a href="#sysctl" class="headerlink" title="sysctl"></a>sysctl</h3><p>大多数类Unix系统都通过(Linux/*BSD/OS X)都提供该命令来更改资源限制和内核配置：</p>
<pre><code># 查看当前内核和进程能打开的文件描述符限制
$ sysctl -A | grep kern.maxfiles
kern.maxfiles: 12288             # 系统级的限制
kern.maxfilesperproc: 10240    # 内核级的限制

# 通过sysctl命令热更改 系统重启后失效
$ sysctl -w kern.maxfilesperproc=20480

# 通过配置文件永久更改 重启生效
# 在/etc/sysctl.conf中写入
kern.maxfiles=20480 kern.maxfilesperproc=24576
</code></pre><h3 id="ulimit"><a href="#ulimit" class="headerlink" title="ulimit"></a>ulimit</h3><p>ulimit是shell的内置命令，用于查看/更改当前shell及其创建的子进程的资源限制。使用比较简单：</p>
<pre><code># 查看当前shell(及其子进程)的所有限制
ulimit -a
# 改变进程能打开的最大文件描述符数软限制 当shell关闭后失效
# 将其写入对应shell的startup文件(如~/.bashrc, ~/.zshrc)，可保留更改
ulimit -S -n 1024
</code></pre><h2 id="区别联系"><a href="#区别联系" class="headerlink" title="区别联系"></a>区别联系</h2><p>这三个命令的关系在Mac OS X各版本中尤其混乱，先说说本人的一些试验(Mac OS X 10.10.3)：</p>
<ul>
<li>在默认配置下(不配置plist和sysctl.conf)，launchctl的maxfiles默认值为(256, unlimited)，sysctl的maxfiles默认值为(12288, 10240)，而ulimit -n得到的值为4864。</li>
<li>当不定义plist而定义sysctl.conf，那么重启后launchctl和ulimit看到的上限仍为默认值，sysctl看到的上限与sysctl.conf定义的一致。</li>
<li>当同时在<code>/etc/sysctl.conf</code>和<code>/Library/LaunchDaemons/limit.maxfiles.plist</code>中定义maxfiles时，plist文件中的配置会覆盖sysctl.conf中的配置。如果通过系统重启应用plist，三个命令看到的上限均为plist配置。如果通过launchctl load加载plist，则会同步影响sysctl看到的上限，而不会影响shell下的ulimit上限。</li>
<li>如果通过launchctl配置的软上限和硬上限分别为S和H(非unlimited)，那么通过launchctl应用配置后最终得到软上限和硬上限都为S。如果设定的上限为S和unlimited，实际上应用的参数为S和10240(sysctl中kern.maxfilesperproc默认值)，当S&gt;10240时，会设置失败，S&lt;10240时，会得到(S, 10240)</li>
<li><code>ulimit -H -n 1000</code> 降低硬上限无需Root权限，升高则需要</li>
</ul>
<p>趁着头大，还可以看看这几篇文章:</p>
<ol>
<li><a href="http://superuser.com/questions/827984/open-files-limit-does-not-work-as-before-in-osx-yosemite">open files limit does not work as before in osx yosemite</a></li>
<li><a href="http://krypted.com/mac-os-x/maximum-files-in-mac-os-x/">maximum files in mac os x</a></li>
<li><a href="http://unix.stackexchange.com/questions/108174/how-to-persist-ulimit-settings-in-osx-mavericks">how to persist ulimit settings in osx mavericks</a></li>
<li><a href="https://docs.basho.com/riak/kv/2.2.0/using/performance/open-files-limit/#mac-os-x">open files limit in max os x</a></li>
<li><a href="http://superuser.com/questions/302754/increase-the-maximum-number-of-open-file-descriptors-in-snow-leopard">increase the maximum number of open file descriptors in snow leopard</a></li>
</ol>
<p>网上对Mac OS X各版本的解决方案各不相同，并且对这三个命令(特别是launchctl和sysctl)在资源限制上的联系与区别也没有清晰的解释。</p>
<p>按照我的理解和折腾出来的经验：</p>
<ol>
<li>ulimit只影响当前Shell下的进程，并且受限于kern.maxfilesperproc</li>
<li>如果配置了plist，那么重启后，ulimit和sysctl均会继承plist中的值</li>
<li>热修改sysctl上限值不会影响launchctl，而反之，launchctl会影响sysctl上限值</li>
</ol>
<p>综上，在Mac OS X 10.10(我的版本，没试过之前的)之后，使用plist是最合理的方案(但launchctl貌似只能设定一样的软限制和硬限制，如果将硬限制设为ulimited，则会使用kern.maxfilesperproc值)。在系统重启后，kern.maxfilesperproc和ulimit -n都会继承plist maxfiles的值。</p>
]]></content>
      <categories>
        <category>system</category>
      </categories>
      <tags>
        <tag>system</tag>
        <tag>macosx</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang+Lua的一次重构</title>
    <url>/2017/03/erlang-lua-reconstruction/</url>
    <content><![CDATA[<p>目前所在的项目基于<a href="http://wudaijun.com/2015/08/erlang-server-design1-cluster-server/">erlang cluster</a>搭建框架，再接入lua用于写逻辑。由于之前有一些erlang+lua的开发经验，因此着手项目的重构和优化，过程中一些体会，记录于此。</p>
<p>先简述一下项目架构，erlang做集群，网络层，节点交互，DB交互等，lua层只写逻辑。一个erlang的Actor持有一个luastate，为了加速erlang和lua之间的交互效率：</p>
<ol>
<li>将逻辑数据置于lua中而不是erlang中，在落地时，以二进制格式丢给erlang进行DB操作</li>
<li>以<code>lual_ref</code>和msgid等方式，尽量用整数代理字符串</li>
<li>erlang和lua异步运行，lua跑在原生线程池中，这在<a href="http://wudaijun.com/2015/09/erlang-server-design2-erlang-lua-battle/">这篇博文</a>中介绍过</li>
</ol>
<span id="more"></span>
<p>除了这些，还需要注意lua的沙盒环境管理，错误处理，热更新等，这里不再详述。就目前这种结构而言，还有一些缺陷：</p>
<ol>
<li>原子线程池忙碌可能导致的erlang虚拟机假死，需要保证原生线程池最多占用的核数不超过erlang虚拟机能使用的核数</li>
<li>lua state本身带来的不稳定性，特别是内存，在Actor过多时将会非常明显</li>
</ol>
<p>第二点，也是目前我们遇到的最棘手的问题，我们知道，在lua中，模块，函数，均是一个闭包，闭包包含函数和外部环境(UpValue，ENV等)，因此在lua中，每个lua state都完整包含加载的所有模块和函数，并且很难共享。我们项目通过一个share lua state完成了对配置表这类静态数据的共享(跨系统进程级的共享可参考<a href="http://blog.codingnow.com/2012/07/dev_note_24.html">云风blog</a>)，但本身逻辑代码占用内存仍然很大，随着逻辑和功能模块的增加，基本一个lua state加载完模块什么也不做，会占用6-7M内存。意味着如果一个玩家一个lua state，那么一台16G内存的服务器，基本只能容纳2000个玩家，内存吃紧，而CPU过剩。因此本次重构也只要针对这个问题。</p>
<p>之前项目组曾针对玩家进行了优化，将主城位于一个岛的玩家归位一组，再将岛按照<code>%M</code>的方式放到M个lua state容器上，这样得到一个复杂的，三层逻辑的lua state。针对玩家这一块的内存占用确实大大减少了，但调试难度也提升了，并且扩展性不好，不能将这种容器扩展到其它service(如Union)上。</p>
<p>按照系统本身的理想设计，一个service(player, union)对应一个lua state，由一个erlang process代理这个lua state，并且通过cluster注册/共享这个service的状态信息。但由于lua state的内存占用，不能再奢侈地将service和lua state 1:1调配，多service在逻辑代码中共用一个lua state已经无可避免，我们可以简单将整个系统分为几个层级，</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>service</th>
<th>lua state</th>
<th>erlang process</th>
<th>cluster</th>
</tr>
</thead>
<tbody>
<tr>
<td>N</td>
<td>1</td>
<td>?</td>
<td>?</td>
</tr>
</tbody>
</table>
</div>
<p>因此有以下几种可能的方案：</p>
<ol>
<li><code>N 1 N N</code>：每个service对应一个erlang process，多个erlang process将代理同一个lua state，这就需要lua state可以”被并发”，也就是同一个lua state只能绑定一个原生线程池上执行，这一点是可以实现的。这种方案在erlang层会获得更好的并发性能，并且cluster层语义不变。</li>
<li><code>N 1 1 N</code>：一个erlang process作为container的概念代理一个lua state，容纳N个service，并且将service和erlang process的映射关系写入cluster，cluster层对外提供的语义不变，但service的actor属性被弱化，service的一致性状态是个问题。</li>
<li><code>N 1 1 1</code>：与上种方案类似，只不过将service到container的映射通过算法算出来，而不写入cluster，container本身被编号（编号时，可考虑将serverid编入，这样开新服有一定的扩展性，PS: <a href="http://yikun.github.io/2016/06/09/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8E%E5%AE%9E%E8%B7%B5/">一致性哈希</a>方案不适用于游戏这类强状态逻辑），某个service将始终分配在指定container上。这种方案减少了cluster负担，并且减少了service不一致性的BUG。但由于container有状态，在每次系统启动后，service和container的映射关系就确定了，因此整个集群的可伸缩性降低了。</li>
</ol>
<p>经过几番讨论，我们最终选择了第三个方案，虽然个人认为这类固定分配的方案，与分布式的理念是相悖的，但目前稳定性和一致性才是首要目标。由于采用计算而不是通过mnesia保存映射关系，mnesia的性能和系统一致性得到了提升。本次重构在某些方面与我上一个项目<a href="http://wudaijun.com/2016/01/erlang-server-design5-server-node/">针对cluster的优化</a>有点相似，一个对系统服务进行横向切割，另一个则纵向切割，前者的初衷是为了更好地交互效率，后者则是处于对lua state资源的复用，两者都降低了系统的可伸缩性，得到了”一个更大粒度”的service。</p>
<p>整个重构过程中，有几点感触：</p>
<p>erlang和lua结合本身不是一种好的解决方案，或者说，erlang接入其它语言写逻辑都不合适，异质化的系统会打乱erlang本身的调度(不管通过nif还是线程池)，并且给整个系统带来不稳定性(CPU，内存)。另外，接入其它语言可能破坏erlang的原子语义和并发性。拿lua来说，原生线程池会和erlang调度线程抢占CPU并且很难管控，加之lua有自己的GC，因此在内存和CPU这两块关键资源上，erlang失去了控制权，给系统带来不稳定性。再加之lua state的内存占用以及lua state不支持并发，你可能要花更多的时间来调整系统结构，最终得到一个相对稳定的系统。如果处理得不好，用erlang做底层的可靠性和并发性将荡然无存。</p>
<p>系统设计，是一个不断根据当前情况取舍的过程，想要一步到位是不可能的。简单，可控，开发效率高才是主要指标，才能最大程度地适应各种变化，快速响应需求。</p>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>lua</tag>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>Go vs Erlang</title>
    <url>/2017/05/go-vs-erlang/</url>
    <content><![CDATA[<p>源于从Erlang转到Go的一些思维碰撞，整理下来记于此。</p>
<h3 id="Erlang-Actor"><a href="#Erlang-Actor" class="headerlink" title="Erlang Actor"></a>Erlang Actor</h3><p>Actor模型，又叫参与者模型，其”一切皆参与者(Actor)”的理念与面向对象编程的“一切皆是对象”类似，但是面向对象编程中对象的交互通常是顺序执行的(占用调用方的时间片)，而Actor模型中Actor的交互是并行执行的(不占用调用方的时间片)。</p>
<p>在Actor模型中，Actor的交互通过向对方Actor发送消息来完成。即Actor只关注要和谁通信，并不关注对方在哪里、如何和对方通信。模型只提供<strong>异步消息交互</strong>一种通信原语，甚至不保证对端一定能正确收到消息。</p>
<p>从Actor自身来说，它的行为模式很简单:</p>
<ul>
<li>发送消息给其它的Actor</li>
<li>接收并处理消息，更新自己的数据状态</li>
<li>创建其它的Actor</li>
</ul>
<p>每个Actor都有一个通信信箱(mailbox，FIFO消息队列)，用于保存已经收到但尚未被处理的消息。actorA要向actorB发消息，只需持有actorB ID(mailbox邮箱地址)，发送的消息将被Push到actorB的消息信箱尾部，然后返回。因此Actor的通信原语是异步的。消息QoS和请求-响应机制完全交给应用层去实现。这是Actor分布式友好的基础。</p>
<p>由于Actor这种”最坏预期”的设计理念，Actor模型天然有如下好处:</p>
<ul>
<li>由于Actor只通过消息交互，因此避免了锁的问题</li>
<li>由于Actor并不关心对方具体位置以及通信介质，这种位置透明的特性使得它在分布式下具备很好的扩展性</li>
<li>由于Actor只提供异步消息交互，因此整个系统的下限更高(锁和同步调用是高可用系统深深的痛)</li>
</ul>
<p>Erlang作为最早的Actor模型实践者，同时也是Actor模型的推广者和标杆。Erlang实现了完整的轻量级Actor(Erlang Process)，包括位置透明性、异步交互、基于规约的公平调度器等。使得它在并发和分布式方面有得天独厚的优势。</p>
<p>除此之外，Erlang OTP还在Actor模型的基础上，扩展了容错和热更两大杀手级工业特性: 容错和热更。</p>
<p>Erlang 热更我在<a href="https://wudaijun.com/2015/04/erlang-hotcode/">这里</a>有提到，Erlang热更是非常完备成熟的，配合<code>gen_server State</code>和FP，让”永不停服”成为了可能。</p>
<p>至于容错，一些文章将容错作为Actor模型的核心理念之一，我个人不是很认同，如<a href="https://zh.m.wikipedia.org/zh-hans/%E6%BC%94%E5%91%98%E6%A8%A1%E5%9E%8B">WIKI Actor模型</a>介绍的，Actor本身更多强调Actor本身的行为抽象和交互方式。而容错是Erlang link和supervisor机制提供的，可能由于Erlang代言Actor太成功了，以至于不少人认为: “没有容错的Actor不是纯正的Actor”。我在<a href="https://wudaijun.com/2018/07/gs-flexiblity-reliability/">这里</a>提到过一些Erlang的”let it crash”理念。</p>
<p>因为本文主要聊Erlang Actor 和 Golang CSP，因此热更和容错不作为重点暂开。前面说了Actor的优点，凡事都有两面性，再来看看Actor(仍以Erlang为例)的缺点:</p>
<ol>
<li>由于只提供不可靠异步交互原语，因此消息QoS，请求响应语义，都需要应用层实现，并且Erlang中的同步请求效率是很低的(需要遍历mailbox)</li>
<li>Actor有隔离和边界带来的并发和分布式的优势，也有其劣势，典型地如Actor聚合管理，消息流控等，OOM也是Erlang最常见的问题(Actor数量过大、Mailbox积压消息过多等)</li>
<li>强业务耦合Actor交互场景下，通常只能舍弃强一致性而使用最终一致性，对Actor的建模和划分粒度比较考究。</li>
</ol>
<h3 id="Golang-CSP"><a href="#Golang-CSP" class="headerlink" title="Golang CSP"></a>Golang CSP</h3><p>顺序通信进程(Communicating sequential processes，CSP)和Actor模型一样，都由独立的，并发的执行实体(process)构成，执行实体间通过消息进行通信。但CSP模型并不关注实体本身，而关注发送消息使用的通道(channel)，在CSP中，channel是第一类对象，process只管向channel写入或读取消息，并不知道也不关心channel的另一端是谁在处理。channel和process是解耦的，可以单独创建和读写，一个process可以读写(订阅)个channel，同样一个channel也可被多个process读写(订阅)。</p>
<p>对每个process来说：</p>
<ul>
<li>从命名channel取出并处理消息</li>
<li>向命名channel写入消息</li>
<li>创建新的process</li>
</ul>
<p>Golang并没有完全实现CSP理论(参见<a href="https://www.zhihu.com/question/26192499">知乎讨论</a>)，只提取了CSP的process和channel的概念为并发提供理论支持。目前Go已经是CSP的代表性语言。</p>
<h3 id="Golang-CSP-vs-Erlang-Actor"><a href="#Golang-CSP-vs-Erlang-Actor" class="headerlink" title="Golang CSP vs Erlang Actor"></a>Golang CSP vs Erlang Actor</h3><p>从Actor和CSP模型来说:</p>
<ul>
<li>Actor 和 CSP 有相同的宗旨：”不要通过共享内存来通信，而应该通过通信来共享内存”</li>
<li>Actor 和 CSP 都有独立的，并发执行的通信实体</li>
<li>Actor中第一类对象为执行实体(Actor)，CSP第一类对象为通信介质(Channel)</li>
<li>Actor中实体和通信介质是紧耦合的，一个Actor持有一个Mailbox，而CSP中process和channel是解耦的，没有从属关系。从这一层来说，CSP更加灵活</li>
<li>Actor模型中Actor是主体，Mailbox是匿名的，CSP模型中Channel是主体，Process是匿名的。从这一层来说，由于Actor不关心通信介质，底层通信对应用层是透明的。因此在分布式和容错方面更有优势。大部分的Actor框架原生支持分布式和容错</li>
</ul>
<p>具体到Golang和Erlang中的实现来说:</p>
<ul>
<li>两者均实现了语言级的轻量级Actor，在阻塞时能自动让出调度资源，在可执行时重新接受调度。Erlang调度更注重公平性(实时性)，Golang调度更注重吞吐量(性能)</li>
<li>Golang的Channel是有容量限制的，因此只能一定程度地异步(本质上仍然是同步的)，Erlang的Mailbox是无限制的(也带来了消息队列膨胀的风险)，并且Erlang并不保证消息是否能到达和被正确处理(但保证消息顺序)，是纯粹的异步语义，Actor之间做到完全解耦，奠定其在分布式和容错方面的基础。</li>
<li>Erlang/OTP在Actor上扩展了对分布式(支持异质节点)、热更和容错的原生支持，Golang在这些方面还有一段路要走(受限于Channel，想要在语言级别支持分布式是比较困难的)</li>
<li>Golang CSP具备更灵活地并发机制，因为Channel的两个特性: 有容量限制并独立于Goroutine存在。前者可以控制消息流量并反馈消息处理进度，后者让Goroutine本身有更高的处理灵活性。典型的应用场景是扇入扇出，生产者消费者，多路IO复用等。而在Erlang中实现这些则比较困难。另外，Erlang中的做同步请求需要遍历MailBox，而如果用Golang做同步调用，通过单独的Channel来做则更优雅高效</li>
</ul>
<h3 id="CSP-with-Actor"><a href="#CSP-with-Actor" class="headerlink" title="CSP with Actor"></a>CSP with Actor</h3><p>在用Go写GameServer框架时，发现可以将CSP和Actor的一些特性结合起来:</p>
<ul>
<li>游戏中的独立业务实体，如玩家，公会，具备强状态和功能聚合性，适合作为Actor的职责边界，即一个实体一个Goroutine</li>
<li>实体与实体之间只通过消息交互，每个实体暴露一个Logic Channel与其它实体进行逻辑交互，再做一层服务发现，即可让请求方只关注对方ID而不关注对方Channel</li>
<li>实体还有一些内部的Channel，如定时器，外部命令等。实体Goroutine对这些不同的消息来源Channel进行统一Select，形成多路IO复用的消息泵，并且可以独立控制各Channel大小</li>
<li>实体在行为和交互模型上，如Actor一样，从消息泵取出消息进行处理，并更新自己的数据，通过消息与其他Actor(本质是Channel)交互。但由于通信介质是Channel，可以封装更高级易用的交互语义，如同步、请求响应、扇入扇出、流控等</li>
<li>当然，基于Golang CSP支持有限，分布式，容错这些就只能框架自己搭建了</li>
</ul>
<p>如此，即有Actor的封装与边界，又有一定CSP的灵活性。</p>
<p>在研究这个问题的过程中，发现已经有人已经用Golang实现了Actor模型: <a href="https://github.com/AsynkronIT/protoactor-go。">https://github.com/AsynkronIT/protoactor-go。</a> 支持分布式，甚至supervisor，整体思想和用法和erlang非常像，真是有种他山逢知音的感觉。:)</p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
        <tag>golang</tag>
        <tag>actor</tag>
        <tag>csp</tag>
      </tags>
  </entry>
  <entry>
    <title>Lua 闭包 环境 包管理</title>
    <url>/2017/02/lua-notes/</url>
    <content><![CDATA[<h2 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h2><ul>
<li>访问一个不存在的全局变量得到nil</li>
<li>释放一个全局变量只需将其赋值为nil，效果与未定义该变量一样</li>
<li>Lua 中的变量全是全局变量，那怕是语句块或是函数里，除非用 local 显式声明为局部变量</li>
<li>局部变量比全局变量访问更快</li>
</ul>
<span id="more"></span>
<h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><h3 id="1-基本特性"><a href="#1-基本特性" class="headerlink" title="1. 基本特性"></a>1. 基本特性</h3><ol>
<li>多参数/返回值匹配：多余忽略，缺少用nil补足</li>
<li>可变参数：arg，table.pack，table.unpack</li>
<li>命名参数：参数的非顺序填充方式</li>
<li>正确处理尾调用：Lua能够高效正确处理尾调用，而不会导致栈溢出</li>
</ol>
<h3 id="2-第一类函数"><a href="#2-第一类函数" class="headerlink" title="2. 第一类函数"></a>2. 第一类函数</h3><p>函数是第一类值，函数可以像其它值（string, number）样用于赋给变量，作为函数参数或返回值。函数定义实际上是一个赋值语句，将类型为function的变量赋给一个变量。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">foo.bar</span> <span class="params">(x)</span></span> <span class="keyword">return</span> <span class="number">2</span>*x <span class="keyword">end</span></span><br><span class="line"><span class="comment">-- 等价于</span></span><br><span class="line">foo.bar = <span class="function"><span class="keyword">function</span> <span class="params">(x)</span></span> <span class="keyword">return</span> <span class="number">2</span>*x <span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>从这个角度来看，自然，与变量一样，Lua有全局函数和局部函数之分。</p>
<h3 id="3-词法闭包"><a href="#3-词法闭包" class="headerlink" title="3. 词法闭包"></a>3. 词法闭包</h3><p>词法闭包是指当在一个函数内部嵌套定义另一个函数时，内部函数体可以访问到外部函数的局部变量。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">newCounter</span><span class="params">()</span></span></span><br><span class="line">    <span class="keyword">local</span> i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">function</span><span class="params">()</span></span>     <span class="comment">-- anonymous function</span></span><br><span class="line">        i = i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> i</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">c1 = newCounter()</span><br><span class="line"><span class="built_in">print</span>(c1())  <span class="comment">--&gt; 1</span></span><br><span class="line"><span class="built_in">print</span>(c1())  <span class="comment">--&gt; 2</span></span><br><span class="line">c2 = newCounter()</span><br><span class="line"><span class="built_in">print</span>(c2())  <span class="comment">--&gt; 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 打印c1所有的upvalue 输出: i</span></span><br><span class="line"><span class="keyword">local</span> i=<span class="number">1</span></span><br><span class="line"><span class="keyword">local</span> up = <span class="built_in">debug</span>.<span class="built_in">getupvalue</span>(c1, i)</span><br><span class="line"><span class="keyword">while</span>(up ~= <span class="literal">nil</span>) <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">print</span>(up, <span class="string">&quot;  &quot;</span>)</span><br><span class="line">    i = i+<span class="number">1</span></span><br><span class="line">    up = <span class="built_in">debug</span>.<span class="built_in">getupvalue</span>(c1, i)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="built_in">print</span>(c1, c2) <span class="comment">-- function: 0x7f8df1d02100        function: 0x7f8df1d02160</span></span><br></pre></td></tr></table></figure>
<p>这种情况下，我们称i为匿名函数的外部局部变量(external local variable)或upvalue。在这里，newCounter函数返回了一个闭包(closure)。闭包是指一个函数和它的upvalues，闭包机制保证了即使upvalue已经超出了其作用域(newCounter返回)，仍然能正确被闭包函数引用而不会释放(由Lua GC管理)。在上例中，我们说c1和c2是建立在同一个函数上，但作用于同一个局部变量(i)不同实例的两个不同的闭包。</p>
<p>通过打印的upvalues可以看到，只有被闭包函数引用的外部局部变量，才算作该闭包函数的upvalue，Lua会按照闭包函数引用的顺序为upvalue编号，该编号与upvalue定义顺序无关。</p>
<p>最后一点是，闭包函数都是动态生成的，这和<a href="http://wudaijun.com/2016/09/go-basic/">Go中的闭包</a>有所不同，Go的闭包函数是在编译时生成的，不同的闭包可以共享闭包函数(同一个函数地址)。Lua的闭包函数动态生成会一定程度地影响运行效率和内存占用。</p>
<p>Lua闭包除了用于高级函数，回调函数，迭代器等上下文环境中以外，在完全不同的上下文环境，可用于重定义或预定义函数，通过这种方法，可以为代码创建一个安全的执行环境(也叫沙箱，sandbox)。</p>
<p>Lua还提供了对C闭包的支持，每当你在Lua中创建一个新的C函数，你可以将这个函数与任意多个upvalues联系起来，每一个upvalue 可以持有一个单独的Lua值。当函数被调用的时候，可以通过假索引(<code>lua_upvalueindex</code>)自由的访问任何一个upvalues。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">counter</span> <span class="params">(lua_State *L)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> val = lua_tonumber(L, lua_upvalueindex(<span class="number">1</span>));</span><br><span class="line">    lua_pushnumber(L, ++val);   <span class="comment">/* new value */</span></span><br><span class="line">    lua_pushvalue(L, <span class="number">-1</span>);       <span class="comment">/* duplicate it */</span></span><br><span class="line">    lua_replace(L, lua_upvalueindex(<span class="number">1</span>));  <span class="comment">/* update upvalue */</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;  <span class="comment">/* return new value */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">newCounter</span> <span class="params">(lua_State *L)</span> </span>&#123;</span><br><span class="line">    lua_pushnumber(L, <span class="number">0</span>);</span><br><span class="line">    lua_pushcclosure(L, &amp;counter, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>C闭包与Lua闭包在概念上很相似，但有两点不同：</p>
<ol>
<li>C函数的upvalues是显示push到栈中的，而Lua则可通过闭包函数引用确定哪些是upvalues</li>
<li>C闭包不能共享upvalues，每个闭包在栈中都有独立的变量集，但你可以通过将upvalues指向同一个table来实现共享</li>
</ol>
<h2 id="Chunk"><a href="#Chunk" class="headerlink" title="Chunk"></a>Chunk</h2><p>Chunk是一系列语句，Lua执行的每一块语句，比如一个文件或者交互模式下的每一行都是一个Chunk。</p>
<p>当我们执行loadfile(“test.lua”)时，便将test.lua的内容编译后的Chunk作为一个函数返回，如果出现编译错误，则返回nil和错误信息。而dofile相当于:</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">dofile</span> <span class="params">(filename)</span></span></span><br><span class="line">    <span class="keyword">local</span> f = <span class="built_in">assert</span>(<span class="built_in">loadfile</span>(filename))</span><br><span class="line">    <span class="keyword">return</span> f()</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>loadstring和dostring的关系类似，只是接收字符串而不是文件名为参数。</p>
<p>再看require，require和dofile完成同样的功能，但主要有几点不同：</p>
<ol>
<li>require会搜索Lua环境目录来加载文件</li>
<li>require会判断文件是否已经加载而避免重复加载统一文件</li>
<li>require可以用于加载C .so库，功能类似loadlib，参考<a href="http://wudaijun.com/2014/12/lua-C/">这里</a></li>
</ol>
<p>一个lua模块编译后的Chunk被作为匿名函数被执行，那么定义于模块中函数对模块局部变量的引用就形成了闭包，所以说Lua中的闭包真是无处不在。</p>
<h2 id="Enviroment"><a href="#Enviroment" class="headerlink" title="Enviroment"></a>Enviroment</h2><p>Lua中的环境用table来表示，这简化了环境处理也带来了不少灵活性。</p>
<p>在Lua5.1及之前，Lua将环境本身存储在一个全局变量_G中，其中包含了全局变量，内置函数，内置模块等。我们在使用任何符号x时，如果在当前函数的局部变量和upvalues无法找到符号定义(PS: Lua查找变量定义的规则为：局部变量 -&gt; 外部局部变量(upvalue) -&gt; 全局变量)，则会返回_G.x的值。由于_G是一个table，因此我们可以用它实现一些有意思的功能：</p>
<ol>
<li>通过动态名字访问全局变量： <code>_G[varname]</code></li>
<li>通过_G的metatable改变对未定义全局变量的读(<code>__index</code>)和写(<code>__newindex</code>)行为</li>
<li>通过setfenv改变指定函数的_G环境，制造函数执行的沙盒环境</li>
</ol>
<p>现在再回头来看闭包，实际上，Lua闭包除了函数和upvalues，还包括函数环境，这三者组成了一个完整的执行沙盒。</p>
<p>在Lua5.2及之后，Lua取消了setfenv函数，用_ENV方案替代了_G方案：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- before Lua 5.1</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line">  <span class="built_in">setfenv</span>(<span class="number">1</span>, &#123;&#125;)</span><br><span class="line">  <span class="comment">-- code here</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- after Lua 5.2</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line">  <span class="keyword">local</span> <span class="built_in">_ENV</span> = &#123;&#125;</span><br><span class="line">  <span class="comment">-- code here</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">or</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line">    <span class="keyword">local</span> <span class="built_in">_ENV</span> = &#123;&#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">function</span><span class="params">()</span></span> ... <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>_ENV有三个特性：</p>
<ol>
<li>对全局变量x的引用，将转换为_ENV.x</li>
<li>每个编译后的Chunk，都有一个_ENV upvalue(哪怕并未使用)，作为Chunk环境，并作用于其内定义的函数</li>
<li>在初始化时，_ENV=_G</li>
</ol>
<p>除了以上三点外，_ENV和普通变量并无区别。因此我们可以直接通过<code>local _ENV = &#123;&#125;</code>来覆盖接下来的代码的环境。将环境(_ENV)作为一个普通的upvalue来处理，这样做的好处是简化了闭包的概念，闭包等于函数加upvalues(没有了全局变量_G)，为闭包优化(如合并相同upvalues的闭包)提供更好的支持，同时也减少了<code>setfenv(f, env)</code>带来的不确定性和不安全性(函数的_ENV upvalue在闭包返回时就已经确定了)。</p>
<p>有_ENV还是一个table，因此对全局变量的访问控制等trick，仍然很容易实现。Lua目前仍然保留_G，但理解它们的别是比较重要的：</p>
<p>我们都知道Lua有一个全局注册表(Registry)，其中包含整个Lua虚拟机的信息，在Registry的<code>LUA_RIDX_GLOBALS</code>索引中，保存了Globals(也就是_G)，在创建Globals时，会生成<code>_G._G=_G</code>的自引用。在引入_ENV后，初始时，<code>_ENV=_G</code>，一旦编译器将_ENV放入Chunk的upvalue后，_ENV将作为普通upvalue被看待，因此我们可以对其重新赋值：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">i = <span class="number">1</span> <span class="comment">-- 此时 _ENV.i == _G.i == 1</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line">    <span class="keyword">local</span> <span class="built_in">_ENV</span>=&#123;i=<span class="number">2</span>, <span class="built_in">print</span>=<span class="built_in">print</span>, <span class="built_in">_G</span>=<span class="built_in">_G</span>&#125;</span><br><span class="line">    <span class="built_in">print</span>(i, <span class="built_in">_ENV</span>.i, <span class="built_in">_G</span>.i)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">g</span><span class="params">()</span></span></span><br><span class="line">    <span class="built_in">print</span>(i, <span class="built_in">_ENV</span>.i, <span class="built_in">_G</span>.i)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">f() <span class="comment">-- 2 2 1</span></span><br><span class="line">g() <span class="comment">-- 1 1 1</span></span><br></pre></td></tr></table></figure>
<p>因此，_ENV除了在创建时和_G都指向Registry[LUA_RIDX_GLOBALS]之外，和_G并没有直接联系(<code>_G=&#123;&#125;</code>不会影响函数环境，<code>_G.x=1</code>仍然会影响注册表中的Globals)，Lua5.2及之后的环境都由_ENV指定，_G出于历史原因保留，但实际上Lua并不在内部再使用：</p>
<blockquote>
<p>Lua keeps a distinguished environment called the global environment. This value is kept at a special index in the C registry (see §4.5). In Lua, the global variable _G is initialized with this same value. (_G is never used internally.)</p>
</blockquote>
<ul>
<li>参考<a href="http://lua-users.org/lists/lua-l/2014-08/msg00345.html">_ENV vs _G</a>，<a href="http://stackoverflow.com/questions/14290527/recreating-setfenv-in-lua-5-2">setfenv in Lua5.2</a></li>
</ul>
<h2 id="Packages"><a href="#Packages" class="headerlink" title="Packages"></a>Packages</h2><p>在Lua中，有闭包，灵活的table和环境管理，想要实现包管理有非常多的方法：</p>
<h3 id="1-基本方法"><a href="#1-基本方法" class="headerlink" title="1. 基本方法"></a>1. 基本方法</h3><p>最简单的方法就是直接使用table和第一类函数特性：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">complex = &#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">complex.new</span><span class="params">(r,i)</span></span> ... <span class="keyword">end</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">complex.add</span><span class="params">(c1,c2)</span></span> ... <span class="keyword">end</span></span><br><span class="line">...</span><br><span class="line"><span class="keyword">return</span> complex</span><br></pre></td></tr></table></figure>
<p>执行这个Chunk后，便可以通过<code>complex.xxx()</code>使用complex中定义的API了。这种方案主要的缺点是包内包外的调用都必须加上前缀，并且不能很好地隐藏私有成员。</p>
<h3 id="2-局部函数"><a href="#2-局部函数" class="headerlink" title="2. 局部函数"></a>2. 局部函数</h3><p>通过局部函数再导出的方式，我们可以解决包内调用前缀和隐藏私有成员(不导出即可)的问题。<br><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">new</span><span class="params">(r,i)</span></span> ... <span class="keyword">end</span></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">add</span><span class="params">(c1,c2)</span></span> ... <span class="keyword">end</span></span><br><span class="line">...</span><br><span class="line">complex = &#123;new = new, add = add&#125;</span><br><span class="line"><span class="keyword">return</span> complex</span><br></pre></td></tr></table></figure><br>但这样容易忘了local，造成全局命名空间污染。</p>
<h3 id="3-独立环境"><a href="#3-独立环境" class="headerlink" title="3. 独立环境"></a>3. 独立环境</h3><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">complex = &#123;&#125;</span><br><span class="line"><span class="comment">-- before Lua5.1: setfenv(1, complex)</span></span><br><span class="line"><span class="keyword">local</span> <span class="built_in">_ENV</span> = complex</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">new</span><span class="params">(r,  i)</span></span> ... <span class="keyword">end</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">new</span><span class="params">(c1, c2)</span></span> ... <span class="keyword">end</span></span><br><span class="line"><span class="keyword">return</span> complex</span><br></pre></td></tr></table></figure>
<p>现在，包内所有全局符号new, add都会被转换为complex.new, complex.add，并且我们为包创建了一个独立沙盒环境，如果要在包内访问全局符号，也有多种方法:</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 方案1: 保存老的全局环境 之后访问全局符号需要加上 _G.前缀</span></span><br><span class="line"><span class="keyword">local</span> <span class="built_in">_G</span> = <span class="built_in">_G</span></span><br><span class="line"><span class="comment">-- 方案2: 通过metatable 效率低一些，并且外部可通过complex.print访问_G.print</span></span><br><span class="line"><span class="built_in">setmetatable</span>(complex, &#123;<span class="built_in">__index</span> = <span class="built_in">_G</span>&#125;)</span><br><span class="line"><span class="comment">-- 方案3: 只导出要使用的函数 这种方法隔离型更好，并且更快</span></span><br><span class="line"><span class="keyword">local</span> <span class="built_in">sqrt</span> = <span class="built_in">math</span>.<span class="built_in">sqrt</span></span><br><span class="line"><span class="keyword">local</span> <span class="built_in">print</span> = <span class="built_in">print</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title>Erlang Unicode编码</title>
    <url>/2016/12/unicode-in-erlang/</url>
    <content><![CDATA[<h2 id="Unicode基础"><a href="#Unicode基础" class="headerlink" title="Unicode基础"></a>Unicode基础</h2><h3 id="编码方式"><a href="#编码方式" class="headerlink" title="编码方式"></a>编码方式</h3><p>定义字符集中每个字符的<strong>codepoint(数字编码)</strong></p>
<ul>
<li>ASCII: 不用多说，编码空间为7位(0-127)</li>
<li><a href="https://zh.wikipedia.org/wiki/ISO/IEC_8859-1">ISO 8859-1</a>: 又称Latin-1，以ASCII为基础，在空置的0xA0-0xFF的范围内，加入96个字母及符号。编码空间为8位(0-255)</li>
<li>UCS-2: 16位编码空间 又称基本多文种平面或零平面</li>
<li>UCS-4: 32位编码空间 在UCS-2基本上，加入辅助平面(目前有16个辅助平面，至少需要21位)</li>
<li>注1: UCS(Universal Character Set, <a href="https://zh.wikipedia.org/wiki/%E9%80%9A%E7%94%A8%E5%AD%97%E7%AC%A6%E9%9B%86">通用字符集</a>)</li>
<li>注2: 以上四种编码都是向前兼容的，通常我们所说的Unicode编码指UCS-2和UCS-4，目前广泛运用的是UCS-2</li>
</ul>
<span id="more"></span>
<h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><p>实现方式将字符的数字编码存储在计算机字节中，由于节省空间和平台差异性等，衍生不同的实现方式</p>
<ul>
<li><a href="https://zh.wikipedia.org/wiki/UTF-8">UTF-8</a>: 一种变长编码，使用1-3个字节编码UCS-2字符集，1-6个字节可编码UCS-4字符集(目前只用最多四个字节即可表示UCS-4所定义的17个平面)。优点是兼容ASCII，节省空间，并且不存在字节序的问题</li>
<li><a href="https://zh.wikipedia.org/wiki/UTF-16">UTF-16</a>: 和UTF-8类似，使用2个字节来编码UCS-2字符集(UCS-2中有预留的位用于实现UTF-16扩展多字节)，使用4个字节来编码UCS-4字符集。由于使用两个字节作为基本编码单位，UTF-16存在字节序的问题，通常使用BOM来解决</li>
<li><a href="https://zh.wikipedia.org/wiki/UTF-32">UTF-32</a>: 32位定长编码，能够表示UCS-4字符集所有字符，但空间占用大，因此很少见</li>
<li>注1: UTF(Unicode Transformation Format, Unicode转换格式)</li>
<li>注2: BOM(byte-order mark, <a href="https://zh.wikipedia.org/wiki/%E4%BD%8D%E5%85%83%E7%B5%84%E9%A0%86%E5%BA%8F%E8%A8%98%E8%99%9F">字节顺序标记</a>)</li>
</ul>
<h2 id="Erlang中的Unicode"><a href="#Erlang中的Unicode" class="headerlink" title="Erlang中的Unicode"></a>Erlang中的Unicode</h2><h3 id="Unicode表示"><a href="#Unicode表示" class="headerlink" title="Unicode表示"></a>Unicode表示</h3><pre><code>%% 环境 Mac OSX Yosemite &amp; Erlang OTP/19
Eshell V8.1  (abort with ^G)
1&gt; L = &quot;中文&quot;.
[20013,25991] % Erlang lists存放的是字符的Unicode编码
2&gt; B = &lt;&lt;&quot;中文&quot;&gt;&gt;.
&lt;&lt;45,135&gt;&gt; % Erlang只知&quot;中文&quot;的Unicode编码[20013,25991]，并不知应该用何种实现方式(UTF8或其他)，默认它会将Unicode编码 rem 256，产生0-255间的编码(并按照Lantin-1解码)

% 下面我们将考虑将&quot;中文&quot;转换为binary
% 方案一. erlang:list_to_binary -&gt; error
3&gt; list_to_binary(L). % 该函数支持的list只能是iolist(见后面术语参考)，否则Erlang并不知道你想将字符串转换为何种编码格式的binary
** exception error: bad argument
     in function  list_to_binary/1
        called as list_to_binary([20013,25991])

% 方案二. unicode:characters_to_binary -&gt; ok
4&gt; UTF8 = unicode:characters_to_binary(L).% 将L中的unicode编码转换为UTF8 binary
&lt;228,184,173,230,150,135&gt;&gt;
5&gt; UTF16Big = unicode:characters_to_binary(UTF8,utf8,utf16).
&lt;&lt;78,45,101,135&gt;&gt; % 默认为Big Endian
6&gt; UTF16Little = unicode:characters_to_binary(UTF8,utf8,&#123;utf16,little&#125;).
&lt;&lt;45,78,135,101&gt;&gt;

% 方案三. 利用binary构造语法构建
7&gt; UTF8 = &lt;&lt;&quot;中文&quot;/utf8&gt;&gt;.
&lt;&lt;228,184,173,230,150,135&gt;&gt;
8&gt; UTF8 = &lt;&lt;L/utf8&gt;&gt;. % Why ?
** exception error: bad argument
</code></pre><p>在Erlang中，字符串就是整数列表，并且这个整数可以无限大，lists将保存其中每个字符的Unicode编码，只要lists中的整数是有效的Unicode codepoint，就可以找到对应的字符。因此也就不存在UTF8/UTF16格式的lists字符串一说。而binary的处理则要麻烦一些，Erlang用UTF8作为Unicode在binary上的实现方式，unicode模块提供了这方面丰富的unicode编码处理接口。</p>
<h3 id="Unicode使用"><a href="#Unicode使用" class="headerlink" title="Unicode使用"></a>Unicode使用</h3><pre><code>8&gt; io:format(&quot;~s&quot;, [L]).
** exception error: bad argument
 in function  io:format/3
    called as io:format(&lt;0.50.0&gt;,&quot;~s&quot;,[[20013,25991]])
9&gt; io:format(&quot;~p&quot;, [L]).
[20013,25991]ok
10&gt; io:format(&quot;~ts&quot;, [L]).
中文ok
11&gt; io:format(&quot;~s&quot;, [UTF8]).
ä¸­æok
12&gt; io:format(&quot;~p&quot;, [UTF8]).
&lt;&lt;228,184,173,230,150,135&gt;&gt;ok
13&gt; io:format(&quot;~ts&quot;, [UTF8]).
中文ok
</code></pre><p>先解释几个Erlang术语：</p>
<ul>
<li><a href="http://www.cnblogs.com/me-sa/archive/2012/01/31/erlang0034.html">iolist</a>: 0-255编码(Latin-1)的lists，binary，或它们的嵌套，如<code>[[&quot;123&quot;,&lt;&lt;&quot;456&quot;&gt;&gt;],&lt;&lt;&quot;789&quot;&gt;&gt;]</code></li>
<li>unicode binary: UTF8编码的binary(Erlang默认使用UTF8 binary编码unicode)</li>
<li>charlist: UTF8编码的binary，或包含有效unicode codepoint的lists，或它们的嵌套，如<code>[&lt;&lt;&quot;hello&quot;&gt;&gt;, &quot;中国&quot;]</code></li>
</ul>
<p><code>~s</code>只能打印iolist，binary，或atom，因此不能直接打印中文lists(无法解码超过255的codepoint)或UTF8 binary(会按字节解释，出现乱码)。</p>
<p><code>~ts</code>则可打印charlist和unicode binary。</p>
<p><code>~p</code>如果不能打印出ASCII(0-127)字符，则直接打印出原生Term，不会对Unicode编码进行处理。</p>
<p>参考：</p>
<ol>
<li><a href="http://erlang.org/doc/man/unicode.html">http://erlang.org/doc/man/unicode.html</a></li>
<li><a href="http://erlang.org/doc/apps/stdlib/unicode_usage.html">http://erlang.org/doc/apps/stdlib/unicode_usage.html</a></li>
</ol>
]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title>go select机制与常见的坑</title>
    <url>/2017/10/go-select/</url>
    <content><![CDATA[<p>go select思想来源于网络IO模型中的select，本质上也是IO多路复用，只不过这里的IO是基于channel而不是基于网络，同时go select也有一些自己不同的特性，这里简单探讨下。</p>
<p>go select 的特性:</p>
<ol>
<li>每个case都必须是一个通信</li>
<li>所有channel表达式都会被求值</li>
<li>所有被发送的表达式都会被求值</li>
<li>如果任意某个通信可以进行，它就执行；其他被忽略。</li>
<li>如果有多个case都可以运行，select会随机公平地选出一个执行。其他不会执行。否则执行default子句(如果有)</li>
<li>如果没有default字句，select将阻塞，直到某个通信可以运行；Go不会重新对channel或值进行求值。</li>
</ol>
<p>下面通过几个例子来理解这些特性:</p>
<span id="more"></span>
<p>1.select closed/nil channel</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> v1, ok := &lt;-c1:</span><br><span class="line">        <span class="comment">// 如果c1被关闭(ok==false)，每次从c1读取都会立即返回，将导致死循环</span></span><br><span class="line">        <span class="comment">// 可以通过将c1置为nil来让select ignore掉这个case，继续评估其它case</span></span><br><span class="line">		<span class="keyword">if</span> !ok &#123;</span><br><span class="line">			c1 = <span class="literal">nil</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">case</span> v2 := &lt;- c2:</span><br><span class="line">	    <span class="comment">// 同样，如果c2被关闭，每次从c1读取都会立即返回对应元素类型的零值(如空字符串)，导致死循环</span></span><br><span class="line">	    <span class="comment">// 解决方案仍然是置c2为nil，但是有可能误判(写入方是写入了一个零值而不是关闭channel，比如整数0)</span></span><br><span class="line">	    </span><br><span class="line">	<span class="keyword">case</span> c3 &lt;- v3:</span><br><span class="line">	    <span class="comment">// 如果c3已经关闭，则panic</span></span><br><span class="line">	    <span class="comment">// 如果c3为nil，则ignore该case	    </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2.实现非阻塞读写</p>
<p>结合特性5,6，可以通过带 default 语句的 select 实现非阻塞读写，在实践中还是比较有用的，比如 GS 尝试给玩家推送某条消息，可能并不希望 GS 阻塞在该玩家的 writeChan 上。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> writeChan &lt;- msg:</span><br><span class="line">        <span class="comment">// do something write successed</span></span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">// drop msg, or log err</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>需要注意，一些同学可能将select与switch搞混，习惯先把default写好，然后加上外层的for循环导致死循环。使用select语句，for和default基本不会同时出现。</p>
<p>3.实现定时任务</p>
<p>结合特性2，每次 select 都会对所有通信表达式求值，因此可通过 <code>time.After</code>简洁实现定时器功能，并且定时任务可通过 done channel 停止:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> &lt;- time.After(time.Second):</span><br><span class="line">	    <span class="comment">// do something per second</span></span><br><span class="line">	<span class="keyword">case</span> &lt;- donec:</span><br><span class="line">		<span class="keyword">return</span>	</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>现在我们稍微变更一下:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">donec := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">bool</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">close</span>(donec)</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> &lt;- time.After(time.Second):</span><br><span class="line">		fmt.Println(<span class="string">&quot;timer&quot;</span>)</span><br><span class="line">	<span class="keyword">case</span> &lt;- donec:</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>现在这段代码会输出什么？还是 panic？答案是什么也不会，因为:</p>
<ol>
<li>donec close 了，每次 select 都会执行到 <code>case &lt;- donec</code>，并读出零值(false)</li>
<li>每次执行了 <code>case &lt;- donec1</code> 后，select 再次对 case1 的 <code>timer.After</code> 求值，返回一个新的下一秒超时的 Timer</li>
<li>再次执行到 <code>case &lt;- donec</code> ….</li>
</ol>
<p>因此，<code>case &lt;- timer.After(time.Second)</code> 不应该解释为每一秒执行一次，而是其它 case 如果有一秒都没有执行，那么就执行这个 case。</p>
<p>4.多个case满足读写条件</p>
<p>结合特性4，如果多个case满足读写条件，select会随机选择一个语句执行：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">1024</span>)</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(ch <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">		<span class="keyword">for</span> &#123;</span><br><span class="line">			val := &lt;-ch</span><br><span class="line">			fmt.Printf(<span class="string">&quot;val:%d\n&quot;</span>, val)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;(ch)</span><br><span class="line">    </span><br><span class="line">	tick := time.NewTicker(<span class="number">1</span> * time.Second)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> ch &lt;- i:</span><br><span class="line">		<span class="keyword">case</span> &lt;-tick.C:</span><br><span class="line">			fmt.Printf(<span class="string">&quot;%d: case &lt;-tick.C\n&quot;</span>, i)</span><br><span class="line">		&#125;</span><br><span class="line">    </span><br><span class="line">		time.Sleep(<span class="number">500</span> * time.Millisecond)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">close</span>(ch)</span><br><span class="line">	tick.Stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出:</p>
<pre><code>val:0
val:1
2: case &lt;-tick.C
val:3
4: case &lt;-tick.C
</code></pre><p>可以看到向ch写入的2和4”不见”了，因为当tick.C和ch同时满足读写条件时，select随机选择了一个执行，导致看起来一些数据丢了，其实这个例子是比较极端的，因为向ch写入的数据本身就与外部for循环计数耦合了，导致依赖于select的随机结果(本次没随机到，放到下次，但此时写入的数据已经变更了)，因此实际不是数据丢了，而是代码设计时没有考虑到每次select只会执行一条读写语句(并且是随机选取的)，导致结果不如预期。</p>
<p>总的来说，go select还是比较容易踩坑的，比如加了不该加的default，没有考虑到channel关闭的情况，没有理解随机性等等，在使用的时候还是要小心。</p>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>用context库规范化Go的异步调用</title>
    <url>/2017/08/go-conetxt-usage/</url>
    <content><![CDATA[<h3 id="常见并发模型"><a href="#常见并发模型" class="headerlink" title="常见并发模型"></a>常见并发模型</h3><p>之前对比过<a href="http://wudaijun.com/2017/05/go-vs-erlang/">Go和Erlang的并发模型</a>，提到了Go的优势在于流控，下面列举几种常见的流控:</p>
<h4 id="Ping-Pong"><a href="#Ping-Pong" class="headerlink" title="Ping-Pong"></a>Ping-Pong</h4><p>这通常针对于两个goroutine之间进行简单的数据交互和协作，我们常用的RPC也属于此类，通过channel的类型可以灵活实现交互方式:</p>
<ul>
<li>同步单工: 单个双向非缓冲channel</li>
<li>同步双工: 多个单向非缓冲channel</li>
<li>异步双工: 多个单向缓冲channel</li>
</ul>
<span id="more"></span>
<h4 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h4><p>流水线如其词语，goroutine是”流水线工人”，channel则为”流水线”，衔接不同的goroutine的输入输出，每个goroutine有一个输入(inbound)channel和输出(outbound)channel:</p>
<pre><code>// 以下定义一个流水线工人 用于将inbound channel中数字求平方并放入outbound channel
func sq(in &lt;-chan int) &lt;-chan int &#123;
    out := make(chan int)
    go func() &#123;
        for n := range in &#123;
            out &lt;- n * n
        &#125;
        close(out)
    &#125;()
    return out
&#125;
</code></pre><p>流水线goroutine有一些特质：它负责创建并关闭channel(在完成自己的工作后)，这样外部调用无需关心channel的创建和关闭，当channel被关闭，它的下游goroutine会读出零值的数据。我们还可以用链式调用来组装流水线：</p>
<pre><code>sq(sq(sq(ch)))
</code></pre><p>在实际应用中，如DB读写，网络读写等外部阻塞操作通常都放到单独的流水线去做，下游主goroutine可以灵活处理IO结果(如通过select完成IO复用)。</p>
<h4 id="扇入扇出"><a href="#扇入扇出" class="headerlink" title="扇入扇出"></a>扇入扇出</h4><p>流水线工作通常是一对一的”工作对接”，通过select可以达成IO复用，比如GS同时处理网络消息，RPC调用，Timer消息等，这其实就是简单的扇入模型，扇出模型也比较常见，比如在对一些无状态的任务做分发时，可以让多个goroutine处理一个channel任务队列上的数据，最大程度地提升处理效率。</p>
<p>上面三个模式是应用最常用到的，因此不再举例具体说明，<a href="https://studygolang.com/articles/11908">Go并发可视化</a>这篇文章很好地归纳和总结了这些模型，推荐一读。</p>
<h3 id="交互规范"><a href="#交互规范" class="headerlink" title="交互规范"></a>交互规范</h3><p>上面只所以提出这三种模型主要是为了导出接下来的问题，当用到多个goroutine时，如何协调它们的工作：</p>
<h4 id="如何正确关闭其它goroutine"><a href="#如何正确关闭其它goroutine" class="headerlink" title="如何正确关闭其它goroutine"></a>如何正确关闭其它goroutine</h4><p>这类问题的通常情形是：当某个goroutine遇到异常或错误，需要退出时，如何通知其它goroutine，或者当服务器需要停止时，如何正常终止整个并发结构，为了简化处理问题模型，以流水线模型为例，在正常情况下，它们会按照正常的流程结束并关闭channel(上游关闭channel，下游range停止迭代，如此反复)，但当某个下游的goroutine遇到错误需要退出，上游是不知道的，它会将channel写满阻塞，channel内存和函数栈内存将导致内存泄露，在常规处理方案中，我们会使用一个done channel来灵活地通知和协调其它goroutine，通过向done channel写入数据(需要知道要关闭多少个goroutine)或关闭channel(所有的读取者都会收到零值，range会停止迭代)。</p>
<h4 id="如何处理请求超时"><a href="#如何处理请求超时" class="headerlink" title="如何处理请求超时"></a>如何处理请求超时</h4><p>至于超时和请求放弃，通常我们可以通过select来实现单次请求的超时，比如 A -&gt; B -&gt; C 的Ping-Pong异步调用链，我们可以在A中select设置超时，然后在B调用C时也设置超时，这种机制存在如下问题:</p>
<ol>
<li>每次请求链中的单次调用都要启一个timer goroutine</li>
<li>调用链中的某个环节，并不知道上层设置的超时还有多少，比如B调用C时，如果发现A设置的超时剩余时间不足1ms，可以放弃调用C，直接返回</li>
<li>A-&gt;B的超时可能先于B-&gt;C的超时发生，从而导致其它问题</li>
</ol>
<h4 id="如何安全放弃异步请求"><a href="#如何安全放弃异步请求" class="headerlink" title="如何安全放弃异步请求"></a>如何安全放弃异步请求</h4><p>这个问题可以理解为如何提前结束某次异步调用，接上面提到的A-&gt;B-&gt;C调用链，如果A此时遇到了其它问题，需要提前结束整个调用链(如)，B是不知道的，A和B之间数据交互channel和done channel，没有针对某个请求的取消channel，尽管大部分时候不会遇到这种需求，但针对某个请求的协同机制是缺失的，还需要另行设计。</p>
<h4 id="如何保存异步调用上下文"><a href="#如何保存异步调用上下文" class="headerlink" title="如何保存异步调用上下文"></a>如何保存异步调用上下文</h4><p>异步调用通常会有上下文，这个上下文不只指调用参数，还包括回调处理参数(非处理结果)，请求相关上下文(如当前时间)等，这类数据从设计上可以通过包含在请求中，或者extern local value，或者每次请求的session mgr来解决，但并不通用，需要开发者自行维护。</p>
<h3 id="使用context"><a href="#使用context" class="headerlink" title="使用context"></a>使用context</h3><p>以上几个问题并不限于Go，而是异步交互会遇到的普遍问题，只是在Go应用和各类库会大量用到goroutine，所以这类问题比较突出。针对这些问题，Go的内部库(尤其是net,grpc等内部有流水线操作的库)作者开发了context(golang.org/x/net/context)包，用于简化单个请求在多个goroutie的请求域(request-scoped)数据，它提供了:</p>
<ol>
<li>请求的超时机制</li>
<li>请求的取消机制</li>
<li>请求的上下文存取接口</li>
<li>goroutine并发访问安全性</li>
</ol>
<p>context以组件的方式提供超时(WithTimeout/WithDeadline)，取消(WithCancel)和K-V(WithValue)存取功能，每次调用WithXXX都将基于当前的context(Background为根Context)继承一个Context,一旦父Context被取消，其子Context都会被取消，应用可通过&lt;-context.Done()和<br>context.Err()来判断当前context是否结束和结束的原因(超时/取消)。</p>
<p>比如针对我们前面的”sq流水线工人”，我们可以通过context让它知道当前流水线的状态，并及时终止:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sq</span><span class="params">(ctx context.Context, in &lt;-<span class="keyword">chan</span> <span class="keyword">int</span>)</span> <span class="title">out</span> &lt;-<span class="title">chan</span> <span class="title">int</span></span>&#123;</span><br><span class="line">	out := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">	    <span class="keyword">for</span> n := <span class="keyword">range</span> in &#123;</span><br><span class="line">	        <span class="keyword">select</span>&#123;</span><br><span class="line">	        <span class="keyword">case</span> &lt;-ctx.Done():	<span class="comment">// 当前流水线被终止</span></span><br><span class="line">	        		<span class="built_in">close</span>(out)</span><br><span class="line">	        		<span class="keyword">return</span> ctx.Err() <span class="comment">// 终止原因: DeadlineExceeded or Canceled</span></span><br><span class="line">	        <span class="keyword">case</span> out &lt;- n * n:</span><br><span class="line">	    &#125;</span><br><span class="line">	    <span class="built_in">close</span>(out)</span><br><span class="line">	&#125;()</span><br><span class="line">	<span class="keyword">return</span> out</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以将context在goroutine之间传递，并且针对当前调用通过WithXXX创建子context，设置新的超时，请求上下文等，一旦请求链被取消或超时，context的done channel会被关闭，当前context的所有<code>&lt;-ctx.Done()</code>操作都会返回，并且所有当前context的子context会以相同原因终止。</p>
<p>比如在A-&gt;B-&gt;C中，B基于A的context通过WithTimeout或WithValue创建子context，子Context的超时和上下文都可以独立于父context(但如果子context设置超时大于父context剩余时间，将不会创建timer)，通过context库内部的继承体系来完成对应用层调用链的记录，并执行链式的超时和取消。</p>
<p>关于context的进一步了解可参考<a href="https://segmentfault.com/a/1190000006744213">Go语言并发模型：使用 context</a>，也可直接阅读源码，实现也比较简单，单文件不到300行代码，但本身的意义却是重大的，go的很多异步库(如net,grpc,etcd等)都用到了这个模块，context正在逐渐成为异步库的API规范，我们也可以从context这个库中得到一些启发，适当地用在自己的项目中。</p>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>探讨服务端回合制战斗系统</title>
    <url>/2017/09/ngs-battle/</url>
    <content><![CDATA[<p>本文记录最近做战斗系统的一些心得和思考，由于我们的战斗系统是回合制的，与大部分回合制游戏一样，需要服务器计算战斗，客户端以战报的方式回放。这里探讨一下服务端战斗系统的设计思路，实现一个灵活，可配置，扩展性强的战斗系统。</p>
<h2 id="战斗流程"><a href="#战斗流程" class="headerlink" title="战斗流程"></a>战斗流程</h2><p>战斗地图是一个X*Y的矩阵，每个参与者(Fighter)初始位于其中一个格子上。战斗开始后，按照回合迭代，达到胜负条件或最大回合数则战斗结束。回合内，英雄按照出手顺序先后行动(Action)，英雄的Action包括移动，释放技能和普攻。</p>
<p>战斗流程是比较简明易懂的，整个战斗系统的难点在于多样的技能实现。每个英雄有N个技能，每个英雄可通过学习其它技能来实现不同的战斗效果，技能的效果和作用比较繁杂，例如：</p>
<span id="more"></span>
<ul>
<li>SkillA: 英雄每回合前3次伤害有50%机率使伤害翻倍(最多生效2次)</li>
<li>SkillB: 诅咒一片区域（以一个敌方为中心的3*3格子）的敌人，使其攻击距离减1，持续两回合</li>
<li>SkillC: 分裂箭，英雄普攻可对多个敌人造成伤害</li>
<li>…</li>
</ul>
<p>以下我们主要围绕灵活的技能系统为主要需求，讨论如何实现一个稳定，可扩展的战斗系统。</p>
<h2 id="Event系统"><a href="#Event系统" class="headerlink" title="Event系统"></a>Event系统</h2><p>Event事件管理是实现复杂技能效果的基石，通过Event可以将复杂，易变的技能效果和核心流程解耦。对回合制游戏，典型地Event有回合开始/结束，英雄移动/普攻/受击/死亡等，EventMgr管理这些Event和它们的Handler，主要提供如下接口:</p>
<pre><code>// Go Code
type EventArgs map[string]interface&#123;&#125;
type EventHandler func(EventArgs)

// 触发Event， 由战斗流程调用 如回合开始，英雄移动等
FireEvent(EventType, EventId, EventArgs)
// 监听Event， ListenerId通常为Buff的唯一ID 
AddEventListener(EventType, EventId, ListenerId, EventHandler)
// 注销ListenerId监听的所有Event，通常在Buff结束时调用
DelEventListener(ListenerId)
</code></pre><p>EventMgr实际上是一个订阅者模式，战斗流程通过FireEvent发布事件，Buff订阅关心的事件并更新自己状态，在Buff结束时注销所有相关的事件监听。两者通过订阅者模式完成解耦，便于扩展。</p>
<h2 id="技能系统"><a href="#技能系统" class="headerlink" title="技能系统"></a>技能系统</h2><p>技能分为主动技能(概率触发)和被动技能(相当于战斗开始立即触发)。技能的效果分为瞬时性和持续性两种，前者即像普通一样立即造成伤害(其实普攻也可以看做技能的一种)，后者指技能效果包含状态性，有自己的生命周期和状态更新，如Dot伤害，无法移动，沉默等，这个状态通常叫做Buff，关于技能和Buff的区别我的理解是，技能是Buff的容器，是静态的，Buff是技能触发后的实现效果，是动态的。瞬时伤害的技能也可以通过Buff实现，只不过这个Buff生命周期很短，在造成伤害后就消失了。关于Buff的详细实现我们放到后面，我们先看技能系统本身。</p>
<p>考虑到技能以后的扩展性和可维护性，对其尽可能做抽象是有必要的，抽象出公共的流程，将可变量配置化，可以提升系统稳定性和扩展性，也方便后期做测试。技能本身包含几个阶段：技能触发(概率触发，战斗开始触发)，目标选取(敌军/友军，一个/多个)，技能作用(造成伤害，挂接Buff)，前两个是可抽离到配置的，通过通用的技能触发器和目标选取脚本得到技能所需要的信息传给技能作用模块，由于技能作用效果的多样性，目前我们没有对技能作用进行抽象，是通过脚本各个实现的。</p>
<h2 id="Buff系统"><a href="#Buff系统" class="headerlink" title="Buff系统"></a>Buff系统</h2><p>技能的各种复杂效果都通过BUFF实现，每个Buff都挂于战场某个参与者(Fighter)上，当Fighter阵亡，其上所有的Buff都会被移除(包括Event关联)。BUFF系统是由一个基于战场事件(Event)的回调系统驱动，整个战场在战斗流程中不断抛出各种Event(如回合开始/结束，Fighter普攻/受击/释放技能，伤害结算等)，BUFF注册这些Event并更新自己Owner(Fighter)的状态，来实现灵活强大的技能效果。</p>
<h3 id="1-Buff抽象"><a href="#1-Buff抽象" class="headerlink" title="1.Buff抽象"></a>1.Buff抽象</h3><ul>
<li>Start():Buff开始，即Buff启动脚本，负责初始化状态，注册BUFF的生命周期和相关Event等。</li>
<li>Update():Buff状态更新，实现Buff作用并更新Buff的状态，对于次数性BUFF(如前N次免伤)，可能调用N次Update，复杂的技能也可能有多个Update函数(关心不同的Event)</li>
<li>Finish():Buff的正常结束，当BUff结束条件满足(比如Update了N次，或者持续了N回合)调用</li>
<li>Cancel():Buff被冲突(中断)时的处理</li>
</ul>
<p>以上阐述的是Buff的行为抽象，而不是具体实现，在设计Buff时从这四个触法点思考，加上EventMgr注册回调机制，基本可以实现绝大部分各式的Buff效果。例如最开始提到的SkillA: 英雄每回合前3次伤害有50%机率使伤害翻倍(最多生效2次)，这是一个持续整场战斗的Buff(BuffA)，它注册两个Update Event:</p>
<ul>
<li><code>BEFORE_DAMAGE</code>(英雄攻击伤害结算前): Update1 中判断如果本回合已触发次数小于2并且满足触发条件(50%概率)，则更新自己的状态(计数器+1)，并产生<strong>伤害翻倍子Buff</strong>(后面讨论)。</li>
<li><code>ROUND_START</code>(每回合开始): Update2 中重置Buff状态(计数器)。</li>
</ul>
<p>目前我们所讨论的Buff都是独立的，有自己生命周期的个体，通过Event注册回调与战斗主流程解耦。但实际上Buff之间是有相互关联的，主要分为三种：Buff属性作用，Buff冲突免疫关系和Buff生命周期，下面分别介绍。</p>
<h3 id="2-Buff属性作用"><a href="#2-Buff属性作用" class="headerlink" title="2. Buff属性作用"></a>2. Buff属性作用</h3><p>仍然是我们前面的SkillA技能，我们现在来看如何实现伤害翻倍这个Buff，该Buff是SkillA对应的Buff生成的子Buff，它应该被设计为可公用的伤害增加Buff，这个Buff的作用是影响伤害结算流程，按照我们之前的事件注册回调思路，我们可以注册伤害结算这个Event，接收当前算出的伤害，然后*200%并返回新伤害值。如BuffA提升10%伤害，BuffB增加20点真实伤害，BuffC降低20%的伤害，那么最终得到伤害为: <code>(基础伤害*110%+20)*80%</code>，这种方案默认公式计算的顺序与Buff挂载顺序一致，，而正确的伤害值应该为<code>(基础伤害+20)*(1+10%-20%)</code>，如果要处理这种优先级关系，需要遍历所有注册伤害结算Event的Handler，按照类型排序，再依次处理，如果一旦有同类Buff添加或移除，又要重新计算。这样公式与事件管理做到了一起，是不稳定的。</p>
<p>BuffA,BuffB,BuffC之所以会有复杂的公式计算，一个原因在于它们作用于同一属性的不同维度，BuffA,BuffC作用于伤害值的比例增加这一维度，而BuffB作用于伤害值的绝对值增长这一维度，我们可以将它们分开，作为Fighter两个独虚拟属性ATTR_DAMAGE_ABS, ATTR_DAMAGE_PCT来维护，允许Buff对其修改，但此时的修改是只有加减关系的，避免了优先级的问题，在伤害结算时，通过公式计算: (基础伤害+ATTR_DMAGE_ABS)*ATTR_DAMAGE_PCT即可。</p>
<p>整个交互流程为: </p>
<ul>
<li>战斗流程抛出事件 -&gt; 事件系统 -&gt;Buff系统 -&gt; Fighter属性维度</li>
<li>战斗流程获取属性 -&gt; 属性系统 -&gt; 公式计算  -&gt; Fighter属性维度</li>
</ul>
<p>通过属性系统和事件系统，将战斗流程和Buff系统解耦，将组件职责降到最小，方便测试和扩展。</p>
<p>比如沉默，眩晕等效果，如果没有虚拟属性，沉默Buff会注册EVENT_BEFORE_SKILL(Fighter释放技能前)这个Event，并且返回false来告知战斗系统它当前不能释放技能。同样，眩晕Buff会注册Fighter EVENT_BEFORE_MOVE, EVENT_BEFORE_ATTACK, EVENT_BEFORE_SKILL三个Event来实现眩晕效果，一来整个战斗流程每次都要合并各类Event的各种返回值(并且EventHandler得不到统一的接口抽象)，效率低下，二来战斗流程不应该依赖外部EventHandler的实现，它只关心值本身(能否移动，能否施法等)，因此虚拟属性本身实际上起一个依赖倒置的作用。如果使用虚拟属性，那么沉默Buff会在ATTR_FORBIDEN_SKILL这个属性上+1，眩晕同理，这样战斗流程在Fighter尝试施放技能时，获取Fighter的ATTR_FORBIDEN_SKILL属性，如果&gt;0，则不能施法。</p>
<p>Buff通过属性来影响战斗流程，一方面解耦了战斗流程和Buff之间的依赖，另一方面也减轻了Buff与Buff之间的依赖，并且通过属性来固化战斗系统不易变的部分，可以减轻系统复杂度，易于调试。</p>
<h3 id="3-Buff作用链"><a href="#3-Buff作用链" class="headerlink" title="3. Buff作用链"></a>3. Buff作用链</h3><p>不是所有的Buff都可以通过属性来完成解耦，比如护盾效果，A Buff 加200护盾，B Buff 加300护盾，那么 Fighter 护盾属性为500，此时战斗伤害结算流程扣除400护盾值，那么这个值应该从 A 减还是 B 减，战斗流程并不知晓，需要护盾Buff自己来维护(并且在护盾为0时结束Buff)，并且护盾还有各种类型(物理护盾，魔法护盾等)。属性系统在这里并不适用，因此，我们需要一个Buff作用链来完成护盾的结算流程。比如受击400点魔法伤害，战斗系统抛出 EVENT_FLOW_SHIELD 事件，传入400以及伤害类型，A Buff 收到后判断伤害类型，减免200点伤害(并结束自身)，返回400-200=200，B Buff 伤害类型不满足，返回200，战斗流程得到返回值200，继续后续处理。</p>
<p>到这里，可能你会问：为什么不将沉默，眩晕这些效果也通过 Buff作用链来完成？实现上是可以的，每次 Fighter移动/攻击/释放技能前，抛出对应事件，检查其返回值，决定是否执行操移动/攻击等。但就我的设计理念而言，能够通过虚拟属性固化的效果尽量固化，对系统复杂度和效率都有好处。</p>
<p>Buff 作用链和 Buff 事件处理的机制是一样的，只不过前者关心返回值，后者不关心返回值。可公用EventMgr来处理，通过引用类型的EventArgs来更新和返回。</p>
<h3 id="4-Buff相互关系"><a href="#4-Buff相互关系" class="headerlink" title="4.Buff相互关系"></a>4.Buff相互关系</h3><ul>
<li>Buff 冲突:  即该BUFF生效时，已有的哪些Buff会失效，如一些清除负面状态的Buff</li>
<li>Buff 免疫:     即该BUFF生效时，后面来的哪些BUFF不能生效，如BKB免疫眩晕</li>
<li>Buff 叠加:  两种同类增益或减益BUFF同时生效时，按照某个规则进行BUFF效果重新计算生成</li>
</ul>
<p>Buff的冲突免疫关系实际上是Buff作用效果的一部分，但是一个可抽象和配置化的流程，在挂载Buff时统一处理。至于Buff叠加，在Buff B的Start节点中，判断是否有指定Buff A存在，如果存在，修正BuffB的效果(或移除已有BuffA)，是个特例流程，做到Buff脚本里面就行了。</p>
<p>至此，我们通过属性维度和公式计算来避免了作用于同一个属性的Buff的顺序依赖，通过公用流程来处理Buff的免疫和冲突，仅针对Buff叠加这类少见的特殊作用进行特例化处理，这样最大程度的提升了Buff的扩展性，Buff可以独立实现，Buff的关系可通过配置表配置，新加一个Buff无需修改已有的Buff系统，对其它模块的影响也降到最小。</p>
<h3 id="5-Buff生命周期"><a href="#5-Buff生命周期" class="headerlink" title="5.Buff生命周期"></a>5.Buff生命周期</h3><p>为了达成复用，我们会通过子Buff的概念来实现一些复杂的Buff，SkillA的BuffA，它维护自己的状态，并在条件满足时，产生伤害翻倍这个子Buff，父子Buff的生命周期关系大致有三种:</p>
<ol>
<li>完全独立，创建完成之后即不再相互引用</li>
<li>父Buff结束时，子Buff随之结束</li>
<li>父Buff通过内部状态控制子Buff的生命周期</li>
</ol>
<p>对战斗系统来说，理想情况下，每个Buff应该自己管理自己的生命周期，这样状态内聚在Buff本身，更好地满足正交性和复用性。并且Buff的生命周期耦合容易引发状态错误，如子Buff由于Buff冲突被移除时，父Buff可能并不知晓，当父Buff结束子Buff时会再次触发Buff Finish或Cancel操作。</p>
<p>因此我们应该尽可能将父子Buff关系弱化(向第一种关系靠齐)，将Buff生命周期独立:</p>
<ul>
<li>将Buff的生命周期作为创建子Buff的参数传入，如一个持续两回合的属性Buff，则将”持续两回合”这个周期以事件类型(回合结束), 事件ID(0), 触发次数(2)传入</li>
<li>用子Buff监听”父Buff移除”事件的方式来将关系2转换为关系1</li>
<li>用唯一事件ID来完成父子Buff的特例的事件交互，将部分关系3转换为关系1</li>
</ul>
<p>由于更复杂的状态控制，比如Buff的结束机制可能不止一种，所以想要完全只保留关系1的父子Buff是比较难的。对于这类少数父子Buff，可考虑特例化实现这个子Buff，比如吸血Buff独立实现可能会比复用恢复Buff更好，如果以上方案都不能很好解决，最后再考虑将其生命周期完全交由父Buff控制(子Buff本身无Event状态)。</p>
<h2 id="属性系统"><a href="#属性系统" class="headerlink" title="属性系统"></a>属性系统</h2><p>属性系统针对Fighter的各种属性进行管理，属性系统包括K-V Map和公式计算两部分，前面我们讲到通过虚拟属性来完成Buff与战斗流程间的解耦，那么K-V Map的Key有如下几种:</p>
<ul>
<li>固定属性: 当前不受Buff影响的属性，无需公式计算直接获取即可。如Fighter当前血量，位置信息等</li>
<li>基础属性: 受Buff影响的属性的基础值，如Fighter进入战斗时的初始攻击力，防御力等，基础属性在战斗过程中不变</li>
<li>Buff属性: 基础属性的可变维度，由各类Buff修改，如攻击力增加值(绝对值)，防御力加成(百分比)</li>
<li>虚拟属性: 如禁足，沉默，伤害加成等，这些属性原本Fighter上面没有，属于战斗系统需要，也由Buff修改</li>
</ul>
<p>我将属性管理器K-V Map保存的”属性”称为属性维度，它们是Buff操作属性的最小粒度，每个属性维度都是纯加减运算，不受Buff先后顺序的影响。对最终属性的计算，由公式计算系统，比如: 最终攻击力 = (攻击力基础值+攻击力增加值)*(1+攻击力加成值)，战斗流程关心Fighter最终攻击力，Buff系统关心其影响的某个属性维度(如攻击力增加值或攻击力加成值)，中间的这一块就是公式计算，将公式计算抽象出来的好处是公式系统可独立变化，甚至可以将公式配置化。属性的计算过程对战斗流程来说是透明的，这给属性维度和公式计算的变更带来的很大的灵活度。</p>
<h2 id="配置框架"><a href="#配置框架" class="headerlink" title="配置框架"></a>配置框架</h2><p>评估一套配置框架好坏不能简单从可配置性这一点来看，一个完全可配置技能效果，做到通过配置即可添加一些简单技能的配置框架不是不能实现，但开发和维护成本过高，对策划的要求，出错的可能性也更高。因此在设计配置框架时，要结合项目需求，在开发效率，可维护性，可扩展性等方面作出权衡。</p>
<p>简单提一下我们目前用的配置方案:</p>
<p>技能基础表:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>技能ID</th>
<th>技能类型</th>
<th>技能距离</th>
<th>技能目标选取器</th>
<th>目标数量</th>
<th>技能BuffIds</th>
<th>技能描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>主动</td>
<td>同攻击距离</td>
<td>敌人</td>
<td>1</td>
<td>[1001]</td>
<td>对目标造成Args[0]的伤害，并眩晕Args[1]回合(Buff[0])</td>
</tr>
</tbody>
</table>
</div>
<p>技能成长表，即技能的Args表: </p>
<div class="table-container">
<table>
<thead>
<tr>
<th>技能ID</th>
<th>技能等级</th>
<th>技能参数</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>[0.8,1]</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>[0.9,1]</td>
</tr>
</tbody>
</table>
</div>
<p>Buff表:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>BuffId</th>
<th>描述</th>
<th>所属Tags</th>
<th>冲突Tags</th>
<th>免疫Tags</th>
<th>冲突自身</th>
<th>免疫自身</th>
</tr>
</thead>
<tbody>
<tr>
<td>1001</td>
<td>眩晕</td>
<td>[控制]</td>
<td>[]</td>
<td>[]</td>
<td>false</td>
<td>false</td>
</tr>
</tbody>
</table>
</div>
<p>技能根据技能类型，距离和目标选取器以及目标数量，通过通用目标选取流程得到目标，然后传入技能作用脚本，技能作用脚本由程序维护，通过技能描述使用技能参数(来自技能成长表)和技能BuffIds(传入Buff作用脚本)，由于多个Buff可能由同一个Buff脚本实现(如攻击力提高，防御力降低)，因此Buff脚本需要外部传入BuffId来获取冲突免疫关系，对程序来说，BuffId是透明的，它只代表一类冲突免疫关系，对策划来讲，Buff脚本是透明的，他只关心Buff相互关系(如A技能的攻击力提升与B技能的攻击力提升不能同时存在)，至于技能和技能参数以及BuffID的关联本身，是不常变的，因此直接硬编码映射。</p>
<p>Buff的配置方案有两种，一是通过BuffID来配置冲突免疫关系，这种方案灵活性高，但扩展性和维护性差。另一种方案是通过BuffTag，每个Buff可配置自己的Tag(如增益，减益，控制)，根据这些Tag来控制冲突免疫关系，免疫负面状态的Buff对应的配置中免疫Tag为[减益，控制]。这种方案与BuffId无关(免疫自身和冲突自身需单独配置)，维护性和扩展性更高。</p>
<h2 id="战报系统"><a href="#战报系统" class="headerlink" title="战报系统"></a>战报系统</h2><p>战斗跑在服务器，客户端需要通过战报进行战斗回放，那么战报就要包含整个战斗的详细过程，每回合那个英雄放了什么技能，攻击了谁，等等，客户端根据这些信息”拼凑”出战斗动画。战报的每一”桢”应该为一个最小粒度的事件，如A对B发起了普通攻击应该是: 1. A对B发起普攻，2. B损失了50HP，中间还可能穿插反击和其它Buff效果，客户端在”按桢表现”的时候，还需要一些关联，如B是因为A的普攻而掉血，因此实际上更好的格式为: B由于A的普攻损失了50HP，为了协议扩展性，我们会将这些事件格式统筹起来:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事件类型</th>
<th>FighterId</th>
<th>事件参数</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>回合开始</td>
<td>0</td>
<td>[1]</td>
<td>第一回合开始</td>
</tr>
<tr>
<td>发起普攻</td>
<td>1</td>
<td>[2]</td>
<td>Fighter1向Fighter2发起普攻</td>
</tr>
<tr>
<td>受到伤害</td>
<td>2</td>
<td>[1,0,50]</td>
<td>Fighter2由于Fighter1的普攻(BuffId0)损失了50HP</td>
</tr>
</tbody>
</table>
</div>
<p>每个事件都有自己的参数意义，这部分和客户端约定即可。这里的事件类型和之前提到的战斗系统的EventMgr很相似，很多触发点也一样，只是是针对各种Buff，一个是针对客户端表现。</p>
<p>至于事件参数的类型，最常见的可能有整型，浮点数，字符串，在protobuf协议里面可以直接通过复合结构定义:</p>
<pre><code>message Elem &#123;
    sint32  type = 1; // 1: intv 2: fltv 3: strv
    sint32  intv = 2;
    float   fltv = 3;
    string  strv = 4;
&#125;
</code></pre><p>这种方案很丑陋，但在protobuf3中，由于optional字段默认值不发送和sint32的变长编码，实际发送一个type=1,intv=20的Elem只会占用四个字节(两个字段的内容和编号各占 一个字节)，因此还是比较实用的。参考过<a href="https://developers.google.com/protocol-buffers/docs/proto3#oneof">protobuf的oneof</a>，不是很好用，对repeat和map等复合结构的支持不好。</p>
<h2 id="技能效果扩展"><a href="#技能效果扩展" class="headerlink" title="技能效果扩展"></a>技能效果扩展</h2><h3 id="1-召唤物"><a href="#1-召唤物" class="headerlink" title="1. 召唤物"></a>1. 召唤物</h3><p>SkillB: 诅咒一片区域（以一个敌方为中心的3*3格子）的敌人，使其攻击距离减1持续两回合</p>
<p>该技能可用前面介绍的已有机制实现: 技能目标选取规则中，配置攻击范围内一个敌人，技能作用脚本中，获取到该目标周围九宫格所有的敌人，对它们施加持续两回合的属性子Buff(攻击距离-1，由子Buff自身管理生命周期)。</p>
<p>现在考虑SkillB的诅咒区域如果有状态和AI(如存在两回合，每回合跟随施法者移动)，则实现上更为复杂:</p>
<ul>
<li>监控所有敌人的移动，当其进入区域时，添加Buff，出去时，移除Buff</li>
<li>当自己移动时，根据前后状态更新敌人身上的Buff</li>
<li>两回合后，结束自身</li>
</ul>
<p>那如果是召唤一个宠物，并且宠物有血量，可移动，攻击和被攻击呢，是的，答案是以”Fighter”来实现召唤物，这里的Fighter是一个更广泛的概念，它只是一系列接口，如移动/攻击/属性变更等，这样所有能够通过Fighter实现的，技能都可以实现，也算是终极方案了。</p>
<h3 id="2-行为属性"><a href="#2-行为属性" class="headerlink" title="2. 行为属性"></a>2. 行为属性</h3><p>SkillC: 分裂箭，英雄普攻可对多个敌人造成伤害</p>
<p>这类技能的特性是会影响已有技能或其它行为，比如改变普攻流程，移动方式等，这种通常很难用属性系统去做，解决方案是将Fighter的行为(普攻/技能/移动等)抽离为可插拨模块(也可理解为行为属性)，初始每个英雄的行为属性被赋默认值，技能可以更改这些行为(如分裂箭可更换普攻行为)，实现更高级别的抽象，战斗流程根据行为类型和次序(如移动/技能/普攻)取出并执行这些行为，行为属性也是召唤物Fighter实现的基础。</p>
<h3 id="3-全局Buff"><a href="#3-全局Buff" class="headerlink" title="3. 全局Buff"></a>3. 全局Buff</h3><p>SkillD: 腐蚀一片区域，进入区域的敌人受到持续伤害，区域存在2回合，并且不会随施法者死亡消失</p>
<p>由于其简单，用Fighter实现过于重度，由于其独立的生命周期，不能以普通Buff的形式存在(会随Fighter死亡消失)，那么可以考虑用全局Buff，全局Buff挂在战场上，介于Fighter和普通Buff之间，适合实现一些简单，全局的效果，如天气效果。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里，战斗系统的主要组件就已经介绍得差不多了，总结起来，核心思路是将相对稳定的核心战斗流程和相对动态的技能Buff扩展隔离开来，战斗流程通过事件系统来解耦外部Buff脚本，Buff通过属性系统(包括行为属性)来反馈到战斗流程。在构建的过程中，还要时刻关注到哪些是易变的，比如Buff 冲突免疫关系，伤害计算公式等，将其单独抽出来，封装成模块甚至抽离到配置，尽量将功能做到模块化，离线化，方便模块的扩展和测试。</p>
<p>将战斗流程”固化”下来，不要交给Buff系统去任意递归迭代，这种思路适用于回合制这类战斗流程相对固定的情形。另一种思路，是”去流程化”，将流程做到Buff中，比如将移动作为一个Buff，那么”禁足”的效果可以直接通过Buff免疫来实现: 如果Fighter已经有禁足Buff，则移动Buff不能挂上去，达成不能移动的效果。沉默和缴械效果也类似。这种思路更为灵活，但相对更复杂和难以调试。通常我们将通用/固定的行为作为流程，特例/易变的流程作为Buff。</p>
<p>在战斗系统设计中，很多方案都不是绝对的左或者是右，比如普攻是否应该当做特殊技能处理(这样能很方便实现特殊的普攻效果，如分裂箭)？哪些属于流程，哪些属于Buff？哪些效果以Buff实现，哪些效果以Fighter实现？哪些可抽到配置文件，哪些直接写在代码里等等，在实际决策中，往往都是根据实际情况(开发效率，GD需求，扩展性，维护性等)在中间选一个合适点，并且尽可能在细节上封装解耦，以便之后能根据变化进行调整。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
      </tags>
  </entry>
  <entry>
    <title>docker 网络</title>
    <url>/2017/11/docker-network/</url>
    <content><![CDATA[<p>以Docker为平台部署服务器时，最应该理解透彻的便是网络配置。离上次学习，Docker网络又更新了不少内容，重新温习一下。</p>
<p>通过<code>docker run</code>的<code>--network</code>选项可配置容器的网络，Docker提供了多种网络工作模式，none, host, bridge, overlay 等。</p>
<h3 id="none"><a href="#none" class="headerlink" title="none"></a>none</h3><p>不为Docker容器进行任何网络配置，容器将不能访问任何外部的路由(容器内部仍然有loopback接口)，需要手动为其配置网卡，指定IP等，否则与外部只能通过文件IO和标准输入输出交互，或通过<code>docker attach 容器ID</code>进入容器。</p>
<h3 id="host"><a href="#host" class="headerlink" title="host"></a>host</h3><p>与宿主机共用网络栈，IP和端口，容器本身看起来就像是个普通的进程，它暴露的端口可直接通过宿主机访问。相比于bridge模式，host模式有显著的性能优势(因为走的是宿主机的网络栈，而不是docker deamon为容器虚拟的网络栈)。</p>
<h3 id="bridge"><a href="#bridge" class="headerlink" title="bridge"></a>bridge</h3><p>默认网络模式，此模式下，容器有自己的独立的Network Namespace。简单来说，Docker在宿主机上虚拟了一个子网络，宿主机上所有容器均在这个子网络中获取IP，这个子网通过网桥挂在宿主机网络上。Docker通过NAT技术确保容器可与宿主机外部网络交互。</p>
<span id="more"></span>
<p><img src="/assets/image/201711/docker-bridge.png" alt=""></p>
<p>Docker服务默认会创建一个docker0网桥，并为网桥指定IP和子网掩码(通常为172.17.0.1/16)。当启动bridge模式的容器时，Docker Daemon利用veth pair技术，在宿主机上创建两个虚拟网络接口设备。veth pair技术保证无论哪一个veth收到报文，都将转发给另一方。veth pair的一端默认挂在docker0网桥上，另一端添加到容器的namespace下，并重命名为eth0，保证容器独享eth0，做到网络隔离。连接在同一个Docker网桥上的容器可以通过IP相互访问。如此实现了宿主机到容器，容器与容器之间的联通性。</p>
<p>关于网桥:</p>
<ul>
<li><p>网桥(Bridges):<br>  工作在数据链路层，连接多个端口，负责转发数据帧。网桥知道它的各个端口的数据链路协议(目前几乎都是以太网)，将来自一个端口的数据帧转发到其它所有端口。有多个端口的网桥又叫做交换机，目前这两个概念没有本质区别。</p>
<p>  网桥可以用来连接不同的局域网(LAN)，按照最简单的方法，网桥会将某个端口收到的数据无脑转发给其它所有端口，这种泛洪(Flooding)算法效率过低，网桥依靠转发表来转发数据帧，通过自学习算法，记录各个Mac地址在对应哪个端口(转发表数据库)，辅之超时遗忘(Aging)和无环拓扑算法(Loop-Free Topology，典型地如Spanning Tree Protocol, STP)。</p>
</li>
<li><p>Linux网桥:</p>
<p>  Linux下网桥是一个虚拟设备，你可以通过命令创建它，并且为其挂载设备(物理或虚拟网卡)。可通过<code>brctl</code>命令来创建和Linux网桥。管理Linux bridge的具体用法参考: <a href="https://wiki.linuxfoundation.org/networking/bridge。">https://wiki.linuxfoundation.org/networking/bridge。</a></p>
</li>
<li><p>Docker网桥:</p>
<p>  Docker网桥通过Linux网桥实现，加上NAT, veth pair, 网络命名空间等技术，实现网络隔离和容器互联。可通过<code>sudo docker network inspect bridge</code>查看Docker网桥配置以及状态。</p>
</li>
</ul>
<p>当容器需要和宿主机外部网络交互时，会在宿主机上分配一个可用端口，通过这个端口做SNAT转换(将容器IP:Port换为宿主机IP:Port)，再向外部网络发出请求。当外部响应到达时，Docker再根据这一层端口映射关系，将响应路由给容器IP:Port。</p>
<p>外部网络要访问容器Port0，需要先将Port0与宿主机Port1绑定(外部网络无法直接访问宿主机二级网络)，将宿主机IP:Port1暴露给外部网络，外部网络请求到达宿主机时，会进行DNAT转换(将宿主机IP:Port1换为容器IP:Port0)。</p>
<p>从实现上来讲，Docker的这种NAT(实际上是NATP，包含IP,Port的转换)规则，是Docker Daemon通过修改ipatables规则来实现的，ubuntu下可通过<code>sudo ipatbles -t nat -L</code>来查看和NAT相关的规则。</p>
<p>总之，Docker容器在bridge模式下不具有一个公有IP，即和宿主机的eth0不处于同一个网段。导致的结果是宿主机以外的世界不能直接和容器进行通信。虽然NAT模式经过中间处理实现了这一点，但是NAT模式仍然存在问题与不便，如：容器均需要在宿主机上竞争端口，容器内部服务的访问者需要使用服务发现获知服务的外部端口等。另外NAT模式会一定程度的影响网络传输效率。</p>
<p>默认设置下，Docker允许容器之间的互联，可通过<code>--icc=false</code>关闭容器互联(通过iptables DROP实现)，此时容器间相互访问只能通过<code>--link</code>选项链接容器来实现容器访问。<code>—link</code> 选项实际在链接容器的/etc/hosts中添加了一行被链接容器名和其IP的映射，并且会在被链接容器重启后更新该行(这样即使IP有变动也可以通过容器名正确连接)，此外还会添加一条针对两个容器允许连接的iptables规则。但Docker官方文档说<code>--link</code>已经是遗留的选项，更推荐通过已有或自定义网络模式实现互连。</p>
<h3 id="overlay"><a href="#overlay" class="headerlink" title="overlay"></a>overlay</h3><p>前面提到的网络模式，主要解决同一个主机上容器与容器，容器与主机，容器与外界的连接方案。overlay网络可以实现跨主机的容器VLAN，主要用于 docker swarm 上，docker 文档中也基本是两者同时出现，因此docker swarm是跨主机的容器与容器之间的官方标准通信方案。<a href="wudaijun.com/2018/03/08/docker-swarm/">这里</a>有关于 docker swarm 的更多介绍。当初始化 swarm 时，会生成如下东西:</p>
<ul>
<li>docker_gwbridge: 用于实现 host 上的 container 互联，类似 docker0，以及对swarm container暴露端口的SNAT, DNAT转换</li>
<li>ingress: 用于实现跨主机的 swarm 网络，相同集群的不同节点上的 swarm cotainer 属于同一个 ingress</li>
<li>ingress-sbox: 一个隐藏的 container，连接 ingress 和 docker_gwbridge，实现 routing mesh (ipvs)</li>
</ul>
<p>比如我们有两个host，node1, node2, 在node2上启动了ngnix，并通过<code>-p 80:8080</code>将端口暴露到 host:8080，当我们对 node1:1080发起请求时:</p>
<ol>
<li>通过 iptables DNAT 转换，将 node1:1080 通过 docker_gwbridge 转到 node1 上的ingress_sbox:1080</li>
<li>ingress-sbox PREROUTING Chain 将目的端口1080 转换为 80</li>
<li>ingress-sbox POSTROUTING Chain 将该请求路由到 ngnix 的 vip(ingress 上), <a href="http://www.zsythink.net/archives/2134">ipvs</a> 是 Linux 内核提供的四层负载均衡器</li>
<li>ipvs 中记录了vip -&gt; 真实ip 的映射，比如目前只有 node1上ingress:1080 可用，则转发到该地址。</li>
</ol>
<p><img src="/assets/image/201711/docker-overlay.png" alt=""></p>
<p><a href="https://neuvector.com/network-security/docker-swarm-container-networking/">图片出处</a></p>
<p>关于 overlay 更多实现细节推荐阅读参考4和5。</p>
<h3 id="网络管理"><a href="#网络管理" class="headerlink" title="网络管理"></a>网络管理</h3><p>同一个容器可以加入多个不同的网络，并在每个网络中获得一个 IP，由 Docker Daemon 充当 DHCP Server 角色:</p>
<pre><code># 容器启动时，它默认只能连接到一个网络
docker run --name alpine1 --network bridge -dit alpine ash

# 通过`docker network create`可创建一个指定类型的网络
# 如果创建的是 overlay 网络，则需要添加--attachable选项后才能加入其它独立容器
docker network create -d bridge my_bridge

# 手动将容器添加到其它已有网络
docker network connect my_bridge alpine1

# 查看容器网络配置，可发现其存在于bridge 和 my_bridge 两个网络中
# ip 分别为 172.17.0.2，172.18.0.2
docker inspect alpine1 

# 将容器移除网络
docker network disconnect my_bridge alpine1

# 删除网络
docker network rm alpine1
</code></pre><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><p>在使用Docker时，要注意平台之间实现的差异性，如[Docker For Mac]的实现和标准Docker规范有区别，Docker For Mac的Docker Daemon是运行于虚拟机(xhyve)中的(而不是像Linux上那样作为进程运行于宿主机)，因此Docker For Mac没有docker0网桥，不能实现host网络模式，host模式会使Container复用Daemon的网络栈(在xhyve虚拟机中)，而不是与Host主机网络栈，这样虽然其它容器仍然可通过xhyve网络栈进行交互，但却不是用的Host上的端口(在Host上无法访问)。bridge网络模式 -p 参数不受此影响，它能正常打开Host上的端口并映射到Container的对应Port。文档在这一点上并没有充分说明，容易踩坑。参考<a href="https://docs.docker.com/docker-for-mac/networking/">Docker文档</a> 和 <a href="https://forums.docker.com/t/should-docker-run-net-host-work/14215">这篇帖子</a></p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol>
<li><a href="http://www.infoq.com/cn/articles/docker-source-code-analysis-part7">Docker源码分析(七)：Docker Container网络(上)</a></li>
<li><a href="https://docs.docker.com/engine/userguide/networking/">Docker networking</a></li>
<li><a href="http://tonybai.com/2016/02/15/understanding-docker-multi-host-networking/">理解Docker跨多主机容器网络</a></li>
<li><a href="https://neuvector.com/network-security/docker-swarm-container-networking/">How Docker Swarm Container Networking Works</a></li>
<li><a href="https://blog.octo.com/en/how-does-it-work-docker-part-3-load-balancing-service-discovery-and-security/">How does it work? Docker! Part 3</a></li>
</ol>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>常见GC算法及Golang GC</title>
    <url>/2017/12/gc-study/</url>
    <content><![CDATA[<p>先来看看GC(自动垃圾回收)的主要问题:</p>
<ol>
<li>额外的开销(内存/CPU)</li>
<li>执行GC的时机无法预测，在实时性要求高的场景或事务处理来说可能是不可容忍的</li>
<li>部分GC算法会Stop-the-world</li>
</ol>
<p>各语言运行时在选取GC算法时，都要从这几个方面进行衡量与取舍，下面是一些常见的GC算法。</p>
<span id="more"></span>
<h3 id="引用计数-Reference-counting"><a href="#引用计数-Reference-counting" class="headerlink" title="引用计数(Reference counting):"></a>引用计数(Reference counting):</h3><p>为每个对象维护一个计数，保存其它对象指向它的引用数量。当一个引用被覆盖或销毁，该引用对象的引用计数-1，当一个引用被建立或拷贝，引用对象的引用计数+1，如果对象的引用计数为0，则表明该对象不再被访问(inaccessible)，将被回收。引用计数有如下优缺点:</p>
<p>优点:</p>
<ol>
<li>GC开销将被均摊到程序运行期，不会有长时间的回收周期。</li>
<li>每个对象的生命周期被明确定义，可用于某些编译器的runtime优化。</li>
<li>算法简单，易于实现。</li>
<li>即时回收，不会等内存状态到达某个阀值再执行回收。</li>
</ol>
<p>缺点:</p>
<ol>
<li>引用计数会频繁更新，带来效率开销</li>
<li>原生的引用计数算法无法回收循环引用的对象链(如<a href="http://wudaijun.com/2014/12/shared_ptr-reference/">C++ shared_ptr引用链</a>)</li>
</ol>
<p>针对第一个频繁更新的缺点，可以使用延迟更新和合并更新等技术，这通常能够很好优化局部频繁的引用更新(如for循环)，虽然这也增加了算法实现复杂度。</p>
<p>针对循环引用的问题，一种解决方案是弱引用(<a href="https://en.wikipedia.org/wiki/Weak_reference">weak reference</a>)，弱引用不影响GC，通常的实践是owner持有child的强引用，child持有owner的弱引用，在事件注册器或其它容器中，如果你只希望保存这个引用，但不希望这个引用影响GC时，也可弱引用。弱引用在使用时，需要先判断对象是否还存在，如C++的weak_ptr需要先转换为shared_ptr。但这不能完全避免无意的循环墙引用，一些GC算法可以检测循环引用，例如以追踪式GC的思路，从根出发，回收那些不可达的对象。</p>
<h3 id="标记-清扫-Mark-and-Sweep"><a href="#标记-清扫-Mark-and-Sweep" class="headerlink" title="标记-清扫(Mark-and-Sweep):"></a>标记-清扫(Mark-and-Sweep):</h3><p>标记-清扫算法为每个对象预留一个Flag位，分为两个阶段，标记阶段会从Root向下递归遍历所有对象，并将所有可达对象的Flag位设为”正在使用”。第二阶段，清扫阶段，遍历所有内存，回收那些所有未被标记为”正在使用”的对象。整个算法的思路很简单，也基本上避免了引用计数法的缺点，但最大的缺点在于回收期间整个系统必须暂停(Stop-the-world)。</p>
<p><img src="/assets/image/201712/mark-and-sweep.gif" alt=""></p>
<h3 id="三色标记法-Tri-color-marking"><a href="#三色标记法-Tri-color-marking" class="headerlink" title="三色标记法(Tri-color marking):"></a>三色标记法(Tri-color marking):</h3><p>针对原生标记-清扫算法标记过程会STW的缺点，三色标记法改进了标记方案。三色标记法将所有对象分为三类:</p>
<ul>
<li>白色: GC的候选对象集合(待处理)</li>
<li>灰色: 可从根访问，并且还未扫描对白色集合对象的引用(处理中,不会被GC,但引用待确认)</li>
<li>黑色: 可从根访问，并且不存在对白色集合的引用(处理完成)</li>
</ul>
<p>步骤如下:</p>
<ol>
<li>初始化，所有对象都是白色</li>
<li>从根遍历，所有可达对象标记为灰色</li>
<li>从灰色对象队列中取出对象，将其引用的对象标记为灰色，并将自己标记为黑色</li>
<li>重复第三步，直到灰色队列为空，此时白色对象即为孤儿对象，进行回收</li>
</ol>
<p>三色标记法有个重要的不变量: <strong>黑色对象不会引用任何白色对象</strong>，因此白色对象可以在灰色对象处理完成之后立即回收。此算法最大的特点在于将标记过程拆分和量化，使得用户程序和标记过程可并行执行(需要其它技术追踪标记过程中的对象引用变更)，不用Stop-the-world，算法可按照各个集合的大小阶段性执行GC，并且不用遍历整个内存空间。</p>
<p><img src="/assets/image/201712/tri-color-marking.gif" alt=""></p>
<h3 id="半空间回收器-semi-space-collector"><a href="#半空间回收器-semi-space-collector" class="headerlink" title="半空间回收器(semi-space collector)"></a>半空间回收器(semi-space collector)</h3><p>半空间收集器将内存分为两半，分别叫<strong>from space</strong>和<strong>to space</strong>，初始时，所有的对象都在<strong>to space</strong>中分配直到空间用完，触发一次回收周期，此时<strong>to space</strong>和<strong>from space</strong>互换，然后将所有根可访问的对象从<strong>from space</strong>拷贝到<strong>to space</strong>，之后程序可以继续执行。新的对象继续在新的<strong>to space</strong>中分配，直到再次空间用完触发回收。该算法的优点是所有存活的数据结构都紧凑排列在<strong>to space</strong>，内存分配也可通过简单的分配指针自增来实现，缺点是浪费了一半的内存空间。这种GC方案也叫<strong>stop-and-copy</strong>。</p>
<h3 id="三色标记法的一些变形"><a href="#三色标记法的一些变形" class="headerlink" title="三色标记法的一些变形"></a>三色标记法的一些变形</h3><h4 id="moving-or-non-moving"><a href="#moving-or-non-moving" class="headerlink" title="moving or non-moving"></a>moving or non-moving</h4><p>三色标记法执行标记流程后(灰色队列为空)，所有的白色对象可被回收，那么这些白色对象是直接被回收，其它不变还是执行内存拷贝(non-moving)，将黑色对象移动并覆盖不再使用的白色对象内存(moving)。相当于执行内存块调整(compact)，可以让内存结构更有序，下次分配更快。这部分算法独立于三色标记，可以由GC算法在运行时选择。</p>
<h4 id="mark-and-non-sweep"><a href="#mark-and-non-sweep" class="headerlink" title="mark and non-sweep"></a>mark and non-sweep</h4><p>基于半空间收集器的copy思路，可以运用到三色标记法中，通过颜色互换来模拟space互换，该算法对三色标记的颜色定义有所不同，步骤如下:</p>
<ol>
<li>对象只有黑色与白色两种颜色，并且黑色与白色是可以互换的(可通过修改黑白的位映射来实现，无需修改对象)</li>
<li>所有可被访问的对象都是黑色，所有可被回收的对象为白色</li>
<li>对象从白色对象空间分配，被分配后即标记为黑色</li>
<li>当内存空间不足(不再有白色对象)，触发GC，此时所有黑色对象变为白色对象，从根遍历所有可访问的对象，将其由白色变为黑色，此时剩下的白色即为可被回收对象，程序可继续运行</li>
<li>程序继续从白色空间分配，直到白色空间用完，再次触发GC</li>
</ol>
<h3 id="分代GC-Generational-GC"><a href="#分代GC-Generational-GC" class="headerlink" title="分代GC(Generational GC)"></a>分代GC(Generational GC)</h3><p>前面的各种标记扫描算法，都有一个缺点，每次需要遍历标记所有可达对象，包括一些长期存活的对象，或者说，GC也具有局部性: 最近被分配的对象越容易不再使用。分代GC即基于这一启发，它将内存空间按”代(Generation)”分为几个部分(通常是两代，即Young Generation和Old Generation)，并尽可能频繁地在年轻的一代执行GC，当年轻一代的内存空间不够时，将可达对象全部移到上一代，此时年轻代的内存全部闲置，可用于分配新对象，这样更快并且通常也更有效率。当老一代GC不够用时，才执行Full Sweep。</p>
<p>通常大部分语言的运行时都会混合多种GC算法，比如Erlang的GC(参考<a href="https://segmentfault.com/a/1190000003758525">1</a>,<a href="http://blog.csdn.net/mycwq/article/details/26613275">2</a>)就混合了分代GC和引用计数(高效)，在进程堆内使用分代GC，对全局数据使用引用计数(即时释放内存)。</p>
<h3 id="Golang-GC"><a href="#Golang-GC" class="headerlink" title="Golang GC"></a>Golang GC</h3><p>简单学习了一下Golang GC，Golang使用的是三色标记法方案，并且支持并行GC，即用户代码何以和GC代码同时运行。具体来讲，Golang GC分为以下阶段:</p>
<ol>
<li>Mark: 包含两部分:<ul>
<li>Mark Prepare: 初始化GC任务，包括开启写屏障(write barrier)和辅助GC(mutator assist)，统计root对象的任务数量等，这个过程需要STW</li>
<li>GC Drains: 扫描所有root对象，包括全局指针和goroutine(G)栈上的指针（扫描对应G栈时需停止该G)，将其加入标记队列(灰色队列)，并循环处理灰色队列的对象，直到灰色队列为空。该过程后台并行执行</li>
</ul>
</li>
<li>Mark Termination: 完成标记工作，重新扫描(re-scan)全局指针和栈。因为Mark和用户程序是并行的，所以在Mark过程中可能会有新的对象分配和指针赋值，这个时候就需要通过写屏障（write barrier）记录下来，re-scan 再检查一下，这个过程也是会STW的。</li>
<li>Sweep: 按照标记结果回收所有的白色对象，该过程后台并行执行</li>
<li>Sweep Termination: 对未清扫的span进行清扫, 只有上一轮的GC的清扫工作完成才可以开始新一轮的GC。</li>
</ol>
<p>Golang GC流程图:</p>
<p><img src="/assets/image/201712/go-gc-phases.png" alt=""></p>
<p><a href="http://www.cnblogs.com/zkweb/p/7880099.html">图片出处</a></p>
<h4 id="1-STW-Stop-The-World"><a href="#1-STW-Stop-The-World" class="headerlink" title="1. STW(Stop The World)"></a>1. STW(Stop The World)</h4><p>Golang的GC过程有两次STW:</p>
<p>第一次STW会准备根对象的扫描, 启动写屏障(Write Barrier)和辅助GC(mutator assist).</p>
<p>第二次STW会重新扫描部分根对象, 禁用写屏障(Write Barrier)和辅助GC(mutator assist).</p>
<h4 id="2-Write-Barrier"><a href="#2-Write-Barrier" class="headerlink" title="2. Write Barrier"></a>2. Write Barrier</h4><p>写屏障用于在编译器在写操作时插入一段代码，对应的还有读屏障。在三色标记法的标记过程中，我们需要保证黑色对象只能引用黑色对象或者灰色对象，不能引用白色对象，否则该白色对象可能无法被标记到从而被回收。因此需要写屏障对写操作插入代码来做对应的记录，以用于re-scan。</p>
<p>在Go1.8之前，Go使用Dijkstra-style insertion write barrier [Dijkstra ‘78]来完成在Mark过程中，用户程序对指针的赋值和覆盖追踪，该方案的优点是无需读屏障(read barrier)，但保守地将有变更的栈标记为灰色，这样在第一遍Mark之后，还需要re-scan所有灰色的栈。</p>
<p>Go1.8及之后采用另一种混合屏障(hybrid write barrier that combines a Yuasa-style deletion write barrier [Yuasa ‘90] and a Dijkstra-style insertion write barrier [Dijkstra ‘78]. )，大幅度减少了第二次STW的时间，详细参考<a href="https://github.com/golang/proposal/blob/master/design/17503-eliminate-rescan.md">17503-eliminate-rescan</a>。</p>
<p>参考:</p>
<ol>
<li><a href="https://en.wikipedia.org/wiki/Reference_counting">Reference counting - wikipedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection">Tracing garbage collection - wikipedia</a></li>
<li><a href="http://www.cnblogs.com/zkweb/p/7880099.html">Golang源码探索(三) GC的实现原理</a></li>
<li><a href="http://legendtkl.com/2017/04/28/golang-gc/">Golang 垃圾回收剖析</a></li>
</ol>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera 《Neural Networks and Deep Learning》 笔记</title>
    <url>/2017/12/deep-learning/</url>
    <content><![CDATA[<p>本文是Coursera课程<a href="https://www.coursera.org/learn/neural-networks-deep-learning">Neural Networks and Deep Learning</a>的学习笔记，课程本身深入浅出，质量非常高，这里主要做思路整理和知识备忘，很多模块还需要自己扩展。</p>
<p>什么是深度学习(Deep Learning)？简单来说，深度学习是机器学习的一个子领域，研究受人工神经网络的大脑的结构和功能启发而创造的算法。Wiki上给出的解释则更复杂一点: 深度学习（deep learning）是机器学习的分支，是一种试图使用包含复杂结构或由多重非线性变换构成的多个处理层对数据进行高层抽象的算法。</p>
<h3 id="一-逻辑回归模型"><a href="#一-逻辑回归模型" class="headerlink" title="一. 逻辑回归模型"></a>一. 逻辑回归模型</h3><p>监督学习(Supervised learning): 是一个机器学习中的方法，可以由训练资料中学到或建立一个模式（函数 / learning model），并依此模式推测新的实例。训练资料是由输入物件（通常表示为张量）和预期输出（Label标签层）所组成。函数的输出可以是一个连续的值（称为回归分析），或是预测一个分类标签（称作分类）。</p>
<h4 id="逻辑回归算法"><a href="#逻辑回归算法" class="headerlink" title="逻辑回归算法"></a>逻辑回归算法</h4><p>逻辑回归算法是一个二元分类算法，是监督学习的常用算法之一，用于估计某种事物的可能性。假设我们要设计一个深度学习算法识别某张图片是不是一只猫，即输出该图片是猫的概率。我们可以将图片的RGB通道放入到一个输入向量中，比如图片大小为100*100，则最终得到长度为3*100*100的输入向量x，即x(n)=30000。逻辑回归算法对于每个输入向量$x^i$，都应该计算得到对应的预估值$y^i$([0,1])。现在来看看如何设计这个算法，最简单的函数是: <script type="math/tex">\hat{y}=w.T*x+b</script> ，其中w为维度为n的列向量，我们用$ \hat{y} $来表示算法得到的预估值，以和训练数据中的已知结果$y$区分，但这个函数是线性的(线性回归)，$y$取值为负无穷到正无穷，而我们期望的$y$取值为[0,1]。一个可用的算法是sigmoid函数 $y = \sigma(z) = \frac{1}{(1+e^{-z})}$，其中 $z = w.T*x + b$，这样我们的到$y$值始终限定在0($z$无穷小时)到1($z$无穷大时)之间。现在我们的任务就是找到合理的$w$和$b$参数。</p>
<h4 id="损失函数和代价函数"><a href="#损失函数和代价函数" class="headerlink" title="损失函数和代价函数"></a>损失函数和代价函数</h4><p>现在我们有了$y=\sigma(w.T*x+b)$，对于训练集${(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)})…(x^{(m)},y^{(m)})}$，我们希望算法得到的$\hat{y}^i \approx y^i$，因此对于确定的w和b，我们需要定义一些函数来帮助我们确定这个参数的误差。</p>
<p>损失函数(Lost Function): 也叫误差函数(Error Function)，用于评估算法的误差，即算法得到的$\hat{y}$和实际的$y$的误差有多大，损失函数需要是凸函数，用于后续优化(非凸函数将在梯度下降算法中产生多个局部最优解)，因此像$L(\hat{y},y)=\frac{1}{2}(\hat{y}-y)^2$这种函数不是一个好的误差函数，这里给出一个好的损失函数: $L(\hat{y},y)=-(y\lg\hat{y}+(1-y)\lg(1-\hat{y}))$，当已知事实$y=1$(图片是猫)时，$L(\hat{y},y)=-\lg{\hat{y}}$，即要使误差更小，$\hat{y}$需要尽可能大($\sigma函数极限为1$)，反之，当$y=0$时，$\hat{y}$需要尽可能小，即接近于0。</p>
<p>代价函数(Cost Function): 也叫做整体损失函数，用于检查算法的整体运行情况，即对给定的$w$和$b$，${\hat{y}^{(1)}, \hat{y}^{(2)}…\hat{y}^{(m)}}$和${y^{(1)}, y^{(2)}…y^{(m)}}$误差的平均值，代价函数用符号J表示:</p>
<p>$J(w,b)=\frac{1}{m}\sum_1^mL(\hat{y}^{(i)},y^{(i)})=-\frac{1}{m}\sum_1^m[y^{(i)}\lg\hat{y}^{(i)}+(1-y^{(i)})\lg(1-\hat{y}^{(i)})]$</p>
<p>有了代价函数之后，我们的目标变成了找到合适的参数$w$和$b$，以缩小整体成本$J(w,b)$的值。</p>
<h4 id="梯度下降模型"><a href="#梯度下降模型" class="headerlink" title="梯度下降模型"></a>梯度下降模型</h4><p>前面在选择损失函数的时候，提到过凸函数，一个典型地凸函数如下所示:</p>
<p><img src="/assets/image/201712/deep-learning-j-w-b.png" alt=""></p>
<p>我们的目的就是找到$J(w,b)$值最低时的$w$和$b$值，即图中红色箭头标记的Aim Point。为了找到这个点，我们可以对$w$和$b$初始化任意值，如图中的Init Point点，利用梯度下降模型，每一次参数迭代，我们都调整$w$和$b$的值，以使$J(w,b)$的值更小，如图中标识的方向，逐步地逼近最优解。</p>
<p>梯度下降模型的本质是对每个参数都求偏导数，利用偏导数导数去调整下一步走向，为了简化模型，这里我们只讨论$J(w)$和$w$的关系:</p>
<p><img src="/assets/image/201712/deep-learning-j-w.png" alt=""></p>
<p>如图，通过不断地迭代$w=w-\alpha dw$即可让$w$的值逐渐逼近于凸函数的最低点，其中$\alpha$称为学习率或步长，用于控制$w$每次的调整幅度。损失函数一定要是凸函数，因为非凸函数会有多个局部最优解(想象为波浪形状)，此时梯度下降算法可能找不到全局最优解。</p>
<p>因此，利用梯度下降算法，我们的参数调整应该是这样的：</p>
<p>$w = w - \alpha * \frac{dJ(w,b)}{dw}$</p>
<p>$b = b - \alpha * \frac{dJ(w,b)}{db}$</p>
<h4 id="对逻辑回归使用梯度下降"><a href="#对逻辑回归使用梯度下降" class="headerlink" title="对逻辑回归使用梯度下降"></a>对逻辑回归使用梯度下降</h4><p>现在我们来看看如何求导，目前我们已经知道对于给定的$w$和$b$，如何求得代价函数$J(w,b)$的值，假设输入数据x的维度n=2，则计算流程如下:</p>
<p><img src="/assets/image/201712/deep-learning-propagation.png" alt=""></p>
<p>这里的$a$即$\hat{y}$，图中$\sigma(z)=\frac{1}{(1+e^{-z})}$，$L(a,y)=-(y\lg{a}+(1-y)\lg(1-a))$。整个从参数$w$，$b$推导到损失函数值的过程被称为<strong>正向传播(Forward Propagation)</strong>，而我们现在要做的，是根据损失函数反过来对参数求偏导，这个过程叫<strong>反向传播(Backward Propagation)</strong>:</p>
<p>&emsp; <script type="math/tex">da = \frac{dL}{da} = -\frac{y}{a}+\frac{1-y}{1-a}</script></p>
<p>&emsp; <script type="math/tex">dz = \frac{dL}{dz} = \frac{da}{dz} * \frac{dL(a,y)}{da} = a(1-a) * (-\frac{y}{a}+\frac{1-y}{1-a}) = a - y</script></p>
<p>&emsp; <script type="math/tex">dw_1 = \frac{dL}{dw_1} = \frac{dz}{dw_1} * \frac{dL}{dz} = x_1*dz = x_1(a-y)</script></p>
<p>&emsp; <script type="math/tex">dw_2 = x_2dz = x_2(a-y)</script></p>
<p>&emsp; <script type="math/tex">db = dz = a-y</script></p>
<p>当我们有m个训练数据时，算法迭代看起来像是这样:</p>
<p>J=0; $dw_1$=0; $dw_2$=0; $db$=0;</p>
<p>for i=1 to m:</p>
<p>&emsp; $z^{(i)}$ = $w.T*x^{(i)}+b$</p>
<p>&emsp; $a^{(i)}$ = $\sigma(z^{(i)})$</p>
<p>&emsp; $J$ += $-[y^{(i)}\lg\hat{y}^{(i)}+(1-y^{(i)})\lg(1-\hat{y}^{(i)})] $ </p>
<p>&emsp; $dz^{(i)}$ = $ a^{(i)} - y^{(i)} $ </p>
<p>&emsp; $dw_1$ += $x_1*dz^{(i)}$ </p>
<p>&emsp; $dw_2$ += $x_2*dz^{(i)}$ </p>
<p>&emsp; $db$ += $dz^{(i)}$</p>
<p>end</p>
<p>J /= m; $dw_1$ /= m; $dw_2$ /= m; $db$ /= m</p>
<p>现在我们得到了$dw_1$, $dw_2$和$db$，就可以结合学习率来引导参数的下一步调整方向，以获得更小的J值:</p>
<p>&emsp; $w_1$ = $w_1$ - $\alpha dw_1$</p>
<p>&emsp; $w_2$ = $w_2$ - $\alpha dw_2$</p>
<p>&emsp; $b$ = $b$ - $\alpha db$</p>
<p>注意到，整个计算过程中，我们会用到三个for循环:</p>
<ol>
<li>用于迭代迭代训练数据个数m的for循环</li>
<li>用于求$dw_1$，$dw_2$…$dw_n$的循环，上面的例子中n=2</li>
<li>用于迭代梯度下降的for循环，这是最外层的for循环</li>
</ol>
<p>由于深度学习的训练数据往往是非常大的，因此for循环是很慢的，深度学习之所以能够支撑海量数据，和<strong>向量化(vectoraztion)</strong>技术是分不开的。接下来将讨论如何通过向量化技术去除前面两个for循环。</p>
<h4 id="张量计算加速"><a href="#张量计算加速" class="headerlink" title="张量计算加速"></a>张量计算加速</h4><p>在Python中，可以用<a href="http://www.numpy.org/">numpy</a>包来快速方便地进行张量运算，对于两个百万维度的向量求内积，用<code>np.dot</code>函数要比自己用for循环快大概300倍，这得益于numpy充分运用并发和GPU来加速张量运算。</p>
<p>设训练数据的大小为m(即图片的数量)，我们用带括号的上标表示训练数据的索引(即某张图片)，下标表示某个输入向量的索引(即某个RGB值)，然后将每个输入数据x作为列向量，输入数据m作为列数对输入进行矩阵化:</p>
<span id="more"></span>
<script type="math/tex; mode=display">
 \left\{
 \begin{matrix}
   x^{(1)}_1 & x^{(2)}_1 & ... & x^{(m)}_1 \\
   x^{(1)}_2 & x^{(2)}_2 & ... & x^{(m)}_2  \\
   ... & ... & ... & ... \\
   x^{(1)}_n & x^{(2)}_n & ... & x^{(m)}_n
  \end{matrix}
  \right\}</script><p>此时x的个数称为了输入矩阵的一部分，我们将向量化后得到的输入矩阵称为X，对应的，将向量化后得到的a,z均替换为大写，再结合numpy，整个流程变得简洁且高效:</p>
<p>Z = $w^TX+b$ = np.dot(w.T,X)+b<br>A = $\sigma(Z)$<br>dZ = A-Y<br>dw = $\frac{1}{m}$XdZ.T = np.dot(X, dZ.T)/m<br>db = $\frac{1}{m}$np.sum(dZ)</p>
<h3 id="二-神经网络"><a href="#二-神经网络" class="headerlink" title="二. 神经网络"></a>二. 神经网络</h3><h4 id="浅层神经网络"><a href="#浅层神经网络" class="headerlink" title="浅层神经网络"></a>浅层神经网络</h4><p>我们再来看下逻辑回归算法中的运算模型:</p>
<p><img src="/assets/image/201712/1-layer-nn.png" alt=""></p>
<p>它实际上是一个只有一层的神经网络，在神经网络中，输入层L0通常不作为层数，最靠近a的被称为输出层，其它层被称为中间层或隐藏层，我们用<code>[i]</code>上标来表示层数，在多层神经网络模型中，$a^{[l]}$是第l层的输出，并且会作为第l+1层的输入，并且我们引入$g^{[l]}$来表示第l层的<strong>激活函数(Activation function)</strong>，比如在我们的逻辑中$g^{[1]}=\sigma(z)$。</p>
<h5 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h5><p>如下是一个两层的神经网络:</p>
<p><img src="/assets/image/201712/2-layer-nn.png" alt=""></p>
<p>在这个神经网络中，L1中一共有四个神经元，也就是会输出$a^{[1]}_1$, $a^{[1]}_2$, $a^{[1]}_3$, $a^{[1]}_4$，同样，为了方便向量化加速，我们通常会将同一层的神经元堆叠起来，用$a^{[1]}$来代替L1层的输出:</p>
<p>&emsp; <script type="math/tex">z^{[1](i)}=w^{[1]T}*x^{(i)}+b^{[1]}</script><br>&emsp; <script type="math/tex">a^{[1](i)}=g^{[1]}(z^{[1](i)})</script></p>
<p>其中$w^{[1]}$经堆叠后为(3,4)矩阵(w本身是列向量)，$x^{(i)}$为(3,1)矩阵，$b^{[1]}$为(4,1)，最终$a^{[1]}$为(4,1)，即为L1层的输出，也是L2层的输入:</p>
<p>&emsp; <script type="math/tex">z^{[2](i)}=w^{[2](i)T}*a^{[1](i)}+b^{[2](i)}</script><br>&emsp; <script type="math/tex">a^{[2](i)}=g^{[2]}(z^{[2](i)})</script></p>
<p>是的，你可能发现了，这里的上标$^{(l)}$仍然可以像逻辑回归中一样被向量化，所以最终我们的正向传播流程为:</p>
<p>&emsp; <script type="math/tex">Z^{[1]}=W^{[1]}*X+b^{[1]}</script><br>&emsp; <script type="math/tex">A^{[1]}=g^{[1]}(Z^{[1]})</script><br>&emsp; <script type="math/tex">Z^{[2]}=W^{[2]}*A^{[1]}+b^{[2]}</script><br>&emsp; <script type="math/tex">A^{[2]}=g^{[2]}(Z^{[2]})</script><br>&emsp; <script type="math/tex">\hat {Y} = A^{[2]}</script></p>
<p>为了后续描述和计算，我们用$W^{[l]}$替代了$w^{[l]T}$，这里的向量维度分别是: $X$为(3,m)，$W^{[1]}$为(4,3), $b^{[1]}$为(4,1)，$A^{[1]}$为(4,m)，$W^{[2]}$为(1,4)，$b^{[2]}$为(1,1)，$A^{[2]}$为(1,m)。有时候为了方便，我们也可以将输入$X$称作$A^{[0]}$。</p>
<p>注: python <a href="https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html">numpy broadcast</a>广播机制可以支持维度在运算时扩展，比如$w^{[1]}.T*X+b^{[1]}$中，前者是(4,m)后者是(4,1)，numpy会自动扩展b为(4,m)。</p>
<h5 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h5><p>现在我们来为两层神经网络选定激活函数:</p>
<p>&emsp; <script type="math/tex">g^{[1]} = tanh(z) = \frac{e^z-e^{-z}}{e^z+e^{-z}}</script> &emsp;&emsp;&emsp; 注: $g^{[1]}\prime = 1-a^2$<br>&emsp; <script type="math/tex">g^{[2]} = \sigma(z) = \frac{1}{(1+e^{-z})}</script> &emsp;&emsp;&emsp;&emsp; 注: $g^{[2]}\prime = a(1-a)$</p>
<p>现在我们尝试反向传播:</p>
<p>&emsp; $dZ^{[2]}$ = $A^{[2]} - Y$<br>&emsp; $dW^{[2]}$ = $\frac{1}{m}dZ^{[2]}A^{[1]T}$<br>&emsp; $db^{[2]}$ = $\frac{1}{m}$np.sum($dZ^{[2]}$)<br>&emsp; $dZ^{[1]}$ = $W^{[2]}dZ^{[2]}*1-A^{[1]2}））$<br>&emsp; $dW^{[1]}$ = $\frac{1}{m}dZ^{[1]}X^T$<br>&emsp; $db^{[1]}$ = $\frac{1}{m}$np.sum(dZ^{[1]})</p>
<h4 id="深度神经网络"><a href="#深度神经网络" class="headerlink" title="深度神经网络"></a>深度神经网络</h4><p>前面我们讨论的是一层和两层的神经网络，现在来看看N层的深度神经网络，在深度神经网络中，我们通过$n^{[l]}$来代表第l层的神经元个数，我们知道:</p>
<script type="math/tex; mode=display">Z^{[l]}=W^{[l]}*A^{[l-1]}+b^{[l]}</script><p>由于$A^{[l]}$的维数为($n^{[l]}$, m)，$A^{[l-1]}$的维数为($n^{[l-1]}$, m)，因此$W^{[l]}$的维数为($n^{[l]}$, $n^{[l-1]}$)，$b^{[l]}$维数为($n^{[l]}$, 1)。</p>
<h5 id="正向传播和反向传播"><a href="#正向传播和反向传播" class="headerlink" title="正向传播和反向传播"></a>正向传播和反向传播</h5><p>我们再来看看深度神经网络的正向传播和反向传播:</p>
<p><img src="/assets/image/201712/forward_propagation_backword_propagation.png" alt=""></p>
<p>我们可以将传播迭代化:</p>
<p>正向传播:</p>
<p>输入: $A^{[l-1]}$， 输出: $A^{[l]}$</p>
<p>相关公式:</p>
<p>&emsp; <script type="math/tex">Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}</script><br>&emsp; <script type="math/tex">A^{[l]} = g^{[l]}(Z^{[l]})</script></p>
<p>反向传播:</p>
<p>输入: $dA^{[l]}$，输出: $dA^{[l-1]}$, $dW^{[l]}$，$db^{[l]}$</p>
<p>相关公式:</p>
<p>&emsp; <script type="math/tex">dZ^{[l]} = dA^{[l]}*g^{[l]}\prime(Z^{[l]})</script><br>&emsp; <script type="math/tex">dW^{[l]} = \frac{1}{m}dZ^{[l]}*A^{[l-1]T}</script><br>&emsp; <script type="math/tex">db^{[l]} = \frac{1}{m}</script>np.sum($dZ^{[l]}$)<br>&emsp; <script type="math/tex">dA^{[l-1]} = W^{[l]T}*dZ^{[L]}</script></p>
<h5 id="参数和超参数"><a href="#参数和超参数" class="headerlink" title="参数和超参数"></a>参数和超参数</h5><p>前面我们反复讨论如何通过反向传播调优参数$W$和$b$，而实际上一个神经网络算法除了这类参数之外，还有一些超参数需要考虑:</p>
<ol>
<li>学习率/步长 $\alpha$</li>
<li>迭代次数</li>
<li>神经网络的层数L</li>
<li>每层的神经元数$n^{[l]}$</li>
<li>每层激活函数的选择</li>
</ol>
<p>神经网络的构建本身就是一个不断迭代的过程，根据最初选择的超参数得到一个粗略的模型，然后在此基础上进行训练，但是仍要不断尝试其它超参数以获取更优的网络模型，这个在后面的课程会提到。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>有了以上理论，我们便可以自己定义一个神经网络(层数L，每层神经元数$n^{[l]}$，激活函数$g^{[l]}$)，根据训练数据X，得到它的误差J，并反过来通过偏导来不断调整每一层的参数以优化这个误差。再辅以向量化这类优化手段，然后”神奇”地发现，整个系统开始工作了。深度学习属于这个时代的黑魔法，已经在语音识别，计算机视觉，自然语言处理等多个领域有了非常成熟的应用，至于机器是否真的能通过神经网络，达到向人一样思考这个且不讨论，就目前而言，深度学习的理论基础还是比较欠缺，比如激活函数的选取，为什么神经网络能有效运转，应该定义多大的神经网络等等。正如课程作者Andrew Ng所言，深度学习的研究，仍然处于初级阶段，很多时候都需要不断地尝试与对比，比如过段就换一次超参数。最后，非常推荐大家上Coursera学习这门课程，毕竟绝大部分时候，我们都在用机器的思维来思考和构建程序，而深度学习是让尝试机器像人一样思考和学习。这本身就是一件很有意思的事情。</p>
]]></content>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Go 调度模型</title>
    <url>/2018/01/go-scheduler/</url>
    <content><![CDATA[<h3 id="G-P-M-模型"><a href="#G-P-M-模型" class="headerlink" title="G P M 模型"></a>G P M 模型</h3><p>定义于src/runtime/runtime2.go:</p>
<ul>
<li>G: Gourtines, 每个Goroutine对应一个G结构体，G保存Goroutine的运行堆栈，即并发任务状态。G并非执行体，每个G需要绑定到P才能被调度执行。</li>
<li>P: Processors, 对G来说，P相当于CPU核，G只有绑定到P(在P的local runq中)才能被调度。对M来说，P提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等</li>
<li>M: Machine, OS线程抽象，负责调度任务，和某个P绑定，从P的runq中不断取出G，切换堆栈并执行，M本身不具备执行状态，在需要任务切换时，M将堆栈状态写回G，任何其它M都能据此恢复执行。</li>
</ul>
<span id="more"></span>
<p>Go1.1之前只有G-M模型，没有P，Dmitry Vyukov在<a href="https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#heading=h.mmq8lm48qfcw">Scalable Go Scheduler Design Doc</a>提出该模型在并发伸缩性方面的问题，并通过加入P(Processors)来改进该问题。</p>
<p>G-P-M模型示意图:</p>
<p><img src="/assets/image/201801/go-schedule.png" alt=""></p>
<p>补充说明:</p>
<ol>
<li>P的个数由GOMAXPROCS指定，是固定的，因此限制最大并发数</li>
<li>M的个数是不定的，由Go Runtime调整，默认最大限制为10000个</li>
</ol>
<h3 id="调度流程"><a href="#调度流程" class="headerlink" title="调度流程"></a>调度流程</h3><p>在M与P绑定后，M会不断从P的Local队列(runq)中取出G(无锁操作)，切换到G的堆栈并执行，当P的Local队列中没有G时，再从Global队列中返回一个G(有锁操作，因此实际还会从Global队列批量转移一批G到P Local队列)，当Global队列中也没有待运行的G时，则尝试从其它的P窃取(steal)部分G来执行，源代码如下:</p>
<pre><code>// go1.9.1  src/runtime/proc.go
// 省略了GC检查等其它细节，只保留了主要流程
// g:       G结构体定义
// sched:   Global队列
// 获取一个待执行的G
func findrunnable() (gp *g, inheritTime bool) &#123;
    // 获取当前的G对象
    _g_ := getg()

top:
    // 获取当前P对象
    _p_ := _g_.m.p.ptr()

    // 1. 尝试从P的Local队列中取得G 优先_p_.runnext 然后再从Local队列中取
    if gp, inheritTime := runqget(_p_); gp != nil &#123;
        return gp, inheritTime
    &#125;

    // 2. 尝试从Global队列中取得G
    if sched.runqsize != 0 &#123;
        lock(&amp;sched.lock)
        // globrunqget从Global队列中获取G 并转移一批G到_p_的Local队列
        gp := globrunqget(_p_, 0)
        unlock(&amp;sched.lock)
        if gp != nil &#123;
            return gp, false
        &#125;
    &#125;

    // 3. 检查netpoll任务
    if netpollinited() &amp;&amp; sched.lastpoll != 0 &#123;
        if gp := netpoll(false); gp != nil &#123; // non-blocking
            // netpoll返回的是G链表，将其它G放回Global队列
            injectglist(gp.schedlink.ptr())
            casgstatus(gp, _Gwaiting, _Grunnable)
            if trace.enabled &#123;
                traceGoUnpark(gp, 0)
            &#125;
            return gp, false
        &#125;
    &#125;

    // 4. 尝试从其它P窃取任务
    procs := uint32(gomaxprocs)
    if atomic.Load(&amp;sched.npidle) == procs-1 &#123;
        goto stop
    &#125;
    if !_g_.m.spinning &#123;
        _g_.m.spinning = true
        atomic.Xadd(&amp;sched.nmspinning, 1)
    &#125;
    for i := 0; i &lt; 4; i++ &#123;
        // 随机P的遍历顺序
        for enum := stealOrder.start(fastrand()); !enum.done(); enum.next() &#123;
            if sched.gcwaiting != 0 &#123;
                goto top
            &#125;
            stealRunNextG := i &gt; 2 // first look for ready queues with more than 1 g
            // runqsteal执行实际的steal工作，从目标P的Local队列转移一般的G过来
            // stealRunNextG指是否steal目标P的p.runnext G
            if gp := runqsteal(_p_, allp[enum.position()], stealRunNextG); gp != nil &#123;
                return gp, false
            &#125;
        &#125;
    &#125;
    ...
&#125;
</code></pre><p>当没有G可被执行时，M会与P解绑，然后进入休眠(idle)状态。</p>
<h3 id="用户态阻塞-唤醒"><a href="#用户态阻塞-唤醒" class="headerlink" title="用户态阻塞/唤醒"></a>用户态阻塞/唤醒</h3><p>当Goroutine因为Channel操作而阻塞(通过gopark)时，对应的G会被放置到某个wait队列(如channel的waitq)，该G的状态由<code>_Gruning</code>变为<code>_Gwaitting</code>，而M会跳过该G尝试获取并执行下一个G。</p>
<p>当阻塞的G被G2唤醒(通过goready)时(比如channel可读/写)，G会尝试加入G2所在P的runnext，然后再是P Local队列和Global队列。</p>
<h3 id="syscall"><a href="#syscall" class="headerlink" title="syscall"></a>syscall</h3><p>当G被阻塞在某个系统调用上时，此时G会阻塞在<code>_Gsyscall</code>状态，M也处于block on syscall状态，此时仍然可被抢占调度: 执行该G的M会与P解绑，而P则尝试与其它idle的M绑定，继续执行其它G。如果没有其它idle的M，但队列中仍然有G需要执行，则创建一个新的M。</p>
<p>当系统调用完成后，G会重新尝试获取一个idle的P，并恢复执行，如果没有idle的P，G将加入到Global队列。</p>
<p>系统调用能被调度的关键有两点:</p>
<p>runtime/syscall包中，将系统调用分为SysCall和RawSysCall，前者和后者的区别是前者会在系统调用前后分别调用entersyscall和exitsyscall(位于src/runtime/proc.go)，做一些现场保存和恢复操作，这样才能使P安全地与M解绑，并在其它M上继续执行其它G。某些系统调用本身可以确定会长时间阻塞(比如锁)，会调用entersyscallblock在发起系统调用前直接让P和M解绑(handoffp)。</p>
<p>另一个关键点是sysmon，它负责检查所有系统调用的执行时间，判断是否需要handoffp。</p>
<h3 id="sysmon"><a href="#sysmon" class="headerlink" title="sysmon"></a>sysmon</h3><p>sysmon是一个由runtime启动的M，也叫监控线程，它无需P也可以运行，它每20us~10ms唤醒一次，主要执行:</p>
<ol>
<li>释放闲置超过5分钟的span物理内存； </li>
<li>如果超过2分钟没有垃圾回收，强制执行；</li>
<li>将长时间未处理的netpoll结果添加到任务队列；</li>
<li>向长时间运行的G任务发出抢占调度； </li>
<li>收回因syscall长时间阻塞的P；</li>
</ol>
<p>入口在src/runtime/proc.go:sysmon函数，它通过retake实现对syscall和长时间运行的G进行调度:</p>
<pre><code>func retake(now int64) uint32 &#123;
    n := 0
    for i := int32(0); i &lt; gomaxprocs; i++ &#123;
        _p_ := allp[i]
        if _p_ == nil &#123;
            continue
        &#125;
        pd := &amp;_p_.sysmontick
        s := _p_.status
        if s == _Psyscall &#123;
            // Retake P from syscall if it&#39;s there for more than 1 sysmon tick (at least 20us).
            t := int64(_p_.syscalltick)
            if int64(pd.syscalltick) != t &#123;
                pd.syscalltick = uint32(t)
                pd.syscallwhen = now
                continue
            &#125;
            // 如果当前P Local队列没有其它G，当前有其它P处于Idle状态，并且syscall执行事件不超过10ms，则不用解绑当前P(handoffp)
            if runqempty(_p_) &amp;&amp; atomic.Load(&amp;sched.nmspinning)+atomic.Load(&amp;sched.npidle) &gt; 0 &amp;&amp; pd.syscallwhen+10*1000*1000 &gt; now &#123;
                continue
            &#125;
            // handoffp
            incidlelocked(-1)
            if atomic.Cas(&amp;_p_.status, s, _Pidle) &#123;
                if trace.enabled &#123;
                    traceGoSysBlock(_p_)
                    traceProcStop(_p_)
                &#125;
                n++
                _p_.syscalltick++
                handoffp(_p_)
            &#125;
            incidlelocked(1)
        &#125; else if s == _Prunning &#123;
            // Preempt G if it&#39;s running for too long.
            t := int64(_p_.schedtick)
            if int64(pd.schedtick) != t &#123;
                pd.schedtick = uint32(t)
                pd.schedwhen = now
                continue
            &#125;
            // 如果当前G执行时间超过10ms，则抢占(preemptone)
            if pd.schedwhen+forcePreemptNS &gt; now &#123;
                continue
            &#125;
            // 执行抢占
            preemptone(_p_)
        &#125;
    &#125;
    return uint32(n)
&#125;
</code></pre><h3 id="抢占式调度"><a href="#抢占式调度" class="headerlink" title="抢占式调度"></a>抢占式调度</h3><p>当某个goroutine执行超过10ms，sysmon会向其发起抢占调度请求，由于Go调度不像OS调度那样有时间片的概念，因此实际抢占机制要弱很多: Go中的抢占实际上是为G设置抢占标记(g.stackguard0)，当G调用某函数时(更确切说，在通过newstack分配函数栈时)，被编译器安插的指令会检查这个标记，并且将当前G以runtime.Goched的方式暂停，并加入到全局队列。源代码如下:</p>
<pre><code>// src/runtime/stack.go
// Called from runtime·morestack when more stack is needed.
// Allocate larger stack and relocate to new stack.
// Stack growth is multiplicative, for constant amortized cost.
func newstack(ctxt unsafe.Pointer) &#123;
    ...
    // gp为当前G
    preempt := atomic.Loaduintptr(&amp;gp.stackguard0) == stackPreempt
    if preempt &#123;
        ...

        // Act like goroutine called runtime.Gosched.
        // G状态由_Gwaiting变为 _Grunning 这是为了能以Gosched的方式暂停Go
        casgstatus(gp, _Gwaiting, _Grunning)
        gopreempt_m(gp) // never return
    &#125;
&#125;

// 以goched的方式将G重新放入
func goschedImpl(gp *g) &#123;
    status := readgstatus(gp)
    // 由Running变为Runnable
    casgstatus(gp, _Grunning, _Grunnable)
    // 与M解除绑定
    dropg()
    lock(&amp;sched.lock)
    // 将G放入Global队列
    globrunqput(gp)
    unlock(&amp;sched.lock)
    // 重新调度
    schedule()
&#125;


func gopreempt_m(gp *g) &#123;
    if trace.enabled &#123;
        traceGoPreempt()
    &#125;
    goschedImpl(gp)
&#125;
</code></pre><h3 id="netpoll"><a href="#netpoll" class="headerlink" title="netpoll"></a>netpoll</h3><p>前面的findrunnable，G的获取除了p.runnext，p.runq和sched.runq外，还有一中G从netpoll中获取，<a href="http://morsmachine.dk/netpoller">netpoll</a>是Go针对网络IO的一种优化，本质上为了避免网络IO陷入系统调用之中，这样使得即便G发起网络I/O操作也不会导致M被阻塞（仅阻塞G），从而不会导致大量M被创建出来。</p>
<h3 id="G创建流程"><a href="#G创建流程" class="headerlink" title="G创建流程"></a>G创建流程</h3><p>G结构体会复用，对可复用的G管理类似于待运行的G管理，也有Local队列(p.gfree)和Global队列(sched.gfree)之分，获取算法差不多，优先从p.gfree中获取(无锁操作)，否则从sched.gfree中获取并批量转移一部分(有锁操作)，源代码参考src/runtime/proc.go:gfget函数。</p>
<p>从Goroutine的角度来看，通过<code>go func()</code>创建时，会从当前闲置的G队列取得可复用的G，如果没有则通过malg新建一个G，然后:</p>
<ol>
<li>尝试将G添加到当前P的runnext中，作为下一个执行的G</li>
<li>否则放到Local队列runq中(无锁)</li>
<li>如果以上操作都失败，则添加到Global队列sched.runq中(有锁操作，因此也会顺便将当P.runq中一半的G转移到sched.runq)</li>
</ol>
<h3 id="G的几种暂停方式"><a href="#G的几种暂停方式" class="headerlink" title="G的几种暂停方式:"></a>G的几种暂停方式:</h3><ol>
<li>gosched: 将当前的G暂停，保存堆栈状态，以<code>_GRunnable</code>状态放入Global队列中，让当前M继续执行其它任务。无需对G进行唤醒操作，因为总会有M从Global队列取得并执行该G。抢占调度即使用该方式。</li>
<li>gopark: 与goched的最大区别在于gopark没有将G放回执行队列，而是位于某个等待队列中(如channel的waitq，此时G状态为<code>_Gwaitting</code>)，因此G必须被手动唤醒(通过goready)，否则会丢失任务。应用层阻塞通常使用这种方式。</li>
<li>notesleep: 既不让出M，也不让G和P重新调度，直接让线程休眠直到被唤醒(notewakeup)，该方式更快，通常用于gcMark，stopm这类自旋场景</li>
<li>notesleepg: 阻塞G和M，放飞P，P可以和其它M绑定继续执行，比如可能阻塞的系统调用会主动调用entersyscallblock，则会触发 notesleepg</li>
<li>goexit: 立即终止G任务，不管其处于调用堆栈的哪个层次，在终止前，确保所有defer正确执行。</li>
</ol>
<h3 id="Go调度器的查看方法"><a href="#Go调度器的查看方法" class="headerlink" title="Go调度器的查看方法"></a>Go调度器的查看方法</h3><p>示例程序，对比cgo sleep和time.sleep系统调用情况:</p>
<pre><code>// #include &lt;unistd.h&gt;
import &quot;C&quot;

func main() &#123;
    var wg sync.WaitGroup
    wg.Add(1000)
    for i := 0; i &lt; 1000; i++ &#123;
        go func() &#123;
            C.sleep(1)                     // 测试1
            // time.Sleep(time.Second)     // 测试2
            wg.Done()
        &#125;()
    &#125;
    wg.Wait()
    println(&quot;done!&quot;)
    time.Sleep(time.Second * 3)
&#125;
</code></pre><p>通过GODEBUG运行时环境变量的schedtrace=1000参数，可以每隔1000ms查看一次调度器状态:</p>
<pre><code>$ GODEBUG=schedtrace=1000 ./test

// 测试1输出结果
SCHED 0ms: gomaxprocs=4 idleprocs=2 threads=1003 spinningthreads=2 idlethreads=32 runqueue=0 [0 0 0 0]
done!
SCHED 1001ms: gomaxprocs=4 idleprocs=4 threads=1003 spinningthreads=0 idlethreads=1000 runqueue=0 [0 0 0 0]
SCHED 2001ms: gomaxprocs=4 idleprocs=4 threads=1003 spinningthreads=0 idlethreads=1000 runqueue=0 [0 0 0 0]
SCHED 3010ms: gomaxprocs=4 idleprocs=4 threads=1003 spinningthreads=0 idlethreads=1000 runqueue=0 [0 0 0 0]

// 测试2输出结果
SCHED 0ms: gomaxprocs=4 idleprocs=2 threads=6 spinningthreads=1 idlethreads=2 runqueue=129 [0 128 0 0]
done!
SCHED 1009ms: gomaxprocs=4 idleprocs=4 threads=6 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0]
SCHED 2010ms: gomaxprocs=4 idleprocs=4 threads=6 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0]
SCHED 3019ms: gomaxprocs=4 idleprocs=4 threads=6 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0]
</code></pre><p>其中schedtrace日志每一行的字段意义:</p>
<pre><code>SCHED：调试信息输出标志字符串，代表本行是goroutine scheduler的输出；
1001ms：即从程序启动到输出这行日志的时间；
gomaxprocs: P的数量；
idleprocs: 处于idle状态的P的数量；通过gomaxprocs和idleprocs的差值，我们就可知道执行go代码的P的数量；
threads: os threads的数量，包含scheduler使用的m数量，加上runtime自用的类似sysmon这样的thread的数量；
spinningthreads: 处于自旋状态的os thread数量；
idlethread: 处于idle状态的os thread的数量；
runqueue： go scheduler全局队列中G的数量；
[0 0 0 0]: 分别为4个P的local queue中的G的数量。
</code></pre><p>可以看出，time.Sleep并没有使用系统调用，而是进行了类似netpoll类似的优化，使得仅仅是G阻塞，M不会阻塞，而在使用cgo sleep的情况下，可以看到大量的闲置M。</p>
<p>通过运行时环境变量GODEBUG的schedtrace参数可定时查看调度器状态:</p>
<pre><code>// 每1000ms打印一次
$GODEBUG=schedtrace=1000 godoc -http=:6060
SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=3 spinningthreads=0 idlethreads=0 runqueue=0 [0 0 0 0]
SCHED 1001ms: gomaxprocs=4 idleprocs=0 threads=9 spinningthreads=0 idlethreads=3 runqueue=2 [8 14 5 2]
SCHED 2006ms: gomaxprocs=4 idleprocs=0 threads=25 spinningthreads=0 idlethreads=19 runqueue=12 [0 0 4 0]
SCHED 3006ms: gomaxprocs=4 idleprocs=0 threads=26 spinningthreads=0 idlethreads=8 runqueue=2 [0 1 1 0]
...
</code></pre><p> GODEBUG还可使用<code>GODEBUG=&quot;schedtrace=1000,scheddetail=1&quot;</code>选项来查看每个G,P,M的调度状态，打出的信息非常详尽复杂，平时应该是用不到。关于Go调试可参考Dmitry Vyukov大牛的<a href="https://software.intel.com/en-us/blogs/2014/05/10/debugging-performance-issues-in-go-programs">Debugging performance issues in Go programs</a>。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>再回头来看，Go 为什么要使用GPM？而不是像大多数调度器一样只有两层关系GM，直接用M(OS线程)的数量来限制并发能力。我粗浅的理解是为了更好地处理syscall，当某个M陷入系统调用时，P则”抛妻弃子”，与M解绑，让阻塞的M和G等待被OS唤醒，而P则带着local queue剩下的G去找一个(或新建一个)idle的M，当阻塞的M被唤醒时，它会尝试给G找一个新的归宿(idle的P，或扔到global queue，等待被领养)。多么忧桑的故事。</p>
<p>相关资料:</p>
<ol>
<li><a href="https://www.ardanlabs.com/blog/2015/02/scheduler-tracing-in-go.html">scheduler-tracing-in-go</a></li>
<li><a href="http://tonybai.com/2017/06/23/an-intro-about-goroutine-scheduler/">也谈goroutine调度器—TonyBai</a></li>
<li><a href="https://github.com/qyuhen/book/blob/master/Go%201.5%20%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%20%EF%BC%88%E4%B9%A6%E7%AD%BE%E7%89%88%EF%BC%89.pdf">Go学习笔记—雨痕</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/42057783">Head First of Golang Scheduler</a></li>
</ol>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Go Interface 实现</title>
    <url>/2018/01/go-interface-implement/</url>
    <content><![CDATA[<p>本文从源码的角度学习下Go接口的底层实现，以及接口赋值，反射，断言的实现原理。作为对比，用到了go1.8.6和go1.9.1两个版本。</p>
<h3 id="1-eface"><a href="#1-eface" class="headerlink" title="1. eface"></a>1. eface</h3><p>空接口通过eface结构体实现，位于runtime/runtime2.go: </p>
<span id="more"></span>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// src/runtime/runtime2.go</span></span><br><span class="line"><span class="comment">// 空接口</span></span><br><span class="line"><span class="keyword">type</span> eface <span class="keyword">struct</span> &#123;</span><br><span class="line">    _type *_type</span><br><span class="line">    data  unsafe.Pointer</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>空接口(eface)有两个域，所指向对象的类型信息(_type)和数据指针(data)。先看看<code>_type</code>字段：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 所有类型信息结构体的公共部分</span><br><span class="line">&#x2F;&#x2F; src&#x2F;rumtime&#x2F;runtime2.go</span><br><span class="line">type _type struct &#123;</span><br><span class="line">    size       uintptr         &#x2F;&#x2F; 类型的大小</span><br><span class="line">    ptrdata    uintptr      &#x2F;&#x2F; size of memory prefix holding all pointers</span><br><span class="line">    hash       uint32          &#x2F;&#x2F; 类型的Hash值</span><br><span class="line">    tflag      tflag              &#x2F;&#x2F; 类型的Tags </span><br><span class="line">    align      uint8       &#x2F;&#x2F; 结构体内对齐</span><br><span class="line">    fieldalign uint8       &#x2F;&#x2F; 结构体作为field时的对齐</span><br><span class="line">    kind       uint8       &#x2F;&#x2F; 类型编号 定义于runtime&#x2F;typekind.go</span><br><span class="line">    alg        *typeAlg    &#x2F;&#x2F; 类型元方法 存储hash和equal两个操作。map key便使用key的_type.alg.hash(k)获取hash值</span><br><span class="line">    gcdata    *byte            &#x2F;&#x2F; GC相关信息</span><br><span class="line">    str       nameOff   &#x2F;&#x2F; 类型名字的偏移    </span><br><span class="line">    ptrToThis typeOff    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>_type是go所有类型的公共描述，里面包含GC，反射等需要的细节，它决定data应该如何解释和操作，这也是它和C void*不同之处。<br>各个类型所需要的类型描述是不一样的，比如chan，除了chan本身外，还需要描述其元素类型，而map则需要key类型信息和value类型信息等:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// src/runtime/type.go</span></span><br><span class="line"><span class="comment">// ptrType represents a pointer type.</span></span><br><span class="line"><span class="keyword">type</span> ptrType <span class="keyword">struct</span> &#123;</span><br><span class="line">   typ     _type   <span class="comment">// 指针类型 </span></span><br><span class="line">   elem  *_type <span class="comment">// 指针所指向的元素类型</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> chantype <span class="keyword">struct</span> &#123;</span><br><span class="line">    typ  _type        <span class="comment">// channel类型</span></span><br><span class="line">    elem *_type     <span class="comment">// channel元素类型</span></span><br><span class="line">    dir  <span class="keyword">uintptr</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> maptype <span class="keyword">struct</span> &#123;</span><br><span class="line">    typ           _type</span><br><span class="line">    key           *_type</span><br><span class="line">    elem          *_type</span><br><span class="line">    bucket        *_type <span class="comment">// internal type representing a hash bucket</span></span><br><span class="line">    hmap          *_type <span class="comment">// internal type representing a hmap</span></span><br><span class="line">    keysize       <span class="keyword">uint8</span>  <span class="comment">// size of key slot</span></span><br><span class="line">    indirectkey   <span class="keyword">bool</span>   <span class="comment">// store ptr to key instead of key itself</span></span><br><span class="line">    valuesize     <span class="keyword">uint8</span>  <span class="comment">// size of value slot</span></span><br><span class="line">    indirectvalue <span class="keyword">bool</span>   <span class="comment">// store ptr to value instead of value itself</span></span><br><span class="line">    bucketsize    <span class="keyword">uint16</span> <span class="comment">// size of bucket</span></span><br><span class="line">    reflexivekey  <span class="keyword">bool</span>   <span class="comment">// true if k==k for all keys</span></span><br><span class="line">    needkeyupdate <span class="keyword">bool</span>   <span class="comment">// true if we need to update key on an overwrite</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这些类型信息的第一个字段都是<code>_type</code>(类型本身的信息)，接下来是一堆类型需要的其它详细信息(如子类型信息)，这样在进行类型相关操作时，可通过一个字(<code>typ *_type</code>)即可表述所有类型，然后再通过<code>_type.kind</code>可解析出其具体类型，最后通过地址转换即可得到类型完整的”_type树”，参考<code>reflect.Type.Elem()</code>函数:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// reflect/type.go</span></span><br><span class="line"><span class="comment">// reflect.rtype结构体定义和runtime._type一致  type.kind定义也一致(为了分包而重复定义)</span></span><br><span class="line"><span class="comment">// Elem()获取rtype中的元素类型，只针对复合类型(Array, Chan, Map, Ptr, Slice)有效</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *rtype)</span> <span class="title">Elem</span><span class="params">()</span> <span class="title">Type</span></span> &#123;</span><br><span class="line">   <span class="keyword">switch</span> t.Kind() &#123;</span><br><span class="line">   <span class="keyword">case</span> Array:</span><br><span class="line">      tt := (*arrayType)(unsafe.Pointer(t))</span><br><span class="line">      <span class="keyword">return</span> toType(tt.elem)</span><br><span class="line">   <span class="keyword">case</span> Chan:</span><br><span class="line">      tt := (*chanType)(unsafe.Pointer(t))</span><br><span class="line">      <span class="keyword">return</span> toType(tt.elem)</span><br><span class="line">   <span class="keyword">case</span> Map:</span><br><span class="line">      <span class="comment">// 对Map来讲，Elem()得到的是其Value类型</span></span><br><span class="line">      <span class="comment">// 可通过rtype.Key()得到Key类型</span></span><br><span class="line">      tt := (*mapType)(unsafe.Pointer(t))</span><br><span class="line">      <span class="keyword">return</span> toType(tt.elem)</span><br><span class="line">   <span class="keyword">case</span> Ptr:</span><br><span class="line">      tt := (*ptrType)(unsafe.Pointer(t))</span><br><span class="line">      <span class="keyword">return</span> toType(tt.elem)</span><br><span class="line">   <span class="keyword">case</span> Slice:</span><br><span class="line">      tt := (*sliceType)(unsafe.Pointer(t))</span><br><span class="line">      <span class="keyword">return</span> toType(tt.elem)</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="built_in">panic</span>(<span class="string">&quot;reflect: Elem of invalid type&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-iface"><a href="#2-iface" class="headerlink" title="2. iface"></a>2. iface</h3><p>iface结构体表示非空接口:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// runtime/runtime2.go</span></span><br><span class="line"><span class="comment">// 非空接口</span></span><br><span class="line"><span class="keyword">type</span> iface <span class="keyword">struct</span> &#123;</span><br><span class="line">    tab  *itab</span><br><span class="line">    data unsafe.Pointer</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 非空接口的类型信息</span></span><br><span class="line"><span class="keyword">type</span> itab <span class="keyword">struct</span> &#123;</span><br><span class="line">    inter  *interfacetype    <span class="comment">// 接口定义的类型信息</span></span><br><span class="line">    _type  *_type                <span class="comment">// 接口实际指向值的类型信息</span></span><br><span class="line">    link   *itab  </span><br><span class="line">    bad    <span class="keyword">int32</span></span><br><span class="line">    inhash <span class="keyword">int32</span></span><br><span class="line">    fun    [<span class="number">1</span>]<span class="keyword">uintptr</span>             <span class="comment">// 接口方法实现列表，即函数地址列表，按字典序排序</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// runtime/type.go</span></span><br><span class="line"><span class="comment">// 非空接口类型，接口定义，包路径等。</span></span><br><span class="line"><span class="keyword">type</span> interfacetype <span class="keyword">struct</span> &#123;</span><br><span class="line">   typ     _type</span><br><span class="line">   pkgpath name</span><br><span class="line">   mhdr    []imethod      <span class="comment">// 接口方法声明列表，按字典序排序</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 接口的方法声明 </span></span><br><span class="line"><span class="keyword">type</span> imethod <span class="keyword">struct</span> &#123;</span><br><span class="line">   name nameOff          <span class="comment">// 方法名</span></span><br><span class="line">   ityp typeOff                <span class="comment">// 描述方法参数返回值等细节</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>非空接口(iface)本身除了可以容纳满足其接口的对象之外，还需要保存其接口的方法，因此除了data字段，iface通过tab字段描述非空接口的细节，包括接口方法定义，接口方法实现地址，接口所指类型等。iface是非空接口的实现，而不是类型定义，iface的真正类型为interfacetype，其第一个字段仍然为描述其自身类型的_type字段。</p>
<p>为了提高查找效率，runtime中实现(interface_type, concrete_type) -&gt; itab(包含具体方法实现地址等信息)的hash表:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// runtime/iface.go</span></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">   hashSize = <span class="number">1009</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">   ifaceLock mutex <span class="comment">// lock for accessing hash</span></span><br><span class="line">   hash      [hashSize]*itab</span><br><span class="line">)</span><br><span class="line"><span class="comment">// 简单的Hash算法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">itabhash</span><span class="params">(inter *interfacetype, typ *_type)</span> <span class="title">uint32</span></span> &#123;</span><br><span class="line">   h := inter.typ.hash</span><br><span class="line">   h += <span class="number">17</span> * typ.hash</span><br><span class="line">   <span class="keyword">return</span> h % hashSize</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据interface_type和concrete_type获取或生成itab信息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getitab</span><span class="params">(inter *interfacetype, typ *_type, canfail <span class="keyword">bool</span>)</span> *<span class="title">itab</span></span> &#123;</span><br><span class="line">   ...</span><br><span class="line">    <span class="comment">// 算出hash key</span></span><br><span class="line">   h := itabhash(inter, typ)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="keyword">var</span> m *itab</span><br><span class="line">   ...</span><br><span class="line">           <span class="comment">// 遍历hash slot链表</span></span><br><span class="line">      <span class="keyword">for</span> m = (*itab)(atomic.Loadp(unsafe.Pointer(&amp;hash[h]))); m != <span class="literal">nil</span>; m = m.link &#123;</span><br><span class="line">         <span class="comment">// 如果在hash表中找到则返回</span></span><br><span class="line">         <span class="keyword">if</span> m.inter == inter &amp;&amp; m._type == typ &#123;</span><br><span class="line">            <span class="keyword">if</span> m.bad &#123;</span><br><span class="line">               <span class="keyword">if</span> !canfail &#123;</span><br><span class="line">                  additab(m, locked != <span class="number">0</span>, <span class="literal">false</span>)</span><br><span class="line">               &#125;</span><br><span class="line">               m = <span class="literal">nil</span></span><br><span class="line">            &#125;</span><br><span class="line">            ...</span><br><span class="line">            <span class="keyword">return</span> m</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">    <span class="comment">// 如果没有找到，则尝试生成itab(会检查是否满足接口)</span></span><br><span class="line">   m = (*itab)(persistentalloc(unsafe.Sizeof(itab&#123;&#125;)+<span class="keyword">uintptr</span>(<span class="built_in">len</span>(inter.mhdr)<span class="number">-1</span>)*sys.PtrSize, <span class="number">0</span>, &amp;memstats.other_sys))</span><br><span class="line">   m.inter = inter</span><br><span class="line">   m._type = typ</span><br><span class="line">   additab(m, <span class="literal">true</span>, canfail)</span><br><span class="line">   <span class="keyword">if</span> m.bad &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> m</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 检查concrete_type是否符合interface_type 并且创建对应的itab结构体 将其放到hash表中</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">additab</span><span class="params">(m *itab, locked, canfail <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">   inter := m.inter</span><br><span class="line">   typ := m._type</span><br><span class="line">   x := typ.uncommon()</span><br><span class="line"></span><br><span class="line">   ni := <span class="built_in">len</span>(inter.mhdr)</span><br><span class="line">   nt := <span class="keyword">int</span>(x.mcount)</span><br><span class="line">   xmhdr := (*[<span class="number">1</span> &lt;&lt; <span class="number">16</span>]method)(add(unsafe.Pointer(x), <span class="keyword">uintptr</span>(x.moff)))[:nt:nt]</span><br><span class="line">   j := <span class="number">0</span></span><br><span class="line">   <span class="keyword">for</span> k := <span class="number">0</span>; k &lt; ni; k++ &#123;</span><br><span class="line">      i := &amp;inter.mhdr[k]</span><br><span class="line">      itype := inter.typ.typeOff(i.ityp)</span><br><span class="line">      name := inter.typ.nameOff(i.name)</span><br><span class="line">      iname := name.name()</span><br><span class="line">      ipkg := name.pkgPath()</span><br><span class="line">      <span class="keyword">if</span> ipkg == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">         ipkg = inter.pkgpath.name()</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">for</span> ; j &lt; nt; j++ &#123;</span><br><span class="line">         t := &amp;xmhdr[j]</span><br><span class="line">         tname := typ.nameOff(t.name)</span><br><span class="line">         <span class="comment">// 检查方法名字是否一致</span></span><br><span class="line">         <span class="keyword">if</span> typ.typeOff(t.mtyp) == itype &amp;&amp; tname.name() == iname &#123;</span><br><span class="line">            pkgPath := tname.pkgPath()</span><br><span class="line">            <span class="keyword">if</span> pkgPath == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">               pkgPath = typ.nameOff(x.pkgpath).name()</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 是否导出或在同一个包</span></span><br><span class="line">            <span class="keyword">if</span> tname.isExported() || pkgPath == ipkg &#123;</span><br><span class="line">               <span class="keyword">if</span> m != <span class="literal">nil</span> &#123;</span><br><span class="line">                    <span class="comment">// 获取函数地址，并加入到itab.fun数组中</span></span><br><span class="line">                  ifn := typ.textOff(t.ifn)</span><br><span class="line">                  *(*unsafe.Pointer)(add(unsafe.Pointer(&amp;m.fun[<span class="number">0</span>]), <span class="keyword">uintptr</span>(k)*sys.PtrSize)) = ifn</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="keyword">goto</span> nextimethod</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// didn&#x27;t find method</span></span><br><span class="line">      <span class="keyword">if</span> !canfail &#123;</span><br><span class="line">         <span class="keyword">if</span> locked &#123;</span><br><span class="line">            unlock(&amp;ifaceLock)</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="built_in">panic</span>(&amp;TypeAssertionError&#123;<span class="string">&quot;&quot;</span>, typ.<span class="keyword">string</span>(), inter.typ.<span class="keyword">string</span>(), iname&#125;)</span><br><span class="line">      &#125;</span><br><span class="line">      m.bad = <span class="literal">true</span></span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">   nextimethod:</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> !locked &#123;</span><br><span class="line">      throw(<span class="string">&quot;invalid itab locking&quot;</span>)</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// 加到Hash Slot链表中</span></span><br><span class="line">   h := itabhash(inter, typ)</span><br><span class="line">   m.link = hash[h]</span><br><span class="line">   m.inhash = <span class="literal">true</span></span><br><span class="line">   atomicstorep(unsafe.Pointer(&amp;hash[h]), unsafe.Pointer(m))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，并不是每次接口赋值都要去检查一次对象是否符合接口要求，而是只在第一次生成itab信息，之后通过hash表即可找到itab信息。</p>
<h3 id="3-接口赋值"><a href="#3-接口赋值" class="headerlink" title="3. 接口赋值"></a>3. 接口赋值</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> MyInterface <span class="keyword">interface</span> &#123;</span><br><span class="line">   Print()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> MyStruct <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ms MyStruct)</span> <span class="title">Print</span><span class="params">()</span></span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">   a := <span class="number">1</span></span><br><span class="line">   b := <span class="string">&quot;str&quot;</span></span><br><span class="line">   c := MyStruct&#123;&#125;</span><br><span class="line">   <span class="keyword">var</span> i1 <span class="keyword">interface</span>&#123;&#125; = a</span><br><span class="line">   <span class="keyword">var</span> i2 <span class="keyword">interface</span>&#123;&#125; = b</span><br><span class="line">   <span class="keyword">var</span> i3 MyInterface = c</span><br><span class="line">   <span class="keyword">var</span> i4 <span class="keyword">interface</span>&#123;&#125; = i3</span><br><span class="line">   <span class="keyword">var</span> i5 = i4.(MyInterface)</span><br><span class="line">   fmt.Println(i1, i2, i3, i4, i5)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>用go1.8编译并反汇编:</p>
<pre><code>$GO1.8PATH/bin/go build -gcflags &#39;-N -l&#39; -o tmp tmp.go
$GO1.8PATH/bin/go tool objdump -s &quot;main\.main&quot; tmp
</code></pre><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; var i1 interface&#123;&#125; &#x3D; a</span><br><span class="line">test.go:16      0x1087146       488b442430                      MOVQ 0x30(SP), AX</span><br><span class="line">test.go:16      0x108714b       4889442438                      MOVQ AX, 0x38(SP)</span><br><span class="line">test.go:16      0x1087150       488d05a9e10000                  LEAQ 0xe1a9(IP), AX &#x2F;&#x2F; 加载a的类型信息(int)</span><br><span class="line">test.go:16      0x1087157       48890424                        MOVQ AX, 0(SP)</span><br><span class="line">test.go:16      0x108715b       488d442438                      LEAQ 0x38(SP), AX &#x2F;&#x2F; 加载a的地址</span><br><span class="line">test.go:16      0x1087160       4889442408                      MOVQ AX, 0x8(SP)</span><br><span class="line">test.go:16      0x1087165       e84645f8ff                      CALL runtime.convT2E(SB)</span><br><span class="line">test.go:16      0x108716a       488b442410                      MOVQ 0x10(SP), AX &#x2F;&#x2F; 填充i1的type和data</span><br><span class="line">test.go:16      0x108716f       488b4c2418                      MOVQ 0x18(SP), CX </span><br><span class="line">test.go:16      0x1087174       48898424a0000000                MOVQ AX, 0xa0(SP)</span><br><span class="line">test.go:16      0x108717c       48898c24a8000000                MOVQ CX, 0xa8(SP)</span><br><span class="line">&#x2F;&#x2F; var i2 interface&#123;&#125; &#x3D; b</span><br><span class="line">&#x2F;&#x2F; 与i1类似 加载类型信息 调用convT2E</span><br><span class="line">...</span><br><span class="line">test.go:17      0x10871bc       e8ef44f8ff                      CALL runtime.convT2E(SB)</span><br><span class="line">test.go:17      0x10871c1       488b442410                      MOVQ 0x10(SP), AX</span><br><span class="line">test.go:17      0x10871c6       488b4c2418                      MOVQ 0x18(SP), CX</span><br><span class="line">test.go:17      0x10871cb       4889842490000000                MOVQ AX, 0x90(SP)</span><br><span class="line">test.go:17      0x10871d3       48898c2498000000                MOVQ CX, 0x98(SP)</span><br><span class="line">&#x2F;&#x2F; var i3 MyInterface &#x3D; c</span><br><span class="line">test.go:18      0x10871db       488d051e000800                  LEAQ 0x8001e(IP), AX &#x2F;&#x2F; 加载c的类型信息(MyStruct)</span><br><span class="line">test.go:18      0x10871e2       48890424                        MOVQ AX, 0(SP)</span><br><span class="line">test.go:18      0x10871e6       488d442430                      LEAQ 0x30(SP), AX</span><br><span class="line">test.go:18      0x10871eb       4889442408                      MOVQ AX, 0x8(SP)</span><br><span class="line">test.go:18      0x10871f0       e86b45f8ff                      CALL runtime.convT2I(SB)</span><br><span class="line">test.go:18      0x10871f5       488b442410                      MOVQ 0x10(SP), AX</span><br><span class="line">test.go:18      0x10871fa       488b4c2418                      MOVQ 0x18(SP), CX</span><br><span class="line">test.go:18      0x10871ff       4889842480000000                MOVQ AX, 0x80(SP)</span><br><span class="line">test.go:18      0x1087207       48898c2488000000                MOVQ CX, 0x88(SP)</span><br><span class="line">&#x2F;&#x2F; var i4 interface&#123;&#125; &#x3D; i3</span><br><span class="line">test.go:19      0x108720f       488b842488000000                MOVQ 0x88(SP), AX</span><br><span class="line">test.go:19      0x1087217       488b8c2480000000                MOVQ 0x80(SP), CX &#x2F;&#x2F; CX &#x3D; i3.itab</span><br><span class="line">test.go:19      0x108721f       48898c24e0000000                MOVQ CX, 0xe0(SP) </span><br><span class="line">test.go:19      0x1087227       48898424e8000000                MOVQ AX, 0xe8(SP) &#x2F;&#x2F; 0xe8(SP) &#x3D; i3.data</span><br><span class="line">test.go:19      0x108722f       48894c2448                      MOVQ CX, 0x48(SP) </span><br><span class="line">test.go:19      0x1087234       4885c9                          TESTQ CX, CX</span><br><span class="line">test.go:19      0x1087237       7505                            JNE 0x108723e</span><br><span class="line">test.go:19      0x1087239       e915020000                      JMP 0x1087453</span><br><span class="line">test.go:19      0x108723e       8401                            TESTB AL, 0(CX)</span><br><span class="line">test.go:19      0x1087240       488b4108                        MOVQ 0x8(CX), AX &#x2F;&#x2F; (i3.itab+8) 得到 &amp;i3.itab.typ，因此AX&#x3D;i3.itab.typ 即iface指向对象的具体类型信息，这里是MyStruct</span><br><span class="line">test.go:19      0x1087244       4889442448                      MOVQ AX, 0x48(SP) &#x2F;&#x2F; 0x48(SP) &#x3D; i3.itab.typ</span><br><span class="line">test.go:19      0x1087249       eb00                            JMP 0x108724b</span><br><span class="line">test.go:19      0x108724b       488b8424e8000000                MOVQ 0xe8(SP), AX &#x2F;&#x2F; AX &#x3D; i3.data</span><br><span class="line">test.go:19      0x1087253       488b4c2448                      MOVQ 0x48(SP), CX &#x2F;&#x2F; CX &#x3D; i3.itab.typ</span><br><span class="line">test.go:19      0x1087258       48894c2470                      MOVQ CX, 0x70(SP) &#x2F;&#x2F; i4.typ &#x3D; i3.itab.typ</span><br><span class="line">test.go:19      0x108725d       4889442478                      MOVQ AX, 0x78(SP) &#x2F;&#x2F; i4.data &#x3D; i3.data</span><br><span class="line">&#x2F;&#x2F; var i5 &#x3D; i4.(MyInterface)</span><br><span class="line">test.go:20      0x1087262       48c78424f000000000000000        MOVQ $0x0, 0xf0(SP)</span><br><span class="line">test.go:20      0x108726e       48c78424f800000000000000        MOVQ $0x0, 0xf8(SP)</span><br><span class="line">test.go:20      0x108727a       488b442478                      MOVQ 0x78(SP), AX</span><br><span class="line">test.go:20      0x108727f       488b4c2470                      MOVQ 0x70(SP), CX</span><br><span class="line">test.go:21      0x1087284       488d1535530100                  LEAQ 0x15335(IP), DX</span><br><span class="line">test.go:20      0x108728b       48891424                        MOVQ DX, 0(SP) &#x2F;&#x2F; 压入 MyInterface 的 interfacetype</span><br><span class="line">test.go:20      0x108728f       48894c2408                      MOVQ CX, 0x8(SP) &#x2F;&#x2F; 压入 i4.type</span><br><span class="line">test.go:20      0x1087294       4889442410                      MOVQ AX, 0x10(SP) &#x2F;&#x2F; 压入 i4.data</span><br><span class="line">test.go:20      0x1087299       e87245f8ff                      CALL runtime.assertE2I(SB) &#x2F;&#x2F; func assertE2I(inter *interfacetype, e eface) (r iface)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>可以看到编译器通过convT2E和convT2I将编译器已知的类型赋给接口(其中E代表eface，I代表iface，T代表编译器已知类型，即静态类型)，编译器知晓itab的布局，会在编译期检查接口是否适配，并且生成itab信息，因此编译器生成的convT2X调用是必然成功的。</p>
<p>对于接口间的赋值，将iface赋给eface比较简单，直接提取eface的interfacetype和data赋给iface即可。而反过来，则需要使用接口断言，接口断言通过assertE2I, assertI2I等函数来完成，这类assert函数根据使用方调用方式有两个版本:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">i5 := i4.(MyInterface)         <span class="comment">// call conv.assertE2I</span></span><br><span class="line">i5, ok := i4.(MyInterface)  <span class="comment">//  call conv.AssertE2I2</span></span><br></pre></td></tr></table></figure>
<p>下面看一下几个常用的conv和assert函数实现:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// go1.8/src/runtime/iface.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">convT2E</span><span class="params">(t *_type, elem unsafe.Pointer)</span> <span class="params">(e eface)</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> raceenabled &#123;</span><br><span class="line">        raceReadObjectPC(t, elem, getcallerpc(unsafe.Pointer(&amp;t)), funcPC(convT2E))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> msanenabled &#123;</span><br><span class="line">        msanread(elem, t.size)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> isDirectIface(t) &#123;</span><br><span class="line">        <span class="comment">// This case is implemented directly by the compiler.</span></span><br><span class="line">        throw(<span class="string">&quot;direct convT2E&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    x := newobject(t)</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> We allocate a zeroed object only to overwrite it with</span></span><br><span class="line">    <span class="comment">// actual data. Figure out how to avoid zeroing. Also below in convT2I.</span></span><br><span class="line">    typedmemmove(t, x, elem)</span><br><span class="line">    e._type = t</span><br><span class="line">    e.data = x</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">convT2I</span><span class="params">(tab *itab, elem unsafe.Pointer)</span> <span class="params">(i iface)</span></span> &#123;</span><br><span class="line">    t := tab._type</span><br><span class="line">    <span class="keyword">if</span> raceenabled &#123;</span><br><span class="line">        raceReadObjectPC(t, elem, getcallerpc(unsafe.Pointer(&amp;tab)), funcPC(convT2I))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> msanenabled &#123;</span><br><span class="line">        msanread(elem, t.size)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> isDirectIface(t) &#123;</span><br><span class="line">        <span class="comment">// This case is implemented directly by the compiler.</span></span><br><span class="line">        throw(<span class="string">&quot;direct convT2I&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    x := newobject(t)</span><br><span class="line">    typedmemmove(t, x, elem)</span><br><span class="line">    i.tab = tab</span><br><span class="line">    i.data = x</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">assertE2I</span><span class="params">(inter *interfacetype, e eface)</span> <span class="params">(r iface)</span></span> &#123;</span><br><span class="line">    t := e._type</span><br><span class="line">    <span class="keyword">if</span> t == <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="comment">// explicit conversions require non-nil interface value.</span></span><br><span class="line">        <span class="built_in">panic</span>(&amp;TypeAssertionError&#123;<span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, inter.typ.<span class="keyword">string</span>(), <span class="string">&quot;&quot;</span>&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    r.tab = getitab(inter, t, <span class="literal">false</span>)</span><br><span class="line">    r.data = e.data</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在assertE2I中，我们看到了getitab函数，即<code>i5=i4.(MyInterface)</code>中，会去判断i4的concretetype(MyStruct)是否满足MyInterface的interfacetype，由于前面我们执行过<code>var i3 MyInterface = c</code>，因此hash[itabhash(MyInterface, MyStruct)]已经存在itab，所以无需再次检查接口是否满足，从hash表中取出itab即可(里面针对接口的各个方法实现地址都已经初始化完成)。</p>
<p>而在go1.9中，有一些优化:</p>
<p>1.对convT2x针对简单类型(如int32,string,slice)进行特例化优化(避免typedmemmove):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">convT2E16, convT2I16</span><br><span class="line">convT2E32, convT2I32</span><br><span class="line">convT2E64, convT2I64</span><br><span class="line">convT2Estring, convT2Istring</span><br><span class="line">convT2Eslice, convT2Islice</span><br><span class="line">convT2Enoptr, convT2Inoptr</span><br></pre></td></tr></table></figure>
<p>据统计，在编译make.bash的时候，有93%的convT2x调用都可通过以上特例化优化。参考<a href="https://go-review.googlesource.com/c/go/+/36476">这里</a>。</p>
<p>2.优化了剩余对convT2I的调用</p>
<p>由于itab由编译器生成(参考上面go1.8生成的汇编代码和convT2I函数)，可以直接由编译器将itab和elem直接赋给iface的tab和data字段，避免函数调用和typedmemmove。关于此优化可参考<a href="https://go-review.googlesource.com/c/go/+/20901/9">1</a>和<a href="https://go-review.googlesource.com/c/go/+/20902">2</a>。</p>
<p>具体汇编代码不再列出，感兴趣的同学可以自己尝试。</p>
<p>对接口的构造和转换本质上是对object的type和data两个字段的操作，对空接口eface来说，只需将type和data提取并填入即可，而对于非空接口iface构造和断言，需要判断object或eface是否满足接口定义，并生成对应的itab(包含接口类型，object类型，object接口实现方法地址等信息)，每个已初始化的iface都有itab字段，该字段的生成是通过hash表优化的，以及对于每个interfacetype &lt;-&gt; concrettype对，只需要生成一次itab，之后从hash表中取就可以了。由于编译器知晓itab的内存布局，因此在将iface赋给eface的时候可以避免函数调用，直接将iface.itab.typ赋给eface.typ。</p>
<h3 id="4-类型反射"><a href="#4-类型反射" class="headerlink" title="4. 类型反射"></a>4. 类型反射</h3><h4 id="4-1-类型-amp-值解析"><a href="#4-1-类型-amp-值解析" class="headerlink" title="4.1 类型&amp;值解析"></a>4.1 类型&amp;值解析</h4><p>类型和值解析无非就是将eface{}的_type和data字段取出进行解析，针对TypeOf的实现很简单:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 代码位于relect&#x2F;type.go</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; reflect.Type接口的实现为: reflect.rtype</span><br><span class="line">&#x2F;&#x2F; reflect.rtype结构体定义和runtime._type一样，只是实现了reflect.Type接口，实现了一些诸如Elem()，Name()之类的方法:</span><br><span class="line"></span><br><span class="line">func TypeOf(i interface&#123;&#125;) Type &#123;</span><br><span class="line">    &#x2F;&#x2F; emptyInterface结构体定义与eface一样，都是两个word(type和data)</span><br><span class="line">    eface :&#x3D; *(*emptyInterface)(unsafe.Pointer(&amp;i))</span><br><span class="line">    return toType(eface.typ) &#x2F;&#x2F; 将eface.typ赋给reflect.Type接口，供外部使用</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>要知道，对于复合类型，如Ptr, Slice, Chan, Map等，它们的type信息中包含其子类型的信息，如Slice元素类型，而其元素类型也可能是复合类型，因此type实际上是一颗”类型树”，可通过<code>reflect.Elem()</code>和<code>reflect.Key()</code>等API来获取这些子类型信息，但如果如果type不匹配(比如<code>reflect.TypeOf([]int&#123;1,2&#125;).Key()</code>)，会panic。</p>
<p><code>reflect.ValueOf()</code>则要复杂一些，因为它需要根据type来决定数据应该如何被解释:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type Value struct &#123;</span><br><span class="line">    &#x2F;&#x2F; 值的类型</span><br><span class="line">    typ *rtype</span><br><span class="line">    &#x2F;&#x2F; 立即数或指向数据的指针</span><br><span class="line">    ptr unsafe.Pointer</span><br><span class="line">    &#x2F;&#x2F; type flag uintptr</span><br><span class="line">    &#x2F;&#x2F; 指明值的类型，是否只读，ptr字段是否是指针等</span><br><span class="line">    flag</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func ValueOf(i interface&#123;&#125;) Value &#123;</span><br><span class="line">    if i &#x3D;&#x3D; nil &#123;</span><br><span class="line">        return Value&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    escapes(i)</span><br><span class="line"></span><br><span class="line">    return unpackEface(i)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 将数据从interface&#123;&#125;解包为reflec.Value</span><br><span class="line">func unpackEface(i interface&#123;&#125;) Value &#123;</span><br><span class="line">    e :&#x3D; (*emptyInterface)(unsafe.Pointer(&amp;i))</span><br><span class="line">    &#x2F;&#x2F; NOTE: don&#39;t read e.word until we know whether it is really a pointer or not.</span><br><span class="line">    t :&#x3D; e.typ</span><br><span class="line">    if t &#x3D;&#x3D; nil &#123;</span><br><span class="line">        return Value&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    f :&#x3D; flag(t.Kind())</span><br><span class="line">    if ifaceIndir(t) &#123;</span><br><span class="line">        f |&#x3D; flagIndir</span><br><span class="line">    &#125;</span><br><span class="line">    return Value&#123;t, e.word, f&#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">&#x2F;&#x2F; 将数据由reflect.Value打包为interface&#123;&#125;</span><br><span class="line">func packEface(v Value) interface&#123;&#125; &#123;</span><br><span class="line">    t :&#x3D; v.typ</span><br><span class="line">    var i interface&#123;&#125;</span><br><span class="line">    e :&#x3D; (*emptyInterface)(unsafe.Pointer(&amp;i))</span><br><span class="line">    &#x2F;&#x2F; First, fill in the data portion of the interface.</span><br><span class="line">    switch &#123;</span><br><span class="line">    case ifaceIndir(t):</span><br><span class="line">        if v.flag&amp;flagIndir &#x3D;&#x3D; 0 &#123;</span><br><span class="line">            panic(&quot;bad indir&quot;)</span><br><span class="line">        &#125;</span><br><span class="line">        ptr :&#x3D; v.ptr</span><br><span class="line">        if v.flag&amp;flagAddr !&#x3D; 0 &#123;</span><br><span class="line">            c :&#x3D; unsafe_New(t)</span><br><span class="line">            typedmemmove(t, c, ptr)</span><br><span class="line">            ptr &#x3D; c</span><br><span class="line">        &#125;</span><br><span class="line">        e.word &#x3D; ptr</span><br><span class="line">    case v.flag&amp;flagIndir !&#x3D; 0:</span><br><span class="line">        e.word &#x3D; *(*unsafe.Pointer)(v.ptr)</span><br><span class="line">    default:</span><br><span class="line">        e.word &#x3D; v.ptr</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    e.typ &#x3D; t</span><br><span class="line">    return i</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">&#x2F;&#x2F; 将reflect.Value转换为interface&#123;&#125;，相当于reflect.ValueOf的逆操作</span><br><span class="line">&#x2F;&#x2F; 等价于: var i interface&#123;&#125; &#x3D; (v&#39;s underlying value)</span><br><span class="line">func (v Value) Interface() (i interface&#123;&#125;) &#123;</span><br><span class="line">   return valueInterface(v, true)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func valueInterface(v Value, safe bool) interface&#123;&#125; &#123;</span><br><span class="line">   if v.flag &#x3D;&#x3D; 0 &#123;</span><br><span class="line">      panic(&amp;ValueError&#123;&quot;reflect.Value.Interface&quot;, 0&#125;)</span><br><span class="line">   &#125;</span><br><span class="line">   if safe &amp;&amp; v.flag&amp;flagRO !&#x3D; 0 &#123;</span><br><span class="line">      panic(&quot;reflect.Value.Interface: cannot return value obtained from unexported field or method&quot;)</span><br><span class="line">   &#125;</span><br><span class="line">   if v.flag&amp;flagMethod !&#x3D; 0 &#123;</span><br><span class="line">      v &#x3D; makeMethodValue(&quot;Interface&quot;, v)</span><br><span class="line">   &#125;</span><br><span class="line">   &#x2F;&#x2F; 当interface&#123;&#125;作为子类型时，会产生类型为Interface的Value</span><br><span class="line">   &#x2F;&#x2F; 如 reflect.TypeOf(m).Elem().Kind() &#x3D;&#x3D; Interface</span><br><span class="line">   if v.kind() &#x3D;&#x3D; Interface &#123;</span><br><span class="line">      if v.NumMethod() &#x3D;&#x3D; 0 &#123;</span><br><span class="line">         return *(*interface&#123;&#125;)(v.ptr)</span><br><span class="line">      &#125;</span><br><span class="line">      return *(*interface &#123;</span><br><span class="line">         M()</span><br><span class="line">      &#125;)(v.ptr)</span><br><span class="line">   &#125;</span><br><span class="line">   return packEface(v)</span><br><span class="line">&#125;</span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>和<code>reflect.Type.Elem()</code>一样，<code>reflect.Value</code>也提供一系列的方法进行值解析，如<code>Elem()</code>可以得到Interface或Ptr指向的值，<code>Index()</code>可以得到Array, Slice或String对应下标的元素等。但在使用这些API前要先通过<code>reflect.Type.Kind()</code>确认类型匹配，否则会panic。</p>
<h4 id="4-2-类型反射"><a href="#4-2-类型反射" class="headerlink" title="4.2 类型反射"></a>4.2 类型反射</h4><p>类型&amp;值解析实际上对将interface{}的type和data提出来，以<code>reflect.Type</code>和<code>reflect.Value</code>接口暴露给用户使用，而类型反射是指提供一个reflect.Type，我们可以创建一个对应类型的对象，这可以通过<code>reflect.New()</code>来完成：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// reflect/value.go</span></span><br><span class="line"><span class="comment">// New returns a Value representing a pointer to a new zero value</span></span><br><span class="line"><span class="comment">// for the specified type. That is, the returned Value&#x27;s Type is PtrTo(typ).</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(typ Type)</span> <span class="title">Value</span></span> &#123;</span><br><span class="line">   <span class="keyword">if</span> typ == <span class="literal">nil</span> &#123;</span><br><span class="line">      <span class="built_in">panic</span>(<span class="string">&quot;reflect: New(nil)&quot;</span>)</span><br><span class="line">   &#125;</span><br><span class="line">   ptr := unsafe_New(typ.(*rtype))</span><br><span class="line">   fl := flag(Ptr)</span><br><span class="line">   <span class="keyword">return</span> Value&#123;typ.common().ptrTo(), ptr, fl&#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment">// runtime/malloc.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newobject</span><span class="params">(typ *_type)</span> <span class="title">unsafe</span>.<span class="title">Pointer</span></span> &#123;</span><br><span class="line">   <span class="keyword">return</span> mallocgc(typ.size, typ, <span class="literal">true</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//go:linkname reflect_unsafe_New reflect.unsafe_New</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">reflect_unsafe_New</span><span class="params">(typ *_type)</span> <span class="title">unsafe</span>.<span class="title">Pointer</span></span> &#123;</span><br><span class="line">   <span class="keyword">return</span> newobject(typ)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PS: Go的包管理看来还是不够好用，为了达成reflect包和runtime包的”解耦”，先后使用和copy struct define和link method “黑科技”。</p>
<p><code>reflect.New()</code>创建对应Type的对象并返回其指针，以下是一个简单的示例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type User struct &#123;</span><br><span class="line">   UserId     int</span><br><span class="line">   Name   string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">   x :&#x3D; User&#123;UserId: 111&#125;</span><br><span class="line">   typ :&#x3D; reflect.TypeOf(x)</span><br><span class="line">   &#x2F;&#x2F; reflect.New返回的是*User 而不是User</span><br><span class="line">   y :&#x3D; reflect.New(typ).Elem()</span><br><span class="line">   for i:&#x3D;0; i&lt;typ.NumField(); i++ &#123;</span><br><span class="line">      &#x2F;&#x2F; 根据每个struct field的type 设置其值</span><br><span class="line">      fieldT :&#x3D; typ.Field(i) </span><br><span class="line">      fieldV :&#x3D; y.Field(i)</span><br><span class="line">      kind :&#x3D; fieldT.Type.Kind()</span><br><span class="line">      if kind &#x3D;&#x3D; reflect.Int&#123;</span><br><span class="line">         fieldV.SetInt(123)</span><br><span class="line">      &#125; else if kind &#x3D;&#x3D; reflect.String&#123;</span><br><span class="line">         fieldV.SetString(&quot;wudaijun&quot;)</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   fmt.Println(y.Interface())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上代码稍改一下，即可实现简单CSV解析：根据提供的struct原型，分析其字段，并一一映射到csv每一列，将csv读出的string转换为对应的struct field type，对于简单类型使用strconv即可完成，对于复合数据结构如Map, Slice，可使用json库来定义和解析。</p>
<p><code>reflect.New()</code>和<code>reflect.Zero()</code>可用于创建Type对应的对象，除此之外，reflect包还提供了<code>reflect.MapOf()</code>, <code>reflect.SliceOf()</code>等方法用于基于现有类型创建复合类型。具体源码不再列出，参考reflect/type.go和reflect/value.go。</p>
<p>reflect提供的反射能力不可谓不强大，但在实际使用中仍然不够好用，一个因为Go本质上是静态类型语言，要提供”动态类型”的部分语义是比较复杂和不易用的，这有点像C++提供泛型编程，虽然强大，但也是把双刃剑。</p>
<p>参考:</p>
<ol>
<li><a href="https://studygolang.com/articles/2917">Golang汇编快速指南</a></li>
<li><a href="http://legendtkl.com/2017/07/01/golang-interface-implement/">Go Interface源码剖析</a></li>
</ol>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Go sync.Map 实现</title>
    <url>/2018/02/go-sync-map-implement/</url>
    <content><![CDATA[<p>Go基于CSP模型，提倡”Share memory by communicating; don’t communicate by sharing memory.”，亦即通过channel来实现goroutine之间的数据共享，但很多时候用锁仍然是不可避免的，它可以让流程更直观明了，并且减少内存占用等。通常我们的实践是用channel传递数据的所有权，分配工作和同步异步结果等，而用锁来共享状态和配置等信息。</p>
<p>本文从偏实现的角度学习下Go的atomic.Load/Store，atomic.Value，以及sync.Map。</p>
<span id="more"></span>
<h3 id="1-atomic-Load-Store"><a href="#1-atomic-Load-Store" class="headerlink" title="1. atomic.Load/Store"></a>1. atomic.Load/Store</h3><p>在Go中，对于一个字以内的简单类型(如整数，指针)，可以直接通过<code>atomic.Load/Store/Add/Swap/CompareAndSwap</code>系列API来进行原子读写，以Int32为例: </p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"> </span><br><span class="line"><span class="comment">// AddInt32 atomically adds delta to *addr and returns the new value.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AddInt32</span><span class="params">(addr *<span class="keyword">int32</span>, delta <span class="keyword">int32</span>)</span> <span class="params">(<span class="built_in">new</span> <span class="keyword">int32</span>)</span></span></span><br><span class="line"><span class="comment">// LoadInt32 atomically loads *addr.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">LoadInt32</span><span class="params">(addr *<span class="keyword">int32</span>)</span> <span class="params">(val <span class="keyword">int32</span>)</span></span></span><br><span class="line"><span class="comment">// StoreInt32 atomically stores val into *addr.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">StoreInt32</span><span class="params">(addr *<span class="keyword">int32</span>, val <span class="keyword">int32</span>)</span></span></span><br><span class="line"><span class="comment">// SwapInt32 atomically stores new into *addr and returns the previous *addr value.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">SwapInt32</span><span class="params">(addr *<span class="keyword">int32</span>, <span class="built_in">new</span> <span class="keyword">int32</span>)</span> <span class="params">(old <span class="keyword">int32</span>)</span></span></span><br><span class="line"><span class="comment">// CompareAndSwapInt32 executes the compare-and-swap operation for an int32 value.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">CompareAndSwapInt32</span><span class="params">(addr *<span class="keyword">int32</span>, old, <span class="built_in">new</span> <span class="keyword">int32</span>)</span> <span class="params">(swapped <span class="keyword">bool</span>)</span></span></span><br></pre></td></tr></table></figure>
<p>一个有意思的问题，在64位平台下，对Int32，Int64的直接读写是原子的吗？以下是一些有意思的讨论:</p>
<ul>
<li><a href="http://preshing.com/20130618/atomic-vs-non-atomic-operations/">http://preshing.com/20130618/atomic-vs-non-atomic-operations/</a></li>
<li><a href="https://stackoverflow.com/questions/46556857/is-golang-atomic-loaduint32-necessary">https://stackoverflow.com/questions/46556857/is-golang-atomic-loaduint32-necessary</a></li>
<li><a href="https://stackoverflow.com/questions/5258627/atomic-64-bit-writes-with-gcc">https://stackoverflow.com/questions/5258627/atomic-64-bit-writes-with-gcc</a></li>
</ul>
<p>总结就是，现代硬件架构基本都保证了内存对齐的word-sized load和store是原子的，这隐含两个条件: 单条MOV, MOVQ等指令是原子的，字段内存对齐(CPU对内存的读取是基于word-size的)。但安全起见，最好还是使用atomic提供的接口，具备更好的跨平台性，并且atomic还提供了一些复合操作(Add/Swap/CAS)。golang也在实现上会对具体平台进行优化：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var i int64</span><br><span class="line">atomic.StoreInt64(&amp;i, 123)</span><br><span class="line">x :&#x3D; atomic.LoadInt64(&amp;i)</span><br><span class="line">y :&#x3D; atomic.AddInt64(&amp;i, 1)</span><br></pre></td></tr></table></figure>
<p>在MacOS10.12(X86_64)下，对应汇编代码:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; var i int64</span><br><span class="line">tmp.go:9        0x1093bff       488d051af50000                  LEAQ 0xf51a(IP), AX  &#x2F;&#x2F; 加载int64 type</span><br><span class="line">tmp.go:9        0x1093c06       48890424                        MOVQ AX, 0(SP)</span><br><span class="line">tmp.go:9        0x1093c0a       e8c1a1f7ff                      CALL runtime.newobject(SB) &#x2F;&#x2F; i分配在堆上(逃逸分析,escape analytic))</span><br><span class="line">tmp.go:9        0x1093c0f       488b442408                      MOVQ 0x8(SP), AX</span><br><span class="line">tmp.go:9        0x1093c14       4889442450                      MOVQ AX, 0x50(SP) &#x2F;&#x2F; 0x50(SP) &#x3D; &amp;i</span><br><span class="line">tmp.go:9        0x1093c19       48c70000000000                  MOVQ $0x0, 0(AX)  &#x2F;&#x2F; 初始化 i &#x3D; 0</span><br><span class="line">&#x2F;&#x2F; atomic.StoreInt64(&amp;i, 123)</span><br><span class="line">tmp.go:10       0x1093c20       488b442450                      MOVQ 0x50(SP), AX  &#x2F;&#x2F; 加载&amp;i</span><br><span class="line">tmp.go:10       0x1093c25       48c7c17b000000                  MOVQ $0x7b, CX  &#x2F;&#x2F; 加载立即数 123</span><br><span class="line">tmp.go:10       0x1093c2c       488708                          XCHGQ CX, 0(AX)  &#x2F;&#x2F; *(&amp;i) &#x3D; 123  Key Step XCHGQ通过LOCK信号锁住内存总线来确保原子性</span><br><span class="line">&#x2F;&#x2F; x :&#x3D; atomic.LoadInt64(&amp;i)</span><br><span class="line">tmp.go:11       0x1093c2f       488b442450                      MOVQ 0x50(SP), AX</span><br><span class="line">tmp.go:11       0x1093c34       488b00                          MOVQ 0(AX), AX &#x2F;&#x2F; AX &#x3D; *(&amp;i)  Key Step 原子操作</span><br><span class="line">tmp.go:11       0x1093c37       4889442430                      MOVQ AX, 0x30(SP)</span><br><span class="line">&#x2F;&#x2F; y :&#x3D; atomic.AddInt64(&amp;i, 1)</span><br><span class="line">tmp.go:12       0x1093c3c       488b442450                      MOVQ 0x50(SP), AX</span><br><span class="line">tmp.go:12       0x1093c41       48c7c101000000                  MOVQ $0x1, CX</span><br><span class="line">tmp.go:12       0x1093c48       f0480fc108                      LOCK XADDQ CX, 0(AX) &#x2F;&#x2F; LOCK会锁住内存总线，直到XADDQ指令完成，完成后CX为i的旧值 0(AX)&#x3D;*(&amp;i)&#x3D;i+1</span><br><span class="line">tmp.go:12       0x1093c4d       488d4101                        LEAQ 0x1(CX), AX &#x2F;&#x2F; AX &#x3D; CX+1 再执行一次加法 用于返回值</span><br><span class="line">tmp.go:12       0x1093c51       4889442428                      MOVQ AX, 0x28(SP)</span><br></pre></td></tr></table></figure><br>对XCHG和XADD这类X开头的指令，都会通过LOCK信号锁住内存总线，因此加不加LOCK前缀都是一样的。可以看到，由于硬件架构的支持，atomic.Load/Store和普通读写基本没有什么区别，这种CPU指令级别的锁非常快。因此通常我们将这类CPU指令级别的支持的Lock操作称为原子操作或无锁操作。</p>
<h3 id="2-atomic-Value"><a href="#2-atomic-Value" class="headerlink" title="2. atomic.Value"></a>2. atomic.Value</h3><p>atomic.Value于go1.4引入，用于无锁存取任意值(interface{})，它的数据结构很简单:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// sync/atomic/value.go</span></span><br><span class="line"><span class="keyword">type</span> Value <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="comment">// 没有实际意义 用于保证结构体在第一次被使用之后，不能被拷贝</span></span><br><span class="line">  <span class="comment">// 参考: https://github.com/golang/go/issues/8005#issuecomment-190753527</span></span><br><span class="line">   noCopy noCopy</span><br><span class="line">  <span class="comment">// 实际保存的值</span></span><br><span class="line">   v <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Load returns the value set by the most recent Store.</span></span><br><span class="line"><span class="comment">// It returns nil if there has been no call to Store for this Value.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *Value)</span> <span class="title">Load</span><span class="params">()</span> <span class="params">(x <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Store sets the value of the Value to x.</span></span><br><span class="line"><span class="comment">// All calls to Store for a given Value must use values of the same concrete type.</span></span><br><span class="line"><span class="comment">// Store of an inconsistent type panics, as does Store(nil).</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *Value)</span> <span class="title">Store</span><span class="params">(x <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>atomic负责v的原子存取操作，我们知道interface{}对应的数据结构为eface，有两个字段: type和data，因此它不能直接通过atomic.Load/Store来存取，atomic.Value实现无锁存取的原理很简单: type字段不变，只允许更改data字段，这样就能通过<code>atomic.LoadPointer</code>来实现对data的存取。从实现来讲，atomic.Value要处理好两点:</p>
<ol>
<li>atomic.Value的初始化，因为在初始化时，需要同时初始化type和data字段，atomic.Value通过CAS自旋锁来实现初始化的原子性。</li>
<li>atomic.Value的拷贝，一是拷贝过程的原子性，二是拷贝方式，浅拷贝会带来更多的并发问题，深拷贝得到两个独立的atomic.Value是没有意义的，因此atomic.Value在初始化完成之后是不能拷贝的。</li>
</ol>
<p>除此之外，atomic.Value的实现比较简单，结合eface和<code>atomic.LoadPointer()</code>即可理解，不再详述。</p>
<h3 id="3-sync-Map"><a href="#3-sync-Map" class="headerlink" title="3. sync.Map"></a>3. sync.Map</h3><p>sync.Map于go1.9引入，为并发map提供一个高效的解决方案。在此之前，通常是通过<code>sync.RWMutex</code>来实现线程安全的Map，后面会有mutexMap和sync.Map的性能对比。先来看看sync.Map的特性: </p>
<ol>
<li>以空间换效率，通过read和dirty两个map来提高读取效率</li>
<li>优先从read map中读取(无锁)，否则再从dirty map中读取(加锁)</li>
<li>动态调整，当misses次数过多时，将dirty map提升为read map</li>
<li>延迟删除，删除只是为value打一个标记，在dirty map提升时才执行真正的删除</li>
</ol>
<p>sync.Map的使用很简单:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> m sync.Map</span><br><span class="line">m.Store(<span class="string">&quot;key&quot;</span>, <span class="number">123</span>)</span><br><span class="line">v, ok := m.Load(<span class="string">&quot;key&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>下面看一下sync.Map的定义以及Load, Store, Delete三个方法的实现。</p>
<h4 id="3-1-定义"><a href="#3-1-定义" class="headerlink" title="3.1 定义"></a>3.1 定义</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// sync/map.go</span></span><br><span class="line"><span class="keyword">type</span> Map <span class="keyword">struct</span> &#123;</span><br><span class="line">   <span class="comment">// 当写read map 或读写dirty map时 需要上锁</span></span><br><span class="line">   mu Mutex</span><br><span class="line"></span><br><span class="line">   <span class="comment">// read map的 k v(entry) 是不变的，删除只是打标记，插入新key会加锁写到dirty中</span></span><br><span class="line">   <span class="comment">// 因此对read map的读取无需加锁</span></span><br><span class="line">   read atomic.Value <span class="comment">// 保存readOnly结构体</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">// dirty map 对dirty map的操作需要持有mu锁</span></span><br><span class="line">   dirty <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]*entry</span><br><span class="line"></span><br><span class="line">   <span class="comment">// 当Load操作在read map中未找到，尝试从dirty中进行加载时(不管是否存在)，misses+1</span></span><br><span class="line">   <span class="comment">// 当misses达到diry map len时，dirty被提升为read 并且重新分配dirty</span></span><br><span class="line">   misses <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// read map数据结构</span></span><br><span class="line"><span class="keyword">type</span> readOnly <span class="keyword">struct</span> &#123;</span><br><span class="line">   m       <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]*entry</span><br><span class="line">   <span class="comment">// 为true时代表dirty map中含有m中没有的元素</span></span><br><span class="line">   amended <span class="keyword">bool</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> entry <span class="keyword">struct</span> &#123;</span><br><span class="line">   <span class="comment">// 指向实际的interface&#123;&#125;</span></span><br><span class="line">   <span class="comment">// p有三种状态:</span></span><br><span class="line">   <span class="comment">// p == nil: 键值已经被删除，此时，m.dirty==nil 或 m.dirty[k]指向该entry</span></span><br><span class="line">   <span class="comment">// p == expunged: 键值已经被删除， 此时, m.dirty!=nil 且 m.dirty不存在该键值</span></span><br><span class="line">   <span class="comment">// 其它情况代表实际interface&#123;&#125;地址 如果m.dirty!=nil 则 m.read[key] 和 m.dirty[key] 指向同一个entry</span></span><br><span class="line">   <span class="comment">// 当删除key时，并不实际删除，先CAS entry.p为nil 等到每次dirty map创建时(dirty提升后的第一次新建Key)，会将entry.p由nil CAS为expunged</span></span><br><span class="line">   p unsafe.Pointer <span class="comment">// *interface&#123;&#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定义很简单，补充以下几点:</p>
<ol>
<li>read和dirty通过entry包装value，这样使得value的变化和map的变化隔离，前者可以用atomic无锁完成</li>
<li>Map的read字段结构体定义为readOnly，这只是针对map[interface{}]*entry而言的，entry内的内容以及amended字段都是可以变的</li>
<li>大部分情况下，对已有key的删除(entry.p置为nil)和更新可以直接通过修改entry.p来完成</li>
</ol>
<h4 id="3-2-Load"><a href="#3-2-Load" class="headerlink" title="3.2 Load"></a>3.2 Load</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 查找对应的Key值 如果不存在 返回nil，false</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Map)</span> <span class="title">Load</span><span class="params">(key <span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(value <span class="keyword">interface</span>&#123;&#125;, ok <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">  <span class="comment">// 1. 优先从read map中读取(无锁)</span></span><br><span class="line">  read, _ := m.read.Load().(readOnly)</span><br><span class="line">  e, ok := read.m[key]</span><br><span class="line">  <span class="comment">// 2. 如果不存在，并且ammended字段指明dirty map中有read map中不存在的字段，则加锁尝试从dirty map中加载</span></span><br><span class="line">  <span class="keyword">if</span> !ok &amp;&amp; read.amended &#123;</span><br><span class="line">    m.mu.Lock()</span><br><span class="line">    <span class="comment">// double check，避免在加锁的时候dirty map提升为read map</span></span><br><span class="line">    read, _ = m.read.Load().(readOnly)</span><br><span class="line">    e, ok = read.m[key]</span><br><span class="line">    <span class="keyword">if</span> !ok &amp;&amp; read.amended &#123;</span><br><span class="line">      e, ok = m.dirty[key]</span><br><span class="line">      <span class="comment">// 3. 不管dirty中有没有找到 都增加misses计数 该函数可能将dirty map提升为readmap</span></span><br><span class="line">      m.missLocked()</span><br><span class="line">    &#125;</span><br><span class="line">    m.mu.Unlock()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> !ok &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> e.load()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从entry中atomic load实际interface&#123;&#125;</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *entry)</span> <span class="title">load</span><span class="params">()</span> <span class="params">(value <span class="keyword">interface</span>&#123;&#125;, ok <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">  p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">  <span class="keyword">if</span> p == <span class="literal">nil</span> || p == expunged &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> *(*<span class="keyword">interface</span>&#123;&#125;)(p), <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 增加misses计数，并在必要的时候提升dirty map</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Map)</span> <span class="title">missLocked</span><span class="params">()</span></span> &#123;</span><br><span class="line">  m.misses++</span><br><span class="line">  <span class="keyword">if</span> m.misses &lt; <span class="built_in">len</span>(m.dirty) &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 提升过程很简单，直接将m.dirty赋给m.read.m</span></span><br><span class="line">  <span class="comment">// 提升完成之后 amended == false m.dirty == nil</span></span><br><span class="line">  <span class="comment">// m.dirty并不立即创建被拷贝元素，而是延迟创建</span></span><br><span class="line">  m.read.Store(readOnly&#123;m: m.dirty&#125;)</span><br><span class="line">  m.dirty = <span class="literal">nil</span></span><br><span class="line">  m.misses = <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-3-Store"><a href="#3-3-Store" class="headerlink" title="3.3 Store"></a>3.3 Store</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Store sets the value for a key.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Map)</span> <span class="title">Store</span><span class="params">(key, value <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">  <span class="comment">// 1. 如果read map中存在该key  则尝试直接更改(由于修改的是entry内部的pointer，因此dirty map也可见)</span></span><br><span class="line">  read, _ := m.read.Load().(readOnly)</span><br><span class="line">  <span class="keyword">if</span> e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  m.mu.Lock()</span><br><span class="line">  read, _ = m.read.Load().(readOnly)</span><br><span class="line">  <span class="keyword">if</span> e, ok := read.m[key]; ok &#123;</span><br><span class="line">    <span class="keyword">if</span> e.unexpungeLocked() &#123;</span><br><span class="line">      <span class="comment">// 2. 如果read map中存在该key，但p == expunged，则说明m.dirty!=nil并且m.dirty中不存在该key值 此时:</span></span><br><span class="line">      <span class="comment">//    a. 将 p的状态由expunged先更改为nil </span></span><br><span class="line">      <span class="comment">//    b. dirty map新建key</span></span><br><span class="line">      <span class="comment">//    c. 更新entry.p = value (read map和dirty map指向同一个entry)</span></span><br><span class="line">      m.dirty[key] = e</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 3. 如果read map中存在该key，且 p != expunged，直接更新该entry (此时m.dirty==nil或m.dirty[key]==e)</span></span><br><span class="line">    e.storeLocked(&amp;value)</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> e, ok := m.dirty[key]; ok &#123;</span><br><span class="line">    <span class="comment">// 4. 如果read map中不存在该Key，但dirty map中存在该key，直接写入更新entry(read map中仍然没有)</span></span><br><span class="line">    e.storeLocked(&amp;value)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 5. 如果read map和dirty map中都不存在该key，则:</span></span><br><span class="line">    <span class="comment">//    a. 如果dirty map为空，则需要创建dirty map，并从read map中拷贝未删除的元素</span></span><br><span class="line">    <span class="comment">//    b. 更新amended字段，标识dirty map中存在read map中没有的key</span></span><br><span class="line">    <span class="comment">//    c. 将k v写入dirty map中，read.m不变</span></span><br><span class="line">    <span class="keyword">if</span> !read.amended &#123;</span><br><span class="line">      m.dirtyLocked()</span><br><span class="line">      m.read.Store(readOnly&#123;m: read.m, amended: <span class="literal">true</span>&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    m.dirty[key] = newEntry(value)</span><br><span class="line">  &#125;</span><br><span class="line">  m.mu.Unlock()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 尝试直接更新entry 如果p == expunged 返回false</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *entry)</span> <span class="title">tryStore</span><span class="params">(i *<span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">  <span class="keyword">if</span> p == expunged &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> atomic.CompareAndSwapPointer(&amp;e.p, p, unsafe.Pointer(i)) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">    p = atomic.LoadPointer(&amp;e.p)</span><br><span class="line">    <span class="keyword">if</span> p == expunged &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *entry)</span> <span class="title">unexpungeLocked</span><span class="params">()</span> <span class="params">(wasExpunged <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> atomic.CompareAndSwapPointer(&amp;e.p, expunged, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果 dirty map为nil，则从read map中拷贝元素到dirty map</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Map)</span> <span class="title">dirtyLocked</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> m.dirty != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  read, _ := m.read.Load().(readOnly)</span><br><span class="line">  m.dirty = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]*entry, <span class="built_in">len</span>(read.m))</span><br><span class="line">  <span class="keyword">for</span> k, e := <span class="keyword">range</span> read.m &#123;</span><br><span class="line">    <span class="comment">// a. 将所有为 nil的 p 置为 expunged</span></span><br><span class="line">    <span class="comment">// b. 只拷贝不为expunged 的 p</span></span><br><span class="line">    <span class="keyword">if</span> !e.tryExpungeLocked() &#123;</span><br><span class="line">      m.dirty[k] = e</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *entry)</span> <span class="title">tryExpungeLocked</span><span class="params">()</span> <span class="params">(isExpunged <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">  p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">  <span class="keyword">for</span> p == <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> atomic.CompareAndSwapPointer(&amp;e.p, <span class="literal">nil</span>, expunged) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">    p = atomic.LoadPointer(&amp;e.p)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> p == expunged</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="3-4-Delete"><a href="#3-4-Delete" class="headerlink" title="3.4 Delete"></a>3.4 Delete</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Delete deletes the value for a key.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Map)</span> <span class="title">Delete</span><span class="params">(key <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">  <span class="comment">// 1. 从read map中查找，如果存在，则置为nil</span></span><br><span class="line">  read, _ := m.read.Load().(readOnly)</span><br><span class="line">  e, ok := read.m[key]</span><br><span class="line">  <span class="keyword">if</span> !ok &amp;&amp; read.amended &#123;</span><br><span class="line">    <span class="comment">// double check</span></span><br><span class="line">    m.mu.Lock()</span><br><span class="line">    read, _ = m.read.Load().(readOnly)</span><br><span class="line">    e, ok = read.m[key]</span><br><span class="line">    <span class="comment">// 2. 如果read map中不存在，但dirty map中存在，则直接从dirty map删除</span></span><br><span class="line">    <span class="keyword">if</span> !ok &amp;&amp; read.amended &#123;</span><br><span class="line">      <span class="built_in">delete</span>(m.dirty, key)</span><br><span class="line">    &#125;</span><br><span class="line">    m.mu.Unlock()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> ok &#123;</span><br><span class="line">    <span class="comment">// 将entry.p 置为 nil</span></span><br><span class="line">    e.<span class="built_in">delete</span>()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *entry)</span> <span class="title">delete</span><span class="params">()</span> <span class="params">(hadValue <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">    p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">    <span class="keyword">if</span> p == <span class="literal">nil</span> || p == expunged &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> atomic.CompareAndSwapPointer(&amp;e.p, p, <span class="literal">nil</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-5-总结"><a href="#3-5-总结" class="headerlink" title="3.5 总结"></a>3.5 总结</h4><p>除了Load/Store/Delete之外，sync.Map还提供了LoadOrStore/Range操作，但没有提供Len()方法，这是因为要统计有效的键值对只能先提升dirty map(dirty map中可能有read map中没有的键值对)，再遍历m.read(由于延迟删除，不是所有的键值对都有效)，这其实就是Range做的事情，因此在不添加新数据结构支持的情况下，sync.Map的长度获取和Range操作是同一复杂度的。这部分只能看官方后续支持。</p>
<p>sync.Map实现上并不是特别复杂，但仍有很多值得借鉴的地方:</p>
<ol>
<li>通过entry隔离map变更和value变更，并且read map和dirty map指向同一个entry, 这样更新read map已有值无需加锁</li>
<li>double checking</li>
<li>延迟删除key，通过标记避免修改read map，同时极大提升了删除key的效率(删除read map中存在的key是无锁操作)</li>
<li>延迟创建dirty map，并且通过p的nil和expunged，amended字段来加强对dirty map状态的把控，减少对dirty map不必要的使用</li>
</ol>
<p>sync.Map适用于key值相对固定，读多写少(更新m.read已有key仍然是无锁的)的情况，下面是一份使用RWLock的内建map和sync.Map的并发读写性能对比，代码在<a href="https://github.com/wudaijun/Code/tree/master/go/go19_syncmap_test">这里</a>，代码对随机生成的整数key/value值进行并发的Load/Store/Delete操作，benchmark结果如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go test -bench&#x3D;.</span><br><span class="line">goos: darwin</span><br><span class="line">goarch: amd64</span><br><span class="line">BenchmarkMutexMapStoreParalell-4         5000000               260 ns&#x2F;op</span><br><span class="line">BenchmarkSyncMapStoreParalell-4          3000000               498 ns&#x2F;op</span><br><span class="line">BenchmarkMutexMapLoadParalell-4         20000000                78.0 ns&#x2F;op</span><br><span class="line">BenchmarkSyncMapLoadParalell-4          30000000                41.1 ns&#x2F;op</span><br><span class="line">BenchmarkMutexMapDeleteParalell-4       10000000               235 ns&#x2F;op</span><br><span class="line">BenchmarkSyncMapDeleteParalell-4        30000000                49.2 ns&#x2F;op</span><br><span class="line">PASS</span><br></pre></td></tr></table></figure>
<p>可以看到，除了并发写稍慢之外(并发写随机1亿以内的整数key/value，因此新建key操作远大于更新key，会导致sync.Map频繁的dirty map提升操作)，Load和Delete操作均快于mutexMap，特别是删除，得益于延迟删除，sync.Map的Delete几乎和Load一样快。</p>
<p>最后附上一份转载的sync.Map操作图解(<a href="http://russellluo.com/2017/06/go-sync-map-diagram.html">图片出处</a>):</p>
<p><img src="/assets/image/201802/go-sync-map-diagram.png" alt=""></p>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo使用mathjax渲染公式</title>
    <url>/2017/12/hexo-with-mathjax/</url>
    <content><![CDATA[<p>最近有在博客中嵌入公式的需求，目前主要有两个数学公式渲染引擎mathjax和KaTeX，前者应用更广泛，支持的语法更全面，因此这里简述将mathjax整合到hexo。</p>
<h4 id="1-替换Markdown渲染器"><a href="#1-替换Markdown渲染器" class="headerlink" title="1. 替换Markdown渲染器"></a>1. 替换Markdown渲染器</h4><pre><code>npm uninstall hexo-renderer-marked --save
npm install hexo-renderer-kramed --save
</code></pre><p>hexo-renderer-karmed渲染器fork自hexo-renderer-marked，对mathjax的支持更友好，特别是下划线处理(marked会优先将<code>_</code>之间的内容斜体转义)</p>
<h4 id="2-挂载mathjax脚本"><a href="#2-挂载mathjax脚本" class="headerlink" title="2. 挂载mathjax脚本"></a>2. 挂载mathjax脚本</h4><p>在主题<code>layout/_partial/</code>目录下添加mathjax.ejs:</p>
<span id="more"></span>
<pre><code>&lt;!-- mathjax config similar to math.stackexchange --&gt;
&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
  MathJax.Hub.Config(&#123;
    tex2jax: &#123;
      inlineMath: [ [&#39;$&#39;,&#39;$&#39;], [&quot;\\(&quot;,&quot;\\)&quot;] ],
      processEscapes: true
    &#125;
  &#125;);
&lt;/script&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
    MathJax.Hub.Config(&#123;
      tex2jax: &#123;
        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;, &#39;code&#39;]
      &#125;
    &#125;);
&lt;/script&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
    MathJax.Hub.Queue(function() &#123;
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i &lt; all.length; i += 1) &#123;
            all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;
        &#125;
    &#125;);
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=theme.cdn.mathjax + &quot;/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;
&lt;/script&gt;
</code></pre><p>如果用的是jade模板，则添加mathjax.jade:</p>
<pre><code>//mathjax config similar to math.stackexchange
script(type=&quot;text/x-mathjax-config&quot;).
  MathJax.Hub.Config(&#123;
    tex2jax: &#123;
      inlineMath: [ [&#39;$&#39;,&#39;$&#39;], [&quot;\\(&quot;,&quot;\\)&quot;] ],
      displayMath: [ [&#39;$$&#39;,&#39;$$&#39;], [&quot;\\[&quot;,&quot;\\]&quot;] ],
      processEscapes: true
    &#125;
  &#125;);
script(type=&quot;text/x-mathjax-config&quot;).
  MathJax.Hub.Config(&#123;
    tex2jax: &#123;
      skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;, &#39;code&#39;]
    &#125;
  &#125;);
script(async, type=&quot;text/javascript&quot;, src=theme.cdn.mathjax + &#39;/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#39;)
</code></pre><p>在<code>_partial/after_footer.ejs</code>中添加:</p>
<pre><code>&lt;% if (page.mathjax)&#123; %&gt;
&lt;%- partial(&#39;mathjax&#39;) %&gt;
&lt;% &#125; %&gt;
</code></pre><p>如果是jade模板，则在<code>_partial/after_footer.jade</code>中添加:</p>
<pre><code>if page.mathjax == true
  include mathjax
</code></pre><h4 id="3-配置"><a href="#3-配置" class="headerlink" title="3. 配置"></a>3. 配置</h4><p>在主题_config.yml中配置mathjax cdn:</p>
<pre><code>cdn:
    mathjax: https://cdn.mathjax.org
</code></pre><p>当需要用到mathjax渲染器时，在文章头部添加<code>mathjax:true</code>:</p>
<pre><code>layout: post
mathjax: true
...
</code></pre><p>只有添加该选项的文章才会加载mathjax渲染器。</p>
<h4 id="4-支持mathjax的Markdown编辑器"><a href="#4-支持mathjax的Markdown编辑器" class="headerlink" title="4. 支持mathjax的Markdown编辑器:"></a>4. 支持mathjax的Markdown编辑器:</h4><ul>
<li><a href="www.inkcode.net/qute">Qute</a> 原生支持mathjax，界面有点Geek。</li>
<li><p><a href="https://macdown.uranusjr.com/">Macdown</a>: Macdown原生不支持mathjax，在md文件中添加(注意https，Macdown为了安全，只会加载https的远程脚本):</p>
<pre><code>  &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;
  MathJax.Hub.Config(&#123;
      tex2jax: &#123;
          inlineMath: [ [&#39;$&#39;,&#39;$&#39;], [&quot;\\(&quot;,&quot;\\)&quot;] ],
          displayMath: [ [&#39;$$&#39;,&#39;$$&#39;], [&quot;\\[&quot;,&quot;\\]&quot;] ],&#125;,
      TeX: &#123;equationNumbers: &#123;
          autoNumber: &quot;AMS&quot;
        &#125;,Augment: &#123;  Definitions: &#123;
         macros: &#123;
           overbracket:  [&#39;UnderOver&#39;,&#39;23B4&#39;,1],
           underbracket: [&#39;UnderOver&#39;,&#39;23B5&#39;,1],
         &#125;
       &#125;&#125;&#125;,
  &#125;);
  &lt;/script&gt;
</code></pre></li>
</ul>
<h4 id="5-示例"><a href="#5-示例" class="headerlink" title="5. 示例:"></a>5. 示例:</h4><pre><code>行内公式: $$ a+b=c $$

行间公式:

$$
\left( \begin&#123;array&#125;&#123;ccc&#125;
a &amp; b &amp; c \\
d &amp; e &amp; f \\
g &amp; h &amp; i
\end&#123;array&#125; \right)
$$
</code></pre><p>得到:</p>
<p>行内公式: $ a+b=c $</p>
<p>行间公式:</p>
<script type="math/tex; mode=display">
\left( \begin{array}{ccc}
a & b & c \\
d & e & f \\
g & h & i
\end{array} \right)</script><p>具体mathjax语法，这里有一篇不错的<a href="http://jzqt.github.io/2015/06/30/Markdown%E4%B8%AD%E5%86%99%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/">博客</a>。</p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Swarm - 轻量级容器编排工具</title>
    <url>/2018/03/docker-swarm/</url>
    <content><![CDATA[<h3 id="一-Docker-Machine"><a href="#一-Docker-Machine" class="headerlink" title="一. Docker Machine"></a>一. Docker Machine</h3><p>通常我们使用的Docker都是直接在物理机上安装Docker Engine，docker-machine是一个在虚拟机上安装Docker Engine的工具，使用起来很方便:</p>
<pre><code># 创建一个docker machine，命名为abc
&gt; docker-machine create abc
# 列出当前主机上所有的docker machine
&gt; docker-machine ls
# 通过ssh连接到abc
&gt; docker-machine ssh abc
# 现在就已经在abc machine上，可以像使用Docker Engine一样正常使用
docker@abc:~$ docker ps
# 退出machine
docker@abc:~$ exit
</code></pre><p>docker-machine可以用来在本机部署Docker集群，或者在云上部署Docker。docker-machine支持多种虚拟方案，virtualbox，xhyve，hyperv等等。具体使用比较简单，命令参考附录文档。</p>
<span id="more"></span>
<h3 id="二-Docker-Swarm"><a href="#二-Docker-Swarm" class="headerlink" title="二. Docker Swarm"></a>二. Docker Swarm</h3><p>Docker Swarm是docker原生的集群管理工具，之前是个独立的项目，于 Docker 1.12 被整合到 Docker Engine 中,作为swarm model存在，因此Docker Swarm实际上有两种：独立的swarm和整合后swarm model。官方显然推荐后者，本文也使用swarm model。相较于kubernetes，Mesos等工具，swarm最大的优势是轻量，原生和易于配置。它使得原本单主机的应用可以方便地部署到集群中。</p>
<h4 id="相关术语"><a href="#相关术语" class="headerlink" title="相关术语"></a>相关术语</h4><ul>
<li>task: 任务，集群的最小单位，对应单容器实例</li>
<li>service: 服务，由一个或多个task构成，可以统一配置，部署，收缩</li>
<li>node: 机器节点，代表一台物理机    </li>
</ul>
<h4 id="相关命令"><a href="#相关命令" class="headerlink" title="相关命令"></a>相关命令</h4><ul>
<li>docker service: 提供了service创建，更新，回滚，task扩展收缩等功能</li>
<li>docker node: 提供对机器节点的管理</li>
<li>docker swarm: 用于配置机器集群，包括管理manager和worker两类机器节点的增删</li>
</ul>
<h4 id="1-初始化-swarm"><a href="#1-初始化-swarm" class="headerlink" title="1. 初始化 swarm"></a>1. 初始化 swarm</h4><pre><code>[n1-common]&gt; docker swarm init
Swarm initialized: current node (b3a3avned864im04d7veyw06t) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-4mptgs751hcyh3ddlqwvv2aumo5j5mu1qllva52ciim6bun51d-eausald3qqtae604doj639mck 192.168.65.2:2377

To add a manager to this swarm, run &#39;docker swarm join-token manager&#39; and follow the instructions.
</code></pre><p>执行该条命令的node将会成为manager node，该命令会生成两个token: manager token和worker token，通过<code>docker swarm join --token TOKEN MANAGER_NODE_IP</code>提供不同的token来将当前node以不同身份加入到集群。</p>
<p>现在我们尝试加入一个worker node，在另一台机器上执行:</p>
<pre><code>[moby]&gt; docker swarm join --token SWMTKN-1-2w53lkm9h1l5u6yb4hh0k2t8yayub2zx0sidpvcr9nicqwafzx-9jm5zix2041rhfrf7e07oh4l2 172.20.140.39:2377
This node joined a swarm as a worker.
</code></pre><h4 id="2-配置节点"><a href="#2-配置节点" class="headerlink" title="2. 配置节点"></a>2. 配置节点</h4><p>通过 <code>docker node ls</code> 可以查看当前swarm集群中的所有节点(只能在manager节点上运行):</p>
<pre><code>[n1-common]&gt; sudo docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS
yozazaogirhpj8skccfwqtl8f     moby                Ready               Active
rx03hnmwx6z9jc9x9velz46if *   n1-common           Ready               Active              Leader
</code></pre><p>PS: swarm的service和node管理命令的规范和container管理类似:</p>
<pre><code>docker node|service ls: 查看集群中所有的节点(服务)
docker node|service ps: 查看指定节点(服务)的容器信息
docker node|service inspect: 查看指定节点(服务)的内部配置和状态信息
docker node|service update: 更新节点(服务)配置信息
docker node|service rm: 从集群中移除节点(服务)
</code></pre><p>以上命令都只能在manager节点上运行。</p>
<p>在这里，我们通过docker node update为节点设置标签:</p>
<pre><code>n1-common:~$ docker node update --label-add type=db moby
moby
</code></pre><h4 id="3-创建服务"><a href="#3-创建服务" class="headerlink" title="3. 创建服务"></a>3. 创建服务</h4><p>服务有两种模式(mode): </p>
<ul>
<li>复制集模式(—mode replicas): 默认模式，该方式会将指定的(通过—replicas) M个task按照指定方式部署在N个机器节点上(N &lt;= 集群机器节点数)。</li>
<li>全局模式(—mode global): 将服务在每个机器节点上部署一份，因此无需指定任务数量，也不能进行任务扩展和收缩。</li>
</ul>
<p>我们尝试创建一个名为redis的服务，该服务包含5个任务的复制集:</p>
<pre><code>[n1-common]&gt; docker service create \
--replicas 5 \
--name redis \
--constraint &#39;node.labels.type=db&#39; \
--update-delay 10s \
--update-parallelism 2 \
--env MYVAR=foo \
-p 6379:6379 \
redis
</code></pre><p><code>--update-xxx</code>指定了服务更新策略，这里为redis服务指定最多同时更新2个task，并且每批次更新之间间隔10s，在更新失败时，执行回滚操作，回滚到更新前的配置。更新操作通过<code>docker service update</code>命令完成，可以更新<code>docker service create</code>中指定的几乎所有配置，如task数量。<code>docker service create</code>除了更新策略外，还可以为service指定回滚策略(<code>--rollback-xxx</code>)，重启策略(<code>--restart-xxx</code>)等。</p>
<p><code>--constraint</code>指定服务约束，限制服务的任务能够部署的节点，在这里，redis服务的5个任务只能部署在集群中labels.type==db的节点上。除了constraint参数外，还可以通过<code>--placement-pref</code>更进一步地配置部署优先级，如<code>--placement-pref &#39;spread=node.labels.type&#39;</code>将task平均分配到不同的type上，哪怕各个type的node数量不一致。</p>
<p><code>--env MYVAR=foo</code>指定服务环境变量，当然，这里并没有实际意义。</p>
<p>关于服务创建的更多选项参考官方文档。运行以上命令后，服务默认将在后台创建(—detach=false)，通过<code>docker service ps redis</code>可查看服务状态，确保服务的任务都以正常启动:</p>
<pre><code>[n1-common]&gt; docker service ps redis
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS
fegu7p341u58        redis.1             redis:latest        moby                Running             Running 9 seconds ago
hoghsnnamv56        redis.2             redis:latest        moby                Running             Running 9 seconds ago
0klozd8zkz0d        redis.3             redis:latest        moby                Running             Running 10 seconds ago
jpcik7w3hpjx        redis.4             redis:latest        moby                Running             Running 10 seconds ago
29jrofbwfi13        redis.5             redis:latest        moby                Running             Running 8 seconds ago
</code></pre><p>可以看到，由于只有moby节点的labels.type==db，因此所有的task都被部署在moby节点上。现在整个服务已经部署完成，那么如何访问这个服务呢？事实上，我们通过moby或者n1-common两台主机IP:6379均可访问Redis服务，<strong>Swarm向用户屏蔽了服务的具体部署位置，让用户使用集群就像使用单主机一样</strong>，这也为部署策略，负载均衡以及故障转移提供基础。</p>
<h4 id="4-平滑更新"><a href="#4-平滑更新" class="headerlink" title="4. 平滑更新"></a>4. 平滑更新</h4><p>通过<code>docker service update</code>可以完成对服务的更新，可更新的配置很多，包括<code>docker service create</code>中指定的参数，自定义标签等，服务的更新策略由<code>--update-xxx</code>选项配置，只有部分更新需要重启任务，可通过<code>--force</code>参数强制更新。</p>
<p>现在我们尝试限制redis服务能够使用的cpu个数:</p>
<pre><code>[n1-common]&gt; docker service update --limit-cpu 2 redis
redis
Since --detach=false was not specified, tasks will be updated in the background.
In a future release, --detach=false will become the default.
[n1-common]&gt; docker service ps redis
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE             ERROR               PORTS
fegu7p341u58        redis.1             redis:latest        moby                Running             Running 13 minutes ago
hoghsnnamv56        redis.2             redis:latest        moby                Running             Running 13 minutes ago
mgblj8v97al1        redis.3             redis:latest        moby                Running             Running 9 seconds ago
0klozd8zkz0d         \_ redis.3         redis:latest        moby                Shutdown            Shutdown 11 seconds ago
jpcik7w3hpjx        redis.4             redis:latest        moby                Running             Running 13 minutes ago
49mvisd0zbtj        redis.5             redis:latest        moby                Running             Running 8 seconds ago
29jrofbwfi13         \_ redis.5         redis:latest        moby                Shutdown            Shutdown 11 seconds ago
[n1-common]&gt; docker service ps redis
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE             ERROR               PORTS
9396e3x8gp5m        redis.1             redis:latest        moby                Ready               Ready 2 seconds ago
fegu7p341u58         \_ redis.1         redis:latest        moby                Shutdown            Running 2 seconds ago
msugiubez60a        redis.2             redis:latest        moby                Ready               Ready 2 seconds ago
hoghsnnamv56         \_ redis.2         redis:latest        moby                Shutdown            Running 2 seconds ago
mgblj8v97al1        redis.3             redis:latest        moby                Running             Running 13 seconds ago
0klozd8zkz0d         \_ redis.3         redis:latest        moby                Shutdown            Shutdown 15 seconds ago
jpcik7w3hpjx        redis.4             redis:latest        moby                Running             Running 13 minutes ago
49mvisd0zbtj        redis.5             redis:latest        moby                Running             Running 12 seconds ago
29jrofbwfi13         \_ redis.5         redis:latest        moby                Shutdown            Shutdown 15 seconds ago
</code></pre><p>由于限制服务所使用的CPU数量需要重启任务，通过前后两次的<code>docker service ps</code>可以看到，docker service的更新策略与我们在<code>docker service create</code>中指定的一致: 每两个一组，每组间隔10s，直至更新完成，通过指定<code>--detach=false</code>能同步地看到这个平滑更新过程。这种平滑更新重启使得服务在升级过程中，仍然能够正常对外提供服务。docker swarm会保存每个任务的升级历史及对应的容器ID和容器状态，以便在更新失败时正确回滚(如果指定了更新失败的行为为回滚)，<code>docker service rollback</code>命令可强制将任务回滚到上一个版本。</p>
<p>现在我们通过<code>docker service scale</code>来伸缩服务任务数量，在这里我们使用<code>--detach=false</code>选项:</p>
<pre><code>[n1-common]&gt; docker service scale redis=3
redis scaled to 3
overall progress: 3 out of 3 tasks
1/3: running   [==================================================&gt;]
2/3: running   [==================================================&gt;]
3/3: running   [==================================================&gt;]
verify: Service converged
[n1-common]&gt; docker service ps redis
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE             ERROR               PORTS
9396e3x8gp5m         redis.1            redis:latest        moby                Running             Running 10 minutes ago
fegu7p341u58         \_ redis.1         redis:latest        moby                Shutdown            Shutdown 10 minutes ago
8urov9089x6c         redis.4            redis:latest        moby                Running             Running 9 minutes ago
jpcik7w3hpjx         \_ redis.4         redis:latest        moby                Shutdown            Shutdown 9 minutes ago
49mvisd0zbtj         redis.5            redis:latest        moby                Running             Running 10 minutes ago
29jrofbwfi13         \_ redis.5         redis:latest        moby                Shutdown            Shutdown 10 minutes ago
</code></pre><p>服务的任务规模被收缩，现在只剩下redis.1,redis.4,redis.5三个任务。</p>
<h4 id="5-故障转移"><a href="#5-故障转移" class="headerlink" title="5. 故障转移"></a>5. 故障转移</h4><p>现在我们将redis服务停掉，重新创建一个redis服务:</p>
<pre><code>[n1-common]&gt; docker service rm redis
redis
[n1-common]&gt; docker service create --replicas 5 --name redis  -p 6379:6379 redis
fvcwpsmbscxhsmg04vf5zhmbf
Since --detach=false was not specified, tasks will be created in the background.
In a future release, --detach=false will become the default.
[n1-common]&gt; docker service ps redis
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE           ERROR               PORTS
n1dd790efq36        redis.1             redis:latest        moby                Running             Running 2 minutes ago
5fvqbozb7bpr        redis.2             redis:latest        n1-common           Running             Running 2 minutes ago
ma533n5ce09c        redis.3             redis:latest        moby                Running             Running 2 minutes ago
j1f18j2yaqhc        redis.4             redis:latest        n1-common           Running             Running 2 minutes ago
p2kf7ftrexam        redis.5             redis:latest        moby                Running             Running 2 minutes ago
</code></pre><p>由于我们没有指定部署约束，因此redis服务的5个任务将被自动负载到集群节点中，在这里，redis.2,redis.4部署在n1-common上，其余三个部署在moby，现在我们将moby节点退出集群，观察服务任务状态变化:</p>
<pre><code>[moby]&gt;  docker swarm leave
Node left the swarm.
[n1-common]&gt; service ps redis
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE                     ERROR               PORTS
8c5py5p9pcgz        redis.1             redis:latest        n1-common           Ready               Accepted less than a second ago
n1dd790efq36         \_ redis.1         redis:latest        moby                Shutdown            Running 12 seconds ago
5fvqbozb7bpr        redis.2             redis:latest        n1-common           Running             Running 8 minutes ago
ml546ziyey4r        redis.3             redis:latest        n1-common           Ready               Accepted less than a second ago
ma533n5ce09c         \_ redis.3         redis:latest        moby                Shutdown            Running 8 minutes ago
j1f18j2yaqhc        redis.4             redis:latest        n1-common           Running             Running 8 minutes ago
kfu6jeddkvwu        redis.5             redis:latest        n1-common           Ready               Accepted less than a second ago
p2kf7ftrexam         \_ redis.5         redis:latest        moby                Shutdown            Running 12 seconds ago
[n1-common]&gt; docker service ps redis
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS
8c5py5p9pcgz        redis.1             redis:latest        n1-common           Running             Running 3 seconds ago
n1dd790efq36         \_ redis.1         redis:latest        moby                Shutdown            Running 23 seconds ago
5fvqbozb7bpr        redis.2             redis:latest        n1-common           Running             Running 8 minutes ago
ml546ziyey4r        redis.3             redis:latest        n1-common           Running             Running 3 seconds ago
ma533n5ce09c         \_ redis.3         redis:latest        moby                Shutdown            Running 8 minutes ago
j1f18j2yaqhc        redis.4             redis:latest        n1-common           Running             Running 8 minutes ago
kfu6jeddkvwu        redis.5             redis:latest        n1-common           Running             Running 3 seconds ago
p2kf7ftrexam         \_ redis.5         redis:latest        moby                Shutdown            Running 23 seconds ago
</code></pre><p>故障节点moby上面的1,3,5任务已经被自动重新部署在其它可用节点(当前只有n1-common)上，并记录了每个任务的版本和迁移历史。现在如果尝试再将moby节点加入集群，会发现5个task仍然都在n1-common上，没有立即进行任务转移，而是等下一步重启升级或者扩展服务任务时再进行动态负载均衡。</p>
<h4 id="6-再看Swarm集群"><a href="#6-再看Swarm集群" class="headerlink" title="6. 再看Swarm集群"></a>6. 再看Swarm集群</h4><p>再来回顾一下Docker Swarm，在我们初始化或加入Swarm集群时，通过<code>docker network ls</code>可以看到，Docker做了如下事情:</p>
<ol>
<li>创建了一个叫ingress的overlay网络，用于Swarm集群容器跨主机通信，在创建服务时，如果没有为其指定网络，将默认接入到ingress网络中</li>
<li>创建一个docker_gwbridge虚拟网桥，用于连接集群各节点(Docker Deamon)的物理网络到到ingress网络</li>
</ol>
<p>网络细节暂时不谈(也没怎么搞清楚)，总之，Swarm集群构建了一个跨主机的网络，可以允许集群中多个容器自由访问。Swarm集群有如下几个比较重要的特性:</p>
<ol>
<li>服务的多个任务可以监听同一端口(通过iptables透明转发)。</li>
<li>屏蔽掉服务的具体物理位置，通过任意集群节点IP:Port均能访问服务(无论这个服务是否跑在这个节点上)，Docker会将请求正确路由到运行服务的节点(称为routing mesh)。在routine mesh下，服务运行在虚拟IP环境(virtual IP mode, vip)，即使服务运行在global模式(每个节点都运行有任务)，用户仍然不能假设指定IP:Port节点上的服务会处理请求。</li>
<li>如果不想用Docker Swarm自带的routing mesh负载均衡器，可以在服务创建或更新时使用<code>--endpoint-mode = dnsrr</code>，dnsrr为dns round robin简写，另一种模式即为vip，dnsrr允许应用向Docker通过服务名得到服务IP:Port列表，然后应用负责从其中选择一个地址进行服务访问。</li>
</ol>
<p>综上，Swarm通过虚拟网桥和NATP等技术，搭建了一个跨主机的虚拟网络，通过Swarm Manager让这个跨主机网络用起来像单主机一样方便，并且集成了服务发现(服务名-&gt;服务地址)，负载均衡(routing mesh)，这些都是Swarm能够透明协调转移任务的根本保障，应用不再关心服务有几个任务，部署在何处，只需要知道服务在这个集群中，端口是多少，然后这个服务就可以动态的扩展，收缩和容灾。当然，Swarm中的服务是理想状态的微服务，亦即是无状态的。</p>
<h3 id="三-Docker-Compose-amp-Stack"><a href="#三-Docker-Compose-amp-Stack" class="headerlink" title="三. Docker Compose &amp; Stack"></a>三. Docker Compose &amp; Stack</h3><p>docker-compose 是一个用于定义和运行多容器应用的工具。使用compose，你可以通过一份docker-compose.yml配置文件，然后运行<code>docker-compose up</code>即可启动整个应用所配置的服务。一个docker-compose.yml文件定义如下:</p>
<pre><code>version: &#39;3&#39;  # docker-compose.yml格式版本号，版本3为官方推荐版本，支持swarm model和deploy选项
services:     # 定义引用所需服务
  web:        # 服务名字
    build: .  # 服务基于当前目录的Dockerfile构建
    ports:    # 服务导出端口配置
    - &quot;5000:5000&quot;
    volumes:  # 服务目录挂载配置
    - .:/code
    - logvolume01:/var/log
    links:    # 网络链接
    - redis
    deploy:   # 部署配置 和 docker service create中的参数对应 只有版本&gt;3支持
      replicas: 5
      resources:
        limits:
          cpus: &quot;0.1&quot;
          memory: 50M
      restart_policy:
        condition: on-failure
  redis:      # redis 服务
    image: redis # 服务基于镜像构建
</code></pre><p>docker-compose设计之初是单机的，docker-compose中也有服务的概念，但只是相当于一个或多个容器(version&gt;2.2 scale参数)，并且只能部署在单台主机上。版本3的docker-compose.yml开始支持swarm model，可以进行集群部署配置，这里的服务才是swarm model中的服务。但version 3的docker-compose.yml本身已经不能算是docker-compose的配置文件了，因为docker-compose不支持swarm model，用以上配置文件执行<code>docker-compose up</code>将得到警告:</p>
<pre><code>WARNING: Some services (web) use the &#39;deploy&#39; key, which will be ignored. Compose does not support &#39;deploy&#39; configuration - use `docker stack deploy` to deploy to a swarm.
WARNING: The Docker Engine you&#39;re using is running in swarm mode.

Compose does not use swarm mode to deploy services to multiple nodes in a swarm. All containers will be scheduled on the current node.
</code></pre><p>那么<code>docker stack</code>又是什么？<code>docker stack</code>是基于<code>docker swarm</code>之上的应用构建工具，前面介绍的<code>docker swarm</code>只能以服务为方式构建，而docker-compose虽然能以应用为单位构建，但本身是单机版的，Docker本身并没有基于docker-compose进行改造，而是另起炉灶，创建了<code>docker stack</code>命令，同时又复用了docker-compose.yml配置方案(同时也支持另一种bundle file配置方案)，因此就造成了docker-compose能使用compose配置的version 1, version 2,和部分version 3(不支持swarm model和deploy选项)，而<code>docker stack</code>仅支持version 3的compose配置。</p>
<p>总的来说，如果应用是单机版的，或者说不打算使用docker swarm集群功能，那么就通过docker-compose管理应用构建，否则使用docker stack，毕竟后者才是亲生的。</p>
<p>参考:</p>
<ol>
<li><a href="https://docs.docker.com/machine/reference/">Docker Machine</a></li>
<li><a href="https://docs.docker.com/get-started/part4/">Docker Swarm</a></li>
<li><a href="https://docs.docker.com/compose/gettingstarted/">Docker Compose</a></li>
<li><a href="https://docs.docker.com/get-started/part3/">Docker Services</a></li>
<li><a href="https://docs.docker.com/network/overlay/">Docker overlay网络</a></li>
</ol>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 容器管理</title>
    <url>/2018/03/docker-container-ops/</url>
    <content><![CDATA[<h3 id="一-容器资源限制"><a href="#一-容器资源限制" class="headerlink" title="一. 容器资源限制"></a>一. 容器资源限制</h3><p>Docker资源限制主要靠Linux cgroups技术实现，简单说，cgroups是一个个的进程组(实际上是进程树)，这些进程树通过挂接 subsystem(事实上是挂接到 cgroup 上层的hierarchy)来实现对各种资源的限制和追踪，subsystem是内核附加在程序上的一系列钩子（hooks），通过程序运行时对资源的调度触发相应的钩子以达到资源追踪和限制的目的。cgroups 技术的具体介绍和实现参考文末链接。</p>
<span id="more"></span>
<h4 id="1-CPU"><a href="#1-CPU" class="headerlink" title="1. CPU"></a>1. CPU</h4><p>默认情况下，Docker容器对 CPU 资源的访问是无限制的，可使用如下参数控制容器的 CPU 访问:</p>
<p><code>--cpus</code>: 控制容器能够使用的最大 CPU 核数，参数为一个精度为两位小数的浮点数(默认值为0，即不限制 CPU)，不能超出物理机的 CPU 核数。</p>
<pre><code># 通过 stress 开启三个 worker 跑满 CPU 的 worker，并设置容器能访问的 cpus 为1.5
&gt; docker run --rm -it --cpus 1.5 progrium/stress --cpu 3
stress: info: [1] dispatching hogs: 3 cpu, 0 io, 0 vm, 0 hdd
stress: dbug: [1] using backoff sleep of 9000us
stress: dbug: [1] --&gt; hogcpu worker 3 [7] forked
stress: dbug: [1] using backoff sleep of 6000us
stress: dbug: [1] --&gt; hogcpu worker 2 [8] forked
stress: dbug: [1] using backoff sleep of 3000us
stress: dbug: [1] --&gt; hogcpu worker 1 [9] forked

# 开启另一个窗口查看 CPU 占用情况
top
# ...
  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 4296 root      20   0    7316    100      0 R  51.8  0.0   0:07.04 stress
 4294 root      20   0    7316    100      0 R  51.5  0.0   0:07.02 stress
 4295 root      20   0    7316    100      0 R  46.5  0.0   0:06.42 stress
</code></pre><p>三个 worker 进程各自占用了50%的 CPU，共计150%，符合<code>--cpus</code>指定的1.5核约束。</p>
<p><code>--cpu-shares</code>: 通过权重来控制同一物理机上的各容器的 CPU 占用，默认值为1024(该值应该是起源于 Linux2.6+中 CFS 调度算法的默认进程优先级)，它是一个软限制，仅在物理机 CPU 不够用时生效，当 CPU 够用时，容器总是尽可能多地占用 CPU。</p>
<pre><code># 开启8个 cpu worker 跑满所有核 默认 cpu-shares 为1024
&gt; docker run --rm -it  progrium/stress --cpu 8
# 开新窗口查看 CPU 状态
&gt; top
# ...
  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 4477 root      20   0    7316     96      0 R 100.0  0.0   0:08.51 stress
 4481 root      20   0    7316     96      0 R 100.0  0.0   0:08.52 stress
 4474 root      20   0    7316     96      0 R  99.7  0.0   0:08.50 stress
 4476 root      20   0    7316     96      0 R  99.7  0.0   0:08.50 stress
 4478 root      20   0    7316     96      0 R  99.7  0.0   0:08.50 stress
 4479 root      20   0    7316     96      0 R  99.7  0.0   0:08.50 stress
 4480 root      20   0    7316     96      0 R  99.7  0.0   0:08.50 stress
 4475 root      20   0    7316     96      0 R  99.3  0.0   0:08.48 stress
# 再开8个 cpu worker，设置 cpu-shares 为 512
docker run --rm -it  --cpu-shares 512 progrium/stress --cpu 8
# 再次查看 CPU 占用
&gt; top
# ...
  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 4815 root      20   0    7316     96      0 R  67.0  0.0   0:28.56 stress
 4816 root      20   0    7316     96      0 R  67.0  0.0   0:28.30 stress
 4820 root      20   0    7316     96      0 R  67.0  0.0   0:28.13 stress
 4821 root      20   0    7316     96      0 R  67.0  0.0   0:28.31 stress
 4817 root      20   0    7316     96      0 R  66.7  0.0   0:28.04 stress
 4818 root      20   0    7316     96      0 R  66.7  0.0   0:28.42 stress
 4819 root      20   0    7316     96      0 R  66.7  0.0   0:28.24 stress
 4822 root      20   0    7316     96      0 R  66.7  0.0   0:28.38 stress
 4961 root      20   0    7316     96      0 R  33.3  0.0   0:03.93 stress
 4962 root      20   0    7316     96      0 R  33.3  0.0   0:03.96 stress
 4965 root      20   0    7316     96      0 R  33.3  0.0   0:03.95 stress
 4966 root      20   0    7316     96      0 R  33.3  0.0   0:04.02 stress
 4968 root      20   0    7316     96      0 R  33.3  0.0   0:03.90 stress
 4963 root      20   0    7316     96      0 R  33.0  0.0   0:04.01 stress
 4964 root      20   0    7316     96      0 R  33.0  0.0   0:03.97 stress
 4967 root      20   0    7316     96      0 R  33.0  0.0   0:03.94 stress
</code></pre><p>可以看到最开始的8个 worker CPU 占用由100%降到67%左右，而新启动的 worker CPU 占用为32%左右，大致满足2/3和1/3的权重占比。</p>
<p>除此之外，Docker还可以通过<code>--cpuset-cpus</code>参数限制容器运行在某些核上，但环境依赖太强(需要知道主机上有几个CPU核)，有违容器初衷，并且通常都不需要这样做。在 Docker1.13之后，还支持容器的实时调度配置(realtime scheduler)，就应用层而言，基本用不到这项配置，参考: <a href="https://docs.docker.com/config/containers/resource_constraints/#configure-the-realtime-scheduler。">https://docs.docker.com/config/containers/resource_constraints/#configure-the-realtime-scheduler。</a></p>
<h4 id="2-内存"><a href="#2-内存" class="headerlink" title="2. 内存"></a>2. 内存</h4><p>同 CPU 一样，默认情况下，Docker没有对容器内存进行限制。内存相关的几个概念:</p>
<p>memory: 即容器可用的物理内存(RES)，包含 kernel-memory 和 user-memory，即内核内存和用户内存。<br>kernel-memory: 内核内存，每个进程都会占用一部分内核内存，和user-memory 的最大区别是不能被换入换出，因此进程的内核内存占用过大可能导致阻塞系统服务。<br>swap: 容器可用的交换区大小，会swap+memory限制着进程最大能够分配的虚拟页，也是进程理论上能够使用的最大”内存”(虚拟内存)。</p>
<p>以下大部分配置的参数为正数，加上内存单位，如”4m”, “128k”。</p>
<ul>
<li><code>-m</code> or <code>--memory</code>: 容器可以使用的最大内存限制，最小为4m</li>
<li><code>--memory-swap</code>: 容器使用的内存和交换区的总大小</li>
<li><code>--memory-swappiness</code>: 默认情况下，主机可以把容器使用的匿名页(anonymous page) swap 出来，这个参数可以配置可被swap的比例(0-100)</li>
<li><code>--memory-reservation</code>: 内存软限制，每次系统内存回收时，都会尝试将进程的内存占用降到该限制以下(尽可能换出)。该参数的主要作用是避免容器长时间占用大量内存。</li>
<li><code>--kernel-memory</code>: 内核内存的大小</li>
<li><code>--memory-swappiness</code>: 设置容器可被置换的匿名页的百分比，值为[0,100]，为0则关闭匿名页交换，容器的工作集都在内存中活跃，默认值从父进程继承</li>
<li><code>--oom-kill-disable</code>: 当发生内存不够用(OOM) 时，内核默认会向容器中的进程发送 kill 信号，添加该参数将避免发送 kill 信号。该参数一般与<code>-m</code> 一起使用，因为如果没有限制内存，而又启用了 oom-kill-disable，OS 将尝试 kill 其它系统进程。(PS: 该参数我在 Ubuntu 16.04 LTS/Docker17.09.0-ce环境下，没有测试成功，仍然会直接 kill)</li>
<li><code>--oom-score-adj</code>: 当发生 OOM 时，进程被 kill 掉的优先级，取值[-1000,1000]，值越大，越可能被 kill 掉</li>
</ul>
<p><code>--memory</code>和<code>--memory-swap</code>:</p>
<pre><code>1. 当 memory-swap &gt; memory &gt; 0: 此时容器可使用的 swap 大小为: swap = memory-swap - memory
2. memory-swap == 0 或 &lt; memory: 相当于没有设置(如果&lt; memory, docker 会错误提示)，使用默认值，此时容器可使用的 swap 大小为: swap == memory，即 memory-swap = = 2*memory
3. memory-swap == memory &gt; 0: 容器不能使用交换空间: swap = memory-swap - memory = 0
4. memory-swap == -1: 容器可使用主机上所有可用的 swap 空间，即无限制
</code></pre><p>在配置<code>--memory-swap</code> 参数时，可能遇到如下提示:</p>
<pre><code>WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
</code></pre><p>解决方案为:</p>
<pre><code>To enable memory and swap on system using GNU GRUB (GNU GRand Unified Bootloader), do the following:
1. Log into Ubuntu as a user with sudo privileges.
2. Edit the /etc/default/grub file.
3. Set the GRUB_CMDLINE_LINUX value as follows:
    GRUB_CMDLINE_LINUX=&quot;cgroup_enable=memory swapaccount=1&quot;
4. Save and close the file.
5. Update GRUB.
    $ sudo update-grub
Reboot your system.
</code></pre><p>示例:</p>
<p>我们通过一个 带有 stress 命令的 ubuntu 镜像来进行测试:</p>
<pre><code>&gt; cat Dockerfile
FROM ubuntu:latest

RUN apt-get update &amp;&amp; \
apt-get install stress

&gt; docker build -t ubuntu-stress:latest .

# 示例一:
# memory 限制为100M，swap 空间无限制，分配1000M 内存
&gt; docker run -it --rm -m 100M --memory-swap -1 ubuntu-stress:latest /bin/bash
root@e618f1fc6ff9:/# stress --vm 1 --vm-bytes 1000M
# docker stats 查看容器内存占用，此时容器物理内存已经达到100M 限制
&gt; docker stats e618f1fc6ff9
CONTAINER           CPU %               MEM USAGE / LIMIT   MEM %               NET I/O             BLOCK I/O           PIDS
e618f1fc6ff9        15.62%              98.25MiB / 100MiB   98.25%              3.39kB / 0B         22GB / 22.4GB       3
&gt; pgrep stress
27158
27159 # stress worker 子进程 PID
# 通过 top 可以看到进程物理内存占用为100M，虚拟内存占用为1000M
&gt; top -p 27159
top - 19:30:08 up 31 days,  1:55,  3 users,  load average: 1.63, 1.43, 1.03
Tasks:   1 total,   0 running,   1 sleeping,   0 stopped,   0 zombie
%Cpu(s):  1.8 us,  4.3 sy,  2.1 ni, 81.2 id, 10.3 wa,  0.0 hi,  0.3 si,  0.0 st
KiB Mem : 16361616 total,   840852 free,  3206616 used, 12314148 buff/cache
KiB Swap: 16705532 total, 15459856 free,  1245676 used. 12681868 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
27159 root      20   0 1031484  98844    212 D  14.3  0.6   0:53.11 stress

# 示例二:
# memory 限制为100M，swap 比例为 50%
&gt; docker run -it --rm -m 100M --memory-swappiness 50 ubuntu-stress:latest /bin/bash
root@e3fdd8b75f1d:/# stress --vm 1 --vm-bytes 190M # 分配190M 内存
# 190M 内存正常分配，因为190M*50%的页面可以被 swap，剩下50%的页面放在内存中
&gt; top -p 29655
# ...
  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
29655 root      20   0  202044  98296    212 D   9.7  0.6   0:17.52 stress
# 停止 stress，重新尝试分配210M 内存，210M*50%&gt;100M，内存不够，进程被 kill 掉
&gt; root@e3fdd8b75f1d:/# stress --vm 1 --vm-bytes 210M
stress: info: [13] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd
stress: FAIL: [13] (415) &lt;-- worker 14 got signal 9
stress: WARN: [13] (417) now reaping child worker processes
stress: FAIL: [13] (451) failed run completed in 4s

# 示例三:
# memory 限制为100M, swap 比例为60%, memory-swap 为130M
# 可以得到，容器能使用的最大虚拟内存为 min(100/(1-60%), 130) = 130M，现在来简单验证
docker run -it --rm -m 100M --memory-swappiness 50 --memory-swap 30M ubuntu-stress:latest /bin/bash
# 分配120M 内存, OK
root@b54444b40706:/# stress --vm 1 --vm-bytes 120M
stress: info: [11] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd
^C
# 分配140M 内存，Error
root@b54444b40706:/# stress --vm 1 --vm-bytes 140M
stress: info: [13] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd
stress: FAIL: [13] (415) &lt;-- worker 14 got signal 9
stress: WARN: [13] (417) now reaping child worker processes
stress: FAIL: [13] (451) failed run completed in 1s
</code></pre><h3 id="二-容器监控"><a href="#二-容器监控" class="headerlink" title="二. 容器监控"></a>二. 容器监控</h3><h4 id="1-docker-inspect"><a href="#1-docker-inspect" class="headerlink" title="1. docker inspect"></a>1. docker inspect</h4><p><code>docker inspect</code>用于查看容器的静态配置，容器几乎所有的配置信息都在里面:</p>
<pre><code>&gt; docker inspect 5c004516ee59 0e9300806926
[
    &#123;
        &quot;Id&quot;: &quot;5c004516ee592b53e3e83cdee69fc93713471d4ce06778e1c6a9f783a576531b&quot;,
        &quot;Created&quot;: &quot;2018-03-27T16:44:27.521434182Z&quot;,
        &quot;Path&quot;: &quot;game&quot;,
        &quot;Args&quot;: [],
        &quot;State&quot;: &#123;
            &quot;Status&quot;: &quot;running&quot;,
            &quot;Running&quot;: true,
        ...
</code></pre><p><code>docker inspect</code>接收一个容器 ID 列表，返回一个 json 数组，包含容器的各项参数，可以通过 docker format 过滤输出:</p>
<pre><code># 显示容器 IP
&gt; docker inspect --format &#39;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&#39; 5c004516ee59
172.17.0.2
</code></pre><h4 id="2-docker-stats"><a href="#2-docker-stats" class="headerlink" title="2. docker stats"></a>2. docker stats</h4><p><code>docker stats</code>可实时地显示容器的资源使用(内存, CPU, 网络等):</p>
<pre><code># 查看指定容器
&gt; docker stats ngs-game-1
CONTAINER           CPU %               MEM USAGE / LIMIT    MEM %               NET I/O             BLOCK I/O           PIDS
ngs-game-1          0.55%               127.4MiB / 15.6GiB   0.80%               0B / 0B             0B / 0B             18

# 以容器名代替容器ID查看所有运行中的容器状态
&gt; docker stats $(docker ps --format=&#123;&#123;.Names&#125;&#125;)
CONTAINER           CPU %               MEM USAGE / LIMIT    MEM %               NET I/O             BLOCK I/O           PIDS
ngs-game-1          0.74%               127.4MiB / 15.6GiB   0.80%               0B / 0B             0B / 0B             18
ngs-game-4          0.54%               21.99MiB / 15.6GiB   0.14%               0B / 0B             0B / 0B             20
ngs-auth-1          0.01%               11.11MiB / 15.6GiB   0.07%               0B / 0B             0B / 0B             20
</code></pre><h4 id="3-docker-attach"><a href="#3-docker-attach" class="headerlink" title="3. docker attach"></a>3. docker attach</h4><p>将本地的标准输入/输出以及错误输出 attach 到运行中的container 上。</p>
<pre><code>&gt; docker run -d -it --name ubuntu1 ubuntu-stress /bin/bash
da01f119000f7370780eea0220a0fbf6e7b6d8d0dac1d635fc5dd480a64e4f68
&gt; docker attach ubuntu1
root@da01f119000f:/#
# 开启另一个 terminal，再次 attach，此时两个 terminal 的输入输出会自动同步
&gt; docker attach ubuntu1
</code></pre><p>由于本地输入完全重定向到容器，因此输入 exit 或<code>CTRL-d</code>会退出容器，要 dettach 会话，输入<code>CTRL-p</code> <code>CTRL-q</code>。</p>
<h3 id="三-容器停止"><a href="#三-容器停止" class="headerlink" title="三. 容器停止"></a>三. 容器停止</h3><ul>
<li>docker stop: 分为两个阶段，第一个阶段向容器主进程(Pid==1)发送SIGTERM信号，容器主进程可以捕获这个信号并进入退出处理流程，以便优雅地停止容器。第一阶段是有时间限制的(通过<code>-t</code>参数指明，默认为10s)，如果超过这个时间容器仍然没有停止，则进入第二阶段: 向容器主进程发送SIGKILL信号强行终止容器(SIGKILL无法被忽略或捕获)。</li>
<li>docker kill: 不带参数则相当于直接进入docker stop的第二阶段，可通过<code>-s</code>参数指定要发送的信号(默认是SIGKILL)。</li>
</ul>
<p>docker stop/kill仅向容器主进程(Pid==1)发送信号，因此对于ENTRYPOINT/CMD的Shell格式来说，可能导致应用无法接收的信号，Docker命令文档也提到了这一点:</p>
<blockquote>
<blockquote>
<p>Note: ENTRYPOINT and CMD in the shell form run as a subcommand of /bin/sh -c, which does not pass signals. This means that the executable is not the container’s PID 1 and does not receive Unix signals.</p>
</blockquote>
</blockquote>
<p>参考:</p>
<ol>
<li><a href="https://docs.docker.com/config/containers/resource_constraints/">https://docs.docker.com/config/containers/resource_constraints/</a></li>
<li><a href="https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources">https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources</a></li>
<li><a href="https://coolshell.cn/articles/17049.html">DOCKER基础技术：LINUX CGROUP</a></li>
<li><a href="http://www.infoq.com/cn/articles/docker-kernel-knowledge-cgroups-resource-isolation">Docker背后的内核知识——cgroups资源限制</a></li>
</ol>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>go pprof 性能分析</title>
    <url>/2018/04/go-pprof/</url>
    <content><![CDATA[<h3 id="一-pprof-数据采样"><a href="#一-pprof-数据采样" class="headerlink" title="一. pprof 数据采样"></a>一. pprof 数据采样</h3><p>pprof 采样数据主要有三种获取方式:</p>
<ul>
<li><strong>runtime/pprof</strong>: 手动调用<code>runtime.StartCPUProfile</code>或者<code>runtime.StopCPUProfile</code>等 API来生成和写入采样文件，灵活性高</li>
<li><strong>net/http/pprof</strong>: 通过 http 服务获取Profile采样文件，简单易用，适用于对应用程序的整体监控。通过 runtime/pprof 实现</li>
<li><strong>go test</strong>: 通过 <code>go test -bench . -cpuprofile prof.cpu</code>生成采样文件 适用对函数进行针对性测试</li>
</ul>
<span id="more"></span>
<h4 id="1-1-net-http-pprof"><a href="#1-1-net-http-pprof" class="headerlink" title="1.1 net/http/pprof"></a>1.1 net/http/pprof</h4><p>在应用程序中导入<code>import _ &quot;net/http/pprof&quot;</code>，并启动 http server即可:</p>
<pre><code>// net/http/pprof 已经在 init()函数中通过 import 副作用完成默认 Handler 的注册
go func() &#123;
    log.Println(http.ListenAndServe(&quot;localhost:6060&quot;, nil))
&#125;()
</code></pre><p>之后可通过 <a href="http://localhost:6060/debug/pprof/CMD">http://localhost:6060/debug/pprof/CMD</a> 获取对应的采样数据。支持的 CMD 有:</p>
<ul>
<li>goroutine: 获取程序当前所有 goroutine 的堆栈信息。</li>
<li>heap: 包含每个 goroutine 分配大小，分配堆栈等。每分配 runtime.MemProfileRate(默认为512K) 个字节进行一次数据采样。</li>
<li>threadcreate: 获取导致创建 OS 线程的 goroutine 堆栈</li>
<li>block: 获取导致阻塞的 goroutine 堆栈(如 channel, mutex 等)，使用前需要先调用 <code>runtime.SetBlockProfileRate</code></li>
<li>mutex: 获取导致 mutex 争用的 goroutine 堆栈，使用前需要先调用 <code>runtime.SetMutexProfileFraction</code></li>
</ul>
<p>以上五个 CMD 都通过<a href="https://github.com/golang/go/blob/release-branch.go1.9/src/runtime/pprof/pprof.go#L135">runtime/pprof Profile</a> 结构体统一管理，以 Lookup 提供统一查询接口，有相似的返回值(goroutine 堆栈)，它们都支持一个 debug  URL参数，默认为0，此时返回的采样数据是不可人为解读的函数地址列表，需要结合 pprof 工具才能还原函数名字。 debug=1时，会将函数地址转换为函数名，即脱离 pprof 在浏览器中直接查看。对 goroutine CMD来说，还支持 debug=2，此时将以 unrecovered panic 的格式打印堆栈，可读性更高。如启用<code>net/http/pprof</code>后，<a href="http://localhost:6060/debug/pprof/goroutine?debug=2">http://localhost:6060/debug/pprof/goroutine?debug=2</a> 的响应格式为:</p>
<pre><code>goroutine 18 [chan receive, 8 minutes]:
ngs/core/glog.logWorker(0x18b548a, 0x4, 0x7fff5fbffb0e, 0x0, 0x3, 0xc4200e31a0, 0xc4203627c4)
    /Users/wudaijun/go/src/ngs/core/glog/worker.go:43 +0x19c
created by ngs/core/glog.newLogger
    /Users/wudaijun/go/src/ngs/core/glog/glog.go:51 +0xe4

goroutine 6 [syscall, 8 minutes]:
os/signal.signal_recv(0x0)
    /usr/local/Cellar/go/1.9.1/libexec/src/runtime/sigqueue.go:131 +0xa7
os/signal.loop()
    /usr/local/Cellar/go/1.9.1/libexec/src/os/signal/signal_unix.go:22 +0x22
created by os/signal.init.0
    /usr/local/Cellar/go/1.9.1/libexec/src/os/signal/signal_unix.go:28 +0x41

goroutine 50 [select, 8 minutes]:
context.propagateCancel.func1(0x1cfcee0, 0xc42017a1e0, 0x1cf3820, 0xc42005b480)
    /usr/local/Cellar/go/1.9.1/libexec/src/context/context.go:260 +0x113
created by context.propagateCancel
    /usr/local/Cellar/go/1.9.1/libexec/src/context/context.go:259 +0x1da

...
</code></pre><p>以上几种 Profile 可在 <a href="http://localhost:6060/debug/pprof/">http://localhost:6060/debug/pprof/</a> 中看到，除此之外，go pprof 的 CMD 还包括:</p>
<ul>
<li>cmdline: 获取程序的命令行启动参数</li>
<li>profile: 获取指定时间内(从请求时开始)的cpuprof，倒计时结束后自动返回。参数: seconds, 默认值为30。cpuprofile 每秒钟采样100次，收集当前运行的 goroutine 堆栈信息。  </li>
<li>symbol: 用于将地址列表转换为函数名列表，地址通过’+’分隔，如 URL/debug/pprof?0x18d067f+0x17933e7</li>
<li>trace: 对应用程序进行执行追踪，参数: seconds, 默认值1s</li>
</ul>
<p>这几个 CMD 因为各种原因没有整合到 Profile 结构中去，但就使用上而言，是没有区别的，URL格式是一致的，因此可以看做一个整体，从各个角度对系统进行数据采样和分析。</p>
<h4 id="1-2-runtime-pprof"><a href="#1-2-runtime-pprof" class="headerlink" title="1.2 runtime/pprof"></a>1.2 runtime/pprof</h4><p><code>runtime/pprof</code>提供各种相对底层的 API 用于生成采样数据，一般应用程序更推荐使用<code>net/http/pprof</code>，<code>runtime/pprof</code> 的 API 参考<a href="https://golang.org/pkg/runtime/pprof/">runtime/pprof</a>或 <a href="https://github.com/golang/go/blob/release-branch.go1.9/src/net/http/pprof/pprof.go">http pprof 实现</a>。</p>
<h4 id="1-3-go-test"><a href="#1-3-go-test" class="headerlink" title="1.3 go test"></a>1.3 go test</h4><p>通常用<code>net/http/pprof</code>或<code>runtime/pprof</code>对应用进行整体分析，找出热点后，再用<code>go test</code>进行基准测试，进一步确定热点加以优化并对比测试。</p>
<pre><code># 生成 test 二进制文件， pprof 工具需要用到
▶ go test -c -o tmp.test 
# 执行基准测试 BenchAbc，并忽略任何单元测试，test flag前面需要加上&#39;test.&#39;前缀
▶ tmp.test -test.bench BenchAbc -test.run XXX test.cpuprofile cpu.prof     
# 与上面两条命令等价，只不过没有保留 test 二进制文件
▶ go test -bench BenchAbc -run XXX -cpuprofile=cpu.prof .
</code></pre><p><code>go test</code>可以直接加<code>-cpuprofile</code> <code>-mutexprofilefraction</code>等参数实现prof数据的采样和生成，更多相关参数参考 <code>go test -h</code>。</p>
<h3 id="二-pprof-数据分析"><a href="#二-pprof-数据分析" class="headerlink" title="二. pprof 数据分析"></a>二. pprof 数据分析</h3><p>虽然 <code>net/http/pprof</code>提供的数据分析可以通过设置参数后直接在浏览器查看，但 pprof 采样数据主要是用于 pprof 工具的，特别针对 cpuprof, memprof, blockprof等来说，我们需要直观地得到整个调用关系链以及每次调用的详细信息，这是需要通过<code>go tool pprof</code>命令来分析:</p>
<pre><code>go tool pprof [binary] [binary.prof]
# 如果使用的 net/http/pprof 可以直接接 URL
go tool pprof http://localhost:6060/debug/pprof/profile
</code></pre><p>go pprof 采样数据是非常丰富的，大部分情况下我们只会用到 CPU 和 内存分析，因此这里介绍下 cpu, heap, block 和 mutex 四种 pprof 数据分析。</p>
<h4 id="2-1-cpuprofile"><a href="#2-1-cpuprofile" class="headerlink" title="2.1 cpuprofile"></a>2.1 cpuprofile</h4><p>以<a href="https://blog.golang.org/profiling-go-programs">Profiling Go Programs</a>中的<a href="https://github.com/rsc/benchgraffiti">示例代码</a>为例:</p>
<pre><code>▶ go build -o havlak1 havlak1.go 
▶ ./havlak1 --cpuprofile=havlak1.prof
# of loops: 76000 (including 1 artificial root node)
▶ go tool pprof havlak1 havlak1.prof
File: havlak1
Type: cpu
Time: Apr 3, 2018 at 3:50pm (CST)
Duration: 20.40s, Total samples = 23.30s (114.24%)
Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)
(pprof) top5
Showing nodes accounting for 9.60s, 41.20% of 23.30s total
Dropped 112 nodes (cum &lt;= 0.12s)
Showing top 5 nodes out of 90
      flat  flat%   sum%        cum   cum%
     2.59s 11.12% 11.12%      2.78s 11.93%  runtime.mapaccess1_fast64 /usr/local/Cellar/go/1.9.1/libexec/src/runtime/hashmap_fast.go
     2.26s  9.70% 20.82%      4.97s 21.33%  runtime.scanobject /usr/local/Cellar/go/1.9.1/libexec/src/runtime/mgcmark.go
     2.06s  8.84% 29.66%     13.79s 59.18%  main.FindLoops /Users/wudaijun/Code/goprof/havlak/havlak1.go
     1.39s  5.97% 35.62%      1.39s  5.97%  runtime.heapBitsForObject /usr/local/Cellar/go/1.9.1/libexec/src/runtime/mbitmap.go
     1.30s  5.58% 41.20%      4.14s 17.77%  runtime.mapassign_fast64 /usr/local/Cellar/go/1.9.1/libexec/src/runtime/hashmap_fast.go
</code></pre><p>top5用于显示消耗 CPU 前五的函数，每一行代表一个函数，每一列为一项指标:</p>
<ul>
<li>flat: 采样时，该函数正在运行的次数*采样频率(10ms)，即得到估算的函数运行”采样时间”。这里不包括函数等待子函数返回。</li>
<li>flat%: flat / 总采样时间值</li>
<li>sum%: 前面所有行的 flat% 的累加值，如第二行 sum% = 20.82% = 11.12% + 9.70%</li>
<li>cum: 采样时，该函数出现在调用堆栈的采样时间，包括函数等待子函数返回。因此 flat &lt;= cum</li>
<li>cum%: cum / 总采样时间值</li>
</ul>
<p>PS: 老的pprof版本貌似显示的是采样次数，比如 flat 为采样时该函数正在运行的次数，这个次数*采样频率即得到采样时间。</p>
<p><code>go tool pprof</code> 常用命令:</p>
<ul>
<li>topN: 输入 top 命令，默认显示 flat 前10的函数调用，可使用 -cum 以 cum 排序</li>
<li>list Func: 显示函数名以及每行代码的采样分析</li>
<li>web: 生成 svg 热点图片，可在浏览器中打开，可使用 web Func 来过滤指定函数相关调用树</li>
</ul>
<p>通过<code>top5</code>命令可以看到，<code>mapaccess1_fast64</code>函数占用的CPU 采样时间最多，通过 <code>web mapaccess1_fast64</code> 命令打开调用图谱，查看该函数调用关系，可以看到主要在DFS 和 FindLoops 中调用的，然后再通过 <code>list DFS</code>查看函数代码和关键调用，得到 map 结构是瓶颈点，尝试转换为 slice 优化，整个过程参考<a href="https://blog.golang.org/profiling-go-programs">Profiling Go Programs</a>。总的思路就是通过<code>top</code> 和<code>web</code> 找出关键函数，再通过<code>list Func</code> 查看函数代码，找到关键代码行并确认优化方案(辅以 go test Benchmark)。</p>
<h4 id="2-2-memprofile"><a href="#2-2-memprofile" class="headerlink" title="2.2 memprofile"></a>2.2 memprofile</h4><pre><code>▶ go build -o havlak3 havlak3.go 
▶ ./havlak3 --memprofile=havlak3.mprof
▶ go tool pprof havlak3 havlak3.mprof
File: havlak3
Type: inuse_space
Time: Apr 3, 2018 at 3:44pm (CST)
Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)
(pprof) top
Showing nodes accounting for 57.39MB, 100% of 57.39MB total
      flat  flat%   sum%        cum   cum%
   39.60MB 69.00% 69.00%    39.60MB 69.00%  main.FindLoops /Users/wudaijun/Code/goprof/havlak/havlak3.go
   11.29MB 19.67% 88.67%    11.29MB 19.67%  main.(*CFG).CreateNode /Users/wudaijun/Code/goprof/havlak/havlak3.go
    6.50MB 11.33%   100%    17.79MB 31.00%  main.NewBasicBlockEdge /Users/wudaijun/Code/goprof/havlak/havlak3.go
         0     0%   100%    39.60MB 69.00%  main.FindHavlakLoops /Users/wudaijun/Code/goprof/havlak/havlak3.go
         0     0%   100%    17.79MB 31.00%  main.buildBaseLoop /Users/wudaijun/Code/goprof/havlak/havlak3.go
</code></pre><p>memprofile 也就是 heap 采样数据，go tool pprof 默认显示的是使用的内存的大小，如果想要显示使用的堆对象的个数，则通过<code>go tool pprof --inuse_objects havlak3 havlak3.mprof</code>，其它参数还有<code>--alloc_objects</code>和<code>--alloc_space</code>，分别是分配的堆内存大小和对象个数。在本例中，FindLoops 函数分配了39.60M 堆内存，占到69%，同样，接下来是通过<code>list FindLoops</code>对函数代码进行 review，找出关键数据结构，进行优化。</p>
<h4 id="2-3-blockprofile"><a href="#2-3-blockprofile" class="headerlink" title="2.3 blockprofile"></a>2.3 blockprofile</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> mutex sync.Mutex</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// rate = 1 时, 统计所有的 block event, </span></span><br><span class="line">    <span class="comment">// rate &lt;=0 时，则关闭block profiling</span></span><br><span class="line">    <span class="comment">// rate &gt; 1 时，为 ns 数，阻塞时间t&gt;rate的event 一定会被统计，小于rate则有t/rate 的几率被统计</span></span><br><span class="line">    <span class="comment">// 参考 https://github.com/golang/go/blob/release-branch.go1.9/src/runtime/mprof.go#L397</span></span><br><span class="line">	runtime.SetBlockProfileRate(<span class="number">1</span> * <span class="number">1000</span> * <span class="number">1000</span>)</span><br><span class="line">	<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">	wg.Add(<span class="number">1</span>)</span><br><span class="line">	mutex.Lock()</span><br><span class="line">	<span class="keyword">go</span> worker(&amp;wg)</span><br><span class="line">	time.Sleep(<span class="number">2</span>*time.Millisecond)</span><br><span class="line">	mutex.Unlock()</span><br><span class="line">	wg.Wait()</span><br><span class="line"></span><br><span class="line">	writeProfTo(<span class="string">&quot;block&quot;</span>, <span class="string">&quot;block.bprof&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">worker</span><span class="params">(wg *sync.WaitGroup)</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> wg.Done()</span><br><span class="line">	mutex.Lock()</span><br><span class="line">	time.Sleep(<span class="number">1</span>*time.Millisecond)</span><br><span class="line">	mutex.Unlock()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">writeProfTo</span><span class="params">(name, fn <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">	p := pprof.Lookup(name)</span><br><span class="line">	<span class="keyword">if</span> p == <span class="literal">nil</span> &#123;</span><br><span class="line">		fmt.Errorf(<span class="string">&quot;%s prof not found&quot;</span>, name)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	f, err := os.Create(fn)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		fmt.Errorf(<span class="string">&quot;%v&quot;</span>, err.Error())</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">defer</span> f.Close()</span><br><span class="line">	err = p.WriteTo(f, <span class="number">0</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		fmt.Errorf(<span class="string">&quot;%v&quot;</span>, err.Error())</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行程序并 pprof:</p>
<pre><code>▶ go build -o Temp tmp.go
▶ go tool pprof Temp block.bprof
(pprof) top
Showing nodes accounting for 3.37ms, 100% of 3.37ms total
      flat  flat%   sum%        cum   cum%
    2.04ms 60.52% 60.52%     2.04ms 60.52%  sync.(*Mutex).Lock /usr/local/Cellar/go/1.9.1/libexec/src/sync/mutex.go
    1.33ms 39.48%   100%     1.33ms 39.48%  sync.(*WaitGroup).Wait /usr/local/Cellar/go/1.9.1/libexec/src/sync/waitgroup.go
         0     0%   100%     1.33ms 39.48%  main.main /Users/wudaijun/go/src/ngs/test/tmp/tmp.go
         0     0%   100%     2.04ms 60.52%  main.worker /Users/wudaijun/go/src/ngs/test/tmp/tmp.go
         0     0%   100%     3.37ms   100%  runtime.goexit /usr/local/Cellar/go/1.9.1/libexec/src/runtime/asm_amd64.s
         0     0%   100%     1.33ms 39.48%  runtime.main /usr/local/Cellar/go/1.9.1/libexec/src/runtime/proc.go
</code></pre><p>可以看到程序在 mutex.Lock 上阻塞了2.04ms(worker goroutine)， 在 WaitGroup.Wait 上等待了1.33ms(main goroutine)，从更上层来看，在 main 函数中一共阻塞了2.04ms，worker函数中阻塞了1.33ms(cum 列)，通过 <code>web</code>命令生成 svg 图片在浏览器查看:</p>
<p><img src="/assets/image/201804/go-block-prof.png" alt=""></p>
<p>可以很直观地看到整个阻塞调用链，对于耗时较多的阻塞调用加以优化。</p>
<h4 id="2-4-mutexprofile"><a href="#2-4-mutexprofile" class="headerlink" title="2.4 mutexprofile"></a>2.4 mutexprofile</h4><p>仍然用2.3中的代码，只需要改两个地方，将 <code>runtime.SetBlockProfileRate(1 * 1000 * 1000)</code> 改为:</p>
<pre><code>// 当 rate = 0 时，关闭 mutex prof (默认值)
// 当 rate = 1 时，表示记录所有的 mutex event
// 当 rate &gt; 1 时，记录 1/rate 的 mutex event(随机)
runtime.SetMutexProfileFraction(1)
</code></pre><p>再将<code>writeProfTo(&quot;block&quot;, &quot;block.bprof&quot;)</code>改为<code>writeProfTo(&quot;mutex&quot;, &quot;mutex.mprof&quot;)</code>即可，编译运行，并打开 pprof 工具:</p>
<pre><code>▶ go tool pprof bin/Temp mutex.mprof
(pprof) top
Showing nodes accounting for 2.55ms, 100% of 2.55ms total
      flat  flat%   sum%        cum   cum%
    2.55ms   100%   100%     2.55ms   100%  sync.(*Mutex).Unlock /usr/local/Cellar/go/1.9.1/libexec/src/sync/mutex.go
         0     0%   100%     2.55ms   100%  main.main /Users/wudaijun/go/src/ngs/test/tmp/tmp.go
         0     0%   100%     2.55ms   100%  runtime.goexit /usr/local/Cellar/go/1.9.1/libexec/src/runtime/asm_amd64.s
         0     0%   100%     2.55ms   100%  runtime.main /usr/local/Cellar/go/1.9.1/libexec/src/runtime/proc.go
</code></pre><p>查看 svg 图:</p>
<p><img src="/assets/image/201804/go-mutex-prof.png" alt=""></p>
<h3 id="三-实践-Tips"><a href="#三-实践-Tips" class="headerlink" title="三. 实践 Tips"></a>三. 实践 Tips</h3><p>以下是一些从其它项目借鉴或者自己总结的实践经验，它们只是建议，而不是准则，实际项目中应该以性能分析数据来作为优化的参考，避免过早优化。</p>
<ol>
<li>对频繁分配的小对象，使用 <a href="https://golang.org/pkg/sync/#Pool">sync.Pool</a> 对象池避免分配</li>
<li>自动化的 DeepCopy 是非常耗时的，其中涉及到反射，内存分配，容器(如 map)扩展等，大概比手动拷贝慢一个数量级</li>
<li>用 atomic.Load/StoreXXX，atomic.Value, sync.Map 等代替 Mutex。(优先级递减)</li>
<li>使用高效的第三方库，如用<a href="https://github.com/valyala/fasthttp">fasthttp</a>替代 net/http</li>
<li>在开发环境加上<code>-race</code>编译选项进行竞态检查</li>
<li>在开发环境开启 net/http/pprof，方便实时 pprof</li>
<li>将所有外部IO(网络IO，磁盘IO)做成异步</li>
</ol>
<p>参考: </p>
<ol>
<li><a href="https://blog.golang.org/profiling-go-programs">Profiling Go Programs</a></li>
<li><a href="http://artem.krylysov.com/blog/2017/03/13/profiling-and-optimizing-go-web-applications/">profiling-and-optimizing-go-web-applications</a></li>
</ol>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>React - Web中的函数式思维</title>
    <url>/2018/05/react-notes/</url>
    <content><![CDATA[<h3 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h3><p><a href="http://es6.ruanyifeng.com/">ES6</a>: Javascript 的新标准，主要包括引入class，箭头函数，let, const 新关键字等。</p>
<p><a href="https://doc.react-china.org/docs/introducing-jsx.html">JSX</a>: JSX 是JavaScript 语法扩展，让在 js 中写HTML像模板语言一样方便，最终会编译为js。</p>
<h3 id="React-特性"><a href="#React-特性" class="headerlink" title="React 特性"></a>React 特性</h3><h4 id="1-组件"><a href="#1-组件" class="headerlink" title="1. 组件"></a>1. 组件</h4><p>React的核心思想便是将UI切分成一些的独立的、可复用的组件，这样你就只需专注于构建每一个单独的部件，达到非常灵活的组件级别的解耦和复用。</p>
<span id="more"></span>
<p>组件本质上是函数(ES6的 class仍然基于之前的function prototype实现)，接收任意值，并返回一个 React 元素。组件可以像HTML标签一样被使用:</p>
<pre><code>// 组件本身，接收 props，返回界面显示元素
function Welcome(props) &#123;
  return &lt;h1&gt;Hello, &#123;props.name&#125;&lt;/h1&gt;;
&#125;

// 使用Welcome组件提供的 k-v 对将作为props参数(property的缩写)
// 其实本质上就是HTML标签的attribute)传入 Welcome 组件
const element = &lt;Welcome name=&quot;Sara&quot; /&gt;;
ReactDOM.render(
  element,
  document.getElementById(&#39;root&#39;)
);
</code></pre><p>上面的组件被称为无状态组件，有状态(state)的组件通常通过 class 实现，通过 render 方法返回界面元素:</p>
<pre><code>class Clock extends React.Component &#123;
  constructor(props) &#123;
    super(props);
    this.state = &#123;date: new Date()&#125;;
  &#125;

  componentDidMount() &#123;
    this.timerID = setInterval(
      () =&gt; this.tick(),
      1000
    );
  &#125;

  componentWillUnmount() &#123;
    clearInterval(this.timerID);
  &#125;

  tick() &#123;
    this.setState(&#123;
      date: new Date()
    &#125;);
  &#125;

  render() &#123;
    return (
      &lt;div&gt;
        &lt;h1&gt;Hello, world!&lt;/h1&gt;
        &lt;h2&gt;It is &#123;this.state.date.toLocaleTimeString()&#125;.&lt;/h2&gt;
      &lt;/div&gt;
    );
  &#125;
&#125;

ReactDOM.render(
  &lt;Clock /&gt;,
  document.getElementById(&#39;root&#39;)
);
</code></pre><p><a href="https://codepen.io/gaearon/pen/amqdNA?editors=0010">CodePen预览</a></p>
<p>简单来说，组件就是将props和state映射为React 元素。比如 props 可能是一批库存列表，state 可能包含是否勾选了显示无货商品的复选框，然后组件结合这两部分信息，生成对应的 React 元素。</p>
<p>props对于组件来说是只读的，其字段映射到外部使用该组件时传入的属性(除了 props.children，它代表该组件下定义的所有的子节点)，属性值可以是基础数据类型，回调函数，甚至 React 元素，因此，组件还可以通过提供 propTypes 来验证外部使用组件传入的属性是否符合规范。</p>
<p>state仅由其所属组件维护，通常是一些和界面显示相关的内部状态(比如是否勾选复选项)，通过<code>this.setState</code>可变更这些状态。React 会追踪这些状态变更并反映到虚拟DOM上，开发者无需关心何时更新虚拟DOM并反馈到真实DOM上，React 可能会将几次setState操作merge为一个来提高性能，用官方的说法，setState是异步更新的。</p>
<p>元素是 React应用的最小单位，React 当中的元素事实上是普通的对象，比如<code>const element = &lt;h1&gt;Hello, world&lt;/h1&gt;;</code>。React DOM 可以确保 浏览器 DOM 的数据内容与 React 元素保持一致。</p>
<p>每个组件都有自己的生命周期，通过生命周期钩子实现，如componentDidMount，componentWillUnMount等。</p>
<h4 id="2-虚拟-DOM"><a href="#2-虚拟-DOM" class="headerlink" title="2. 虚拟 DOM"></a>2. 虚拟 DOM</h4><p>组件并不是真实的 DOM 节点，而是存在于内存之中的一种数据结构，叫做虚拟 DOM）。只有当它插入文档以后，才会变成真实的 DOM 。根据 React 的设计，所有的 DOM 变动，都先在虚拟 DOM 上发生，然后再将实际发生变动的部分，反映在真实 DOM上，这种算法叫做 <a href="http://www.infoq.com/cn/articles/react-dom-diff">DOM Diff</a> ，它可以极大提高网页的性能表现。</p>
<p>React 中所有的组件被组织为一棵树（虚拟 DOM 树），React将界面视为一个个特定时刻的固定内容（就像一帧一帧的动画），而不是随时处于变化之中（而不是处于变化中的一整段动画）。每个组件只关心如何根据数据(props)和状态(state)得到React元素(element)。而不关心自己何时被渲染，是否需要渲染等细节。React 会在组件的 props 和 state 变更时知晓状态变更，并负责调用render进行渲染(像是”桢驱动”)。如此，组件只负责维护状态和映射，其它的事情(驱动，渲染，优化)React 都帮你做好了。由于 DOM Diff 算法的存在，React会先比较虚拟DOM的差异，在真实 DOM 中只会渲染改变了的部分。</p>
<h4 id="3-DOM-Diff"><a href="#3-DOM-Diff" class="headerlink" title="3. DOM Diff"></a>3. DOM Diff</h4><p>DOM Diff的用于比较新旧虚拟DOM树，找到最少的转换步骤。这本是O(n^3)的复杂度，React使用启发式算法，复杂度仅为O(n)。这归功于React对Web界面作出的两个假设:</p>
<ol>
<li>两个不同类型的元素将产生不同的树。</li>
<li>通过渲染器附带key属性，开发者可以示意哪些子元素可能是稳定的。</li>
</ol>
<p>在实际 Diff 过程中，React只会对同一层次的节点进行比较，如果节点类型不同或者被移动到不同层级，则整个节点(及其子节点)重新插入到真实DOM中。如果节点类型相同，则依靠开发者提供的key属性来优化列表比较。</p>
<p>因此在实际应用中，保持稳定的 DOM 结构，合理使用key属性可以帮助 React 更好的完成 diff 操作。</p>
<p>另外，组件的生命周期(生命周期钩子)其实也跟 DOM Diff 有关。</p>
<h4 id="4-单向数据流"><a href="#4-单向数据流" class="headerlink" title="4. 单向数据流"></a>4. 单向数据流</h4><p>理想情况下，React组件是单向数据流的，任何状态始终由对应组件所有，并且从该状态导出的任何数据或 UI 只能影响树中下方的组件。即整个数据流是从父组件到子组件的。在实际应用中，组件交互往往会更复杂，React 也提供了一些最佳实践:</p>
<ul>
<li>组合而不是继承: 父子组件通过组合而不是继承的方式来实现</li>
<li>子组件更新父组件: 父组件将自己的回调函数通过 props 传给子组件</li>
<li>兄弟组件需要共享状态: 将状态提升到其共有的父组件中，或者通过<a href="https://doc.react-china.org/docs/context.html">Context</a></li>
<li>高阶组件: 参数(props)和返回值都是组件的无状态函数，可以完成对组件更高层次的行为模式抽象，<a href="https://doc.react-china.org/docs/higher-order-components.html">参考</a></li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>俗话说，没有什么是加一层抽象不能解决的，React虚拟DOM，就像操作系统的虚拟内存等概念一样，极大程度简化了开发者负担。虚拟内存屏蔽了内存换入换出等细节，而虚拟DOM屏蔽了何时渲染，渲染优化等问题，开发只关心架设好虚拟DOM，然后随着状态变更，真实DOM会随时更新。</p>
<p>React另一个很棒的想法是将界面看作一帧桢的动画，当前状态决定当前界面，React组件本质上就是将局部状态映射为局部界面(动画某一帧的某一部分)，然后组装为整个UI界面(某一帧的定格)。这其中外部输入(props)是只读的，内部状态(state)是可变的，而输出的界面元素(element)是不可变的。</p>
<p>React 在很多地方都有函数式的影子，比如数据流思想(处理过程输入输出都不可变)，高阶组件(其实就是高阶函数)等，这种思想让开发者理解和调试变得简单，开发者只关心props+state=&gt;element 的映射，React来处理其它的实现细节，如虚拟DOM，DOM Diff(有点像函数式语言实现不可变语义的Copy-On-Write)，以及虚拟DOM到真实DOM的映射等。</p>
<p>React的单向数据流，是一种非常简单和理想化的模型，虽然有回调函数，高阶组件等方法，但不可避免地，React 也提供了类似 Context 这种全局上下文的概念。这和函数式一样，理念在实践中只是原则而不是规则。</p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title>理解函数式编程</title>
    <url>/2018/05/understand-functional-programing/</url>
    <content><![CDATA[<p>源自于我做的一次公司内部的技术分享，这是初稿。 PPT 就不贴了。</p>
<h2 id="一-序章-可计算模型"><a href="#一-序章-可计算模型" class="headerlink" title="一. 序章: 可计算模型"></a>一. 序章: 可计算模型</h2><p>1936 阿隆佐·邱奇发表可计算函数的第一份精确定义，即<a href="https://zh.wikipedia.org/wiki/%CE%9B%E6%BC%94%E7%AE%97">Lambda演算(λ演算)</a>。λ演算是一套从数学逻辑中发展，以变量绑定和替换的规则，来研究函数如何抽象化定义、函数如何被应用以及递归的形式系统。<br>1936 艾伦·图灵提出<a href="ttps://zh.wikipedia.org/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA">图灵机</a>设想，通过TAPE,HEAD,TABLE,STATE四个部分模拟人的纸笔运算<br>1945 冯·诺伊曼提出冯·诺伊曼结构(存储程序型电脑)，是通用图灵机实现<br>1958 约翰·麦卡锡，发明了一种列表处理语言（Lisp），这种语言是一种阿隆佐lambda演算在现实世界的实现，而且它能在冯·诺伊曼计算机上运行</p>
<p>图灵机设想和 Lamdba 演算都是一种抽象计算模型，是解决可计算问题的一种方案，通俗来讲，就是将计算以数学的方式抽象化，以便证明和推导。图灵机和 Lamdba 演算这两个可计算理论已经被证明是等价的。</p>
<span id="more"></span>
<p>函数式的起源Lambda 演算甚至还要早于图灵机，但图灵机由于其更具实现意义，也更容易被理解，因此很早就有了硬件实现基础，而 Lambda 演算是一套更接近软件而非硬件的形式系统，Lambda 演算的第一台硬件则要等到1973年的 MIT 人工智能实验室开发的Lisp机。</p>
<h2 id="二-什么是函数式编程"><a href="#二-什么是函数式编程" class="headerlink" title="二. 什么是函数式编程"></a>二. 什么是函数式编程</h2><p>函数式编程是一种编程范式，我们常见的编程范式有命令式编程，函数式编程，逻辑式编程，常见的面向对象编程和面向过程编程都是命令式编程。</p>
<p>命令式编程是面向计算机硬件的抽象，如变量(抽象存储单元)，表达式(算数运算与内存读写)，控制语句(跳转指令)，最终得到一个冯诺依曼机的指令序列。</p>
<p>函数式编程的基础模型来源于λ演算，是阿隆佐思想的在现实世界中的实现。不过不是全部的lambda演算思想都可以运用到实际中，因为lambda演算在设计的时候就不是为了在各种现实世界中的限制下工作的(毕竟是数学家捣鼓出来的东西)。 目前的函数式编程语言基本都是翻译为冯诺依曼指令实现的。</p>
<h2 id="三-函数式编程概念"><a href="#三-函数式编程概念" class="headerlink" title="三. 函数式编程概念"></a>三. 函数式编程概念</h2><p>变量: </p>
<ul>
<li>命令式: 代表存储可变状态的单元(内存地址)，相当于地址的别名  x = x + 1</li>
<li>函数式: 代表数学函数中的变量，映射到某个值，相当于值的别名  2x = 4</li>
</ul>
<p>函数:</p>
<ul>
<li>命令式: 描述求解过程(怎么做)，本质上是一系列的冯诺依曼机指令，can do anything</li>
<li>函数式: 数学概念里的函数，描述映射(计算)关系(做什么)，也称为纯函数/无状态函数</li>
</ul>
<h2 id="四-函数式编程特性"><a href="#四-函数式编程特性" class="headerlink" title="四. 函数式编程特性"></a>四. 函数式编程特性</h2><h3 id="1-不可变语义"><a href="#1-不可变语义" class="headerlink" title="1. 不可变语义"></a>1. 不可变语义</h3><p>比如我们有一个 Point类，其 moveBy 方法对 x,y 坐标进行偏移，得到新的 Point 对象:</p>
<pre><code>// 命令式写法: 直接修改内存值
func (p *Point) moveBy(deltaX, deltaY int) &#123;
    p.x = p.x + deltaX
    p.y = p.y + deltaX
&#125;

// 函数式写法: 新建一个 Point 对象，函数本身只需关心对象的映射，而非对象复用等实现细节。在语义上，新旧 Point 代表完全独立并可不变的两个&quot;Point 值&quot;。
func moveBy(p *Point, deltaX, deltaY int) *Point &#123;
    return &amp;Point&#123;
        x:    p.x+deltaX,
        y:    p.y+deltaY,
    &#125;
&#125;
</code></pre><p>没有可变状态，也就没有 for, while 循环，使得函数式编程严重依赖递归。</p>
<p>这里的不可变，指的是语义上的不可变，而非其底层实现上的不变。比如Erlang 虚拟机用 C 实现，通过写时拷贝来实现不可变语义，但针对比如binary 升级，Pid打包等，虽然底层的实现结构可能会改变，但对应用层来说语义是不变的。</p>
<h3 id="2-纯函数"><a href="#2-纯函数" class="headerlink" title="2. 纯函数"></a>2. 纯函数</h3><ul>
<li>确定性: 相同输入得到相同输出，函数的返回值和参数以外的其他隐藏信息或状态无关</li>
<li>无副作用: 函数不能有语义上可观察的副作用，诸如“触发事件”，使输出设备输出，或更改输出值以外对象的内容等</li>
</ul>
<p>纯函数都是显式数据流的，即所有的输入都通过参数传入，所有输出都通过返回值传出。</p>
<p>纯函数即无状态函数，微服务中的无状态服务也有一个无状态似，但关注的是整个处理流程的无状态，即把状态往两边推到输入(如Network)和输出(DB，Cache，Log 等)，这样服务能够横向扩展和动态伸缩(就像一个巨大的纯函数)。而对函数式而言，理论上演算过程中的任一处理步骤(每次函数调用)都是无状态的，因此可伸缩和并发的粒度更小。</p>
<p>在实现上，无状态和不可变语义一样，是语义上的，无状态是指函数本身不能有可以改变状态的指令，从系统层次上来看，要说绝对没状态是不可能的，比如调用函数会导致进程栈增长，页面换入换出等。另外，在 Haskell 语言中，还有惰性求值，会使得在执行纯函数时执行一些外部操作(比如文件 IO)。因此从这个角度来看，我们用命令式语言也可以实现无状态效果。</p>
<h3 id="3-递归与尾递归"><a href="#3-递归与尾递归" class="headerlink" title="3. 递归与尾递归"></a>3. 递归与尾递归</h3><p>递归在几乎所有命令式编程语言中都有，即函数调用自身，在函数式编程中，由于没有可变状态，for, while 循环都只能通过递归来实现，因此函数式编程严重依赖递归:</p>
<p>以阶乘为例:<br><img src="leanote://file/getImage?fileId=5ad172004a714562e4000001" alt=""></p>
<pre><code>// 自底向上，递推求解
func fact_1(n int) int &#123;
    acc := 1
    for k:=1; k&lt;=n; k++ &#123;
        acc = acc*k
    &#125;
    return acc
&#125;

//  自顶向下，递归求解
func fact_2(n int) int &#123;
    if n == 0 &#123;
        return 1
    &#125; else &#123;
        return fact_2(n-1)*n
    &#125;
&#125;

// 自顶向下，递归求解 - Erlang
fact(N) when N == 0 -&gt; 1;
fact(N) when N &gt; 0 -&gt; N*fact(N-1).


// 递归求解 - Erlang - 尾递归版
fact1(N) -&gt; fact(1, N).
fact(Acc, N) when N == 0 -&gt; Acc;
fact(Acc, N) when N &gt; 0 -&gt; fact(Acc*N, N-1).
</code></pre><p>我们知道在现代冯诺依曼结构计算机中，递归和普通函数一样，是通过函数调用栈来实现的，为了防止函数栈肆意扩展(导致栈溢出)，通常函数式语言的编译器都会实现尾调用优化。尾调用是指一个函数里的最后一个动作是返回一个函数的调用结果的情形，即最后一步新调用的返回值直接被当前函数的返回结果。这种情况下，函数可以直接复用当前函数栈的栈空间执行尾调用，减少栈空间使用并提高效率。(尾递归是函数式基于命令式语言实现时的一个实现上的优化(栈空间是有限的)，并非Lamda 演算本身的内容。)</p>
<p>递归是函数式中非常核心的一个概念，其在函数式语言中的低位要比在命令式语言高很多，理解递归是理解函数式的基础。递归是另一种我们思考和解决问题的方式，在一些情景下，使用递归会让问题简化许多。比如经典的找零钱问题:</p>
<pre><code>// 若干面值钞票，给一张大面值货币要兑换成零钱，求有多少种兑换方式
// 递归版本
func countChange(money int, coins []int) int &#123;
    if money &lt; 0 || len(coins) == 0 &#123;
        return 0
    &#125;
    if money == 0 &#123;
        return 1
    &#125;
    return countChange(money, coins[1:]) + countChange(money-coins[0], coins)
&#125;

// 迭代版本
func countChange2(changes []int, money int) int &#123;
    n  := len(changes)
    dp := make([]int, money+1)
    for i:=1; i&lt;=money; i++ &#123;
        dp[i] = 0
    &#125;
    dp[0] = 1
    for i:=0; i&lt;n; i++ &#123;
        for j:=changes[i]; j&lt;=money; j++&#123;
            dp[j] += dp[j-changes[i]]
        &#125;
    &#125;
    return dp[money]
&#125;
</code></pre><p>可以看到，递归版比迭代版要容易理解得多，后者需要手动维护状态，而前者将状态隐藏到递归过程中了。类似的还有背包问题，都是理解递归很好的例子。</p>
<h3 id="4-惰性求值-乱序求值"><a href="#4-惰性求值-乱序求值" class="headerlink" title="4. 惰性求值/乱序求值"></a>4. 惰性求值/乱序求值</h3><p>表达式不在它被绑定到变量之后就立即求值，而是在该值被取用的时候求值。<a href="http://wudaijun/2019/02/lazy-evaluation/">这篇文章</a> 更详细地讨论了惰性求值。</p>
<pre><code>A = dosomething1()
B = dosomething2(A)
C = dosomething3()    
</code></pre><p>编译器很容易就可以推断出，A-&gt;B 和 C 可以乱序(无状态)或者并行(不可变语义)执行，并且对 A，B，C 的求值可以等到它们被引用的时候再计算，因此函数式本身的优化空间是比较大的。</p>
<h3 id="5-柯里化-currying"><a href="#5-柯里化-currying" class="headerlink" title="5. 柯里化(currying)"></a>5. 柯里化(currying)</h3><p>柯里化:将一个多参数函数分解成多个单参数函数，然后将单参函数多层封装起来，每层函数都返回一个函数去接收下一个参数，这可以简化函数的多个参数。比如前面我们的尾递归版阶乘计算，可以写成:</p>
<pre><code>fact2(Acc) -&gt;
    fun(N) -&gt; fact(Acc, N) end.

F = fact2(1)
F(10)
</code></pre><p>换成 Lua 可能更容易理解，比如我们有两个参数的 add :</p>
<pre><code>add = function(x, y)
    return x + y
end
print(add(3,4))
</code></pre><p>可将其柯里化为:</p>
<pre><code>add = function(x)
    return function(y)
        return x + y
    end
end
print(add(3)(4)) 
</code></pre><p>上面我们列举的柯里化看起来很像Lua,Go等语言中的闭包(词法闭包，Lexical Closure)，实际上柯里化是Lambda 演算中的概念，用于简化推导流程。闭包只是一种实现方式，如C++ STL 的<code>bind1st</code>和<code>bind2nd</code>也可以实现固化函数参数的作用。 </p>
<p>柯里化所要表达是:如果你固定某些参数，你将得到接受余下参数的一个函数,所以对于有两个变量的函数x+y，如果固定了x=3，则得到有一个变量的函数3+y(是不是很像多项式一个一个变量求解)。这就是求值策略中的部分求值策略。柯里化具有延迟计算、参数复用、动态生成函数的作用。</p>
<h3 id="6-高阶函数"><a href="#6-高阶函数" class="headerlink" title="6. 高阶函数"></a>6. 高阶函数</h3><p>函数式的要义之一就是将函数当做普通对象一样，可以被当做参数传递，也可以作为函数返回值(在λ演算创始人阿隆佐·邱奇的眼里，一切且函数，变量也是函数)。所谓高阶函数就是以函数为参数或返回值的函数，有了高阶函数，就可以将复用的粒度降至函数级别，相对面向对象而言，复用粒度更低。</p>
<pre><code>sumInts(A, B) when A &gt; B -&gt; 0;
sumInts(A, B) -&gt; A + sumInts(A+1, B).

sumFacts(A, B) when A &gt; B -&gt; 0;
sumFacts(A, B) -&gt; fact1(A) + sumFacts(A+1, B).

sum(F, A, B) when A &gt; B -&gt; 0;
sum(F, A, B) -&gt; F(A) + sum(F, A+1, B).

&gt; sum(fun fact1/1, 3, 6)
</code></pre><p>函数式语言通常提供了非常强大的”集合类”，可以基于高阶函数提供便捷的集合操作:</p>
<pre><code>37&gt; L = [1,2,3].
[1,2,3]
38&gt; lists:map(fun(E) -&gt; 2*E end, L).
[2,4,6]
39&gt; lists:foldl(fun(E, Acc) -&gt; Acc+E end, 0, L).
6
</code></pre><p>得益于函数式的无状态和不可变语义，将lists:map 函数改写为并发执行的 map 只需几十行代码，安全无副作用。</p>
<p>可能接触过面向对象编程的人都接触或使用过设计模式，在函数式编程里面，通过 function 实现设计模式要比 class, interface 那一套要简洁灵活得多。比如lists:map本身就是一个很好用的访问者模式。</p>
<h3 id="7-Monad"><a href="#7-Monad" class="headerlink" title="7. Monad"></a>7. Monad</h3><p>前面提到，函数式中变量不可变，且纯函数没有副作用，那么函数式如何处理可变状态比如 IO 呢，在 Erlang 里，IO 通过 C 实现，即引入了可变性和副作用，并且 Erlang没有对这种副作用代码和纯代码分隔开，这得依靠程序员来做。而纯函数式语言 Haskell 采用了另一种方案: Monad。</p>
<p>单子(Monad)是来自范畴论中的概念，范畴论是数学的一门学科，以抽象的方法来处理数学概念，将这些概念形式化成一组组的“对象”及“态射”。</p>
<p>Monad 的概念被引入到 Haskell，表示”注入”和”提取”的概念，用于处理 IO，串联函数等。</p>
<p>Haskell严格地把纯代码从那些有副作用的代码(如 IO)中分隔开。就是说，它给纯代码提供了完全的副作用隔离。除了帮助程序员推断他们自己代码的正确性，它还使编译器可以自动采取优化和并行化成为可能。而 Monad 加上 Haskell 的类型类即成为分离纯函数和副作用函数的利器:</p>
<p><img src="/assets/image/201805/haskell-monad.png" alt=""></p>
<p><a href="http://zhuoqiang.me/what-is-monad.html">图片出处</a></p>
<p>上图说明了 Haskell 如何通过 Monad 管理纯函数副作用函数。具体到代码，看起来像是这样:</p>
<pre><code>name2reply :: String -&gt; String
name2reply name =
    &quot;Pleased to meet you, &quot; ++ name ++ &quot;.\n&quot; ++
    &quot;Your name contains &quot; ++ charcount ++ &quot; characters.&quot;
    where charcount = show (length name)

main :: IO ()
main = do
       putStrLn &quot;Greetings once again.  What is your name?&quot;
       inpStr &lt;- getLine
       let outStr = name2reply inpStr
       putStrLn outStr
</code></pre><p>Haskell在纯代码和I/O动作之间做了很明确的区分。很多语言没有这种区分。 在C或者Java(包括 Erlang)这样的语言中，编译器不能保证一个函数对于同样的参数总是返回同样的结果，或者保证函数没有副作用。程序中的很多错误都是由意料之外的副作用造成的。做好这种隔离有利于程序员和编译器更好地思考和优化程序。</p>
<h2 id="五-函数式的优缺点"><a href="#五-函数式的优缺点" class="headerlink" title="五. 函数式的优缺点"></a>五. 函数式的优缺点</h2><ul>
<li>并发性: 函数无副作用(天然可重入)，原生并发友好</li>
<li>确定性: 可读性高，易于测试和调试，错误易于重现</li>
<li>没有锁和指针就没有伤害</li>
<li>具有很大的优化潜力，如惰性求值，并发，缓存函数计算结果等，很多原本需要程序来做的事情，都可以由编译器来做。比如动态规划的缓存，MapReduce 等。</li>
</ul>
<p>缺点:</p>
<ul>
<li>处理可变状态如 IO 的能力弱(要么使用可变状态，要么使用 Monad)</li>
<li>为了维持不可变性，拷贝的开销</li>
<li>运行效率，依靠并发</li>
</ul>
<h2 id="六-函数式的实现"><a href="#六-函数式的实现" class="headerlink" title="六. 函数式的实现"></a>六. 函数式的实现</h2><h3 id="1-Erlang"><a href="#1-Erlang" class="headerlink" title="1. Erlang"></a>1. Erlang</h3><p>Erlang 不是一门纯函数式语言(提供了外部可变状态组件，如进程字典，Ets)，但它充分利用函数式的无状态和不可变语义，将函数式的各种优势很好地利用了起来。Erlang 的具体介绍和细节我们就谈了，我着重讲一下其三个让其它语言”眼红”的三个特性:</p>
<h4 id="高并发"><a href="#高并发" class="headerlink" title="高并发"></a>高并发</h4><p>Erlang 是 Actor 模型，一个 Actor 即一个 Erlang 进程，创建一个进程是微秒级的。Erlang 可以说是最早支持协程的语言之一，Actor 与 Actor 之间通过消息交互，加上不可变语义，使得 Erlang 比其它语言更易于实现安全的并发(Erlang/OTP并发编程实践作者将共享内存比作这个时代的goto)。</p>
<h4 id="热更新"><a href="#热更新" class="headerlink" title="热更新"></a>热更新</h4><p>说起代码热替换，估计没有语言比 Erlang 做得更好了，这是 Erlang 的黑科技，一个用了你就回不去的功能。热更新对于游戏服务器的意义是很大的，游戏开发版本更新快，有时候有些不大不小的问题(比如一些调试日志忘删除了，某个小功能可能无法使用)，通过重启来解决的代价太大(用户流失)，用 Erlang 直接无缝热更，比无缝重启要方便快捷太多。</p>
<p>热更新的原理是代码版本替换，一方面仰仗于Erlang运行时的代码加载机制，另一方面，函数式也功不可没，一个具有内部状态的函数是很难做热更新的。</p>
<h4 id="容错性"><a href="#容错性" class="headerlink" title="容错性"></a>容错性</h4><p>Erlang 有一个很有意思的slogan，叫”let it crash”，这看起来与命令式编程中的”defensive coding(防御式编程)”背道而驰，在大型分布式程序的构建过程中，代码会遇到各种各样的异常，代码编写者不可能或者说很难预料并且处理到所有的异常，在这个背景下，Erlang 提出”let it crash” 的概念: 既然未预料的异常无可避免，那么就应该统一隔离处理并且恢复它，注意，这里提到了三个词: 错误隔离，错误处理和故障恢复，大部分语言最多做到第一步(比如 Go 语言)，而 Erlang 把整个三步都做到了虚拟机中。一个进程挂了，会由监督者发现，并且根据重启策略重启。 Actor 的状态隔离与轻量为整个容错性提供基础保障。</p>
<p>总的来说，Erlang 在并发，健壮性，可伸缩性方面，都有非常出色的表现。适用于 IO 密集型的软实时系统(设计之初就是为了解决电信通信问题的)。</p>
<h3 id="2-Haskell"><a href="#2-Haskell" class="headerlink" title="2. Haskell"></a>2. Haskell</h3><p>Erlang并不是一门纯函数式语言的话，进程字典，ets，IO 等状态性和副作用，Haskell 则剑走偏锋，号称是纯函数式语言。Haskell 我只看了一部分，以下是一些基础特性:</p>
<ul>
<li>支持惰性求值</li>
<li>更彻底的函数(+,-)</li>
<li>静态类型系统 + 类型推导 + 强大的typeclass (==, Functor)，支持自定义类</li>
<li>原生柯里化(<code>map (+1) [1,2,3]</code>)</li>
<li>引入范畴论的 Monad</li>
</ul>
<h2 id="七-最后"><a href="#七-最后" class="headerlink" title="七. 最后"></a>七. 最后</h2><h4 id="1-为什么函数式没有崛起"><a href="#1-为什么函数式没有崛起" class="headerlink" title="1. 为什么函数式没有崛起?"></a>1. 为什么函数式没有崛起?</h4><p>图灵机是一个具备实现意义的 model，或者换句话说，lambda 演算则是更抽象，更上层的计算模型，图灵机也更符合人解决问题的方式(纸笔推演)，更容易被没有数学背景的工程师所理解，因此很快在现实世界中实现推广。</p>
<p>一个有意思的论题是Worse Is Better，由 Common Lisp 专家Richard P. Gabriel在90年代反思 Lisp 这么牛的语言却日渐式微提出的观点，他提出软件设计有以下四大目标: 简单性，正确性，一致性，完整性</p>
<ul>
<li>函数式语言: 正确性 = 一致性 &gt; 完整性 &gt; 简单(为了接口简单，宁愿实现复杂) </li>
<li>命令式语言: 简单性（实现简单优于接口简单）&gt; 正确性 &gt; 完整性 &gt; 一致性</li>
</ul>
<p>原文 Worse Is Better 中的 Worse 是指C/Unix将其简单性优于其它目标的做法(在作者看来是糟糕的)，Better 是指 C/Unix 当下的处境(当然是非常流行)，因此可以粗略理解为”简单的就是好的”。作者将C/Unix 的流行归功于他们实现简单，使得其像”病毒”一样可快速移植到与传播，用户也更愿意接受，等到用户产生依赖，再逐步完善。</p>
<p>当然，可能还有一个原因，那个年代计算机是稀缺资源，比较注重效率，而在冯诺依曼机上的实现的函数式语言自然没有早期的命令式语言快，自然也让 C，C+这类”简单粗暴”的语言飞速推广。再借助 OS，编译器等形成生态。</p>
<h4 id="2-函数式近几年开始受到更多的关注"><a href="#2-函数式近几年开始受到更多的关注" class="headerlink" title="2. 函数式近几年开始受到更多的关注"></a>2. 函数式近几年开始受到更多的关注</h4><p>由于软件复杂度和 CPU 核数的增加，多线程和其他形式的并行化变得越来越普遍， 管理全局副作用变得越来越困难，函数式的好处(正确性和一致性)开始体现出来，几十年前写的 Erlang 代码放到今天，无需任何改动，核数越多，跑得越快，因此现在的软件设计理念都会从函数式思想中学习一些东西。</p>
<p>从设计上来讲，现代语言都或多或少吸收了函数式的一些特性: 如function，闭包，尾递归，高阶函数等等。从理念上来讲，函数式的无状态为并发提供了另一种解决方案，比如近几年推崇的无状态服务设计，Erlang 的 Actor 模型等。</p>
<p>如今很多语言都支持多种编程范式，一些函数式语言也有可变状态，一些命令式语言支持部分函数式特性，理解函数式可以扩展我们解决问题的思路，找到更简洁有效的解决方案，如递归而不是迭代，函数注入而不是对象注入等。最后，我认为每个程序员都可以去学习一门函数式语言，扩展自己的思维，写出更灵活，安全，”纯洁”的代码。</p>
<p>参考:</p>
<ol>
<li><a href="https://www.zhihu.com/question/28292740">什么是函数式思维?</a></li>
</ol>
<p>Haskell:</p>
<ol>
<li><a href="http://cnhaskell.com/chp/7.html">Real World Haskell 中文版</a></li>
<li><a href="http://jiyinyiyong.github.io/monads-in-pictures/">图解 Monad</a></li>
<li><a href="http://zhuoqiang.me/what-is-monad.html">Monad 最简介绍</a></li>
<li><a href="http://yi-programmer.com/2010-04-06_haskell_and_category_translate.html">Haskell 与范畴轮</a></li>
<li><a href="https://learnyoua.haskell.sg/content/zh-cn/ch11/functors-applicative-functors-and-monoids.html">Haskell 趣学指南</a></li>
</ol>
]]></content>
      <categories>
        <category>programing</category>
      </categories>
      <tags>
        <tag>programing</tag>
      </tags>
  </entry>
  <entry>
    <title>Flux - Web应用的数据流管理</title>
    <url>/2018/06/flux-study/</url>
    <content><![CDATA[<p>React实际上只是View层的一套解决方案，它将View层组件化，并约定组件如何交互，数据如何在组件内流通等，但实际的Web App除了View层外，还包括Model层，界面响应，服务器请求等，Flux则是Facebook为此给出一套非常简洁的方案，用于管理Web应用程序数据流。与其说Flux是一套框架，不如说其是一套设计模式，因为其核心代码只有几百行，它主要表述的是一种Web应用设计理念和模式。</p>
<span id="more"></span>
<p>目前大部分的前端框架(Angular, Vue)都支持双向绑定(MVVM)技术，其中M(Model)指数据层，V(View)指视图层，所谓双向绑定是指Model层发生变化(比如服务器数据更新)，导致对应View层更新，View层产生用户交互，也会反映到Model层。这种机制看起来方便，但在实际应用中，一个Model更新可能导致多个View和Model连锁更新(Cascading Update)。Model可以更新Model，Model可以更新View，View可以更新Model，开发者很难完全掌控数据流，比如到了后期完全不知道View的变化是由那个局部变更导致的。整个关系图看起来像是这样:</p>
<p><img src="/assets/image/201805/mvvm.png" alt=""></p>
<p> Flux为此给出了单向数据流的解决方案，React的单向数据流指的是View层内部的自顶向下的数据流，这里指的整个Web App 的单向数据流，在Flux中，主要有四个部分:</p>
<ul>
<li>View: 在Flux中，View层完全是Store层的展现。它订阅Store的变更(change event)，并反馈到界面上。Flux本身支持你使用任意的前端框架，但Flux的理念与React最为契合(毕竟都源自于Facebook)。</li>
<li>Store: 即应用数据，Store的数据只能由Action更新(对外只有get方法)，每个Store决定自己响应哪些Action，并更新自身，更新完成之后，抛出变更事件(change event)。</li>
<li>Action: 描述应用的内部接口，它代表任何能与应用交互的方式(比如界面交互，后台更新等)，在Flux中，Action被简单定义为Type+Data。</li>
<li>Dispatcher: 如其名，它负责接收所有的Action，并将其派发到注册到它的Store，每个Store都会收到所有的Action。所有的Action都会经由Dispatcher。</li>
</ul>
<p>Flux通过加入Dispatcher和Action避免了Model对View的依赖，形成单向数据流:</p>
<p><img src="/assets/image/201805/react-one-way-dataflow.png" alt=""></p>
<p>假设我们有个Todo应用，在Flux中，一个典型的交互流程如下:</p>
<ol>
<li>View层(被挂载时)订阅TodoStore的内容变更</li>
<li>View层获取TodoStore中所有的TodoList并渲染</li>
<li>用户在界面上输入一条新Todo内容</li>
<li>View捕捉到该输入事件，通过Dispatcher派发一个Action，Type为”add-todo”，Data为用户输入的内容</li>
<li>TodoStore收到这个Action，判断并响应该Action(这个过程叫Reduce)，添加todo内容更新自身，然后抛出更新事件(change event)</li>
<li>View层收到该change event，从TodoStore中获取最新数据，并刷新显示</li>
</ol>
<p>整个流程看起来比双向绑定更麻烦，但实际数据流更清晰可控，这样做有如下好处:</p>
<ol>
<li>View层职责很简单，只负责渲染Store变更和触发Action</li>
<li>每个Store的变更可通过其响应的Action来判断和追踪</li>
<li>所有的Action都必须经由全局Dispatcher，即”消息汞”</li>
</ol>
<p>Flux官方的<a href="https://github.com/facebook/flux/tree/master/examples/flux-todomvc">todomvc</a>是一个很好的入门例子</p>
<p>总结起来就是，Flux通过将职责细分，将模块变得更干净，然后通过必要的中间组件(如Dispatcher)，让所有的操作和状态都变得容易被追踪，调试。前面提过，Flux本身只是一种设计模式，并针对这种设计模式提供了一个简洁的实现，针对小型项目足以应付。但也有一些缺陷，，比如所有的Store都会收到所有Action，因此基于Flux单向数据流思想，衍生了一些其它第三方状态管理器(state container)，目前最火的是<a href="https://cn.redux.js.org/">Redux</a>，它与Flux的主要区别是:</p>
<ol>
<li>整个应用只有一个Store</li>
<li>将Store的State更新操作分离到Reducer中</li>
<li>Reducer用来处理Action对State树的更改，它是纯函数(替换而不是修改State)，这样每个Reducer维护State树的一部分</li>
<li>由于只有一个Store，Flux中的Dispather变成了Store的一个函数</li>
</ol>
<p>当然，框架这种东西，在思想确定后，根据项目选合适的就行了。并不是越复杂越好。</p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title>谈谈GS对象的落地</title>
    <url>/2018/06/gs-model-save/</url>
    <content><![CDATA[<p>现在的游戏服务器通常使用NoSQL作为DB以满足Model设计上的灵活性，特别是即将到来的<a href="https://docs.mongodb.com/master/release-notes/4.0/">MongoDB 4.0</a>将提供多文档事务支持，这意味着，SQL转向NoSQL的最后障碍已经被消除。</p>
<p>理想的MongoDB使用场景是将单个对象映射为单个文档，比如玩家数据，公会数据等，但一方面MongoDB对单文档大小硬限制为16M，另一方面，我们需要根据对象更新频度，固有特性等进一步优化，提高DB性能。这里简单谈谈那些GS对象落地的方方面面。</p>
<span id="more"></span>
<h3 id="一-存储方案"><a href="#一-存储方案" class="headerlink" title="一. 存储方案"></a>一. 存储方案</h3><h4 id="1-单文档"><a href="#1-单文档" class="headerlink" title="1. 单文档"></a>1. 单文档</h4><p>最简单的模型，将对象放在一个文档中，需要能够预估对象空间占用总量，比如玩家数据，单服内所有已经使用的玩家名字等。</p>
<h4 id="2-分组保存"><a href="#2-分组保存" class="headerlink" title="2. 分组保存"></a>2. 分组保存</h4><p>将N个小对象分为M个文档保存，可以按照逻辑或者底层统一划分，比如简单按照<code>对象ID%M</code>得到，这种方案主要用于减少文档数量(文档数量对MongoDB序列化时间的影响是比较可观的)。分组保存主要有两种更新方式：基于$set/$unset的增量式更新(GroupSet)，以及基于文档的覆写更新(GroupWrite)。</p>
<h4 id="3-GridFS"><a href="#3-GridFS" class="headerlink" title="3. GridFS"></a>3. GridFS</h4><p>MongoDB GridFS用于以二进制格式保存大文件，这种方案的优点的简单，将数据整块打包为二进制即可。缺点也很明显:</p>
<ol>
<li>对大对象的序列化时间通常较长(毫秒级别)</li>
<li>二进制存储，DB对运维运营和数据分析不友好</li>
<li>GridFS只能覆写，也就和读写优化搭不上边了</li>
</ol>
<p>因此通常我不建议在GS中使用GridFS。</p>
<h3 id="二-存储优化"><a href="#二-存储优化" class="headerlink" title="二. 存储优化"></a>二. 存储优化</h3><h4 id="1-批量读写"><a href="#1-批量读写" class="headerlink" title="1. 批量读写"></a>1. 批量读写</h4><p>这个是DB操作层的优化，用于提高落地效率，主流的MongoDB驱动都提供的批量操作接口。</p>
<h4 id="2-脏标记"><a href="#2-脏标记" class="headerlink" title="2. 脏标记"></a>2. 脏标记</h4><p>这是逻辑层的优化，主要用于减少和DB不必要的交互。脏标记控制对对象的写操作，对对象打上脏标记。主要用于不常变动的对象，比如玩家Cache，但针对数据结构复杂的对象，维护脏标记状态的工作量就比较大了，否则可能漏存数据。脏标记通常需要语言或框架层有访问控制或Hook机制(提供统一的修改入口)。另外就是脏标记本身有一定的不一致性风险，比如DB操作失败，但脏标记已被清除。</p>
<h4 id="3-初始标记"><a href="#3-初始标记" class="headerlink" title="3. 初始标记"></a>3. 初始标记</h4><p>和脏标记类似，但主要用于减少DB数据量，提升加载效率。Origin标记用于判断一个对象是否是初始状态，如果是初始状态，则不写入DB，当DB加载时，通过配置生成这些Origin对象。比如SLG大地图上的格子，通常SLG大地图绝大部分格子都处于初始状态(未被占领)，因此这类对象通过初始标记优化，可以极大程度提升地图加载效率。当一个格子由初始状态被占领时，该格子落地，当这个格子被玩家放弃回到初始状态时，这个格子被删掉。这个功能在调试期间很有用，在线上也能帮助服务器平滑过渡峰值(开服期间人多，但需要落地的地少，后期地多，但人少)。</p>
<h4 id="4-局部更新"><a href="#4-局部更新" class="headerlink" title="4. 局部更新"></a>4. 局部更新</h4><p>针对比较复杂的对象，比如玩家，公会，对其子模块进行局部脏标记并局部更新(mongodb $set)，和脏标记一样，这减少了DB交互。但是通常用得不多，主要原因一是和脏标记一样，需要语言框架的支持，二是粒度不好把控，粒度太细会导致开发负担增大，带来的弊大于利。</p>
<h3 id="三-存储时机"><a href="#三-存储时机" class="headerlink" title="三. 存储时机"></a>三. 存储时机</h3><h4 id="1-定时落地"><a href="#1-定时落地" class="headerlink" title="1. 定时落地"></a>1. 定时落地</h4><p>GS中大部分的对象并不需要实时地将更新写入DB，只需要每隔一段时间(Tick，通常几分钟)落地即可。定时落地通常会结合分组落地(每次Tick只落地一个分组)，脏标记等优化方案。</p>
<h4 id="2-实时落地"><a href="#2-实时落地" class="headerlink" title="2. 实时落地"></a>2. 实时落地</h4><p>对于少数关键数据，比如支付订单，通常是实时落地的，即数据产生或变更时立即写入数据库。</p>
<h4 id="3-停服落地"><a href="#3-停服落地" class="headerlink" title="3. 停服落地"></a>3. 停服落地</h4><p>停服落地通常会与定时落地不同，为了数据安全性，停服落地可以采用刷盘操作，以再一次确保DB数据一致性。</p>
<h3 id="四-DB交互"><a href="#四-DB交互" class="headerlink" title="四. DB交互"></a>四. DB交互</h3><h4 id="1-同异步"><a href="#1-同异步" class="headerlink" title="1. 同异步"></a>1. 同异步</h4><p>DB交互本质上是外部IO交互，应该放到单独的DB线程中去完成，正常情况下，逻辑线程与DB线程只能异步交互，但在开服和停服逻辑中，为了简化流程，可以同步加载/落地。</p>
<h4 id="2-时序性"><a href="#2-时序性" class="headerlink" title="2. 时序性"></a>2. 时序性</h4><p>为了提升DB模块的效率，通常我们会开个DB Worker Pool来完成实际的DB工作，但要考虑到同一个调用方的多个DB请求的时序性保证，最简单的实现是将来自同一个逻辑模块的DB请求全部交给同一个DB Worker来完成。</p>
<h4 id="3-深拷贝"><a href="#3-深拷贝" class="headerlink" title="3. 深拷贝"></a>3. 深拷贝</h4><p>由于对象需要交由DB模块来落地，因此需要对对象深拷贝(同步保存不需要)，也可以直接序列化为Bson之后再交给DB模块。</p>
<h4 id="4-事务支持"><a href="#4-事务支持" class="headerlink" title="4. 事务支持"></a>4. 事务支持</h4><p>就我目前的开发经验而言，GS逻辑中基本是用不到事务的，或者说，需要用到事务的地方，都可以通过其它方式绕过去，大部分时候，GS都只是将DB作为内存持久化工具，进行单文档读写操作，用不到复杂的多文档事务。</p>
<h3 id="五-总结"><a href="#五-总结" class="headerlink" title="五. 总结"></a>五. 总结</h3><p>这里只是简单提了下DB落地需要考虑的方方面面，在Model层设计上，应该赋予对象存储足够的灵活性，让对象自己根据存储时机，同异步去选择自己的存储方案和存储优化，对通用的存储方案，应该尽量抽象它们的操作，比如批量写，分组保存等。设计准则仍然是开发效率和灵活度优先，然后再是优化层面。具体实现上，还要结合具体的语言框架，比如对Go语言来说，由于其访问控制很弱，也没有Hook机制，因此对对象做脏标记要谨慎。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
      </tags>
  </entry>
  <entry>
    <title>一致Hash算法</title>
    <url>/2018/06/consistent-hashing/</url>
    <content><![CDATA[<h3 id="Hash算法"><a href="#Hash算法" class="headerlink" title="Hash算法"></a>Hash算法</h3><p>Hash算法本质是将一个值域(也称定义域，通常更大)映射到另一个值域(通常更小)，比如SHA-2，MD5等。Hash算法有一些共有特性，比如确定性，不可逆性。Hash算法被广泛应用于加密，Hash表，文件校验等领域。</p>
<p>分布式系统中常用Hash算法来进行任务分配，比如我们要设计一个分布式存储系统，通过Hash算法能够有序均匀地将N个任务分配到M个节点(Hash槽)上:</p>
<p><img src="/assets/image/201806/hash_sample.png" alt=""></p>
<span id="more"></span>
<p>这里的Hash算法的主要作用是将任务均摊到各个Hash槽中，比如我们有1000W份data和100个node，我们可以简单通过取MD5值再取余的方式来分配任务，代码实现<a href="https://github.com/wudaijun/consistent-hash/blob/master/normal_hash.py">normal_hash.py</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*- </span></span><br><span class="line"><span class="keyword">from</span> bisect <span class="keyword">import</span> bisect_left</span><br><span class="line"><span class="keyword">import</span> util</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NormalHash</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, NODES</span>):</span></span><br><span class="line">        self.NODES = NODES</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_node</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        h = util.<span class="built_in">hash</span>(data)</span><br><span class="line">        <span class="keyword">return</span> h % self.NODES</span><br></pre></td></tr></table></figure>
<p>在我们的分布式存储系统中，我们从两个方面来评估一个Hash算法:</p>
<ol>
<li>Hash算法分配是否均匀，即数据是否均匀地分布在各个节点上</li>
<li>当一个节点挂掉时，需要迁移(即前后Hash不一致)的数据量大小</li>
</ol>
<p>我写了个简单的测试用例来评估以上两项，代码实现<a href="https://github.com/wudaijun/consistent-hash/blob/master/test.py">test.py</a>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">NODES1      = <span class="number">100</span></span><br><span class="line">NODES2      = <span class="number">99</span></span><br><span class="line">DATAS       = <span class="number">10000000</span></span><br><span class="line"></span><br><span class="line">node_stat1 = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(NODES1)]</span><br><span class="line">node_stat2 = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(NODES2)]</span><br><span class="line">changes = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">// 在这里替换不同的Hash算法</span><br><span class="line">hash1 = NormalHash(NODES1)</span><br><span class="line">hash2 = NormalHash(NODES2)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> xrange(DATAS):</span><br><span class="line">    n1 = hash1.get_node(data)</span><br><span class="line">    node_stat1[n1] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    n2 = hash2.get_node(data)</span><br><span class="line">    node_stat2[n2] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> n1 != n2:</span><br><span class="line">        changes += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">util.printNodeStats(DATAS, NODES1, node_stat1)</span><br><span class="line">print(<span class="string">&quot;--- Node 99 Down: &quot;</span>, node_stat1[<span class="number">99</span>])</span><br><span class="line">util.printNodeStats(DATAS, NODES2, node_stat2)</span><br><span class="line">util.printChanges(DATAS, changes)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>针对我们的NormalHash，输出如下:</p>
<pre><code>Ave: 100000
Max: 100695     (0.69%)
Min: 99073      (0.93%)
--- Node[99] Down, Datas: 100212
Ave: 101010
Max: 101731     (0.71%)
Min: 100129     (0.87%)
Change: 9900142 (99.00%)
</code></pre><p>可以看到，基于MD5再取模的Hash算法能够很好地将1000W个任务均摊到各个节点上，但传统Hash存在一个问题，就是当Hash槽变动时，需要对所有关键字重新映射，并导致大量的任务迁移。我们的NormalHash迁移的数据条目数占总条目数的99%，而实际上需要迁移的数据量只有1%左右，也就是说，为了提升1%的可用性，我们需要迁移99%的数据，这无疑是很难接受的。而我们想要这样一种Hash算法，在节点变动时，已映射的条目尽可能不变，只需要迁移变更节点(故障节点或新增节点)上的数据，这就是一致性Hash算法的提出背景。</p>
<h3 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h3><p>以下是Wiki给出的一致Hash的定义:</p>
<blockquote>
<blockquote>
<p>一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对K/n 个关键字重新映射，其中K是关键字的数量， n是槽位数量。然而在传统的VNode表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。</p>
</blockquote>
</blockquote>
<h4 id="1-Ring-Hash"><a href="#1-Ring-Hash" class="headerlink" title="1. Ring Hash"></a>1. Ring Hash</h4><p>针对我们上个问题提出的需求，我们可以考虑一种实现：当节点挂掉时，将故障节点上的数据转移到另一个节点上去，其它已有节点和数据的映射不变，这样迁移的数据更少。为了快速找到某个节点的替代节点，可以将所有节点想象成一个环(ring)，每次我们找到这个节点在环上的后继节点:</p>
<p><img src="/assets/image/201806/hash_ring.png" alt=""></p>
<p>如图，当Node3挂掉时，其上的Data2将迁移到Node2。我们可以设计一个RingHash类，代码实现<a href="https://github.com/wudaijun/consistent-hash/blob/master/ring_hash.py">ring_hash.py</a>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RingHash</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, NODES</span>):</span></span><br><span class="line">        self.NODES = NODES</span><br><span class="line">        self.ring = []</span><br><span class="line">        self.hash2node = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> xrange(NODES):</span><br><span class="line">            h = util.<span class="built_in">hash</span>(n)</span><br><span class="line">            self.ring.append(h)</span><br><span class="line">            self.hash2node[h] = n</span><br><span class="line">        self.ring.sort()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_node</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        h = util.<span class="built_in">hash</span>(data)</span><br><span class="line">        n = bisect_left(self.ring, h) % self.NODES</span><br><span class="line">        <span class="keyword">return</span> self.hash2node[self.ring[n]]</span><br></pre></td></tr></table></figure>
<p>复用我们上面写的测试用例，看一下测试结果:</p>
<pre><code>Ave: 100000
Max: 596413     (496.41%)
Min: 103        (99.90%)
--- Node[99] Down, Datas: 65656
Ave: 101010
Max: 596413     (490.45%)
Min: 103        (99.90%)
Change: 65656   (0.66%)
</code></pre><p>如我们所料，现在迁移率更低了，只会迁移挂掉的节点上的那部分数据，将其移到其环上的下一个节点上。这种方案和NormalHash的本质不同在于RingHash基于范围，在NormalHash中，Hash槽变动会导致Hash环变小([0~99]-&gt;[0~98])，最终变更了数据落在环上位置，而在RingHash中，数据和节点落在Hash环上的位置是不变的(Hash环本身没变)，变更的是位置到节点的映射。<br>现在来看看RingHash的分配效果，出乎意料地差，节点间的数据量差距最大达6000倍。这是因为虽然1000W数据的Hash值分布仍然是相对均匀的，但100个节点的Hash值分布却不是(定义域太小)，这种环形算法在数据分配上面是不能满足需求的。这个算法还有一个问题，就是将故障节点上所有的数据都重新分配到了同一个节点，容易造成热点放大。</p>
<h4 id="2-Ring-Hash-Virtual-Node"><a href="#2-Ring-Hash-Virtual-Node" class="headerlink" title="2. Ring Hash + Virtual Node"></a>2. Ring Hash + Virtual Node</h4><p>为了让节点的Hash在环上相对分布均匀，我们可以让一个节点对应多个Hash值，即中间加一层虚拟节点(Virtual Node，以下简称VNode)，然后再由虚拟节点映射到真实节点(Node)。</p>
<p><img src="/assets/image/201806/hash_ring_vnode.png" alt=""></p>
<p>比如我们让每个Node对应100个VNode，一共10000个VNode的Hash值分布在环上，代码实现<a href="https://github.com/wudaijun/consistent-hash/blob/master/ring_hash_vnode.py">ring_hash_vnode.py</a>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RingHashVNode</span>:</span></span><br><span class="line">    VNODES = <span class="number">100</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, NODES</span>):</span></span><br><span class="line">        self.NODES = NODES</span><br><span class="line">        self.ring = []</span><br><span class="line">        self.hash2node = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> xrange(NODES):</span><br><span class="line">            <span class="keyword">for</span> vn <span class="keyword">in</span> xrange(RingHashVNode.VNODES):</span><br><span class="line">                <span class="comment"># 根据n和vn简单拼接得到新的独立k</span></span><br><span class="line">                <span class="comment"># 如n=88 vn=99，则拼接得到&quot;0880000000099&quot;</span></span><br><span class="line">                k = <span class="built_in">str</span>(n).zfill(<span class="number">3</span>) + <span class="built_in">str</span>(vn).zfill(<span class="number">10</span>)</span><br><span class="line">                h = util.<span class="built_in">hash</span>(k)</span><br><span class="line">                self.ring.append(h)</span><br><span class="line">                self.hash2node[h] = n</span><br><span class="line">        self.ring.sort()</span><br><span class="line">        self.ringlen = <span class="built_in">len</span>(self.ring)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_node</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        h = util.<span class="built_in">hash</span>(data)</span><br><span class="line">        n = bisect_left(self.ring, h) % self.ringlen</span><br><span class="line">        <span class="keyword">return</span> self.hash2node[self.ring[n]]</span><br></pre></td></tr></table></figure>
<p>统计分配情况:</p>
<pre><code>Ave: 100000
Max: 124605     (24.61%)
Min: 81856      (18.14%)
--- Node[99] Down, Datas: 116555
Ave: 101010
Max: 125236     (23.98%)
Min: 83320      (17.51%)
Change: 116555  (1.17%)
</code></pre><p>现在数据分配效果理想了很多，数据迁移量也达到最小，并且由于虚节点的存在，被迁移的数据项(分布在环的各个位置)会向就近的VNode迁移，最终相对均匀地落在各个Node上。 </p>
<h4 id="3-Ring-Hash-Fixed-HashVirtual-Node"><a href="#3-Ring-Hash-Fixed-HashVirtual-Node" class="headerlink" title="3. Ring Hash + Fixed HashVirtual Node"></a>3. Ring Hash + Fixed HashVirtual Node</h4><p>虚拟节点方案本质上通过VNode将节点Hash尽可能更均匀地分布在Hash环上，那么实际上我们可以将Hash环固定地分为N份(N个VNode)，再通过维护VNode到Node的映射来完成任务分配，这样在节点变更时，Hash环也是稳定的，代码实现<a href="https://github.com/wudaijun/consistent-hash/blob/master/ring_hash_fixed_vnode.py">ring_hash_fixed_vnode.py</a>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RingHashFixedVNode</span>:</span></span><br><span class="line">    VNODES  = <span class="number">10000</span> <span class="comment"># 将整个环分为VNODES份</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, NODES</span>):</span></span><br><span class="line">        self.NODES = NODES</span><br><span class="line">        self.ring = [] <span class="comment"># 下标为VNode 值为对应的Node</span></span><br><span class="line">        <span class="keyword">for</span> vn <span class="keyword">in</span> xrange(self.VNODES):</span><br><span class="line">            self.ring.append(vn%NODES)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_node</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        h = util.<span class="built_in">hash</span>(data)</span><br><span class="line">        vn = h%self.VNODES</span><br><span class="line">        <span class="keyword">return</span> self.ring[vn]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 某个节点挂掉了，将其数据手动均匀分到其它节点上</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">node_down</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        self.NODES -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> vn <span class="keyword">in</span> xrange(self.VNODES):</span><br><span class="line">            <span class="keyword">if</span> self.ring[vn] == n:</span><br><span class="line">                self.ring[vn] = vn % self.NODES</span><br></pre></td></tr></table></figure>
<p>注意到当节点变更之后，我们需要根据当前的VNode-&gt;Node的映射进行变更，因此两次Hash不是独立的，在测试时，我们需要这样生成两次对比的Hash算法:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hash1 = RingHashFixedVNode(NODES1)</span><br><span class="line">hash2 = RingHashFixedVNode(NODES1)</span><br><span class="line">hash2.node_down(DOWN_NODE_ID)</span><br></pre></td></tr></table></figure>
<p>测试结果为:</p>
<pre><code>Ave: 100000
Max: 100695     (0.69%)
Min: 99073      (0.93%)
--- Node 99 Down, Datas: 100212
Ave: 101010
Max: 102381     (1.36%)
Min: 100087     (0.91%)
Change: 100212  (1.00%)
</code></pre><p>这个算法不仅数据分配更均匀(1000个固定VNode，比RingHashVNode的10000个VNode分配情况要好得多)，数据迁移量也最少，并且计算上也会更快，因为不需要计算VNode的Hash，也不需要基于范围进行<code>bisect_left</code>插入排序操作，在VNode层级，它和普通Hash一样简单快捷，在节点变更时，变更的只是VNode-&gt;Node的映射，并且通过手动维护这份映射(而不是再次通过自动取余等操作)，将数据迁移降到最低。</p>
<p>RingHashFixedVNode还有一定的优化空间，比如通过将VNode个数设为2的幂，以通过位运算(&lt;&lt;)来取代取余(%)操作等。这里不再赘述。</p>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>hash</tag>
      </tags>
  </entry>
  <entry>
    <title>Go package和goroutine的一些理解和实践</title>
    <url>/2018/07/go-package-goroutine-practice/</url>
    <content><![CDATA[<p>Go的package和goroutine，前者组织Go程序的静态结构，后者形成Go程序的动态结构，这里谈谈对这两者的一些理解和实践。</p>
<h3 id="一-package-管理"><a href="#一-package-管理" class="headerlink" title="一. package 管理"></a>一. package 管理</h3><h4 id="1-package-布局"><a href="#1-package-布局" class="headerlink" title="1. package 布局"></a>1. package 布局</h4><p>分包的目的是划分系统，将系统划分为一个个更小的模块，更易于理解，测试和维护。如何组织Go项目的包结构，是大多数Go程序员都遇到过的问题，各个开源项目的实践可能也并不相同。以下是几种常见分包方案。</p>
<h5 id="单一Package"><a href="#单一Package" class="headerlink" title="单一Package"></a>单一Package</h5><p>适用于小型应用程序，无需考虑循环依赖等问题。但在Go中，同一个Package下的类和变量是没有隐私可言的，C++/Java可以在同一个文件中通过Class实现访问控制，但是Go不可以。因此随着项目代码规模增长(超过10K <a href="https://en.wikipedia.org/wiki/Source_lines_of_code">SLOC</a>，代码维护和隔离将变得非常困难。</p>
<span id="more"></span>
<h5 id="按功能模块纵向划分"><a href="#按功能模块纵向划分" class="headerlink" title="按功能模块纵向划分"></a>按功能模块纵向划分</h5><p>按照功能模块纵向划分可能是最容易想到的一种方案，比如玩家/地图/公会，这种划分方案主要的问题之一在于循环依赖，比如玩家包和公会包之间可能相互引用，这个时候通常的做法要么是通过控制反转(依赖注入/查找)，或者观察者模式等设计模式解耦，要么就为其中一个包抽出一个接口包，将A-&gt;B-&gt;A的关系变为IA-&gt;B-&gt;A。随着包增多，交互的复杂，包依赖关系的维护也会变成负担。</p>
<h5 id="MVC横向划分"><a href="#MVC横向划分" class="headerlink" title="MVC横向划分"></a>MVC横向划分</h5><p>Rails风格布局，至今仍然在很多HTTP框架中流行，它之所以适用于HTTP，是因为HTTP框架交互流程相对单一且明确(Request-Response)，而对于GS来说，交互流程则要复杂得多，客户端，Timer，RPC调用等等。因此最终往往做成了Fat Controller/Thin Model，导致绝大部分逻辑都堆在Controller层。循环引用的问题仍然可能存在。</p>
<h5 id="按照依赖划分"><a href="#按照依赖划分" class="headerlink" title="按照依赖划分"></a>按照依赖划分</h5><p>这是Go标准库最常用的方案，比如<code>io.Reader/Writer/Closer</code>接口，字符串读取(bytes.Reader/strings.Reader)，文件读取(os.File)，网络读取(net.Conn)等都实现了io.Reader接口，我们在使用读取相关功能的时候，只需要导入io接口包和对应的Reader实现包(如os.File)即可。这种模型的主要思维按照依赖进行划分:</p>
<ul>
<li>root包: 声明原型和接口，不包含实现。root包本身不依赖任何包。比如这里的io包。</li>
<li>implement包: 对root包中的接口使用和实现。比如这里的os，net，strings等。</li>
<li>main包: 导入root包和implement包，以root包接口为原型，实现对implement的桥接和依赖注入。</li>
</ul>
<p>这种布局有几个好处:</p>
<ol>
<li>按照依赖划分，更容易适应重构和需求变更</li>
<li>将依赖独立出去，代码变得很容易测试，比如很容易实现一个模拟DB操作的dep包，而业务逻辑无需任何变更</li>
<li>以接口为契约的包划分，要比直接包划分有更清晰的交互边界，前面提到的两种包划分，做得不好很容易最终只是将代码分了几个目录存放，实际交互仍然混乱(比如直接修改其它包数据)</li>
</ol>
<p>这种布局其实有点像前面提到的以接口包的形式将A-&gt;B-&gt;A的关系变为IA-&gt;B-&gt;A，后者针对局部关系，而依赖划分强调从整体上思考这个功能模块的原型，然后围绕这些原型(接口)去扩展实现，最后在main包中将这些实现组装起来。关于这种包布局在<a href="https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1">这篇文章</a>有很好的阐述。</p>
<p>以上几种分包的方式都有其适用情形，就我们项目而言，目前这几种布局方案都在用，按依赖划分相比其它方案而言，对开发人员的业务理解能力更高，我们将其应用到战斗，DB，网络等通用模块，而对于普通业务逻辑，按照功能划分即可，毕竟业务逻辑的抽象是变化很快并且极不稳定的。另外，分包最好主要从模块关系出发，不要以代码量为主要考量，否则包关系只会剪不断，理还乱。</p>
<h4 id="2-不要用package-init"><a href="#2-不要用package-init" class="headerlink" title="2. 不要用package init()"></a>2. 不要用package init()</h4><p>init函数依赖于包的导入顺序，并且一个包还可能有多个init函数，通过它来做一些初始化会让整个调用流程不可控，并且让包的导入具有副作用(比如<a href="https://golang.org/pkg/net/http/pprof/">net/http/pprof</a>的<a href="https://github.com/golang/go/blob/dev.boringcrypto.go1.9/src/net/http/pprof/pprof.go#L71">init()</a>便会影响http.DefaultClient的Handler，个人并不认同这种做法)。所有包的初始化应该显式指定，包的导入应该没有副作用。</p>
<h4 id="3-适当应用internal包"><a href="#3-适当应用internal包" class="headerlink" title="3. 适当应用internal包"></a>3. 适当应用internal包</h4><p>对于一些比较复杂的包，将那些外部不可见的逻辑，变量声明等放到<a href="https://golang.org/doc/go1.4#internalpackages">internal包</a>中，这样internal包下的导出内容和子包只能被其父目录引用，起到一定程度的访问控制，包的使用者也更容易理解，这可能也是Go觉得包的访问控制实在是太弱了才加上的，但目前好像很少有项目用这个特性，即使它看起来是无害的。关于包的访问限制，这里有篇<a href="http://colobu.com/2017/05/12/call-private-functions-in-other-packages/">如何访问package私有函数</a>比较有意思，可以了解一下。</p>
<h3 id="二-再谈-goroutine"><a href="#二-再谈-goroutine" class="headerlink" title="二. 再谈 goroutine"></a>二. 再谈 goroutine</h3><p>我在<a href="http://wudaijun.com/2018/07/gs-flexiblity-reliability/">谈谈架构灵活性和可靠性</a>里已经提到过goroutine的一些实践，这里再啰嗦几句，为什么我对goroutine的规范使用如此重视。</p>
<p>goroutine本身只是执行体，并不包含其消息上下文，错误处理以及生命周期管理，Go语言给了开发者最大的灵活度去实现自己的并发模型和流控，这也是CSP模型的长处(参考<a href="http://wudaijun.com/2017/05/go-vs-erlang/">CSP vs Actor</a>)，但对开发者而言，日常会用到的并发模型其实就那么几种: Actor，生产者-消费者，线程池，扇入-扇出等，比如逻辑开发大多数时候需求可能都只是并发执行一个Task，Task完成后在调用方的上下文中执行回调函数: <code>go(task func(), cb func())</code>，而具体这个Task goroutine它的错误处理和生命周期开发者并不关心，交给开发者自己去实现也很容易出错，比如创建出一个没有错误处理和终止条件的goroutine，最终导致轻则导致goroutine泄露，重则因为不知道那个小功能上创建出的goroutine panic没有被defer，然后整个节点就挂了。</p>
<p>Go反复给开发者强调”goroutine is cheap”，让开发者觉得使用goroutine非常简单，无非就是普通函数前面加个<code>go</code>，而实际上goroutine创建是很便宜，但是没有管理好goroutine的代价可不一定便宜。这也是为什么现在的高级语言都有自己的轻量级线程和协程，而不直接使用OS线程的原因，因为原生的OS线程做错误处理和生命周期管理比较困难。而Go的<code>go</code>原语，还是一个非常底层的并发原语，它加上channel能够实现任何并发模型，这就像是指针，goto和手动GC一样，足够强大，但也太锋利，用不好会割手。在Erlang OTP里面，Process包含了消息上下文(mailbox)，错误处理，它在灵活性上可能不如CSP，但大部分用起来却更省心。</p>
<p>谈到<code>go</code>并发原语，前几天读到<a href="https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/">一篇文章</a>，非常有意思，作者将现代并发原语(如<code>go</code>, <code>CreateThread</code>等)比作当今时代的goto，核心依据如下:</p>
<ol>
<li>go和goto一样，容易破坏函数的黑盒封装</li>
<li>没了黑盒，也就没有了易读性，可维护性</li>
<li>没了黑盒，也就丢失了很多语言级高级特性(比如<code>RAII</code>，python的<code>with...as</code>)</li>
<li>没了黑盒，也做不好错误处理和错误传递</li>
</ol>
<p>作者认为<code>goto</code>是从汇编到高级语言的过渡产物，而<code>go</code>则是如今并发编程时代的过渡产物，参考<code>goto</code>的解决方案，作者认为应该提供一些更高级的并发原语替换<code>go</code>，亦如当初用if,for等控制语句替换<code>goto</code>，最后作者安利了一下自己的并发库<a href="https://trio.readthedocs.io/en/latest/">Trio</a>，大概应该是将线程的生命周期管理做到了框架中，以尽可能地保留函数的黑盒理念及其带来的好处。原文比较冗长，作者的眼界确实很广，且不论Trio这个东东到底怎么样，文中的大部分观点我都比较认同，并且得到了很多启发，技术发展的趋势是越来越易于使用，越来越按照人而不是计算机的方式来思考和解决问题。</p>
<p>收回对未来的展望，回到我们的goroutine，在使用过程中，框架应该尽可能对goroutine封装，比如Actor，异步任务，让外部逻辑易于使用，在手动创建goroutine时，将消息上下文，错误处理，生命周期等一并考虑进来，作为一个整体来设计和考量。</p>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Javascript 中的异步编程</title>
    <url>/2018/07/javascript-async-programing/</url>
    <content><![CDATA[<p>简单聊聊Web前端(主要是JS)中的几种异步编程机制和范式，由于JS是单线程的(事实上，几乎所有的前端或GUI框架都是单线程的，如Unity，WPF等)，因此要提高效率，要么新建线程(如Web Worker)，要么就只能异步。由于UI框架的大部分数据都不是线程安全的，如JS中的DOM对象便不支持并发访问，因此新建线程能分担的事情比较有限(如CPU密集运算或IO)，因此单线程异步编程模型成为了JS中的核心编程模型。下面来聊聊JS中异步编程模型演进史。</p>
<h4 id="Callback"><a href="#Callback" class="headerlink" title="Callback"></a>Callback</h4><p>Callback 在 JS 中无处不在，Ajax，XMLHttpRequest 等很多前端技术都围绕回调展开，比如创建一个 Button: <code>&lt;button onclick=&quot;myFunction()&quot;&gt;Click me&lt;/button&gt;</code>。回调的优点是简单易于理解和实现，其最大的缺点是调层数过深时，代码会变得非常难维护(所谓回调地狱，Callback Hell):</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 为了便于测试，通过setTimeout模拟  fs.readFile(file, cb) 读取文件操作</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">MyReadFile</span>(<span class="params">file, cb</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">setTimeout</span>(<span class="function">()=&gt;</span>&#123;</span><br><span class="line">          cb(<span class="literal">null</span>, <span class="string">&quot;filecontent: &quot;</span>+file) <span class="comment">// 将err设为null，模拟读取到文件内容为 filecontent + filename</span></span><br><span class="line">          &#125;, <span class="number">100</span>) <span class="comment">// 模拟读取文件需要100ms</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">MyReadFile(<span class="string">&quot;abc.txt&quot;</span>, <span class="function">(<span class="params">err1, filedata1</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(filedata1);</span><br><span class="line">  MyReadFile(<span class="string">&quot;xyz.txt&quot;</span>, <span class="function">(<span class="params">err2, filedata2</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(filedata2)</span><br><span class="line">    <span class="comment">// MyReadFile( ... )</span></span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>使用Callback需要注意的一个问题是闭包引用可变上下文的问题: 当执行异步回调(闭包)时，闭包引用的外部局部变量可能已经失效了(典型地，比如对应的对象在容器中已经被删除了)，此时闭包会读写无效的数据，产生非预期的结果，且较难调试:</p>
<span id="more"></span>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> objs = &#123;<span class="number">123</span>: &#123;<span class="attr">name</span>: <span class="string">&quot;abc&quot;</span>&#125;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">test</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  	<span class="keyword">var</span> obj = objs[<span class="number">123</span>];</span><br><span class="line">	<span class="built_in">setTimeout</span>(<span class="function">()=&gt;</span>&#123;</span><br><span class="line">      obj[<span class="string">&quot;name&quot;</span>] = <span class="string">&quot;xyz&quot;</span>;	<span class="comment">// 这个时候obj已经从objs中移除了，对它的读写没有意义，并且可能导致非预期后果</span></span><br><span class="line">    &#125;, <span class="number">1000</span>);</span><br><span class="line">  	<span class="keyword">delete</span> objs[<span class="number">123</span>];</span><br><span class="line">  	<span class="built_in">console</span>.log(objs);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">test();</span><br></pre></td></tr></table></figure>
<p>闭包引用可变上下文的问题对JS而言，不是很明显，毕竟前端的业务和数据模型相对简单，造成的后果也通常只是显示层的。但对后端而言，由于涉及到数据存储和强状态性，对这类问题需要更谨慎细致，比如尽可能只在回调上下文中使用值语义对象(如上例中的ObjID 123)，在回调中重新获取引用对象，确保操作结果如预期。</p>
<p>Callback是一种非常简单直观的异步编程模型，不过要在JS中充分发挥作用，还需要JS框架底层的支持，如对Timer、Network、File这种重CPU或IO的模块的封装和集成(到主线程消息泵)。Callback到目前仍然是异步编程模型最主流的方案。</p>
<h4 id="Generator-Thunk-异步"><a href="#Generator-Thunk-异步" class="headerlink" title="Generator + Thunk 异步"></a>Generator + Thunk 异步</h4><p>在JS中，通过迭代器(Iterator)和(Generator)可以实现类似协程的执行权转移和值交换逻辑:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Generator 生成器</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> *<span class="title">numberGenerator</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> a = <span class="keyword">yield</span> <span class="number">1</span>; <span class="comment">// a = 4</span></span><br><span class="line">    <span class="keyword">let</span> b = <span class="keyword">yield</span> <span class="number">3</span>; <span class="comment">// b = 6</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">5</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Iterator 迭代器</span></span><br><span class="line"><span class="keyword">const</span> g = numberGenerator() <span class="comment">// Generator创建之后默认是暂停的，需要手动调用next让其开始执行</span></span><br><span class="line"><span class="keyword">const</span> iter1 = g.next(<span class="number">2</span>)   <span class="comment">// iter1 = &#123;value: 1, done: false&#125;</span></span><br><span class="line"><span class="keyword">const</span> iter2 = g.next(<span class="number">4</span>)   <span class="comment">// iter2 = &#123;value: 3, done: false&#125;</span></span><br><span class="line"><span class="keyword">const</span> iter3 = g.next(<span class="number">6</span>)   <span class="comment">// iter3 = &#123;value: 5, done: true&#125;</span></span><br></pre></td></tr></table></figure>
<p>我在<a href="https://wudaijun.com/2015/01/lua-coroutine/">Lua协程</a>中简单介绍了协程的基本概念和Lua中的协程，JS的Generator和Lua协程的概念看起来类似，其JS yield对应Lua yield，JS <code>g.next()</code>对应Lua <code>resume(g)</code>，且都具备双向传值的能力。但通过Generator+Iterator方式实现的协程，与Lua这种支持运行时堆栈保存的协程，还是有一定的区别的，典型地，Lua协程可以跨越函数堆栈，从yield方直接返回到resume方(yield可以在函数嵌套很深的地方)，而JS中，yield只代表当前函数立即返回，即只能返回到持有当前函数的迭代器方(每一层Generator调用都需要单独处理迭代)。因此，个人认为，JS还不能称为支持协程，只能说支持Generator或生成器，以和Lua这种运行时支持的协程做区分。</p>
<p>在JS中，Generator通常和异步联系在一起，而前面说了，Generator还不能算作完全体协程，它是怎么与异步联系在一起的呢，先看个例子:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 为了便于测试，通过setTimeout模拟  fs.readFile(file, cb) 读取文件操作</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">MyReadFile</span>(<span class="params">file, cb</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">setTimeout</span>(<span class="function">()=&gt;</span>&#123;</span><br><span class="line">          cb(<span class="literal">null</span>, <span class="string">&quot;filecontent: &quot;</span>+file) <span class="comment">// 将err设为null，模拟读取到文件内容为 filecontent + filename</span></span><br><span class="line">          &#125;, <span class="number">100</span>) <span class="comment">// 模拟读取文件需要100ms</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Thunk</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">MyReadFileThunk</span>(<span class="params">file</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function">(<span class="params">cb</span>) =&gt;</span> &#123;</span><br><span class="line">    MyReadFile(file, cb);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> gen = <span class="function"><span class="keyword">function</span>* (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> fileData1 = <span class="keyword">yield</span> MyReadFileThunk(<span class="string">&quot;abc.txt&quot;</span>);</span><br><span class="line">    <span class="built_in">console</span>.log(fileData1);</span><br><span class="line">    <span class="keyword">const</span> fileData2 = <span class="keyword">yield</span> MyReadFileThunk(<span class="string">&quot;xyz.txt&quot;</span>);</span><br><span class="line">    <span class="built_in">console</span>.log(fileData2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// --- 手动单步迭代</span></span><br><span class="line"><span class="comment">// function run(g) &#123;</span></span><br><span class="line"><span class="comment">//   g.next().value((err1, filedata1)=&gt;&#123;</span></span><br><span class="line"><span class="comment">//    g.next(filedata1).value((err2, filedata2)=&gt;&#123;</span></span><br><span class="line"><span class="comment">//        g.next(filedata2);</span></span><br><span class="line"><span class="comment">//      &#125;);</span></span><br><span class="line"><span class="comment">//   &#125;)</span></span><br><span class="line"><span class="comment">// &#125; </span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 循环自动迭代，与前面手动单步迭代得到的结果一样</span></span><br><span class="line"><span class="comment">// 但自动迭代，依赖于每个yield后的异步回调格式是一样的，在本例中，异步结果都是(err, string)=&gt;&#123;...&#125;</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">run</span>(<span class="params">g</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> next = <span class="function">(<span class="params">err, filedata</span>) =&gt;</span> &#123;   <span class="comment">// 这里暂不考虑err错误处理</span></span><br><span class="line">    <span class="keyword">let</span> iter = g.next(filedata); <span class="comment">// 首次调用: 启动Generator 非首次调用: 异步文件读取完成，将执行权和filedata交还给yield</span></span><br><span class="line">    <span class="keyword">if</span> (iter.done) <span class="keyword">return</span>;       <span class="comment">// 如果generator迭代完成，即gen()函数执行完所有的yield语句，则终止流程，这里首次调用时为false</span></span><br><span class="line">    iter.value(next);            <span class="comment">// 这里iter.value本身是MyReadFileThunk函数返回的MyReadFile单回调参数版本(filename参数已经被偏特化了)，本例中，类似于MyReadFile_abc，MyReadFile_xyz，将next作为异步文件读取的callback传给MyReadFile_abc，开始真正的异步文件读取操作</span></span><br><span class="line">  &#125;</span><br><span class="line">  next();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">run(gen());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果:</span></span><br><span class="line"><span class="comment">// &quot;filecontent: abc.txt&quot;</span></span><br><span class="line"><span class="comment">// &quot;filecontent: xyz.txt&quot;</span></span><br></pre></td></tr></table></figure>
<p>如此对于gen函数而言，异步操作的结果会作为yield的返回值传回，yield之后的语句可以直接使用它，而无需再写回调函数(避免了回调地狱)，达成了<strong>像写同步代码一样写异步代码</strong>的目的。从实现的角度来说，这套方案依赖于四个要素:</p>
<ol>
<li>Generator: 支持多段式函数返回，并具备双向传值能力</li>
<li>AsyncOp: 底层的异步操作支持 (如上面的setTimeout，JS会保证超时时间到了后，回调会在主线程触发)</li>
<li>Thunk: Thunk的本质是偏函数，它将注入回调的职责从原本的异步操作中剥离出来，作为yield的返回值传给迭代器方</li>
<li>Iterator: 也就是本例中的run函数，它为Thunk后的函数注入回调函数并执行真正的异步操作，在异步操作完成后，将异步结果传回yield</li>
</ol>
<p>其中Generator和AsyncOp由JS框架提供，Thunk可以使用<a href="https://www.npmjs.com/package/thunkify">thunkify</a>，Iterator可以使用<a href="https://www.npmjs.com/package/co">co</a>，都有现成的轮子，使用thunkify和co之后的MyReadFile如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var co &#x3D; require(&#39;co&#39;);</span><br><span class="line">var thunkify &#x3D; require(&#39;thunkify&#39;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 使用thunkify库替换掉上例手写的Thunk函数</span><br><span class="line">&#x2F;&#x2F; 注: thunkify要求MyReadFile的最后一个参数为callback</span><br><span class="line">var MyReadFileThunk &#x3D; thunkify(MyReadFile);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; ... MyReadFile + gen 定义</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 使用co库替换掉上例手写的run函数，一键执行</span><br><span class="line">&#x2F;&#x2F; 注: co库规范要求异步操作Callback的第一个参数为err，这也是上例中保留 callback(err, fileData) 中的 err 的原因</span><br><span class="line">co(gen);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>thunkify和co的实现和上例手写的Thunk和Iterator类似，它们进一步提升了基于JS Generator的异步编程能力。</p>
<h4 id="Promise"><a href="#Promise" class="headerlink" title="Promise"></a>Promise</h4><p>Promise 是 JS 异步编程中，比回调函数更高级的解决方案。简单来说，Promise 是一个对象，保存着某个异步操作的状态(进行中 pending, 已成功 fulfilled，已失败 rejected)以及回调函数信息(成功回调，错误回调)，Promise旨在以统一，灵活，更易于维护的方式来处理所有的异步操作。仍然以MyReadFile为例，我们可以将Thunk版本的gen函数，用Promise的方式重写:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function MyReadFilePromise(file) &#123;</span><br><span class="line">  return new Promise(function(resolve, reject)&#123;</span><br><span class="line">    &#x2F;&#x2F; resolve 和 reject 由JS引擎提供，用于(也只有它们能)更改 Promise 对象状态</span><br><span class="line">    &#x2F;&#x2F;当异步代码执行成功时，我们才会调用resolve(...), 当异步代码失败时就会调用reject(...)</span><br><span class="line">    &#x2F;&#x2F;在本例中，我们使用setTimeout(...)来模拟异步代码，实际编码时可能是XHR请求或是HTML5的一些API方法.</span><br><span class="line">    MyReadFile(file, (err, data)&#x3D;&gt;&#123;</span><br><span class="line">      if (err !&#x3D; null) &#123;reject(err)&#125;;</span><br><span class="line">      resolve(data)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; then()函数第一个参数是异步操作成功(通过resolve返回)时的回调</span><br><span class="line">&#x2F;&#x2F; 第二个参数(可选)是异步操作失败(通过reject返回)时的回调</span><br><span class="line">MyReadFilePromise(&quot;abc.txt&quot;).then((filedata1)&#x3D;&gt;&#123;</span><br><span class="line">  console.log(filedata1)</span><br><span class="line">  return MyReadFilePromise(&quot;xyz.txt&quot;);</span><br><span class="line">&#125;).then((filedata2)&#x3D;&gt;&#123;</span><br><span class="line">  console.log(filedata2)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>Promise详细介绍可以参考<a href="http://es6.ruanyifeng.com/#docs/promise">ES6教程</a>。简单归纳，Promise 对象有如下特性:</p>
<ol>
<li>Promise 对象中的状态只受异步操作结果影响，并且状态只会变化一次(pending-&gt;fulfilled 或 pending-&gt;rejected)</li>
<li>允许延迟挂接回调函数，即在Promise 状态变更之后挂上去的回调函数，也会立即执行(当然得状态匹配)</li>
<li>能将嵌套回调(又名: 回调地狱)优化为链式回调</li>
<li>尝试用统一的语义和接口来使用异步回调，甚至可以用到同步函数上</li>
</ol>
<p>Promise 的出现对JS异步编程的重要性不言而喻，它在之前单一的Callback模式上，尝试对异步操作进行更高层次的抽象(如异步状态管理、错误处理规范、将异步调用和挂载回调解耦等，让异步代码的书写简洁易读。Promise将回调嵌套升级为回调链(<code>a.then(xxx).then(yyy)</code>)之后，虽然可读性提高了，但你可能还是觉得好像没有上一节Thunk+yield+co来得直接，没关系，Promise也可以yield+co配套:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> co = <span class="built_in">require</span>(<span class="string">&#x27;co&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span>* <span class="title">gen</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  filedata1 = <span class="keyword">yield</span> MyReadFilePromise(<span class="string">&quot;abc.txt&quot;</span>);</span><br><span class="line">  <span class="built_in">console</span>.log(filedata1);</span><br><span class="line">  filedata2 = <span class="keyword">yield</span> MyReadFilePromise(<span class="string">&quot;xyz.txt&quot;</span>);</span><br><span class="line">  <span class="built_in">console</span>.log(filedata2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 手写模拟co(gen)流程，仍然忽略错误处理</span></span><br><span class="line"><span class="comment">// function run(g) &#123;</span></span><br><span class="line"><span class="comment">//   const next = (err, filedata) =&gt; &#123;  </span></span><br><span class="line"><span class="comment">//     let iter = g.next(filedata); </span></span><br><span class="line"><span class="comment">//     if (iter.done) return;      </span></span><br><span class="line"><span class="comment">//     iter.value.then((data)=&gt;&#123; // 主要的区别: 这里的iter.value是Promise，通过.then挂载回调，而再是Thunk版本的iter.value(next)</span></span><br><span class="line"><span class="comment">//       next(null, data);</span></span><br><span class="line"><span class="comment">//     &#125;); </span></span><br><span class="line"><span class="comment">//   &#125;</span></span><br><span class="line"><span class="comment">//   next();</span></span><br><span class="line"><span class="comment">// &#125;</span></span><br><span class="line"><span class="comment">// run(gen());</span></span><br><span class="line"></span><br><span class="line">co(gen);</span><br></pre></td></tr></table></figure>
<p>在这个例子中，co扮演Iterator，Promise同时作为AsyncOp和Thunk，这也是Promise作为异步操作统一规范的好处。</p>
<h4 id="async-await"><a href="#async-await" class="headerlink" title="async/await"></a>async/await</h4><p>前面提到的Generator异步编程四要素: Generator、Thunk、AsyncOp、Iterator，其中前三个都被JS Generator + Promise原生支持了，虽然Iterator也有co这种简单又好用的库，但终究还不够完美，因此async/await诞生了，它被称为JS异步编程的终极方案:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// async 声明异步函数 (类似前面的gen函数)</span></span><br><span class="line"><span class="comment">// 声明 async 的函数才可以使用 await，并且async函数会隐式返回一个Promise(因为await本质是yield，会让出所有权，所以调用方只能异步等待async函数执行结束)，因此async函数本身也可以被await</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">test</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">	<span class="comment">// 使用 await 替代 yield</span></span><br><span class="line">    <span class="keyword">const</span> filedata = <span class="keyword">await</span> MyReadFilePromise(<span class="string">&#x27;abc.txt&#x27;</span>);</span><br><span class="line">    <span class="built_in">console</span>.log(filedata);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;OK&#x27;</span>; <span class="comment">// /本质返回的是: Promise &#123;&lt;resolved&gt;: &#x27;OK&#x27;&#125;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 无需再单独手写或者使用co库作为Iterator，当调用test()方法时，整个Iterator将由JS框架托管执行。</span></span><br></pre></td></tr></table></figure>
<p>在理解前面的<code>Generator+Thunk+AsyncOp+Iterator</code>以及<code>Generator+Promise+Iterator</code>异步编程方案之后，其实你应该能想到，async/await 并不算是新技术，而是基于<code>Generator+Promise+Iterator</code>方案的语法糖，其中async对应Generator的*函数声明，await对应yield，然后在框架底层帮你实现了Iterator(当然要比我们前面手写的版本复杂一些，比如错误处理机制)。如此Generator异步四要素，都在框架原生支持了。</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>总结，本文从初学者角度对JS中异步编程模型演变史进行了大致梳理，按照个人的理解，大概可以分为以下四个阶段:</p>
<ul>
<li>Callback + AsyncOp</li>
<li>Generator + Thunk + AsyncOp + Iterator</li>
<li>Generator + Promise(=Thunk+AsyncOp) + Iterator</li>
<li>async/await(=Generator+Iterator) + Promise(=Thunk+AsyncOp)</li>
</ul>
<p>在理解和学习异步的时候，将异步和并发两个概念区分开是尤其重要的，异步并不一定意味着并发(如JS setTimeout)，反之亦然。如Web前端、Unity、WPF这类前框框架基本都是单线程的(UI层的东西，想要并发太难)，因此通过异步提升单线程的性能是框架和开发者首选解决方案，而让异步编程模型更易用易读，也是前端框架演变的一个方向。</p>
<p>除了 JS 外，Python3.5, .NET4.5 也引入了 asyc/await 特性，不出意外，这会成为 Web 中的主流异步开发模型。比如 Python twisted 框架示例:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> twisted.internet.defer <span class="keyword">import</span> ensureDeferred</span><br><span class="line"><span class="keyword">from</span> twisted.logger <span class="keyword">import</span> Logger</span><br><span class="line">log = Logger()</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">getUsers</span>():</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> json.loads(<span class="keyword">await</span> makeRequest(<span class="string">&quot;GET&quot;</span>, <span class="string">&quot;/users&quot;</span>))</span><br><span class="line">    <span class="keyword">except</span> ConnectionError:</span><br><span class="line">        log.failure(<span class="string">&quot;makeRequest failed due to connection error&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do</span>():</span></span><br><span class="line">    d = ensureDeferred(getUsers())</span><br><span class="line">    d.addCallback(<span class="built_in">print</span>)</span><br><span class="line">    <span class="keyword">return</span> d</span><br></pre></td></tr></table></figure>
<p>这里的 async/await 关键字的意义与 JS 中的类似，<a href="https://twistedmatrix.com/documents/current/core/howto/defer-intro.html">Defer 对象</a>则是类似 JS Promise 的东西，用于保存异步执行结果，挂载回调。同样，C#的也有类似JS Promise的概念，叫Task。语言和框架总是有很多共性，识别和理解这类共性(通常也叫做模型/范式)，是一个非常好的提升技术认知，构建知识体系的机会。</p>
]]></content>
      <categories>
        <category>js</category>
      </categories>
      <tags>
        <tag>coroutine</tag>
        <tag>async programing</tag>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title>谈谈架构灵活性和可靠性</title>
    <url>/2018/07/gs-flexiblity-reliability/</url>
    <content><![CDATA[<p>如果给你一个服务器框架，你如何评估这个框架？不同的人可能有不同的维度和优先级，比如性能，可维护性，可扩展性，可用性，可靠性等等等等，目前已经有相对成熟的几种<a href="http://xhrong.github.io/2017/10/08/%E8%BD%AF%E4%BB%B6%E8%B4%A8%E9%87%8F%E6%A8%A1%E5%9E%8B/">软件质量评估方案</a>。其中McCall软件评估模型(1977)比较有意思:</p>
<p><img src="/assets/image/201807/McCall.png" alt=""></p>
<p>产品修正: 开发视角，反映系统应对变更的能力<br>产品运行: 用户视角，产品稳定性，效率，易用性等<br>产品转移: 运维视角，可移植性，组件复用性等</p>
<span id="more"></span>
<p>对于服务器而言，有跨平台语言和Docker等技术的加持，产品转移已经变得非常容易，我这里主要结合项目实践以及对Go和Erlang的一些理解，谈谈产品修正中的可扩展性/可维护性以及产品运行中的可靠性。</p>
<h3 id="一-可维护性-可扩展性"><a href="#一-可维护性-可扩展性" class="headerlink" title="一. 可维护性/可扩展性"></a>一. 可维护性/可扩展性</h3><p>反映软件适应“变化”的能力。调整、修改或改进正在运行的软件系统以适应新需求或者需求变更的难易程度。</p>
<h4 id="正交设计"><a href="#正交设计" class="headerlink" title="正交设计"></a>正交设计</h4><p>要达成可扩展性，正交是一个非常重要的概念，一个可扩展性好的系统必定是正交的。关于正交，我找到一个很好的例子来帮助理解:</p>
<p>非正交代码：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>客户需求</th>
<th>代码实现</th>
</tr>
</thead>
<tbody>
<tr>
<td>(1 2 3)</td>
<td>(1 2 3)</td>
</tr>
<tr>
<td>(6 5 4)</td>
<td>(1 2 3)+(5 3 1)=(6 5 4)</td>
</tr>
<tr>
<td>(3 6 9)</td>
<td>(6 5 4)+(-3 1 5)=(3 6 9)</td>
</tr>
</tbody>
</table>
</div>
<p>正交代码：</p>
<p>x = (1 0 0)<br>y = (0 1 0)<br>z = (0 0 1)</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>客户需求</th>
<th>代码实现</th>
</tr>
</thead>
<tbody>
<tr>
<td>(1 2 3)</td>
<td>x+2y+3z</td>
</tr>
<tr>
<td>(6 5 4)</td>
<td>6x+5y+4z</td>
</tr>
<tr>
<td>(3 6 9)</td>
<td>3x+6y+9z</td>
</tr>
</tbody>
</table>
</div>
<p>正交是软件工程中非常重要的一个概念，它将一个系统拆分为多个互不依赖的维度，每个维度可以独立变化，整个系统变得更容易理解。正交的优点很多，比如易于测试，维护，可复用程度高，更能够适应变化等等。在我看来，绝大部分软件设计理念都是围绕如何更好地拆分系统，达成正交而产生的，比如面向对象的设计模式，MVC，消息中间件，微服务架构等等，都是从不同的角度来达成软件的正交性。</p>
<p>正交的基本手段仍然是封装和解耦，复用，只是说封装角度(功能模块，公用流程，变化程度等)，解耦方式(组合，中间件，RPC等)，以及复用粒度(函数，类，组件，节点等)的区别，比如设计模式，重点讲的是在类级别上，如何封装变化和解耦依赖，MVC侧重封装的角度(按照变更特性)，消息中间件侧重解耦的方式，微服务则侧重解耦(服务发现)和复用粒度(服务)。</p>
<h4 id="正交实践"><a href="#正交实践" class="headerlink" title="正交实践"></a>正交实践</h4><p>以下是一些项目中的正交实践:</p>
<ul>
<li>正交支持: Func，Package，Actor，Node，后两者由框架提供</li>
<li>正交复用: 复用基本流程，如Actor, DB序列化，Gate等</li>
<li>正交解耦: 解耦组件依赖，如EventMgr，RabbitMQ，Etcd等</li>
<li>正交变化: 以变化特性进行拆分，如Controller/Model，以及<a href="http://wudaijun.com/2017/09/ngs-battle/">战斗配置</a>等</li>
<li>持续重构: 开发中对重复敏感，对变化敏感，适当运用设计模式，常用的如观察者模式，控制反转，策略模式等等</li>
</ul>
<p>正交不只是一个设计目标，也是一个重构目标，它会随着系统功能和需求的迭代而变更，就像微服务一样，粒度过细则可能过犹不及。</p>
<h3 id="二-可靠性"><a href="#二-可靠性" class="headerlink" title="二. 可靠性"></a>二. 可靠性</h3><p>可靠性通常分为两个方面：健壮性(鲁棒性)和容错性。</p>
<ul>
<li>健壮性: 是指一个计算机系统在执行过程中处理错误，以及算法在遭遇输入、运算等异常时继续正常运行的能力。</li>
<li>容错性: 是使系统在部分组件（一个或多个）发生故障时仍能正常运作的能力。</li>
</ul>
<p>健壮性是指系统是对外部输入的处理能力，你按照我的调用规范来使用系统，系统会正常返回，如果你不按照我的调用规范来使用系统，系统返回给你错误，但是系统本身不会Down掉。因此健壮性更多地是强调错误预防，而容错性是指当系统内部错误发生之后，如何处理错误和进行错误恢复。</p>
<h4 id="1-健壮性"><a href="#1-健壮性" class="headerlink" title="1. 健壮性"></a>1. 健壮性</h4><h5 id="防御式编程"><a href="#防御式编程" class="headerlink" title="防御式编程"></a>防御式编程</h5><p>提到错误，不得不提一下防御式编程:</p>
<blockquote>
<blockquote>
<p>你写的代码，应该考虑到所有可能发生的错误，让你的程序不会因为他人的错误而发生错误。</p>
</blockquote>
</blockquote>
<p>我认为部分同学对防御式编程是有误解的，将其简单理解成了不让服务器崩溃，在实践中，有些同学为了方便，可能会忽略对错误的处理(反正有defer)，或者简单打个Log，而不去认真思考这个错误意味着什么，后续逻辑应该怎么处理，这个错误如何反馈给调用方等等，这往往会给系统带来更多的不确定性，并且在错误发生时难以调试。</p>
<p>举个简单的例子，我们的Pf模块，负责和平台进行交互，屏蔽HTTP通信，Token管理，服务地址等细节，我们有个API，用于向平台获取角色列表，这个API在获取到角色列表对其进行解析时，其中一个角色元信息Json解析出错了(简单认为不可能出错)，如果你忽略了这个错误，或者只是简单打个日志，然后跳过这个角色解析，最终逻辑模块将以为一切正常，然后交给客户端，客户端就找不到这个角色了，甚至再发起创建角色流程。</p>
<p>防御式编程强调的是尽可能地考虑并且处理能够预料到的错误，而不是说隐藏或者忽略意料之外的错误，对于不能Handle的错误，该传给调用方传给调用方，该终止服务器就终止。</p>
<p>在实践中，需要设计和使用API时，重视error规范，认真考虑各种异常输入和错误返回等。</p>
<h5 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h5><p>关于测试的问题，我们之前有过探讨了，关于测试的好处和难点这里不再赘述。在项目实践中，我比较推崇API测试和测试用例，前者是白盒测试，结合go test规范，用于底层不常变的基础设施测试，后者是黑盒测试，用于功能性测试，其它更详尽的测试个人认为是不适用于游戏的。</p>
<p>另外为了更好地测试，可以结合开发环境的特性，特例化开发环境配置，比如适当调小模块Channel大小(让错误更早暴露出来)，对一些关键性错误直接Panic(比如消息未注册)，另外，也可以结合一些语言提供的工具，比如通过<code>-race</code>参数来检查竞态(非常吃内存和性能，不建议线上使用)，通过常驻的http pprof工具提供实时地内存，性能和死锁分析等。</p>
<h4 id="2-容错能力"><a href="#2-容错能力" class="headerlink" title="2. 容错能力"></a>2. 容错能力</h4><p>容错能力分为三个层面：错误隔离，错误处理，错误恢复。</p>
<p>谈到容错，我想不得不提的就是Erlang，Erlang提供了错误隔离，处理，恢复一条龙服务，进程出错(不会影响到其它进程，错误隔离)，进入terminal函数(错误处理)，监督者监控到子进程Crash，尝试重启(错误恢复)。</p>
<p>和防御式编程一样，Erlang的Let it Crash，也是个容易误解的概念，它不是说鼓励崩溃，而是说不怕崩溃，Erlang认为你不可能提前预知到所有错误，因此它对错误做最坏的打算，得益于Erlang的Actor模型和错误隔离机制，能够最大程度地控制崩溃的影响范围，因此它可以基于自己的轻量化，帮你尝试做错误恢复。因此反过来讲，正因为其它语言没有像Erlang这样强大的容错能力，因此他们在错误处理上面如履薄冰，鼓励你更多地从错误预防的角度考虑，而Erlang允许你偷懒，写更少的防御代码，它的错误处理和恢复帮你擦屁股。另外，Erlang并不是无脑帮你重启进程，Erlang的错误恢复基于如下三点背景:</p>
<ol>
<li>良好的Actor模型实践，保证Crash的影响范围小，比如单个玩家</li>
<li>大部分的错误可以通过重启恢复(没有什么是重启不能解决的?)</li>
<li>进程监督者会设置重启上限</li>
</ol>
<p>Go语言只给开发者错误捕获机制，错误隔离都需要捕获错误才能够完成。但我们仍然可以从Erlang Actor模型中借鉴学习到一些东西，具体到实践中:</p>
<ul>
<li>Go in Actor: 原生goroutine的使用是比较有风险的(mem leak，deadlock，panic等)，框架上应该封装逻辑goroutine(相当于actor)，统一管理actor的消息队列/交互/顺序依赖等，避免逻辑层对原生goroutine的使用(比如提供一个worker pool，毕竟逻辑层大部分时候只是想要个可以异步执行任务的地方)</li>
<li>defer但不是无限制defer actor error，特别对于逻辑模块，defer打印堆栈信息，但要对错误进行阈值设定，一个进一步的尝试是通过actor当前上下文对错误进行分类统计(主要针对大粒度的Actor)</li>
<li>异步思维是构建高容错系统的必备思维，一个通用的实践是，将所有的外部IO封装成模块，IO模块对所有同步IO操作设置超时(context, deadline)，其它模块与IO模块间异步交互。此外，逻辑模块之间也应该限制对同步调用的使用，防止死锁和并发瓶颈</li>
</ul>
<h4 id="3-可调试能力"><a href="#3-可调试能力" class="headerlink" title="3. 可调试能力"></a>3. 可调试能力</h4><p>可调试能力本身不是可靠性的一部分，这里我把它作为一种错误诊断手段，一并补在这里，Go语言没有像Erlang那种强大的动态调试能力(无痛DEBUG)，也没有热更，因此框架方面需要考虑到这方面的支持，方面快速定位BUG&amp;修复数据。</p>
<p>实践:</p>
<ol>
<li>模拟机器人: 提供一个客户端的Console模拟，用于灵活地向服务器构建&amp;发送消息，用于黑盒测试。</li>
<li>后台Console: 一些状态Debug和GM命令，比如查看各个模块的异步调用状态，PProf数据，刷新大地图NPC等等。</li>
<li>Lua脚本: 可以拉取一些服务器内部数据状态，比如玩家数据，并对其进行简单修改。</li>
<li>PProf: 通过http pprof或者配合Console拿到pprof数据，也能对当前系统状态有一份不错的参考，特别针对与死锁或者性能问题，具体使用<a href="http://wudaijun.com/2018/04/go-pprof/">参考</a></li>
</ol>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
      </tags>
  </entry>
  <entry>
    <title>游戏服务器中的通信模型</title>
    <url>/2018/07/gameserver-communication-model/</url>
    <content><![CDATA[<p>本文聊聊游戏服务器中常见的通信模型和对比，讨论下常见的实现方案，最后分享下我们当前的实践。</p>
<h3 id="常见的交互语义"><a href="#常见的交互语义" class="headerlink" title="常见的交互语义"></a>常见的交互语义</h3><p>在实践中，节点交互中常用的点对点通信方式，对应用层而言，可以大概分为以下几种:</p>
<ul>
<li>同步RPC</li>
<li>同步请求</li>
<li>异步消息</li>
<li>异步请求</li>
<li>发布订阅</li>
</ul>
<p>在本文中，我将围绕一个简单的例子，来聊聊对这几种交互语义的个人理解。</p>
<p>该例子为: 作为client端的A需要执行<code>(x+y)*z</code>操作，但其中的<code>x+y</code>，是由server端B实现的，A需要请求B得到<code>x+y</code>的结果，再将其<code>*z</code>完成业务逻辑。</p>
<h4 id="同步RPC"><a href="#同步RPC" class="headerlink" title="同步RPC"></a>同步RPC</h4><p>RPC库通常有现成的轮子，比如gRPC、thrift等，以golang gRPC为例:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A 线程</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handle</span> <span class="params">(x,y,z <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">	ctx, cancel := context.WithTimeout(context.Background(), <span class="number">5</span>*time.Second)</span><br><span class="line">	<span class="keyword">defer</span> cancel()</span><br><span class="line">	req := &amp;AddReq&#123;X: x, Y: y&#125;</span><br><span class="line">	ack, err := grpcClient.Add(ctx, req)</span><br><span class="line">	<span class="keyword">return</span> ack.Result * z</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// B 线程</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *B)</span> <span class="title">Add</span><span class="params">(ctx context.Context, req *AddReq)</span> <span class="params">(*AddAck, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;AddAck&#123;Result: req.X+req.Y&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码简洁明了，远程请求和本地函数调用一样方便，这种写法应该是开发者最喜欢的方式。诸如超时，错误传递，甚至负载均衡等，gRPC都已经处理好了。同步RPC的缺点在后面讨论同步异步以及具体RPC框架的时候会讨论。</p>
<span id="more"></span>
<h4 id="异步消息"><a href="#异步消息" class="headerlink" title="异步消息"></a>异步消息</h4><p>基于异步消息的通信模式可以说非常古老了，从 C/S 到服务器进程/线程间，这种方案的优点是扩展性强(消息的优点)，吞吐量好(异步的优点)。不管是集群/进程/线程/轻量级线程，可以用同一套通信方案，并且消息语义本身也很容易在各种通信设施上实现，如go channel，TCP，MQ等。像 Erlang 的通信模型就只有一套异步消息这一种。这样最大的好处就是完全屏蔽了目标 Process 的物理位置(同一进程/跨进程/跨网络)，获得非常好的系统扩展性和灵活性。比如某个 Process 被重新部署到其它节点上，已有代码几乎无需任何更改。</p>
<p>谈了这么多优点，下面我们来聊聊它的不足(主要是相较同步RPC而言)，以前面的AddService例子为基础，现在我们尝试将其换成异步消息:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; A 线程</span><br><span class="line">func handle(x,y,z int) &#123;</span><br><span class="line">	&#x2F;&#x2F; 需要将请求数据上下文随消息一并发送</span><br><span class="line">	&#x2F;&#x2F; 由于是异步消息投递，低层通常是不提供超时机制的</span><br><span class="line">	Send2B(&amp;AddReq&#123;X:x,Y:y,Z:z&#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; B 线程</span><br><span class="line">func handleAddReq(req *AddReq) &#123;</span><br><span class="line">	result :&#x3D; req.X + req.Y</span><br><span class="line">	&#x2F;&#x2F; 需要显式指明响应路径，并且透传B根本不应该关心的请求数据上下文z</span><br><span class="line">	Send2A(&amp;AddAck&#123;Result:result,Z:req.z&#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; A 线程</span><br><span class="line">func handleAddAck(ack *AddAck) &#123;</span><br><span class="line">	&#x2F;&#x2F; 从ack中取出处理结果和当时的请求上下文</span><br><span class="line">	result &#x3D; ack.result * ack.Z</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上暴露了异步消息交互的几个问题，在我的理解中，一个完整的异步请求(期待对端返回响应，而非单纯投递一条消息)需要考虑到如下四个部分:</p>
<ol>
<li>消息路由和处理: 即AddReq AddAck消息如何序列化传输，如何映射到指定响应函数等，是消息交互系统的基础支撑</li>
<li>请求数据上下文: 指只有发送方需要用于后续处理，而接收方不关心的内容，即上例中的 z</li>
<li>消息响应路径上下文: 指请求完成处理后，如何指明响应路径。上例中，对响应方B，它在响应AddReq时，需要显式指明响应到A。</li>
<li>超时机制: 用于处理对端无响应或慢响应的情况，避免消息黑洞(消息QoS得不到保证)</li>
</ol>
<p>相比同步RPC，单纯的异步消息模型，以上2，3，4都需要应用层关心和维护: </p>
<ul>
<li>请求数据上下文: 在上例中，请求方A需要将请求上下文与请求内容一起发送给服务方B(如<code>AddReq&#123;x,y,z&#125;</code>)，然后B再原封不动返回回来，这种方案一方面导致代码复用性很差，比如当AddReq有多种上下文时(如<code>AddReq(x,y)*z</code>, <code>AddReq(x,y)-a-b</code>)，则很难复用 AddReq和handleAddReq。当 B 是 DB 这类公用模块时，这类问题尤其突出。另一方面是带来了额外的消息负载开销(B根本不关心A的请求上下文)。最后一方面是这种方案很难实现异步超时(如果B没有响应A，那么A的超时处理中将获取不到当时的请求上下文)。</li>
<li>消息响应路径上下文: 在上面的例子中，我们是在 handleAddReq 中直接调用 <code>Send2A(&amp;AddAck&#123;Result:result&#125;)</code> 的，这意味B假设AddReq是来自于A的，并显式指明响应路径，那么当 C，D也会请求 B 时，就需要定义 AddReqForC, AddReqForD 请求，或者在AddReq中添加标识请求方来源的字段，让请求方来填。这种将响应路径(也是请求来源)绑定在消息内容上的做法，不利于代码复用和解耦。</li>
<li>超时机制: 大部分的异步消息交互系统是不提供超时机制的，因为超时本身是请求-响应模式中的概念(对响应有预期)，是更上层考虑的问题(如TCP和HTTP的关系)。但是在请求-响应语义中，超时又是必要的，比如错误处理，延迟统计，流控降级等</li>
</ul>
<p>总之，纯异步消息框架对于请求-响应式的业务场景缺乏更上层的基础设施支撑，开发起来是不够友好的。</p>
<h4 id="异步请求"><a href="#异步请求" class="headerlink" title="异步请求"></a>异步请求</h4><p>那么有没有办法同时兼顾异步消息交互的扩展性以及请求-响应的便利性呢，异步请求就是两者的结合:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; A 线程</span><br><span class="line">func handle(x,y,z int) &#123;</span><br><span class="line">	&#x2F;&#x2F; 这里传入z，是为了之后的handleAddAck响应处理中，能够正确获取到请求上下文z，进行后续的处理</span><br><span class="line">	&#x2F;&#x2F; 请求上下文将由框架层保存在本端，不会传给对端，如此即使对端B超时无响应，请求方仍然能获取到请求上下文，进行容错处理</span><br><span class="line">	self.AsyncCb(targetB, &amp;AddReq&#123;X: x, Y: y&#125;, z, 3*time.Second, handleAddAck)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; AckCtx由异步回调框架提供，包含响应消息本身，请求错误(超时，网络故障等), 请求上下文(在这里是z)等</span><br><span class="line">func handleAddAck(ackctx *AckCtx) &#123;</span><br><span class="line">	if ackctx.Err !&#x3D; nil &#123;</span><br><span class="line">		&#x2F;&#x2F; 处理超时，对端无响应等框架性错误</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F; 从actCtx.Ctx.(int)中取出请求上下文z，执行后续操作</span><br><span class="line">	result :&#x3D; ackctx.(*AddAck).Result * ackCtx.Ctx.(int)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; B 线程</span><br><span class="line">&#x2F;&#x2F; ReqCtx由异步请求框架提供，包含请求消息本身，响应路径，消息唯一ID等</span><br><span class="line">func handleAddReq(reqctx *ReqCtx) &#123;</span><br><span class="line">	req :&#x3D; reqctx.Req.(*AddReq)</span><br><span class="line">	&#x2F;&#x2F; 直接返回，无需关心请求上下文(z)，响应路径(B)等</span><br><span class="line">	reqctx.Reply(&amp;AddAck&#123;Result: req.X + req.Y&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>异步请求方案通过ReqCtx和AckCtx来维护请求-响应语义，通过回调来处理响应。对请求方而言，框架底层为其处理了超时和请求上下文管理，对服务方B而言，它也无需再关心请求上下文，响应路径。</p>
<p>异步请求语义通常是框架层提供，上例中的异步回调机制只是其中一种实现方案，简单聊聊它的一些特性:</p>
<ol>
<li>请求语义: 设计非对称的请求-响应协议，并通过唯一请求ID进行请求、响应的对应</li>
<li>上下文管理: 请求方统一管理请求ID到请求上下文(包括请求数据上下文、回调函数、超时时间等)的映射</li>
<li>响应路径: 框架层对响应方屏蔽消息来源，响应方不再关注请求数据上下文和响应路径，专注处理请求并响应结果</li>
<li>回调机制: 请求方收到响应后，通过唯一ID找到请求上下文，回调到应用层(并移除请求上下文)</li>
<li>超时机制: 请求方通过ticker or timer来触发超时(并移除请求上下文)</li>
<li>错误机制: 将请求过程中的各种错误(如无效地址，序列化错误，网络错误，甚至对端panic)尽早地反馈给请求方</li>
</ol>
<p>本质上来说，请求-响应和纯异步消息的最大区别在于前者是非对称的(请求走handler路由，响应走回调)，而实际开发中为了更好的数据一致性和错误处理，很多场景的通信模型都是适合请求-响应式的(如扣除资源，检查条件等)，因此站在实用主义的角度来说，架设一套交互语义是有必要的。</p>
<p>这里顺便提一下为什么我们将请求数据上下文单独管理，而不直接使用函数闭包:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func handle(x,y,z int) &#123;</span><br><span class="line">	self.AsyncCb(targetB, &amp;AddReq&#123;A: x, B: y&#125;, func (ackctx *AckCtx) &#123;</span><br><span class="line">		result :&#x3D; ackctx.Ack.(*AddAck).Result * z</span><br><span class="line">	&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这是因为当触发回调函数时，闭包所引用的上下文可能已经失效了，比如z可能是玩家的某个部队的引用，但是异步回调时，玩家的该部队已经解散了，但回调却还在使用，造成写丢失的问题(还很难Debug)。因此我们在实践中限制了异步回调必须分段写，请求数据上下文必须是简单值(如玩家ID，部队ID等)，在分段的回调函数中，去通过ID重新获取相关数据。</p>
<h4 id="同步请求"><a href="#同步请求" class="headerlink" title="同步请求"></a>同步请求</h4><p>同步请求指基于消息的同步阻塞的请求-响应语义，HTTP协议就是一个典型的基于文本消息的同步请求协议，只不过基于性能和消息顺序性的考量，游戏服务器能直接使用HTTP的场景有限。如果要自己实现同步请求语义的话，可以基于异步回调机制封装，形式上，可以是同步回调，也可以是类似RPC的返回值， 同步请求不需要考虑上下文和回调的维护，</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; A线程 返回值方式</span><br><span class="line">func handle (x,y,z int) &#123;</span><br><span class="line">	ackctx	:&#x3D; SyncRequest(&amp;AddReq&#123;X: x, Y: y&#125;, 3*time.Second)</span><br><span class="line">	result :&#x3D; ackctx.Ack.(*AddAck).Result * z</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; A线程 同步回调方式</span><br><span class="line">func handle(x,y,z int) &#123;</span><br><span class="line">	self.SyncCb(targetB, &amp;AddReq&#123;A: x, B: y&#125;, z, 3*time.Second), func (ackctx *AckCtx) &#123;</span><br><span class="line">		if ackctx.Err !&#x3D; nil &#123;</span><br><span class="line">			&#x2F;&#x2F; 处理超时，对端无响应等框架性错误</span><br><span class="line">		&#125;</span><br><span class="line">		result :&#x3D; ackctx.(*AddAck).Result * ackCtx.Ctx.(int)</span><br><span class="line">	&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对服务端B而言，它的实现和异步请求一样，因为它不需要关心请求方是同步还是异步的，同步请求和同步RPC看起来比较类似，但由于其基于消息，有更强的扩展性和可移植性，很容易适配各种底层传输和路由方式，保留较大的灵活性。</p>
<h4 id="发布订阅"><a href="#发布订阅" class="headerlink" title="发布订阅"></a>发布订阅</h4><p>发布订阅本质是多对多的异步消息通信模式，逻辑层的事件通常就基于发布订阅来分发。但是节点内的事件分发和跨节点的事件分发可能还有些区别:</p>
<ul>
<li>节点内: 由于性能高，可以做到细粒度灵活控制，比如基于单个Event去注册，订阅方可能是任务，活动，排行榜等逻辑模块，这些模块可能是跨线程的</li>
<li>节点间: 由于游戏中的Event太多太细，每个Event一个Topic是不现实的，否则单个活动开启，就可能导致瞬间订阅上百个Topic，因此跨节点的事件分发主要靠发布方来做粗过滤，然后发到订阅者的Topic上</li>
</ul>
<p>因此由于游戏服务器对性能的要求，通常节点内会自己实现一套发布订阅组件，使用细粒度Event，而跨节点多对多的模式用得相对较少，Topic大部分时候被用作对端虚拟地址抽象，具体执行的还是点对点的链路。</p>
<h4 id="同步-vs-异步"><a href="#同步-vs-异步" class="headerlink" title="同步 vs 异步"></a>同步 vs 异步</h4><p>尽管同步代码简单直观且易于维护，但为了构建健壮，可靠的后端系统，对于同步的选择是应该慎之又慎的。为了方便讨论同步可能带来的问题，我将同步请求大概分为三类，然后讨论下这些情景下用同步可能导致的一些问题: </p>
<ol>
<li>没有设置超时或不支持超时的同步请求</li>
<li>带超时但非关键的同步请求</li>
<li>带超时且关键的同步请求</li>
</ol>
<p>不带超时的同步请求的问题很明显，就是请求方无法对对端的响应有一个最坏预期，即有可能对端挂掉了，永远也不响应，那么请求方就永远被阻塞了，最终导致服务无响应、资源泄露、甚至雪崩。很多时候我们在实现同步语义的时候会忽略超时处理，或者说对对端的可用性作出过高的假设。要在语言机制上实现同步语义是很简单的，比如Go的<code>res := &lt;-chanRet</code>，Erlang的<code>receive Answer -&gt; ok</code>，但没有考虑边界情况的后果也可能是很严重的。</p>
<p>再来看看带超时的非关键同步请求，非关键请求是指请求方不必等该请求完成之后，再处理接下来的任务。即如果这个请求是异步的，那么其实请求方也可以先处理接下来的消息。比如地图线程在发起一个DB请求加载某个玩家数据时，这个过程中地图线程其实可以先处理来自其它玩家的请求。在这种情况下，很明显的，同步请求相比异步，降低了地图线程的吞吐量。前段时间公司一个项目出现CPU Load上不去，而Erlang消息队列有堆积的情况，排查了很久，发现是日志库log4erl里面有同步调用，导致写日志的API其实是有阻塞的，然后基本所有的逻辑线程都会写大量日志，导致CPU不能跑满。</p>
<p>最后来看看带超时且关键的同步请求，举个例子，玩家登录的时候，玩家的agent线程会向平台去认证鉴权，即使这个鉴权过程是异步的，agent线程也不能处理接下来的任务，因为玩家还没有鉴权成功，它发来的后续消息是没有意义的，agent要么将接下来收到的消息丢掉，要么将其缓存下来，等鉴权完成再处理。在这种情况下，你可能会觉得用同步向平台鉴权总不会有什么问题了吧，既不会降低吞吐量，也不会有永久阻塞的问题，然而我们也有项目躺过坑，玩家多点登录时，新的agent会同步等老的agent走完下线流程之后，再处理后续登录逻辑(这个地方的同步调用没有设置超时)，然而如果老的agent在阻塞处理某些请求(这个请求的超时可能比较长)，并无法即时响应登出请求，那么新的agent也会阻塞，然后玩家觉得几秒钟没登录上，可能又会再次重启游戏重新登录，这个时候新建的agent仍然会继续阻塞，然后agent数量就会暴增，最终导致OOM。当然，这个事故的部分原因是没有正确设置超时，但也从另一方面揭露了关键同步请求相比异步的缺陷: 虽然异步请求过程中，agent也不能处理后续逻辑消息，但起码agent是可响应的，可响应意味着可以处理一些如终止消息，系统消息等高优先级的任务。前面定义的所谓关键二字，其实是对同等优先级的任务而言的，而往往在实践中，总有意外或者更重要的事情发生。</p>
<p>另外，关于同步请求的一个周知问题就是环形依赖，即A同步请求B，B又直接或间接同步请求A，同步意味着强依赖，随着逻辑复杂度的提升，理想的单向依赖会很难保证和检查，一旦出现环形依赖，轻则请求失败，伴随系统吞吐量降低(有超时的情况)，重则环中的线程全部无响应(没做超时的情况)。因此对于以上的三类同步请求，环形依赖都不会带来好结果。</p>
<p>讲了这么多同步的缺点，不是说完全不用同步，而是说慎用同步，要理解同步可能带来的边界问题是什么，比如服务器启停服流程，各种数据模块的加载/保存可能会有顺序依赖，如果做成异步，可能需要维护非常复杂的状态机，并且代码维护成本也比较高，而同步则可以获得清晰的执行流程和错误处理。</p>
<p>相比同步而言，异步看起来健壮性更好，但是也更复杂，其中一个典型的问题就是数据一致性问题: 比如前面讲的agent在异步执行鉴权操作，通常就需要做状态机保护，确保在鉴权完成前，agent不会开始处理后续逻辑消息。又比如A的异步请求还没有响应，后续处理的请求跟前一个异步请求有数据相关性，就可能导致数据不一致。我在<a href="https://wudaijun.com/2019/01/gameserver-acid-consistency/">游戏服务器中的数据一致性</a>中也有一些讨论。</p>
<p>对异步请求-响应而言，超时也是一个需要考虑的问题，如果没有做超时，对同步而言的代价是可能永久阻塞，而对异步的代价则是”消息黑洞”，即请求方在发出异步请求之后，如果对端没有响应，那么这个请求就没有后续处理了，如果日志记录得不好的话，可能都很难追溯到这个请求。</p>
<p>总之，异步很多时候是让服务器不出现大问题(无响应/雪崩/系统吞吐量变低等)，但同时也带来了开发复杂度，以及一些”小问题”(请求沉没/数据不一致/逻辑错误等)。</p>
<h3 id="实现机制"><a href="#实现机制" class="headerlink" title="实现机制"></a>实现机制</h3><p>前面基本讨论的都是交互语义，(同步，异步，RPC，回调)，这里聊聊常见的节点交互实现方案，由于节点内的线程/协程通信机制通常和语言相关，这里主要关注跨节点交互方案。</p>
<h4 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h4><p>HTTP不用过多介绍，它实现的是同步请求语义，它的主要优势在于没有连接上下文，因此对无状态服务而言，可以透明横向扩展。通常第三方服务最常用的协议就是HTTP。但对游戏业务而言，HTTP的性能是一道过不去的坎，毕竟游戏服务器不像第三方服务那样能够做到无数据状态。</p>
<h4 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h4><p>TCP应该是最常见也是最底层的通信方案了，它的主要优势就是高性能和灵活性，应用层可以根据需求自由实现编解码，路由，交互模式等。TCP的缺点主要有几点:</p>
<ol>
<li>要造的轮子比较多: 数据编解码，加密，断线重连，流控，M对N的消息分发等等</li>
<li>网络拓扑的维护: 由于TCP是点对点的，在跨服交互的场景下，得谨慎维护网络拓扑，一方面尽可能避免全联通，另一方面复杂的拓扑依赖不利于维护和扩展</li>
</ol>
<p>TCP适用于网络拓扑相对稳定的场景，对于比较灵活的网络拓扑结构(如动态匹配机制，动态发布订阅模型等)，要么全相联，要么需要维护一套复杂的动态连接管理机制。</p>
<h4 id="UDP-QUIC"><a href="#UDP-QUIC" class="headerlink" title="UDP/QUIC"></a>UDP/QUIC</h4><p>在部分延迟容忍度特别低的游戏中，可能会使用UDP作为C/S协议，然后应用层实现一定程度的传输可靠性。对SLG而言，TCP性能和延迟还处于可接受访问内，而至于服务器集群内部，通常由于局域网环境相对稳定，并且消息顺序性敏感，因此基本都是直接用TCP。</p>
<p>放到这里提一下是因为近几年Google基于UDP封装的应用层可靠传输协议<a href="https://github.com/lucas-clemente/quic-go">QUIC</a>越来越火，各个大厂纷纷<a href="https://www.infoq.cn/article/afncpsfmb3ufwehueak1">跟进</a>，QUIC目前还不够成熟，主要还处于巨头摸索阶段，要推广还有不少问题(比如UDP可能被拦截或被限流)，可以持续关注下，考虑未来借助QUIC来进一步提升游戏客户端的弱网延迟和断线重连体验。</p>
<h4 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h4><p>如HTTP实现同步请求语义一样，RPC框架主要专注实现同步RPC语义，RPC框架通常基于HTTP或TCP，大部分RPC框架都是同步的，以最流行的gRPC框架为例，虽然 <a href="http://senlinzhan.github.io/2017/08/10/grpc-async/">gRPC 支持异步</a>，但还不够易用，也比较依赖应用层的封装，并且gRPC golang生成的代码不支持异步调用(犹如net包不提供异步API一样，主要依赖应用层开goroutine去封装异步)，因此异步RPC这种通信模型实践中基本不会用到。另外，gRPC 的<a href="https://grpc.io/docs/tutorials/basic/go.html#bidirectional-streaming-rpc">双向Stream通信</a>在解决传统RPC中只能一次请求一个返回值，并且不保证顺序性的问题时，其实也实现了异步消息语义(如果传输的消息中包含二进制，逻辑层再自己做一层编解码的话)，但在实践中建议酌情使用，因为这本质是将gRPC和HTTP/2当做TCP来用，上层的消息编解码，消息路由都得自己做，底层仍然可能有全联通等问题，性能和扩展性还不如TCP好。</p>
<p>RPC框架的通用缺点在于耦合过重(当然，这也是它足够易用的原因)，一方面是同步调用，另一方面是函数调用本身，已经耦合了消息编解码，消息路由，方法名，甚至并发处理模型(golang gRPC中，每个请求会开一个goroutine)等，这导致其在灵活性和扩展性上会相对弱一些(比如想要基于其实现其他语义，或者适配到其他已有交互语义)。</p>
<p>实践中，RPC框架在游戏后端中的应用场景比较有限，通常用于对接支付这类相对独立的外部服务。</p>
<h4 id="MQ"><a href="#MQ" class="headerlink" title="MQ"></a>MQ</h4><p>大部分的MQ底层都基于TCP来传输，对应用层提供异步消息，作为中间件单独存在，MQ的优势很多，比如异步，解耦，削峰，M对N的消息分发，Topic本身的灵活性等等，这里聊聊它应用在游戏服务器的利弊:</p>
<p>MQ的优势:</p>
<ol>
<li>将网状拓扑简化为星形拓扑，避免了全联通，同时也能灵活适应各种动态的拓扑调整(topic)</li>
<li>削峰对于游戏中某些峰值场景来说，也比较有用</li>
<li>Driver层通常有一些现成的轮子可用，如流控，加解密，编解码等</li>
</ol>
<p>MQ的不足:</p>
<ol>
<li>MQ通常只提供异步消息语义和发布订阅语义，需要封装其他语义，虽然如nats也提供同步请求语义(request-reply)，但经验上不建议过度依赖中间件专有特性，尽量做到组件可替换</li>
<li>MQ是弱节点状态耦合，强状态耦合场景需要自己实现，如服务发现，对端状态感知，配置共享等</li>
<li>需要MQ提供自己的QoS保证(最少一次/最多一次/精确一次)，但出于性能和可靠性的考量，在实践中，也不建议过度依赖MQ Qos，而是应用层来实现QoS</li>
</ol>
<p>MQ适用于网络拓扑比较灵活的场景，比如对SLG这类后期主要依赖跨服来支撑生态的游戏而言，MQ能充分发挥它的解耦和灵活性优势，我在<a href="https://wudaijun.com/2021/02/gs-mq-practice/">这里</a>也提到了一些MQ相关的实践。</p>
<h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><p>最后简单聊聊我们当下的一些实践，首先说明下我们目前的主要游戏类型是SLG，主要的挑战在于性能(地图战斗，行军均由服务器跑桢)和各种跨服交互(跨服联盟，跨服活动，GvG，KvK等)。技术选型的优劣，只有落实到具体业务挑战上才有标准。</p>
<p>语义层面，我们目前的主逻辑通信模型基本都是基于消息的，主要使用异步消息，同步请求，异步请求三种交互语义，并尽可能让节点内交互和节点间交互使用同一套API(屏蔽底层实现和差异)。</p>
<p>实现层面，我们目前主要使用MQ(nats)来做节点间的通信，以适应游戏服务器后期易变的网络拓扑。虽然MQ天然提供发布订阅，但我们尽量将其屏蔽到底层，将发布语义封装为异步消息语义，将订阅语义封装为注册语义，对应用层而言，主要还是点对点的通信，然后基于这之上再封装同步请求和异步请求语义，并且在driver层做好请求-响应的延迟统计。对于已有的第三方同步接口(如平台HTTP，DB API等)均由单独的proxy代理(内部适当使用worker pool，负载分配等)，对逻辑线程提供异步请求接口。对于一些强状态场景，如网关拉取可用服务器列表，则借助ETCD这类组件来做配置共享。</p>
<p>开发层面，除了服务器启停流程之外，逻辑线程全异步交互，异步请求的一些实践则需要团队通过规范约束和CodeReview不断加强，如可变的闭包上下文，<a href="http://wudaijun.com/2019/01/gameserver-acid-consistency/">数据一致性</a>，超时设置，错误日志规范等。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
        <tag>programing</tag>
      </tags>
  </entry>
  <entry>
    <title>GS DevOps 实践</title>
    <url>/2018/08/gs-devops/</url>
    <content><![CDATA[<h2 id="现状-amp-契机-amp-目标"><a href="#现状-amp-契机-amp-目标" class="headerlink" title="现状&amp;契机&amp;目标"></a>现状&amp;契机&amp;目标</h2><p>DevOps 是分工细化下的产物，用于提高开发和运维的协作效率，实现快速交付。这里主要从开发的角度谈谈游戏服务器中的DevOps，以及我们最近做的一些尝试。</p>
<h3 id="1-现状"><a href="#1-现状" class="headerlink" title="1. 现状"></a>1. 现状</h3><p>我们现在是不同的项目使用不同的语言和框架，上线前，运维了解熟悉各个项目组的配置方案，部署流程，数据管理等，同时开发也需要熟悉运维的检测工具，接入监控报警机制。这通常需要一周甚至更多的时间，并且线上部署和本地部署可能是两套完全不同的流程，由于项目组相关性太强，运维通常也是专职维护指定项目，效率很低。上线后，如果出了BUG 需要紧急修复，通常是开发人员直接ssh到正式环境的主机上，进行日志查看，状态调试，甚至代码修改，对操作人员的要求比较高并且风险大，没有充分发挥运维的作用。</p>
<span id="more"></span>
<h3 id="2-契机"><a href="#2-契机" class="headerlink" title="2. 契机"></a>2. 契机</h3><ul>
<li>微服务理念，比如服务发现，错误处理，无状态服务等等，使得应用的节点拓扑和交互边界更加清晰规范，更易于管理。</li>
<li>容器技术为节点提供了比物理机更快速，一致，隔离的环境，使得服务部署更加容易。容器也比原生OS进程提供了更多的资源控制，状态监控等功能。</li>
</ul>
<h3 id="3-目标"><a href="#3-目标" class="headerlink" title="3. 目标"></a>3. 目标</h3><p><img src="/assets/image/201808/docker-ops.png" alt=""></p>
<p>整个 DevOps 其实就两个关键点:</p>
<ol>
<li>怎么部署上去: 构建与部署流程，其实就是CI流程，目前还没有比较好的基于Docker的界面化CI工具</li>
<li>部署之后怎么管理: 包括状态监控，故障转移等，大部分工作docker swarm都已经做好了，GS只要支持服务发现即可，或者用 docker swarm 网络的服务发现，我们是自己做的 etcd+grpc。</li>
</ol>
<h2 id="具体实践"><a href="#具体实践" class="headerlink" title="具体实践"></a>具体实践</h2><p>就我们目前而言，DevOps的主要途径是让运维尽早地参与到项目的框架设计中，制定相关的标准和规范，开发过程通过遵守这些规范以达成更快的交付速度，更稳定，安全的运行状态，以及更系统，完善的维护流程。这个过程需要开发人员懂一些基本运维知识，最好就是开发环境的部署流程和线上环境一样，这样，运维在规范开发，开发过程中也在完善运维流程，达成双向促进。这里从 GS 的角度谈谈我们从”可运维”角度做的一些具体实践。</p>
<h3 id="1-GS-配置"><a href="#1-GS-配置" class="headerlink" title="1. GS 配置"></a>1. GS 配置</h3><p>GS 配置指节点(容器)配置，通常是运维最关心的，配置方案有很多种，配置文件，启动参数，配置服务，甚至硬编码，之前我们更多的是用配置文件，即将配置模板加入代码仓库，然后在本地拷贝一份改成自己的配置，这份配置是不加入仓库的，这种方案有两个缺点: 1. 拿到代码才能拿到配置模板，2. 需要手动改配置文件，这就产生了文件路径依赖，并且不方便做自动化。<a href="https://peter.bourgon.org/go-for-industrial-programming/#program-configuration">Go 工业级编程</a>这篇文章中曾经提到:最好的配置方案就是通过启动参数，这一点我深表赞同，最好的配置方案就是当你拿到这个二进制时，你就拿到了这个二进制的使用方法，并且作者提到的配置方案已经有了很好的实现: <a href="https://github.com/urfave/cli/tree/v2">cli.v2</a>，可以结合 yml 文件更好地简化和管理配置。我们目前所有的运维配置都通过命令行指定。</p>
<p>命令行配置可以很方面地过渡到容器，绝大部分的参数都通过容器启动参数传入，极少数特殊配置可以考虑通过ENV传入，这两种方案应该能满足任何情况，比文件配置具备更高的灵活性和安全性。</p>
<h3 id="2-GD-配置"><a href="#2-GD-配置" class="headerlink" title="2. GD 配置"></a>2. GD 配置</h3><p>在我们之前的实践中，代码和策划配置csv文件常常是放在一起的，这本身不是一个很好的实践，比如我要热更配置，就必须要更新代码仓库。在容器化之后，这种缺点会更明显，更新配置就意味着要更新代码重新构建镜像，也就要停服，自然也就做不了热更。因此我们现在统一把csv配置通过脚本导入到 mongodb，将策划配置作为外部输入源来管理，这样不同的服务器可以指定使用同一个 DB 的配置(策划配置只读)，热更也得以实现(先更新配置并生成到 DB，再发送hotload命令给GS)。</p>
<h3 id="3-日志规范"><a href="#3-日志规范" class="headerlink" title="3. 日志规范"></a>3. 日志规范</h3><p>日志数据通常分为两大类: 逻辑调试日志和数据分析日志，<br>调试日志是给开发者看得，通常分为几个等级，有时候为了方便，我们还会按照模块功能对调试日志进行归类，比如网络消息日志，地图日志等，数据分析日志主要是给运营，数据部看的，包括 IPO 日志和运营日志。所有这些日志可能来源于不同的节点上，这给日志查阅和整理带来了难度，之前大多数项目组可能都是直接将日志存为文件，然后运维和开发者需要知道每个GS的日志目录在哪里，在容器化部署下，这暴露出几个问题:</p>
<ol>
<li>为了保证日志在容器停止后不丢失，容器的目录需要挂载出来，这样容器和宿主机绑在了一起，不具备位置透明性</li>
<li>当容器被部署在其它物理机的时候，日志前后就被分隔开了</li>
<li>多个无状态容器的日志或者逻辑相关的容器日志分散在各处，不方便按照时间线统一查看</li>
</ol>
<p>因此，基于以上种种原因，我们需要一个统一的日志分发中心，目前我们用的是 Fluentd，它是一个开源的日志收集器，并且已经集成到 Docker <a href="https://docs.docker.com/config/containers/logging/fluentd/">log-driver</a>，<a href="https://www.fluentd.org/guides/recipes/docker-logging">这里</a>有它的简单使用文档，使用了 Fluentd 之后，整个日志流变成这样:</p>
<p><img src="/assets/image/201808/fluentd_sample.png" alt=""></p>
<h3 id="4-微容器"><a href="#4-微容器" class="headerlink" title="4. 微容器"></a>4. 微容器</h3><p>微容器是指仅包含OS库和运行应用所需要的依赖以及应用本身，其他都不需要的容器。微容器是容器轻量化的产物，它有如下好处:</p>
<ol>
<li>镜像很小，占用更低的磁盘空间，并且可以快速发布和部署</li>
<li>更小的镜像意味着更小的攻击面，基础 OS 就更安全</li>
</ol>
<p>微容器我们主要要从两个方面着手: 轻量基础镜像和二进制部署。</p>
<p>得益于Docker的联合文件系统，通常我们平时在使用Dockerfile时，都很少去关心基础镜像的大小，只有在初次并且本地没有对应的基础镜像层时，才会重新从Hub拉取。因此为了方便，通常项目组的Dockerfile都是基于ubuntu这类OS镜像，导致镜像的体积动辄几百 M，比如<code>ubuntu16.04</code>大小为115M，而<code>golang:1.9</code>大小为735M，目前有很多精简的基础镜像，如scratch, alpine等，alpine是一个只有4M左右的轻型Linux发行版，目前大部分官方镜像都已经支持alphine 作为基础镜像，比如也有对应的<code>go1.9-alpine</code>轻量版，大小降低至286M。由于我们是二进制部署，因此我们直接用的alpine作为基础镜像。</p>
<p>二进制部署是指镜像中只存在二进制文件而不是整个源代码，这样一方面减少了镜像体积，另一方面提升了安全性。通常我们是在本地或者某个临时的”构建容器”中编译代码，然后将生成的二进制拷贝到”运行容器”中，这些方案要么很麻烦，要么不容易保证构建环境和运行环境的一致性，直到 Docker17.05引入了多段构建，可以在一个 Dockerfile 中完成之前需要多个 Dockerfile 才能完成的工作。如下是我们当前的 Dockerfile:</p>
<pre><code>#  编译阶段
FROM golang:alpine AS compiler
ADD . /go/src/ngs
# 跑单元测试
RUN go test ngs/...
WORKDIR /go/src/ngs
# 二进制部署必须CGO_ENABLED=0，而race必须在CGO_ENABLED=1下才可用
# 参考: https://github.com/golang/go/issues/128440
RUN CGO_ENABLED=0 go build -o bin/game ngs/game

# 发布阶段
FROM alpine:latest
WORKDIR /tmp/
# https support
RUN apk add --no-cache ca-certificates apache2-utils
COPY --from=compiler /go/src/ngs/bin/game .
COPY --from=compiler /go/src/ngs/gdconf/others gdconf/others
ENTRYPOINT [&quot;./game&quot;]
</code></pre><p>相比之前的源码部署，精简了基础镜像，并且没有了源码和构建工具，镜像从之前的823M (基于<code>go1.9</code>基础镜像)缩小到32M。</p>
<h3 id="5-网络管理"><a href="#5-网络管理" class="headerlink" title="5. 网络管理"></a>5. 网络管理</h3><p>目前我们的容器化部署全部使用 host 网络模式，主要是为了简单和高效，同时对 docker bridge/overlay 网络理解得还不是很深，这会导致容器与主机的网络有所关联。但是基于 Etcd 服务发现机制，容器仍然可以透明在不同主机上进行故障转移和重新部署，因此容器对主机的依赖相对较轻。至于是否需要用 docker bridge/overlay，还有待研究，目前我觉得Docker网络还是要和<a href="http://wudaijun.com/2018/03/docker-swarm/">docker swarm</a>结合起来才能发挥最大优势，我们并不打算用 docker swarm，因为GS大部分节点是强状态的，不能像docker service那样透明扩展，路由，和收缩，或者换句话将，每个节点就是都是一个 service，那这样的话，用了 docker swarm 的好处基本就只有故障转移了。因此我们主要还是单容器部署，每个 GS 容器需要手动配置部署在哪个host上，在之上做一些状态监控，如果容器挂了，可以自己做自动重启，但是如果物理机挂了，需要手动部署到其它host上，然后基于自己做的服务发现将容器加入集群，我将这种集群称为”半自动集群”。</p>
<h3 id="6-测试"><a href="#6-测试" class="headerlink" title="6. 测试"></a>6. 测试</h3><p>我们的测试流程主要包含单元测试和集成测试，单元测试就是 go test，是源码级的白盒测试，单元测试我们放在 Dockerfile 中做，每次构建会跑所有的单元测试，如果有测试没跑通，则构建失败。集成测试则是基于机器人测试用例的黑盒测试，需要单独跑在一个容器中，以 exitcode 作为测试是否成功的标志，集成测试在服务器部署之后，如果集成测试失败，则整个部署工作流失败。</p>
<h3 id="7-CI-工具"><a href="#7-CI-工具" class="headerlink" title="7. CI 工具"></a>7. CI 工具</h3><p>谈到持续集成(CI)工具，大部分项目组都用的 Jenkins，我们前期也用的 Jenkins， 结合 GitLab WebHook 去做自动构建部署。在开发环境中，QA，GD 都能够很快上手。Jenkins很灵活，这也可能导致项目组的集成流程中过度依赖于Jenkins本身，比如依赖Jenkins宿主机环境或路径，在Jenkins上写了很多临时脚本等，另外 Jenkins 缺乏对容器更好的支持，如镜像管理，容器监控等。就运维层面来说，Jenkins 只是个 Trigger + Scripts，离真正的 Ops 工具还差很远。因此目前运维基于 Docker API 搞了一套 Web 持续集成工具，将前面提到的”可运维”指标标准化，流程化。</p>
<p>从 CI 方面，保留 Trigger，WorkFlow，Stage 的概念:</p>
<ul>
<li>Trigger:  触发器，比如代码提交，定时触发，手动触发</li>
<li>WorkFlow: 工作流，由 Trigger 触发，包含多个顺序执行的 Stage，比如某个工作流包含Build，Deploy，Test三个 Stage</li>
<li>Stage: 阶段，包含多个可并行执行的 Task，比如Test Stage 包含多个可并发执行的 Test，其中一个失败，则整个 Stage 失败</li>
<li>Task: 最小粒度的执行单位，目前支持构建，部署和测试</li>
</ul>
<p>从 Docker 方面，集成 Docker Swarm 的 Cluster, Service, Task(这个 Task 是 Swarm 中的概念，相当于一个 Container)及部署策略等，支持单容器部署，同时，基于 Docker API 提供容器和物理机的管理，监控以及报警机制。基于 Docker Swarm，可以实现:</p>
<ul>
<li>资源管理: 集群/主机/容器/镜像的查看和管理</li>
<li>监控报警: 集群/主机/容器的资源占用，阈值和报警机制</li>
<li>扩容收缩: 主要针对无状态容器，可以手动扩容或收缩</li>
<li>故障转移: 基于 Docker Service 的容器级和主机级的故障转移</li>
</ul>
<p>这样，项目在开发过程中就可以通过这套工具去做持续集成，走运维标准的配置，部署，监控方案，项目在开发期间就去考虑和满足运维上的需求和规范，项目上线之后，服务器交付基本就是零成本的。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>go mod 依赖管理</title>
    <url>/2018/10/go-mod-intro/</url>
    <content><![CDATA[<p>go module 是 go1.11 引入的新概念，为 go  当前饱受诟病的 GOPATH 和依赖管理提供了更好的解决方案。在理解 go module 之前，先回顾下当前 Go 的项目结构和依赖管理都有什么问题:</p>
<p>1.GOPATH</p>
<p>GOPATH一定程度上简化了项目构建，但是给了开发者过多的限制，你的项目必须位于 GOPATH 下，否则编译器找到它，想要使用你自己的项目组织结构，要么你需要为每个项目设置一个 GOPATH，要么使用软链接来实现。大多数 go 新手都会纠结于应该使用一个 GOPATH 还是为每个项目创建一个 GOPATH，还是为所有依赖创建一个 GOPATH，受到一堆限制，却并没有得到便利。</p>
<span id="more"></span>
<p>2.依赖管理</p>
<p>依赖管理？对不起，go 没有依赖管理，go1.11之前所有的<a href="https://github.com/golang/go/wiki/PackageManagementTools">依赖管理方案</a>都是基于 Go 没有依赖管理这个事实之上的一些变通方案(tricks)。据说这个起因要追溯到 Google 内部，其使用巨大的单个仓库来维护项目代码，没有第三方仓库，也就不需要版本控制。go1.5开始关于依赖管理的最大变化就是 vendor 机制，它鼓励你将所有的依赖作为项目代码的一部分去管理，其实也是 “Google 风格” 的延续，只不过你可以选择使用某个版本的依赖，然后将其”冻结”到项目的 vendor 目录下，这一方面保证了可重现的构建，另一方面，解决了不同项目使用同一个依赖的不同版本的问题，但单片仓库和版本管理的问题仍然存在，依赖缺乏明确的版本定义，如果没有指定要使用的依赖版本，那么将是依赖这个 branch，然后再通过 hash 来校验，如果版本冲突了，你很难定位版本，并且解决冲突。</p>
<h4 id="go-module-初试"><a href="#go-module-初试" class="headerlink" title="go module 初试"></a>go module 初试</h4><p>一个 module 是指一组相关的 package，通常对应于一个 git 仓库，module 是代码交换和版本管理的基本单位，即 module 的依赖也是一个 module，go 命令现在直接支持 module 相关操作。由于现在还是试验阶段，go1.11 通过一个临时的环境变量 GO111MODULE 来控制启动和停用go module，该环境变量有三个值:</p>
<pre><code>auto: 默认值，即在 GOPATH 目录下，使用传统的 GOPATH 和 vendor 来查找依赖，在非 GOPATH 下则使用 go module 
on: module-aware mode，在任何目录都启用 go module，使用 go module 来控制依赖管理，在这种模式下，GOPATH 不再作为构建时的imports路径，只是作为存放下载的依赖($GOPATH/pkg/mod)和安装二进制文件的目录($GOPATH/bin，如果 GOBIN 未设置)
off: GOPATH mode，停用 go module，和 go1.11之前一样，使用 GOPATH 和 vendor 来定位依赖，并使用 dep 之类的依赖版本管理工具来冻结依赖
</code></pre><p>在介绍<code>go mod</code>命令前，我们先简单看下 go module 长啥样。假设我们设置<code>GO111MODULE=on</code>，现在开始对 GOPATH/src/ngs 库(之前由 dep 管理依赖)进行移植。</p>
<p>执行 <code>go mod init ngs</code>，会在 ngs 根目录下生成一个 go.mod 文件，该文件和 dep 的 Gopkg.toml 文件一样，用于记录当前module所依赖的版本，对新项目而言，只会生成一行<code>module packagename</code>，如果是已有项目，go module 会自动从 Gopkg.toml 等已有的依赖版本信息中导入生成依赖版本信息，比如以下是项目的 Gopkg.toml 文件内容:</p>
<pre><code>[[constraint]]
  branch = &quot;master&quot;
  name = &quot;github.com/yuin/gopher-lua&quot;

[[constraint]]
  name = &quot;google.golang.org/grpc&quot;
  version = &quot;1.12.2&quot;

[[constraint]]
  branch = &quot;v2&quot;
  name = &quot;gopkg.in/mgo.v2&quot;
</code></pre><p>对应生成的 go.mod 为:</p>
<pre><code>module ngs

require (
    github.com/yuin/gopher-lua v0.0.0-20180611022520-ca850f594eaa
    google.golang.org/grpc v1.12.2
    gopkg.in/mgo.v2 v2.0.0-20160818020120-3f83fa500528
)
</code></pre><p>注意，go.mod 中每个依赖都有严格的版本信息，这也是不同于之前 dep 等工具的地方，比如在 Gopkg.toml 中， gopher-lua 使用的 master 分支，go.mod 中，则会为依赖自动生成一个伪版本号<code>v0.0.0-20180611022520-ca850f594eaa</code>，你可以通过命令来手动升级它。这种自动冻结的特性不仅保证了可重现的构建，并且版本冲突的显式清晰的，你可以很直观地在 go.md 中看到冲突的原因，那个版本更新或者更稳定。</p>
<blockquote>
<blockquote>
<p>go module 使用<a href="https://semver.org/lang/zh-CN/">语义化版本(semantic versions)</a>标准来作为描述依赖版本的格式，这样版号可以通过直接比较来决定那个版本更新。版号通常通过 git tag 来标注。对于没有通过 tag 打版本号的提交，go module 使用伪版本号(pseudo-version) 来标记，伪版号的格式为 [之前最近一次的版本号]-[提交时间]-[提交哈希值]，比如 v0.0.0-20180611022520-ca850f594eaa，这样伪版本号也可以用于比较，伪版本号不需要手动输入，会由 go module 在冻结版本时自动生成。</p>
</blockquote>
</blockquote>
<p>现在我们的 ngs 已经成为了一个 go module，现在我们为其添加一个依赖: <code>go get github.com/gorilla/websocket@v1.3.0</code>，可以看到 go.mod 中多出一行: <code>github.com/gorilla/websocket v1.3.0</code>，但 GOPATH 和 vendor 下都没有看到 websocket，其被下载到了 <code>$GOPATH/pkg/mod/github.com/gorilla/websocket@1.3.0</code>目录，在 module-aware mode 下，<code>$GOPATH/pkg/mod</code> 目录会作为依赖被下载后的缓存目录，这里的依赖会将版本作为路径的一部分(与之前依赖管理本质区别)。我们可以以下方式对其进行升级/维护:</p>
<pre><code>go get -u 将会升级到最新的次要版本或者修订版本(x.y.z, z是修订版本号， y是次要版本号)
go get -u=patch 将会升级到最新的修订版本
go get package@version 将会升级到指定的版本号version
</code></pre><p>当然，我们这里在代码中并没有用到 websocket，可以运行 <code>go mod tidy</code> 来新增被漏掉的，或者删除多余的依赖，运行之后 go.mod 恢复如初。</p>
<p>可以看到，在 go module 模式下，我们不再需要 vendor 目录来保证可重现的构建，而是可以通过一个 go.mod 来基于每个依赖的精确管理号，并通过<code>go get</code> 等命令即可管理依赖升级/降级等。当然，如果你仍然想保留 vendor 目录，可以通过 <code>go mod vendor</code> 命令将项目用到的依赖拷贝到 vendor 目录下(为了保证兼容性，vendor 目录下的依赖目录名是不包含版本号的)。除了 go.mod 外，go module 还会生成一个 go.sum 来记录每个依赖版本的哈希值，用于校验版本正确性。通常情况下，你不需要手动编辑 go.mod，通过 <code>go get</code>，<code>go mod</code> 等命令来完成依赖管理的同时，go.mod 也会自动更新。</p>
<p>以下是 go module 相关的一些命令:</p>
<pre><code>go mod init: 初始化 go module
go mod download: 下载 go.mod 中的依赖到本地 Cache ($GOPATH/pkg/mod 下)
go mod vendor: 将项目依赖拷贝到 vendor 下
go mod tidy: 相当于 dep ensure，增加缺失的依赖(module)，丢掉没用的依赖(module)
go mod verify: 校验依赖
go mod edit: 编辑依赖，通过命令行手动升级或获取依赖
go list -m all: 列出当前项目(main module)的构建列表
</code></pre><p>go 的任何构建命令都可以判断依赖缺失并决定是否需要添加到 go.mod，比如如果你在你的项目代码没有依赖redis，然后你在代码中加入<code>import &quot;github.com/go-redis/redis&quot;</code> ，然后直接执行go build，将会导致 redis 被发现为缺失依赖，被自动添加进 go.mod 中。你可以通过 <code>-mod</code> 构建选项来控制这一行为，该选项有如下几个值:</p>
<ul>
<li><code>-mod=readonly</code>: 构建过程中，如果发现需要更改 go.mod，将会构建失败，即 go.mod 在构建过程中为只读的。 注: <code>go get</code> 命令不受此限制，<code>go mod</code> 命令不接受 -mod 选项</li>
<li><code>-mod=vendor</code>: go 命令假设所有的依赖都存放在 vendor 目录下，并且忽略 go.mod 中的依赖描述</li>
</ul>
<p>大概了解了 go module 之后，我们回顾它是如何解决我们前面提出的两个问题的:</p>
<ol>
<li>go module 通过 go.mod 来定位当前 module(也叫做 main module) 的 root path，即从当前执行命令的目录向上查找，直到找到go.mod，而不再通过 <code>$GOPATH/src</code> 来定位项目。</li>
<li>go module 对每个依赖生成严格的版本号，并且将同一个依赖的不同版本以目录区分开来，以 $GOPATH/pkg/mod 作为不同 module 共享依赖的路径。</li>
</ol>
<p>现在 go module 已经有一些依赖版本管理的雏形了，离 <a href="http://wudaijun.com/2016/09/erlang-rebar3/">Erlang Rebar3</a> 这种成熟的依赖管理虽然还有一些距离，但确实实用性，易用性都要好很多。</p>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux CGroup 基础</title>
    <url>/2018/10/linux-cgroup/</url>
    <content><![CDATA[<h3 id="CGroup-V1"><a href="#CGroup-V1" class="headerlink" title="CGroup V1"></a>CGroup V1</h3><h4 id="1-CGroup-概念"><a href="#1-CGroup-概念" class="headerlink" title="1. CGroup 概念"></a>1. CGroup 概念</h4><ul>
<li>Task: 任务，也就是进程，但这里的进程和我们通常意义上的 OS 进程有些区别，在后面会提到。</li>
<li>CGroup: 控制组，一个 CGroup 就是一组按照某种标准划分的Tasks。这里的标准就是 Subsystem 配置。换句话说，同一个CGroup 的 Tasks 在一个或多个 Subsystem 上使用同样的配置。</li>
<li>Hierarchy: 树形结构的 CGroup 层级，每个子 CGroup 节点会继承父 CGroup 节点的子系统配置，每个 Hierarchy 在初始化时会有默认的 CGroup(Root CGroup)。</li>
<li>Subsystem: 子系统，具体的物理资源配置，比如 CPU 使用率，内存占用，磁盘 IO 速率等。一个 Subsystem 只能附加在一个 Hierarchy 上，一个 Hierarchy 可以附加多个 Subsystem。</li>
</ul>
<span id="more"></span>
<p><img src="/assets/image/201810/cgroup-base.png" alt=""></p>
<h4 id="2-CGroup-文件系统"><a href="#2-CGroup-文件系统" class="headerlink" title="2. CGroup 文件系统"></a>2. CGroup 文件系统</h4><p>在具体实现中，CGroup 通过虚拟文件系统实现，一个 CGroup 就是一个文件夹，Hierarchy 层级结构通过文件夹结构实现，而每个 CGroup 的 Subsystem 配置和 Tasks 则通过文件来配置。在 Ubuntu 下，可通过<code>lssubsys -m</code>(需要安装cgroup-tools包)，查看已有的 Subsystem:</p>
<pre><code>root# lssubsys -m
cpuset /sys/fs/cgroup/cpuset
cpu,cpuacct /sys/fs/cgroup/cpu,cpuacct
blkio /sys/fs/cgroup/blkio
memory /sys/fs/cgroup/memory
devices /sys/fs/cgroup/devices
freezer /sys/fs/cgroup/freezer
net_cls,net_prio /sys/fs/cgroup/net_cls,net_prio
perf_event /sys/fs/cgroup/perf_event
hugetlb /sys/fs/cgroup/hugetlb
pids /sys/fs/cgroup/pids
</code></pre><p>这些是 Ubuntu16.04 上已实现的 Subsystem 和对应 Hierarchy。各个Subsystem 的作用可参考 <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/ch01">RedHat CGroup Doc</a>。在其它系统，你可以需要手动挂载虚拟文件系统并建立 Subsystem 和 Hierarchy 的关系:</p>
<pre><code>root# mount -t tmpfs cgroup_root /sys/fs/cgroup
root# mkdir /sys/fs/cgroup/cpu
root# mount -t cgroup cpu -ocpu /sys/fs/cgroup/cpu
</code></pre><p><code>/sys/fs/cgroup/cpu</code> 即成为附加(attach)了 CPU Subsystem 的 Hierarchy 的根目录，即 Root CGroup，我们可以在该 CGroup 下创建一个 Child CGroup:</p>
<pre><code>root# mkdir /sys/fs/cgroup/cpu/demo
root# ls /sys/fs/cgroup/cpu/demo
cgroup.clone_children  cgroup.procs  cpuacct.stat  cpuacct.usage  cpuacct.usage_percpu  cpu.cfs_period_us  cpu.cfs_quota_us  cpu.shares  cpu.stat  notify_on_release  tasks  
</code></pre><p>在创建 CGroup 时，就已经生成了一堆文件，一个 CGroup 目录中的内容大概可以分为四类: </p>
<ul>
<li>Subsystem Conf: 如附加了 CPU Subsystem 的 CGroup 目录下的 cpu* 文件均为 CPU Subsystem 配置</li>
<li>Tasks: 在该 CGroup 下的 Tasks，分为两个文件，tasks 和 cgroup.procs，两者记录的都是在该进程 PID 列表，但是有所区别。</li>
<li>CGroup Conf: CGroup 的一些通用配置，比如 notify_on_release 用于在 CGroup 结构变更时执行 release_agent 中的命令，cgroup.clone_children 用于在 Child CGroup 创建时，自动继承父 Child CGroup 的配置，目前只有 cpuset SubSystem 支持</li>
<li>Child CGroups: 除以上三种文件外的子目录，如Ubuntu16.04中，每个 Root CGroup 下都有个 docker 目录，它由 Docker 创建，用于管理Docker容器的资源配置</li>
</ul>
<p>关于 tasks 和 cgroup.procs，网上很多文章将 cgroup 的 Task 简单解释为 OS 进程，这其实不够准确，更精确地说，cgroup.procs 文件中的 PID 列表才是我们通常意义上的进程列表，而 tasks 文件中包含的 PID 实际上可以是 <a href="https://zh.wikipedia.org/wiki/%E8%BD%BB%E9%87%8F%E7%BA%A7%E8%BF%9B%E7%A8%8B">Linux 轻量级进程(LWP)</a> 的 PID，而由于 Linux pthread 库的线程实际上轻量级进程实现的(Linux 内核不支持真正的线程，可通过<code>getconf GNU_LIBPTHREAD_VERSION</code>查看使用的 pthread 线程库版本，Ubuntu16.04上是NPTL2.23(Native Posix Thread Lib)，简单来说，Linux 进程主线程 PID = 进程 PID，而其它线程的 PID (LWP PID)则是独立分配的，可通过<code>syscall(SYS_gettid)</code>得到。LWP 在 ps 命令中默认是被隐藏的，在/proc/目录下可以看到。为了区分方便，我们将以 Proc 来表示传统意义上的进程，以 Thread 表示 LWP 进程。</p>
<p>我们可以通过 ps 命令的 -T 参数将 LWP 在 SPID 列显示出来:</p>
<pre><code>root# ps -ef | wc -l
218
root# ps -efT | wc -l
816
root# ps -p 28051 -lfT                                                  
F S UID        PID  SPID  PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD               
0 Z root     28051 28051 26889  0  80   0 -     0 exit   10:30 pts/10   00:00:00 [a.out] &lt;defunct&gt; 
1 R root     28051 28054 26889 99  80   0 - 12409 -      10:30 pts/10   00:00:10 [a.out] &lt;defunct&gt; 
1 R root     28051 28055 26889 99  80   0 - 12409 -      10:30 pts/10   00:00:10 [a.out] &lt;defunct&gt;
</code></pre><p>以上示例中，Proc 28051 下有两个 Thread (28054,28055)，即开了两个子线程。总的来说，Linux 下这种通过 LWP 来实现线程的方式，在一些时候会给用户一些困惑，比如如果我 <code>kill -9 28055</code>(默认在 ps 下看不到)，按照 POSIX 标准，28055 “线程”所在的进程会被 Kill掉，因此28051,28054,28055三个进程都会被杀掉，感觉就很诡异。感兴趣的可以看看<a href="https://blog.csdn.net/tianyue168/article/details/7403693">这篇文章</a>)。</p>
<p>当要向某个 CGroup 加入 Thread 时，将Thread PID 写入 tasks 或 cgroup.procs 即可，cgroup.procs 会自动变更为该 Task 所属的 Proc PID。如果要加入 Proc 时，则只能写入到 cgroup.procs 文件(未解)，tasks 文件会自动更新为该 Proc 下所有的 Thread PID。可以通过<code>cat /proc/PID/cgroup</code>查看某个 Proc/Thread 的 CGroup 信息，</p>
<h4 id="3-一个实例"><a href="#3-一个实例" class="headerlink" title="3. 一个实例"></a>3. 一个实例</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _GNU_SOURCE         <span class="comment">/* See feature_test_macros(7) */</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/stat.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/syscall.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> NUM_THREADS = <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">thread_main</span><span class="params">(<span class="keyword">void</span> *threadid)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">long</span> tid;</span><br><span class="line">    tid = (<span class="keyword">long</span>)threadid;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;sub thread#%ld, pid #%ld!\n&quot;</span>, tid, syscall(SYS_gettid));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> a=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        a++;</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;main thread, pid #%ld!\n&quot;</span>, syscall(SYS_gettid));</span><br><span class="line">    <span class="keyword">int</span> num_threads;</span><br><span class="line">    <span class="keyword">if</span> (argc &gt; <span class="number">1</span>)&#123;</span><br><span class="line">        num_threads = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (num_threads&lt;=<span class="number">0</span> || num_threads&gt;=<span class="number">100</span>)&#123;</span><br><span class="line">        num_threads = NUM_THREADS;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pthread_t</span>* threads = (<span class="keyword">pthread_t</span>*) <span class="built_in">malloc</span> (<span class="keyword">sizeof</span>(<span class="keyword">pthread_t</span>)*num_threads);</span><br><span class="line">    <span class="keyword">int</span> rc;</span><br><span class="line">    <span class="keyword">long</span> t;</span><br><span class="line">    <span class="keyword">for</span>(t=<span class="number">0</span>; t&lt;num_threads; t++)&#123;</span><br><span class="line">        rc = pthread_create(&amp;threads[t], <span class="literal">NULL</span>, thread_main, (<span class="keyword">void</span> *)t);</span><br><span class="line">        <span class="keyword">if</span> (rc)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;ERROR; return code from pthread_create() is %d\n&quot;</span>, rc);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">    <span class="built_in">free</span>(threads);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码简单创建了四个死循环线程，运行:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root# gcc -pthread t.c &amp;&amp; .&#x2F;a.out</span><br><span class="line">main thread, pid #30354</span><br><span class="line">sub thread#0, pid #30355</span><br><span class="line">sub thread#2, pid #30357</span><br><span class="line">sub thread#3, pid #30358 </span><br><span class="line">sub thread#1, pid #30356</span><br></pre></td></tr></table></figure>
<p>通过 htop/top(top 默认不会显示 LWP) 看到现在四个 CPU 会被吃满，为了限制资源，我们创建一个 CGroup:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root# mkdir &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;wdj</span><br><span class="line"># 创建 CGroup 之后，会自动生成相关文件</span><br><span class="line">root# ls &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;wdj&#x2F;</span><br><span class="line">cgroup.clone_children  cgroup.procs  cpuacct.stat  cpuacct.usage  cpuacct.usage_percpu  cpu.cfs_period_us  cpu.cfs_quota_us  cpu.shares  cpu.stat  notify_on_release  tasks</span><br><span class="line"># 配置该 CGroup，CPU 使用率不能超过 50%</span><br><span class="line">root# echo 50000 &gt; &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;wdj&#x2F;cpu.cfs_quota_us</span><br><span class="line"># 将 Proc PID 写入 procs</span><br><span class="line">root# echo 30354 &gt; &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;wdj&#x2F;cgroup.procs</span><br><span class="line"># tasks 已经自动更新, # 此时 CPU 占用率会立即下降到 50%</span><br><span class="line">root# cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;wdj&#x2F;tasks</span><br><span class="line">30355</span><br><span class="line">30356</span><br><span class="line">30357</span><br><span class="line">30358</span><br><span class="line"></span><br><span class="line"># 同样的方式，再来限制下 CPU 核的使用</span><br><span class="line">root# mkdir &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpuset&#x2F;wdj</span><br><span class="line"># 限制只能使用 CPU 2,3 两个核</span><br><span class="line"># 在使用前需要先执行，参考https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;28348627&#x2F;echo-tasks-gives-no-space-left-on-device-when-trying-to-use-cpuset</span><br><span class="line">#root echo 0 &gt; cpuset&#x2F;wdj&#x2F;cpuset.mems</span><br><span class="line">#root echo 0 &gt; cpuset&#x2F;wdj&#x2F;cpuset.cpus</span><br><span class="line">echo 2,3 &gt; &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpuset&#x2F;wdj&#x2F;cpuset.cpu</span><br><span class="line"># 这次我们将 Thread PID 写入 cgroup.procs</span><br><span class="line">root# echo 30355 &gt; &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;wdj&#x2F;cgroup.procs</span><br><span class="line"># tasks 会自动更新为该 Proc下所有的 Thread PID</span><br><span class="line">root# cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;wdj&#x2F;tasks</span><br><span class="line">30355</span><br><span class="line">30356</span><br><span class="line">30357</span><br><span class="line">30358</span><br></pre></td></tr></table></figure>
<p>最终我们通过 htop 得到的效果如下:</p>
<p><img src="/assets/image/201810/cgroup-example-htop.png" alt=""></p>
<p>如果我们只将 Thread PID 如30356写入 /sys/fs/cgroup/cpu/wdj/tasks，则只会限制thread#1的CPU使用率。总结一下:</p>
<ul>
<li>将 Thread PID 写入 tasks: 仅对该”线程”(LWP) 生效</li>
<li>将 Thread PID 写入 cgroup.procs: 会加入整个 Proc PID</li>
<li>将 Proc PID 写入 tasks: 没有效果，写不进去</li>
<li>将 Proc PID 写入 cgroup.procs: 会加入整个 Proc PID</li>
</ul>
<p>表现有点怪异，还没找到具体原因，总的来说，目前的 CGroup 还有点乱:</p>
<ol>
<li>Subsystem, Hierarchy, CGroup 三者的结构有点乱，将对进程的分组和对资源的控制混在了一起</li>
<li>由于 Linux 通过 LWP 实现 Thread，导致 CGroup 看起来可以对线程实现控制，但这方面机制不够健全，比如前面提到的加入机制</li>
</ol>
<h3 id="CGroup-V2"><a href="#CGroup-V2" class="headerlink" title="CGroup V2"></a>CGroup V2</h3><p>CGroup V2 在 Linux Kernel 4.5中被引入，并且考虑到其它已有程序的依赖，V2 会和 V1 并存几年。针对于 CGroup V1 中 Subsystem, Herarchy, CGroup 的关系混乱，CGroup V2 中，引入 unified hierarchy 的概念，即只有一个 Hierarchy，仍然通过 mount 来挂载 CGroup V2:</p>
<pre><code>mount -t cgroup2 none $MOUNT_POINT
</code></pre><p>挂载完成之后，目录下会有三个 CGroup 核心文件:</p>
<ul>
<li>cgroup.controllers: 该文件列出当前 CGroup 支持的所有 Controller，如: cpu io memory</li>
<li>cgroup.procs: 在刚挂载时，Root CGroup 目录下的 cgroup.procs 文件中会包含系统当前所有的Proc PID(除了僵尸进程)。同样，可以通过将 Proc PID 写入 cgroup.procs 来将 Proc 加入到 CGroup</li>
<li>cgroup.subtree_control: 用于控制该 CGroup 下 Controller 开关，只有列在 cgroup.controllers 中的 Controller 才可以被开启，默认情况下所有的 Controller 都是关闭的。</li>
</ul>
<p>这三个文件在所有的 CGroup 中都会生成，除此之外，在非 Root CGroup 下，还会有一个 cgroup.events 文件，该文件的 populated 字段会指出当前 CGroup 下的所有存活的 Proc PID，为1则表示其下存活的 Proc PID 数量&gt;1，否则populated为0。这用于 CGroup V1的 release_agent 等事件通知，因为当最后一个进程退出 CGroup 时，cgroup.events 文件会被修改，从而触发事件。</p>
<pre><code># 查看当前 CGroup 支持的所有 Controllers
root# cat cgroup.controllers
cpu io memory
# 开启和关闭 Controller
root# echo &quot;+cpu +memory -io&quot; &gt; cgroup.subtree_control
</code></pre><p>在 CGroup V2 中，A CGroup 开启了某个 Controller，则其直接子 CGroup B会生成对应的 Controller 接口文件(如 <code>cpu.cfs_quota_us</code>)，并且B CGroup 的 cgroup.controllers 会更新。B也可以选择开启或关闭该 Controller，但影响的是 B 的直接子 CGroup。并且只有没有 Tasks 的 CGroup 即中间节点可以开关 Controller，只有叶子节点(和根节点)可以执行资源配置。这样每个节点要么控制子 CGroup 的 Controller 开关(中间节点)，要么控制其下 Tasks 的资源配置(叶子节点)，结构更清晰。</p>
<p>另外，CGroup V2 去掉了 Tasks 文件，增加了 cgroup.threads 文件，用于管理 LWP(仍然没有放弃对”线程”的支持)，但语义上会清晰一些。</p>
<p>站在进程的角度来说，在挂载 CGroup V2时，所有已有Live Proc PID 都会加入到 Root CGroup，之后所有新创建的进程都会自动加入到父进程所属的 CGroup，由于 V2 只有一个 Hierarchy，因此一个进程同一时间只会属于一个 CGroup:</p>
<pre><code>root# cat /proc/842/cgroup
...
0::/test-cgroup/test-cgroup-nested
</code></pre><p>总的来说，CGroup V2去掉了多个 Hierarchy 结构，使用 unified Hierarchy，对 Hierarchy 内部层级结构作出一些限制以保证层级逻辑清晰，并且优化了 CGroup 的文件组织(如 cgroup.events, cgroup.threads)。由于目前手头暂时没有 Kernel 4.5，只能通过文档大概了解下，还是要找机会实际体验一下。</p>
<p>Reference:</p>
<ol>
<li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt">CGroup V1 Document</a></li>
<li><a href="https://www.kernel.org/doc/Documentation/cgroup-v2.txt">CGroup V2 Document</a></li>
<li><a href="https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/resource_management_guide/chap-introduction_to_control_groups">RedHat: 控制群组简介</a></li>
<li><a href="https://lwn.net/Articles/679786/">RedHat: Understanding the new control groups API</a></li>
<li><a href="https://coolshell.cn/articles/17049.html">CoolShell: DOCKER基础技术：LINUX CGROUP</a></li>
</ol>
]]></content>
      <categories>
        <category>os</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>再谈调度</title>
    <url>/2018/11/scheduler-blabla/</url>
    <content><![CDATA[<p>调度的概念这里就不赘述了，调度本质上就是一个资源分配算法，本文谈谈调度的基础策略，常见模型，以及 Go 和 Erlang 的一些调度特性。</p>
<h2 id="调度策略"><a href="#调度策略" class="headerlink" title="调度策略"></a>调度策略</h2><h3 id="抢占-vs-协作"><a href="#抢占-vs-协作" class="headerlink" title="抢占 vs 协作"></a>抢占 vs 协作</h3><p>从调度机制上来讲，调度可以分为抢占式和协作式。</p>
<p>非抢占方式是指一旦将调度资源(如 CPU)分配给某任务 后，便让该任务一直执行，直到该任务完成或阻塞或主动让出CPU控制权，非抢占调度又称为协作式调度，它实现简单，并且对共享资源的访问也更安全(如允许使用不可重入函数)。非抢占算法常见的如 FIFO，STCF(Short time to complete first)等。</p>
<span id="more"></span>
<p>抢占方式则允许调度程序根据某种规则，剥夺当前进程的调度资源，将其分配给其它进程。常见的抢占策略有:</p>
<ol>
<li>基于时间片: 给每个进程分配时间片，当时间片用完后，则停止该进程重新调度下一个进程，这种均分CPU 的算法，又叫轮转调度算法</li>
<li>基于优先级: 给每个进程分配一个优先级，一旦出现一个优先级更高的进程，则停止当前进程并切换到该高优先级进程，这种调度算法又叫优先级抢占</li>
<li>轮转调度和优先级抢占结合: 即相同优先级的进程使用轮转调度，如果遇到更高优先级的进程，则可抢占CPU。现代 OS 如 Linux 通常都使用这种混合调度策略。</li>
</ol>
<p>PS: 基于优先级抢占容易出现优先级反转的问题: 优先级低的任务持有一个被优先级高的任务所需要的共享资源，这种情况下，优先级低的任务有资源而得不到CPU，优先级高的资源有CPU而得不到资源，从而阻塞(导致其它中优先级的任务获得执行)或者忙等(可能永远无法获得资源)。</p>
<p>解决优先级反转的方案:</p>
<ol>
<li>给临界区一个高优先级，所有进入该临界区的任务将获得该高优先级，避免其被随意抢占</li>
<li>当高优先级任务在等待低优先级进程持有资源时，低优先级进程将暂时获得高优先级进程的优先级，VxWorks采用的方式。</li>
<li>禁止中断，也就是在临界区不可被抢占，Linux 采用的就是这种方式，在 thread_info.preeempt_count 记录每个进程当前持锁计数。</li>
</ol>
<p>另外，调度器是不能在进程指令流的任意一点执行打断的，因为进程可能此时正在做任何事情，如系统调用，死循环，锁操作等，要实现任意状态的可抢占性代价是很大的，需要 OS 和 App 的通力配合，特别是在涉及在内核态的时候，目前所有OS都不能在进程执行的任意点进行抢占。只是说不断让抢占区更大，抢占点尽可能地密集。</p>
<h3 id="实时-vs-非实时"><a href="#实时-vs-非实时" class="headerlink" title="实时 vs 非实时"></a>实时 vs 非实时</h3><p>从系统需求或用户角度而言，调度系统可以分为实习系统和非实时系统。</p>
<p>在实时操作系统中，系统必须在特定的时间内完成指定的应用。实时通常分为软实时(soft real-time)和硬实时(hard real-time)，硬实时是指系统要有确定的最坏情况下的服务时间，即对于事件的响应时间截止期限无论如何都必须得到满足，通常应用在军工航天领域。而软实时只提供统计意义上的实时，比如应用要求在95%的情况下都会确保在规定的时间内执行某个任务，而不一定要求100%。实时系统通常采用抢占调度，实现一个硬实时系统的代价是很高的，要做到进程可以在任意时刻被抢占，在现代OS上来讲，基本是不可能的，因为OS的很多系统调用都是不可被打断的，并且很多操作具备时间的随机性，比如 CPU Cache Miss，Page Fault，CPU Branch Predictor 等等。</p>
<p>BTW, 为什么现代OS不尽可能地去掉这些不稳定性(如虚拟内存，CPU多级Cache，分支预测等)，从而为成为实时系统打好基础呢？对桌面操作系统而言，对实时性的要求没有那么高，应用切换偶尔卡一卡并无大碍，桌面系统更关注的一方面是对内核的统一抽象，屏蔽硬件差异化，接口丰富易用，让上层应用易于开发，比如虚拟内存，文件描述符等。另一方面，桌面系统在选择牺牲部分的实时性来提高吞吐量，比如多级Cache，分支预测。因此尽管如 Linux 这类桌面系统支持实时优先级和多种调度机制，但仍然最多只能实现软实时，这是设计目标决定的。</p>
<p>而非实时系统，则没有对最低任务处理时延的要求，比如简单的非抢占调度模型。</p>
<h2 id="调度结构"><a href="#调度结构" class="headerlink" title="调度结构"></a>调度结构</h2><p>这里我们讨论基于OS之上的几种常见的应用层调度。对应用层而言，所谓调度器(scheduler)便是OS线程，在此之上应用实现自己的任务，任务队列，以及调度算法。</p>
<h3 id="single-scheduler"><a href="#single-scheduler" class="headerlink" title="single scheduler"></a>single scheduler</h3><p><img src="/assets/image/201811/scheduler-1-1.png" alt=""></p>
<p>这是最简单的模型，实际上，几乎所有调度器最开始就是这样的，如Go,Erlang,甚至OS(单核年代)的早期版本，复杂项目的通用最佳实践是先跑起来再优化(“First make it work, then measure, then optimize”.)。这种调度模型只有一个调度器和一个任务队列，由于不需要锁，所以单核吞吐量很高，主要的缺点在于无法充分利用调度资源(如多核)，并且容易出现任务饥饿(多调度器本质也会有这种情况，只不过被掩盖了一些)。</p>
<h3 id="multi-scheduler-with-global-queue"><a href="#multi-scheduler-with-global-queue" class="headerlink" title="multi scheduler with global queue"></a>multi scheduler with global queue</h3><p>为了最大化多核收益，我们需要多个调度器，理想情况下是调度器的数量和CPU核心数一致。因此有了如下调度模型:</p>
<p><img src="/assets/image/201811/scheduler-n-1.png" alt=""></p>
<p>如图，多个调度器共享一个全局任务队列，Erlang OTP R11B 便使用这种模型，该模型主要的瓶颈在于全局任务队列的操作需要加锁，并且CPU核心数越多，调度瓶颈越明显，从而限制了调度算法在多核下的扩展性。</p>
<h3 id="multi-scheduler-with-local-queue"><a href="#multi-scheduler-with-local-queue" class="headerlink" title="multi scheduler with local queue"></a>multi scheduler with local queue</h3><p>为了优化全局任务队列带来的瓶颈问题，借鉴”Cache思维”，可以给每个调度器分配一个本地的任务队列:</p>
<p><img src="/assets/image/201811/scheduler-n-n.png" alt=""></p>
<p>这样调度器可以无锁操作本地任务队列，显著减少锁竞争，提升多核下的调度效率。但这样又引入了新的问题: 如何尽可能地让各个调度器都随时有事情做(任务分配尽可能均衡)。比如如果给每个调度器本地任务队列分配了10个任务，执行最快的调度器A执行完这10个任务时，执行最慢的调度器B可能才执行完第一个，在这种情况下，调度器A是否应该去调度B的任务队列steal(窃取)一部分任务过来，以让整体调度效率最高。这个过程叫任务迁移(Task Migration)或任务窃取(Task Stealing)。Erlang R13B+ 和 Go 调度都是基于此结构，但有一些区别。</p>
<p>以上三种模型是大多数调度器历经的三个阶段，最终演化得到的是一个多层次，局部性的结构(类似 CPU Cache层级)。</p>
<h2 id="现实中的调度器"><a href="#现实中的调度器" class="headerlink" title="现实中的调度器"></a>现实中的调度器</h2><p>就调度器结构而言，各个调度算法大同小异，各个调度算法的根本差异还是在调度策略上，基于设计目标，在复杂性，吞吐量，实时性之间去做取舍，这里我仍然想以 Erlang 和 Go来举例说明。</p>
<p>基于Erlang的产生背景(通信领域)，Erlang 在设计之初就对实时性(低延迟)非常看重，为了达成软实时性，Erlang的调度必然是抢占式的，它通过给每个Erlang进程设定规约(Reduction)来作为一个进程的虚拟时间片，进程调用函数，BIF，GC，ETS操作，发送消息等，都会消耗规约，甚至用Erlang自带的用C写的正则表达式处理，也添加了扣除规约的代码，每个Erlang进程默认有2000规约，在Erlang的设计理念中，天下没有”免费”的操作，它重度依靠规约来衡量进程何时被换出。但理想和现实往往有差别，NIF的出现打破了这个定律，NIF是用户用C实现的可供Erlang调用的函数，它是不可被调度的，对此，Erlang打出了如下补丁:</p>
<ol>
<li>官方建议NIF不要超过1ms(相信开发者对自己写的代码心里有数…)</li>
<li>在NIF中给Erlang虚拟机手动汇报当前执行时间，并手动记录上下文和恢复(抢占式变成了协作式，强制变成了自愿…)</li>
<li>将NIF放到自己创建的OS线程中执行，通过消息的方式将结果返回到Erlang进程(走开，别脏了我的公平调度器)</li>
<li>将NIF放到OTP为你准备的脏调度器(OTP R17引入，需要在启动时通过参数开启)中执行(好吧，我给你提供脏调度器)</li>
</ol>
<p>PS: Erlang OTP R17之后提供了脏调度器功能，这也是继R13B之后对调度结构的又一次改进，虚拟机调度器就变成了M+N个。</p>
<p>以上方案可以说都是治标不治本，所以写纯Erlang代码，你可以享受到它很多的便利，但是一旦你因为性能问题，或要对接外部库等各种原因需要用到C的时候，一切都开始不美好了。</p>
<p>Erlang 的另一个问题也来自于其”公平调度”，我们假设有10000个逻辑进程，它们会将日志数据发到一个logger进程，那么系统上一共有10001个进程(忽略其它)，理想情况下，我们当然希望这个logger有任务就处理，避免消息堆积，最大化吞吐量，但Erlang的公平调度会想尽办法让这个logger进程和其它逻辑进程平起平坐，哪怕它有很多事情要做，然后导致导致logger进程消息队列膨胀，内存随之增长，甚至VM随之挂掉。针对这个问题通常的处理方案是:</p>
<ol>
<li>提升logger进程的优先级(没有具体测试过)</li>
<li>开多个logger进程争取更多的执行权(笨办法)</li>
<li>从设计上尽量避免这种扇入扇出模型，同一节点尽可能跑相同类型的任务，比如将logger放到其它节点(Erlang的”并发思维”)</li>
<li>通过NIF来绕过时间片限制(骚操作)</li>
</ol>
<p>因此，我们通常说Erlang在进程数少的时候表现不怎么样，而在进程多的却有很好的低延时表现。Erlang 调度器还有一些其它细节没有提到，比如:</p>
<ol>
<li>通过三个优先级队列(low/normal,high,max)来实现进程的优先级调度</li>
<li>当调度器idle时，会自旋一段时间，如果没有新任务到达，则关闭该调度器(节能减排)</li>
<li>除了Process外，Erlang还处理Port任务，Port是Erlang与外部通信(文件，网络，C等)的一种机制</li>
<li>Erlang对网络IO进行了特别的优化(System Level Activities)，即将所有的套接字设置为非阻塞，然后通过epoll机制去轮询并唤醒调用进程，通过应用层的阻塞/唤醒模拟系统调用。</li>
</ol>
<p>反过来谈 Go，如果说 Erlang 为实时性殚精竭虑的话，那么Go则要实务得多，更加偏向于吞吐量和实用性，我之前谈过<a href="http://wudaijun.com/2018/01/go-scheduler/">Go GPM模型</a>，Go没有时间片或规约的概念，它的抢占也不是完全抢占的，它通过一个后台线程sysmon来监控并决定何时发起抢占，何时 GC 等，比如一个goroutine执行超过了10ms，sysmon则会向其发出抢占请求。抢占的方式也很简单，给goroutine打一个标记，goroutine在调用函数分配函数栈时会检查该标记，来决定当前G是否应该让出调度权，因此它没办法抢占死循环。可以看到，Go的调度模型实现相对比较简单，一方面可能调度器仍然还很年轻(STW的痛还历历在目)，另一方面Go的设计哲学就是简单。如果要解释得再官方一些: Go 更看重吞吐量，而非实时性。</p>
<p>另外，由于Erlang和Go都是为服务器设计的语言，因此它们都是网络IO进行了优化，将所有套接字设置为 nonblock，通过轮询/唤醒来向应用层屏蔽系统调用，通过IO复用+应用层阻塞来避免调度器阻塞在系统调用上。</p>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>要理解一个调度器，需要结合其产生背景，设计目标，变更历史等，万丈高楼平地起，调度器这类复杂的系统，通常都是”First make it work, then measure, then optimize”，比如 Erlang 的 NIF，Go 的 STW 等，都在逐渐优化。</p>
<p>实时性和吞吐量是不可兼得的，这已经在其它系统上得到了验证。实时系统通常实现都比较复杂，并且由于现代 OS 最多满足软实时特性，因此应用层的调度也最多实现软实时。严格意义上的硬实时系统通常由特定领域的嵌入式系统实现。同时，也因为应用层的调度受更底层的OS调度的影响，要达到一个系统的整体最优，需要协调不同的调度层级，比如 Erlang 提供一个<code>+sbt</code>参数可以将调度器与 CPU 核心绑定，这样可以更好地利用 CPU 缓存和局部性，以提升整体性能。</p>
<p>相关资料:</p>
<ol>
<li><a href="http://wudaijun.com/2018/01/go-scheduler/">Go 调度模型</a></li>
<li><a href="https://blog.csdn.net/gatieme/article/details/51872618">Linux用户抢占和内核抢占详解</a></li>
<li><a href="http://erlang.org/euc/08/euc_smp.pdf">Inside the Erlang VM</a></li>
<li><a href="http://www.cnblogs.com/zhengsyao/p/how_erlang_does_scheduling_translation.html">Erlang的调度原理(译文)</a></li>
</ol>
]]></content>
      <categories>
        <category>os</category>
      </categories>
      <tags>
        <tag>erlang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>一致性杂谈</title>
    <url>/2018/09/consistency/</url>
    <content><![CDATA[<p>在计算机领域，谈到一致性这个词时，你会想到CAP理论的 consistency，或者数据 ACID 中的 consistency，或者 cache 一致性协议的 coherence，还是 Raft/Paxos 中的 consensus？</p>
<p>一致性大概是开发者最容易造成困惑的概念之一，在很多中文文献中，都将consistency，coherence，consensus 三个单词统一翻译为”一致性”，但是它们的意义是有所不同的。本文尝试以”一致性”为线头，梳理下相关概念，以及它们之间的区别和联系。</p>
<h4 id="Consensus"><a href="#Consensus" class="headerlink" title="Consensus"></a>Consensus</h4><p>更准确的翻译是共识，共识是容错分布式系统中的一个基本问题，共识的本质是多个节点就某个提议达成一致。在分布式系统下，由于节点故障，网络时延，网络分区等问题的存在，2PC/3PC这类强一致事务手段通常是不可取的: 任何节点故障或网络问题都会阻塞整个事务，降低系统的可用性，并且系统节点越多，可用性受影响越大。为了解决这个矛盾，分布式系统通常采用状态机复制+多数投票的机制来构建高可用容错系统:</p>
<ul>
<li>状态机复制(<a href="https://en.wikipedia.org/wiki/State_machine_replication">State Machine Replication</a>): 它的理论基础是任何初始状态一样的状态机(如KV Store)，如果执行的命令日志(包括新增、修改、删除等任何操作本质都将转化为新的命令日志追加)一样，则它们的状态机最终状态也将一样(KV数据一致)。如此不需要强制这些命令在各个节点是同时开始、同步完成的，只需要将连续的命令日志同步给其他节点(这个步骤也叫日志复制Log Replication)，允许在此期间节点存在内部状态的不一致(只要这些不一致不被外观察到)，所有的分布式节点的最终状态会达成一致。</li>
<li>投票机制(<a href="https://en.wikipedia.org/wiki/Quorum_(distributed_computing">Quorum</a>)): 少数服从多数原则，如果能在多数节点达成一致时就作出不可推翻的最终决策，那么就可以容忍少数节点的不可用，这也就打破了前面说的节点数越多，可用性越低的悖论</li>
</ul>
<p>在状态机复制的场景下，Paxos/Raft 等共识算法被用来确保各个复制状态机(节点)的日志是一致的，但Paxos/Raft 本身对外不直接体现出一致性(Consistency)，一致性是应用层的决策，比如Raft算法中，写操作成功，仅仅意味着超过半数节点对该写日志进行Commit(命令日志一致)，但不保证它们对该命令进行了Apply(状态机一致)，这一层就是交由应用层去灵活实现的，类似的应用层取舍点还包括Follower是否提供读服务，网络分区后Follower/Candidate是否对外提供读服务等等，因此不同的应用可以基于Raft算法实现不同的一致性，比如ETCD基于Raft支持线性一致性(后面会聊到这个概念)的读写操作。从另一个角度来说，共识算法可以理解为达成一致的一种算法手段。</p>
<p>Paxos/Raft属于宕机容错(CFT，Crash Fault Tolerance)算法，因为它们只容忍了节点/网络故障，没有考虑节点不可信任，可能”作恶”的问题，如经典的<a href="https://zh.m.wikipedia.org/zh-hans/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98">拜占庭将军问题</a>。能够(一定程度)容忍拜占庭问题的共识算法被称为拜占庭容错(Byzantine Fault Tolerance)算法，典型如POW(Proof of Work)、POS(Proof of Stake)、PBFT(Practical Byzantine Fault Tolerance)算法等，BFT算法通常比CFT算法实现成本更高，它通常适合用在公网，去中心化的情形下，如区块链场景。</p>
<span id="more"></span>
<h4 id="ACID-Consistency"><a href="#ACID-Consistency" class="headerlink" title="ACID Consistency"></a>ACID Consistency</h4><p>ACID 中的C指代Consistency or Correctness(From <a href="https://en.wikipedia.org/wiki/ACID#Consistency_(Correctness">WIKI</a>))，但通常被译作事务的一致性，主流理解这里的一致性是指数据库的一致性约束，包括唯一键、外键约束，级联，触发器等。在事务开始之前和事务结束以后，都必须遵守这些不变量，保证<strong>数据库</strong>的一致性状态不被破坏。即ACID是数据为支持事务提供的四种正交的机制支撑。</p>
<p>不过也有对ACID的另一种理解，将C纳入到通用的<a href="https://en.wikipedia.org/wiki/Consistency_model">一致性模型</a>(<a href="https://jepsen.io/consistency">这篇文章</a>总结的一致性模型也不错，将事务一致性和分布式一致性整合到了一起)，从这个角度而言，ACID中的AID只是数据库提供的实现事务的手段，C是应用层使用事务的目的。前面说的数据库级联、触发器等相关约束，只是数据库系统为应用层提供的可选辅助机制。这种理解的本质是将DB数据一致性的概念和职责从数据库层提到了应用层，将事务一致性的概念拓宽了(从<strong>数据库</strong>的约束一致到<strong>应用层</strong>的状态一致)。应用层通过使用事务来获得数据一致性(广义的事务数据一致性)，而不是数据库通过一致性(狭义的数据库一致性约束，受限于具体数据库系统)去实现事务。我个人比较认可这种理解，因为事务虽然起源于数据库，而如今在其他各种分布式系统也推广开来，这种理解有助于在数据库事务(刚性事务)和后面提到的分布式事务(柔性事务)联系起来，相互借鉴学习。</p>
<p>事务一致性后面提到的分布式一致性是有所不同的，分布式一致性讨论的粒度是单个读写操作，这些读写操作对外表现的读写预期如何。事务一致性讨论的粒度是单个事务，而单个事务包含多个读写操作，因此事务一致性还需要考虑原子性(单个事务会不会只生效了一半)和隔离性(不同事务会不会交织影响)。</p>
<h4 id="CAP-Consistency"><a href="#CAP-Consistency" class="headerlink" title="CAP Consistency"></a>CAP Consistency</h4><p>CAP 理论中的 C 也就是我们常说的分布式系统中的一致性，更确切地说，指的是分布式一致性中的一种: 线性一致性(Linearizability)。</p>
<p>谈到 CAP，网上各种理解也有很多版本，我个人更推荐的CAP资料来自于<a href="https://www.the-paper-trail.org/page/cap-faq/">cap faq</a>。简单总结，在一个分布式的存储系统(即副本集)中，只能Consistency, Availability, Partition三选二，而由于在大规模的分布式系统中，网络不可靠几乎是不可避免的，即Partition网络分区容忍是必选项，因此对系统设计需要在AP(出现分区时可能响应过期的数据，即舍弃一致性)和CP(出现分区时阻塞请求直到故障恢复，在此期间整个系统不可用)之间权衡。</p>
<p>很多时候我们会用 CAP 模型去评估一个分布式系统，但<a href="https://blog.the-pans.com/cap/">这篇文章</a>提到了 CAP 理论的局限性，因为 CAP 理论是一个被过度简化的理论模型，按照 CAP 理论，很多系统包括 MongoDB，ZooKeeper 既不满足一致性(线性一致性)，也不满足可用性(任意一个工作中的节点都要可以处理请求)，但这并不意味着它们不是优秀的系统，而是 CAP 定理本身并没有考虑强弱一致性、处理时延、硬件故障、部分可用、SLA等等。这里不再展开，推荐阅读原文。</p>
<p>正因为 CAP 中对C和A的定义过度理想化，后来又有人提出了BASE 理论，即基本可用(Basically Available）、软状态(Soft State)、最终一致性(Eventual Consistency)。BASE的核心思想是即使无法做到强一致性，但每个应用都可以根据自身的业务特点，采用适当的方法来使系统达到最终一致性(关于一致性和可用性的取舍，这篇亚马逊CTO <a href="https://www.allthingsdistributed.com/2008/12/eventually_consistent.html">Werner Vogels的博客</a>值得一读)。显然，最终一致性弱于 CAP 中的 线性一致性。很多分布式系统都是基于 BASE 中的”基本可用”和”最终一致性”来实现的，比如 MySQL/PostgreSQL Replication 异步复制等。</p>
<p>前面说到，CAP 中的 C 是分布式系统的一致性模型中的一种，这里的分布式一致性，更确切地说，应该是分布式多副本场景下，系统对用户/客户端保证的读写一致性约定。大部分时候我们说的分布式系统一致性模型，都是针对这种情形(我个人将其理解为读写一致性，对应的，还有事务一致性，文末会做个小结)，以下再展开说明下。</p>
<p>在分布式共享内存系统或者分布式数据存储中，数据一致性模型指定程序员和系统之间的契约，系统保证如果程序员遵守规则，则存储器将是一致的，并且读取，写入或更新存储器的结果将是可预测的。我们最常用于讨论的便是复制状态机(Replicated state machines)的一致性问题，比如 etcd, zookeeper，当进程 A 执行 <code>set x 3</code> 时，进程 B 是否能在 A 执行完成后立即读到 x 的新值。这个问题在单节点上是显而易见的，但在分布式中，对进程 来说，则需要通过一致性模型来确保server 给出的结果可预测。分布式系统中的一致性有强弱之分，理想情况下，当进程写入 replicate 中的某个节点，其改变会被立即同步到集群其它节点，其它进程 能立即读取到该值。弱一些的一致性是最终一致性，即操作完成之后的某段时间内可能各个节点的数据副本不一致(导致不同进程 访问到的数据会不一致)，但最终会是一致的。比如 DNS 服务。</p>
<p>要理解分布式一致性，先来谈谈分布式中几个必要的概念: 时间，事件，和顺序。</p>
<p>分布式系统的时间主要分为物理时间和逻辑时间两种，物理时间是指程序能够直接获取到的 OS 时间，在分布式系统中，由于光速有限，你永远无法同步两台计算机的时间。想要在分布式中仅依靠物理时间来决定事件的客观先后顺序是不可能的。因此分布式系统中，通常使用<a href="https://my.oschina.net/fileoptions/blog/1821958">逻辑时间</a>来处理事件的先后关系。</p>
<p>分布式中的事件不是瞬间的概念，它有一个起始和结束时间，因此不同进程 发起的事件可能发生重叠，对于发生重叠的事件，我们说它们是并发执行的，在物理时间上是不分先后的。</p>
<p>理想情况下，我们希望整个分布式系统中的所有事件都有先后顺序，这种顺序就是全序，即整个事件集合中任意两个事件都有先后顺序。但 1.物理时间是很难同步的，2. 网络是异步的，因此在分布式系统中，想要维持全序是非常困难的。不同的节点对两个事件谁先发生可能具有不同的看法，并且大部分时候我只需要知道偏序关系，用于确保因果关系。所谓偏序关系是指:</p>
<ol>
<li>如果a和b是同一个进程中的事件，并且a在b前面发生，那么 a-&gt;b </li>
<li>如果a代表了某个进程的消息发送事件，b代表另一进程中针对这同一个消息的接收事件，那么a-&gt;b </li>
<li>如果 a-&gt;b且b-&gt;c，那么a-&gt;c (传递性)</li>
</ol>
<p>逻辑时间中的 Lamport Clock和Vector Clock等都可以用于建立偏序关系。</p>
<h5 id="顺序一致性-Sequential-Consistency"><a href="#顺序一致性-Sequential-Consistency" class="headerlink" title="顺序一致性(Sequential Consistency)"></a>顺序一致性(Sequential Consistency)</h5><p>Leslie Lamport 在1979年提出了Sequential Consistency, Leslie Lamport的定义如下:</p>
<blockquote>
<blockquote>
<p>A multiprocessor is said to be sequentially consistent if the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.[How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs by Leslie Lamport ,1979]</p>
</blockquote>
</blockquote>
<p>这个定义比较晦涩，通常来讲，他可以分为两个部分:</p>
<ol>
<li>单个节点的事件历史在全局历史上看符合程序顺序</li>
<li>事件历史在各个节点上看全局一致</li>
</ol>
<p>约束1保证了单个节点的所有事件是按照程序中指定的顺序执行的，约束2保证了所有的事件是原子的，不会相互干扰。更通俗的理解是，将整个分布式系统想象成一个调度器，将多个进程 的请求看做是多个FIFO请求队列， 调度器依次处理队列中的请求，并在多个队列中不断切换。是的，这和<a href="http://wudaijun.com/2018/01/go-scheduler/">Go调度器</a>原理类似，只不过我们探讨一致性模型时，会将系统规约为一个黑盒，从进程的角度来看这个黑盒对外表现出的一致性强弱。</p>
<p>下面举个例子来加深理解，假设我们有个分布式 KV 系统，以下是四个进程 对其的操作顺序和结果:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A: --W(x,1)--</span><br><span class="line">B:  --W(x,2)--</span><br><span class="line">C:                      -R(x,1)-   --R(x,2)-</span><br><span class="line">D:                 -R(x,1)-      --R(x,2)--</span><br></pre></td></tr></table></figure>
<p>其中<code>W(x,1)</code>表示更新 x 的值为1，<code>R(x,1)</code>表示读出 x 的值为2，横向为物理时间，事件两边的’-‘代表事件持续时间，那么按照我们前面对顺序一致性的描述，显然这个 KV 系统是满足顺序一致性的。</p>
<p>如果我们将进程 C 和 D 的 <code>R(x,1)</code> 和 <code>R(x,2)</code> 对换一下，也就是如果 C 和 D 都是先读出 x 为 2，再读出 x 为 1，那么还满足顺序一致性么，答案是肯定的，因为仍然能够找出一个全局的执行顺序: <code>B W(x,2) -&gt; A W(x,1) -&gt; C R(x,2) -&gt; D R(x,2) -&gt; C R(x,1) -&gt; D R(x,1)</code>，这个顺序满足前面提到的两点约束，即使直观上看来，这是”错误的一致性”。</p>
<p>如果我们只是把进程 D 的两个 R 操作对换，那么我们说这个系统是不满足顺序一致性的，因为你无法找出一个全局顺序满足以上两点约束。同样，如果 <code>W(x,1)</code> 和 <code>W(x,2)</code> 都发生在进程 A 中，那么系统也不满足顺序一致性。</p>
<h5 id="线性一致性-Linearizability"><a href="#线性一致性-Linearizability" class="headerlink" title="线性一致性(Linearizability)"></a>线性一致性(Linearizability)</h5><p>也叫做strong consistency或者atomic consistency，于 1987年提出，线性一致性强于顺序一致性，是程序能实现的最高的一致性模型，也是分布式系统用户最期望的一致性。 与顺序一致性相比，线性一致性只多了一条约束：<strong>如果事件A开始时间晚于事件B结束时间，则在最终事件历史中，要求B在A前。</strong>或者换句话说:<strong>事件生效时间是在事件开始时间到结束事件之间的某个时刻。</strong> 举个例子:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A: --W(x,1)--</span><br><span class="line">B:  ---W(x,2)---</span><br><span class="line">C:         --R(x,2)-- -R(x,1)-</span><br><span class="line">D:               --R(x,1)-</span><br></pre></td></tr></table></figure>
<p>这个案例是满足线性一致性的，因为<code>W(x,1)</code>和<code>W(x,2)</code>两个事件是同时发生的，因此事件生效点可能出现在开始和结束之间的任意点，就这个例子来讲，全局事件历史为: <code>B-W(x, 2), C-R(x,2), A-W(x,1), D-R(x,1), C-R(x,1)</code>，其中<code>D-R(x,1), C-R(x,1)</code>可以对换。</p>
<p>如果将 D 的 <code>R(x,1)</code>改为 <code>R(x,2)</code>，则不满足线性一致性，因为 C 的 <code>R(x,1)</code> 和  D 的 <code>R(x,2)</code>都发生在 A, B 的 W 事件之后，因此它们应该对 x 的值结果具有相同的视角，不会读出不一致的结果。</p>
<p>如果说顺序一致性只保证单节点事件先后顺序的话，线性一致性还保证节点间的事件先后顺序，因此线性一致性的实现是非常困难的，一方面它需要一个全局同步的时钟(顺序一致性不需要全局同步的时钟)，另一方面，越严格的一致性，会让分布式系统的复杂度更高，并且与之对应的，性能也会更差。</p>
<p>除了线性一致性和顺序一致性外，还一些其它更弱的一致性模型，比如因果一致性，最终一致性等，这里不再赘述。理解一致性本身和一些基础概念之后，理解其它一致性都不难。</p>
<h4 id="Cache-Coherence-amp-Meomory-Consistency"><a href="#Cache-Coherence-amp-Meomory-Consistency" class="headerlink" title="Cache Coherence &amp; Meomory Consistency"></a>Cache Coherence &amp; Meomory Consistency</h4><p><a href="https://en.wikipedia.org/wiki/Cache_coherence">Cache Coherence</a> 被译为缓存一致性、缓存连贯性或缓存同调。我在<a href="https://wudaijun.com/2019/04/cache-coherence-and-memory-consistency/">Cache一致性和内存一致性</a>中详细聊了Cache Coherence 和 Memory Consistency，其中提到: Cache Conherence本质是多个CPU对同一内存地址的读写预期，这通常通过缓存一致性协议(如MESI)来保证，如果多CPU对同一内存地址的读写满足顺序一致性，那么我们就说该多CPU架构是缓存一致的。</p>
<p>既然Cache Coherence的目标是顺序一致性，那么常见架构体系的 Memory Consistency 满足顺序一致性么，来看个例子:</p>
<p>初始状态下，x = 0, y = 0</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>进程 A</th>
<th>进程 B</th>
</tr>
</thead>
<tbody>
<tr>
<td>x=1</td>
<td>y=1</td>
</tr>
<tr>
<td>r1=y</td>
<td>r2=x</td>
</tr>
</tbody>
</table>
</div>
<p>按照顺序一致性的定义，我们将四条指令交叉任意排列，最终可能得到三种结果: <code>r1==1,r2==0</code>,<code>r1==0,r2=1</code>, <code>r1=1,r2=1</code> 三种结果，但不可能得到 <code>r1=0,r2=0</code> 的结果，因为这意味着全局执行顺序为 <code>r1=y, r2=x, x=1, y=1</code>，并不符合单个进程内部的执行顺序。那么实际上，这段程序会输出<code>r1=0,r2=0</code>的结果么？答案是会的，原因如下:</p>
<ol>
<li>编译器指令重排，编译器会在不影响程序语义的情况下，调整代码中的指令顺序。但编译器只能够解析显示语义，即单线程上下文，它无法(或者说非常难)解析程序的隐式语义，即程序的多线程上下文依赖。</li>
<li>CPU指令乱序执行，由于内存读取非常慢，CPU在不影响单线程语义的情况下，会将数据提前加载到缓存，提高执行效率。这就可能造成CPU指令处理顺序和程序指令顺序不一致，由于CPU 乱序只保证单线程语义，因此同样无法解析程序逻辑隐私因果关系，也可能造成结果不符程序预期。</li>
<li>缓存一致性，由于 LB/SB 的存在，缓存一致性是有极短延迟的，可能某个共享数据被CPU更新并写入到 SB(Store Buffer)中，其它 CPU 并不能即时看到。</li>
</ol>
<p>基于以上三点，现代 CPU 架构基本都是不支持顺序一致性的，因为其需要非常高昂的代价，严重限制编译器和硬件的优化能力。比如顺序一致性要求处理器按照程序序(program order)来执行程序，但在大部分情况下，这是没必要的。因此，现代硬件体系遵循的其实是: sequential consistency for data race free programs，即对没有 data race 的程序来说，是满足顺序一致性的(编译器能够分析上下文相关性)，但如果涉及到 data race，程序员需要使用 compile barrier 和 memory barrier 来限制编译器和 CPU 的乱序能力，以确保多线程程序执行结果如预期。</p>
<p>另外，系统架构、编译器、编程语言通常会提供默认的不同强弱的内存一致性(也叫做内存模型，如<a href="https://go.dev/ref/mem">Go Memory Model</a>)，以及相关并发同步机制。</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>按照个人理解，对以上提到的各种一致性做个小结:</p>
<p><img src="/assets/image/201809/一致性.png" alt=""></p>
]]></content>
      <categories>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>Go 的一些&quot;坑&quot;</title>
    <url>/2018/08/go-is-not-good/</url>
    <content><![CDATA[<h4 id="访问控制"><a href="#访问控制" class="headerlink" title="访问控制"></a>访问控制</h4><ol>
<li>package 内没有任何访问控制</li>
<li>package 间的访问控制只由大小写区分</li>
</ol>
<p>问题1我们可以通过合理拆分 package，来避免代码维护变得越来越困难，为了避免循环依赖，这里有<a href="http://wudaijun.com/2018/07/go-package-goroutine-practice/">一些实践</a>。</p>
<p>问题2则更难处理一些，因此 Go语言的reflect这类基础设施也受此影响，有时候你为了对象能够序列化或者 DeepCopy，就必须将其字段大写，也就对所有的package都暴露了实现。也就是说，Go 语言的基础设施(如reflect)也受此访问控制的限制(reflect本质上也是个package)。</p>
<span id="more"></span>
<p>比如游戏服务器中 Model，为了序列化，没有办法将其结构实现对外隐藏起来，只暴露API，这也就导致没有一种安全的方法来做脏标记这种状态封装(Go也没有类似Lua metatable这种Hook机制)。</p>
<h4 id="可变语义"><a href="#可变语义" class="headerlink" title="可变语义"></a>可变语义</h4><p>Go语言鼓励你用指针，还帮你做了指针的自动解引用，但是 Go 的大部分数据结构都是引用语义并且goroutine不安全的，如 slice，map等，Go不提供任何不可变语义，比如 const，copy-on-write等，这很符合 Go 的哲学: 简单(实现起来简单)。要想共享数据，要么通过 channel 或 mutex 来实现串行访问，要么就拷贝一份(深拷贝,DeepCopy)。初学者要没搞明白Go的数据结构实现之前，很容易写出并发不安全的代码。</p>
<h4 id="没有泛型"><a href="#没有泛型" class="headerlink" title="没有泛型"></a>没有泛型</h4><p>泛型本质上就是基于现有类型创造新的类型，达成代码复用。比如<code>map[KeyType]ValueType</code>，Go的reflect可以完成这个任务，你可以反射得到对象的type和value，然后可以通过这个type来创建新的对象或者构建更复杂的类型，比如<code>[]type</code>，<code>chan type</code>，<code>map[int]type</code>，甚至 struct，但是这一切都是运行时的，没有类型安全保证。是的，一门静态语言提供给开发者的泛型机制(reflect)并不提供类型安全保证。开发者只能通过interface来做一些丑陋的代码复用，典型的如sync.Map。</p>
<h4 id="deepcopy"><a href="#deepcopy" class="headerlink" title="deepcopy"></a>deepcopy</h4><p>前面说了，go不支持不可变语义，如果你要共享，要么加锁，要么拷贝。是的，Go 当然有 deepcopy 函数，但不是 Go 本身提供的，而是<a href="https://github.com/mohae/deepcopy/blob/master/deepcopy.go">第三方基于reflect的</a>。首先，基于 reflect 的 deepcopy 比自己写一个 deepcopy 要慢一个数量级，和直接序列化为 bson/json差不多。其次，前面也提到了，reflect 不能访问小写开头字段，因此基于reflect的deepcopy是不完整的，这可能导致一些问题，比如该对象的某个API访问了小写字段，或者大写字段和小写字段有相互关联。</p>
<p>解决DeepCopy的方案有两个，一是自己实现一个基于代码生成(<a href="https://golang.org/pkg/text/template/">text/template</a>)的deepcopy，这也是我们最近在尝试的。而是等着哪一天Go 想通了，做了个语言层面的deepcopy :)</p>
<h4 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h4><p>Go没有构造函数，Go”尽量”让零值(var t T)易于使用，比如int默认为0，string默认为””，sync 包的大部分数据结构都可以拿来即用(<code>sync.Mutex</code>,<code>sync.WaitGroup</code>等)。但也有例外，比如map:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> m1 = <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>&#123;&#125; <span class="comment">// empty map</span></span><br><span class="line"><span class="keyword">var</span> m0 <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>     <span class="comment">// zero map (nil)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">println</span>(<span class="built_in">len</span>(m1))   <span class="comment">// outputs &#x27;0&#x27;</span></span><br><span class="line"><span class="built_in">println</span>(<span class="built_in">len</span>(m0))   <span class="comment">// outputs &#x27;0&#x27;</span></span><br><span class="line"><span class="built_in">println</span>(m1[<span class="string">&quot;foo&quot;</span>]) <span class="comment">// outputs &#x27;&#x27;</span></span><br><span class="line"><span class="built_in">println</span>(m0[<span class="string">&quot;foo&quot;</span>]) <span class="comment">// outputs &#x27;&#x27;</span></span><br><span class="line">m1[<span class="string">&quot;foo&quot;</span>] = <span class="string">&quot;bar&quot;</span>  <span class="comment">// ok</span></span><br><span class="line">m0[<span class="string">&quot;foo&quot;</span>] = <span class="string">&quot;bar&quot;</span>  <span class="comment">// panics!</span></span><br></pre></td></tr></table></figure>
<p>对零值map的读取是ok的，但写入会panic!，我想大家都经历过<code>panic: assignment to entry in nil map</code>这类错误。特别在使用别人的结构体时，如果其内包含指针或map，而你没有显示调用其初始化函数(通常是NewXXX, OpenXXX, InitXXX)，后果通常是panic，毕竟库作者不一定会在每个 API上都检查初始状态，这通常需要使用者去谨慎检查并承担责任。</p>
<h4 id="切片和动态数组"><a href="#切片和动态数组" class="headerlink" title="切片和动态数组"></a>切片和动态数组</h4><p>Go 的切片用于引用数组的一部分，如<code>s := a[1:3]</code>，切换本身可以访问或修改数组的部分元素，但不会拷贝数组或者对数组大小造成影响。动态数组则是可以不断追加(append)元素的数组，这两个东西本来是两个概念，但是不巧的是，在 Go 中，它们都叫 slice，在一个切片语义的 slice上执行append一个元素将可能导致:</p>
<ol>
<li>len&lt;cap时，切片修改了原本不属其引用范围的数组元素</li>
<li>len==cap 时，切片重新分配，并拷贝原本所指向数组元素，从而丢失切片的引用语义</li>
</ol>
<p>因此我们在使用 slice 的一个实践就是一个slice只表达一种语义(要么切片，要么动态数组)，不要混用，关于slice 的更多细节参考<a href="http://wudaijun.com/2016/09/go-notes-1-datastructures/">这里</a>。</p>
<h4 id="nil-interface"><a href="#nil-interface" class="headerlink" title="nil interface"></a>nil interface</h4><p>我在<a href="http://wudaijun.com/2018/01/go-interface-implement/">这篇博客</a>里谈了下interface的实现，简单来说，interface{}本身就是一个结构体，包含 type/itab, data 两个字段，现在我们来看个有趣的示例:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> ITester <span class="keyword">interface</span> &#123;</span><br><span class="line">	A()</span><br><span class="line">	B()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Test <span class="keyword">struct</span> &#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*Test)</span> <span class="title">A</span><span class="params">()</span></span> &#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(Test)</span> <span class="title">B</span><span class="params">()</span></span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> t *Test = <span class="literal">nil</span></span><br><span class="line">	<span class="keyword">var</span> it ITester = t</span><br><span class="line">	<span class="built_in">println</span>(t, it) <span class="comment">// &#x27;0x0 (0x1071e60,0x0)&#x27;</span></span><br><span class="line">	<span class="keyword">if</span> it != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">println</span>(<span class="string">&quot;Not nil!&quot;</span>) <span class="comment">// 程序会走到这里</span></span><br><span class="line">		it.A()     <span class="comment">// ok</span></span><br><span class="line">		it.B()     <span class="comment">// panic: value method main.Test.B called using nil *Test pointer</span></span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="built_in">println</span>(<span class="string">&quot;nil!&quot;</span>)     <span class="comment">// 对interface&#123;&#125;不了解的同学可能会认为应该走到这里</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>现在我们来大概看看发生了什么，it本身是个itab+data的结构体，其中itab包含了t的类型以及ITester方法定义等，data则指向t，因此it打印出来第二个字段为0x0，但指向nil值的it本身并不为nil，也就是说<code>var it1 ITester = nil</code>和<code>var it2 Itester = (*Test)(nil)</code>，两条语句的性质是完全不一样的。it可以正常调用A()，因为A()的receiver是指针，而调用B()则会panic，因为需要解nil指针。这个示例能够说明interface{}实现的一些非直观性，以及自动解引用和nil receiver结合时引发的一些问题。另外，如果你真的需要判断一个interface{}指向的值是否为nil，还得用到”万能的”反射: <code>if it != nil &amp;&amp; !reflect.ValueOf(it).IsNil()</code>。</p>
<h4 id="And-More…"><a href="#And-More…" class="headerlink" title="And More…"></a>And More…</h4><p>前面只是列举了部分我在使用中对Go语言设计的反思，还有一些被广为诟病的如GOPATH，依赖管理等，它们有些可能是 Feature(嗯，万能的词汇)，有些则可能有设计上的考量(你我皆凡人)，Go语言目前给我的整体感觉就是”差那么一步”，比如map没有clear接口，没有提供deepcopy函数，没有构造函数等，这一步或难(比如添加 const语义)或不难(比如map clear)，但设计者终究没有为开发者提供这样的选项，这种差一步的好处便是简单(这里当然说的是语言实现简单)，这可能是Go语言最重要的设计哲学之一，也是对”互联网C语言”Slogan的践行。另一个角度来说，开发者对语言的期望是很高的，灵活性/安全性，开发效率/运行效率，命令式/面向对象/函数式/泛型等统统都要。:) 有意思的是，网上有人将对 Go 语言的吐槽收集起来，做成了<a href="https://github.com/ksimka/go-is-not-good">go is not good</a>系列，然后赚了3000多个Star。。。真的是Go社区火了，带动了一堆”副产业”。。。</p>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>游戏服务器的数据一致性</title>
    <url>/2019/01/gameserver-data-consistency/</url>
    <content><![CDATA[<p>前段时间又和同事讨论到 GS 中的 数据一致性，在这里简单聊聊。这里的数据一致性即系统内部的数据一致性(ACID中的C)，而非分布式系统对外体现的一致性(CAP中的C)。</p>
<p>假设我们有一个业务逻辑叫做行军，玩家需要先消耗一定的钻石，才能发起行军。在单线程下，其逻辑如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if !checkDiamond(cost) &#123;</span><br><span class="line">    return error_Diamond_not_enough</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if !checkMarch(troopId) &#123;</span><br><span class="line">    return error_troop_can_not_march</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">deductDiamond(cost)</span><br><span class="line">startMarch(troopId)</span><br></pre></td></tr></table></figure>
<p>这个逻辑在单线程下是没什么问题的，如果现在我们由于性能原因，将 Play(玩家数据逻辑) 和 Map(大地图玩法) 分为了两个 Actor (如goroutine,节点)，玩家钻石由 Play Actor 管理，部队数据由 Map Actor 管理，那么我们现在的逻辑变成了分布式中最常见的 Check-Do 模型:</p>
<span id="more"></span>
<div class="table-container">
<table>
<thead>
<tr>
<th>Play</th>
<th>Map</th>
</tr>
</thead>
<tbody>
<tr>
<td>checkDiamond</td>
<td>checkMarch</td>
</tr>
<tr>
<td>deductDiamond</td>
<td>startMarch</td>
</tr>
</tbody>
</table>
</div>
<p>现在我们讨论如何在这种情形下尽可能提升数据一致性，假设 Play 和 Map 以异步消息的方式交互，然后我们来考虑如下执行流:</p>
<p>执行流A:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Steps</th>
<th>Play</th>
<th>Map</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>checkDiamond</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>deductDiamond</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td></td>
<td>checkMarch</td>
</tr>
<tr>
<td>4</td>
<td></td>
<td>startMarch</td>
</tr>
</tbody>
</table>
</div>
<p>该执行流的异步交互少(理想情况下只需要一次)，但问题也比较明显，出现数据不一致的概率(时间窗口)太大了: Play在完全没有检查Map行军状态的时候，就扣钻石了。当Map执行到<code>checkMarch</code>检查失败时，通常有两种做法:</p>
<ul>
<li>回滚: 发消息给Play把钻石加回来，开发复杂度上去了，玩家体验还不一定好(大概率会看到钻石扣了又涨)</li>
<li>不回滚: 玩家差评和客服工单正在路上</li>
</ul>
<p>为了减少数据回滚的可能性，我们先总结第一条 Rule: 先 Check 再 Do:</p>
<p>执行流B:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Steps</th>
<th>Play</th>
<th>Map</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>checkDiamond</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td></td>
<td>checkMarch</td>
</tr>
<tr>
<td>3</td>
<td></td>
<td>startMarch</td>
</tr>
<tr>
<td>4</td>
<td>deductDiamond</td>
</tr>
</tbody>
</table>
</div>
<p>这个执行流稍微要复杂一些，通过先 check 再 do 的方式缩小了数据不一致的时间窗口，避免了逻辑检查(<code>checkMarch</code>)导致需要回滚的问题。但异步交互本身的不一致问题仍然存在，比如Play在checkDiamond之后，立马收到并处理了一条购买消息，扣除了钻石，导致行军deductDiamond时，钻石不够了，此时就麻烦了: 玩家做了事，但没扣(够)钻石，还很难回滚行军(广播，任务统计等牵扯系统太多)，并且玩家很可能会总结并找到这种刷漏洞的方法。因此，我们可以总结出第二条 Rule: 先 Deduct 再 Do。</p>
<p>执行流C:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Steps</th>
<th>Play</th>
<th>Map</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>checkDiamond</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td></td>
<td>checkMarch</td>
</tr>
<tr>
<td>3</td>
<td>deductDiamond</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td></td>
<td>startMarch</td>
</tr>
</tbody>
</table>
</div>
<p>现在这个执行流异步交互最复杂，如果 Step 1,3 发生不一致，Step 3失败，行军逻辑无法继续。但如果 Step 2,4 发生不一致，Step 4失败，此时钻石已经扣除，可以通过 Step 5 发消息给 Play 把钻石加回来，也可以通过日志手动 Fix(当逻辑回滚比较复杂，或者是非关键业务时)。</p>
<p>执行流D:</p>
<p>上例中，其实我们有假设deductDiamond和startMarch内部包含checkDiamond和checkMarch逻辑，以保证API的原子性。如果deductDiamond不包含checkDiamond语义的话(比如deductDiamond在钻石不够时，会尝试将剩余的钻石全部扣除，而不是直接返回错误码)，那么逻辑层应该显式再check一遍，确保逻辑的完备性。因此，更完整的执行流是这样的:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Steps</th>
<th>Play</th>
<th>Map</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>checkDiamond</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td></td>
<td>checkMarch</td>
</tr>
<tr>
<td>3</td>
<td>checkDiamond</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>deductDiamond</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td></td>
<td>checkMarch</td>
</tr>
<tr>
<td>6</td>
<td></td>
<td>startMarch</td>
</tr>
</tbody>
</table>
</div>
<p>到目前为止，我们来理理前面提到的:</p>
<ol>
<li>整个执行链，应该是 Check 链 + Do 链，减少数据不一致的时间窗口</li>
<li>必要时，Do之前再Check一次，保证Do语义的准确性</li>
<li>Do链中，先 Deduct 再 Give，保证数据安全性(如玩家刷道具)以及回滚的可行性</li>
<li>关键或易发的数据不一致可以逻辑回滚(如涉及到货币扣除)，其他数据不一致可通过排查日志来修复</li>
</ol>
<p>下面是几个常见问题:</p>
<p>Q1. 为什么不通过分布式事务或锁来保证一致性？</p>
<p>分布式事务，如常见的2PC、3PC、TCC、SAGA等(我在<a href="https://wudaijun.com/2018/09/consistency/">一致性杂谈</a>中有聊过)，对游戏服务器而言，通常都过于重度。以2PC为例，它其实和我们的执行流C有点类似，都是先询问各个参与者(Play, Map)是否可以提交(CanCommit)，再执行提交(DoCommit)，只不过2PC中的协调者可用性和可靠性更高。但引入2PC，会带来如单点问题，响应延迟，开发效率等新的问题。</p>
<p>分布式锁(如redis锁)也有类似的问题，并且锁主要是解决数据互斥访问的问题，而非数据事务一致性的问题。不恰当地用锁来解决解决事务一致性问题，会严重降低系统的吞吐量，甚至降低服务器的健壮性。</p>
<p>游戏服务器的大部分场景，是数据一致性不敏感但性能敏感(包括吞吐量和响应延迟)的，我们会时常为了性能舍弃部分数据一致性。因此通常在游戏服务器中，只有极少数关键业务场景，才会考虑用事务和锁来实现数据一致性。</p>
<p>Q2. 为什么不用同步RPC？</p>
<p>为了避免<code>checkDiamond</code>和<code>deductDiamond</code>，以及<code>checkMarch</code>和<code>startMarch</code>的不一致性，我们可以让 Map <code>checkMarch</code> 后，直接同步调用 Play 的<code>deductDiamond</code>，然后根据扣除是否成功执行后续操作。这样很大程度上避免了不一致性。然而同步调用可能会带来更多的问题(吞吐量，环形阻塞，雪崩等)，我在<a href="https://wudaijun.com/2018/07/gameserver-communication-model/">游戏服务器中的通信模型</a>中有详细讨论。</p>
<p>Q3. 关于超时?</p>
<p>考虑这样一种情况，当执行流C Step3 <code>deductDiamond</code>之后，Map 因为各种原因(网络波动，甚至节点挂掉)没有处理到 <code>startMarch</code> 这条消息，然后整个执行流就断掉了，就没有下文了(这也是2PC 协调者单独存在的一个作用)。那么我们是否应该给异步调用一个超时，让发起者可以对对端无响应有所感知加以处理？这个问题我在游戏服务器中的通信模型也提到过(异步消息和异步请求-响应的区别)。就我们目前的实践而言，这类逻辑耦合较重的场景会被实现为异步请求-响应式而非单纯异步消息，而一个完整的请求-响应语义，是应该带超时机制的。</p>
<p>Q4. 通过更细粒度的 Actor 化异步为同步？</p>
<p>既然异步交互维护数据一致性这么麻烦，并且开发效率也低，那如果是将Actor粒度拆细，比如单个玩家一个goroutine，甚至单请求一个goroutine，那么同步调用的代价也就不那么可怕了。道理是这样的，但是一方面在游戏后端，业务复杂性才是限制并发模型的主要原因(数据耦合越重，拆分越困难，比如地图线程)，另一方面，细粒度Actor+同步本质只一定程度减轻(没有根治)了同步调用带来的吞吐量和雪崩的问题，没有解决环形阻塞问题，并且还有Actor管理，调度开销等新引入的问题要纳入考虑。最终还是开发效率、性能、健壮性、数据一致性以及业务需求(比如棋牌/卡牌就比较适合Actor模型)上的综合权衡。对游戏服务器而言，大部分情况下，对性能和健壮性的考量，要优于数据一致性。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
      </tags>
  </entry>
  <entry>
    <title>GS 中的 Mesh 寻路</title>
    <url>/2019/02/gs-mesh-nav/</url>
    <content><![CDATA[<p>本文简单讨论如何在服务端实现基于三角形网格的寻路算法。</p>
<h3 id="地图表示"><a href="#地图表示" class="headerlink" title="地图表示"></a>地图表示</h3><h4 id="1-基于路点"><a href="#1-基于路点" class="headerlink" title="1. 基于路点"></a>1. 基于路点</h4><p>基于路点是最原始的寻路方案，比如要让你实现一个迷宫，你会很自然地想到用0代表通路，1代码障碍物，整个迷宫地图由0和1构成的点阵来表示。这就是基于路点，本质上是将地图上可以通过的位置(坐标状态)都记录下来。</p>
<span id="more"></span>
<p><img src="/assets/image/201902/nav_point_1.jpeg" alt=""></p>
<center> 图1 基于路点的地图 </center>

<h4 id="2-基于网格"><a href="#2-基于网格" class="headerlink" title="2. 基于网格"></a>2. 基于网格</h4><p>基于网格是指对地图进行预处理，将地图边界拐点和障碍物外围拐点所形成的离散点集合转换为一个由多边形(通常是三角形)构成的网格，然后去掉障碍物内部的多边形，剩下即为所有可达地点的网格，称作寻路网格。或者换个角度来讲，将地图上的障碍物和边界之外去掉，然后将剩下的部分通过多边形切割，得到寻路网格。</p>
<p><img src="/assets/image/201902/nav_mesh_1.jpeg" alt=""></p>
<center> 图2 基于网格的地图 </center>

<p>以下简单对比基于路点和基于网格的寻路:</p>
<ol>
<li>基于路点要比基于网格存储更多的信息</li>
</ol>
<p><img src="/assets/image/201902/nav_point_2.jpeg" alt=""></p>
<center> 图3 基于路点存储的数据量 </center>

<p><img src="/assets/image/201902/nav_mesh_2.jpeg" alt=""></p>
<center> 图4 基于路点存储的数据量 </center>

<ol>
<li>基于路点寻路，即使没有障碍物，也可能走折线</li>
</ol>
<p><img src="/assets/image/201902/nav_point_3.jpeg" alt=""></p>
<center> 图5 基于路点寻路，从 A 点到 B 点 </center>

<p><img src="/assets/image/201902/nav_mesh_3.jpeg" alt=""></p>
<center> 图6 基于网格寻路，从 A 点到 B 点 </center>

<ol>
<li><p>基于网格可以更好地处理平滑转弯，角色大小等细节，如体型过大的角色可能无法通过某个小通道</p>
</li>
<li><p>基于网格可以通过网格保存更多的地表信息，如水中移动速度更慢，可用于寻路算法计算权重</p>
</li>
</ol>
<h3 id="寻路算法"><a href="#寻路算法" class="headerlink" title="寻路算法"></a>寻路算法</h3><p>不管是基于网关还是基于路点，最终的地图都是图结构，只不过基于路点的图结构基本单位是点，而基于网格的基本单位是网格。基于路点的寻路比较简单，通常通过 A* 或 Dijkstra 算法即可直接算出。这里讨论基于三角形的网格寻路。</p>
<h4 id="Step-1-导出网格数据"><a href="#Step-1-导出网格数据" class="headerlink" title="Step 1. 导出网格数据"></a>Step 1. 导出网格数据</h4><p>网格地图需要对地图进行预处理生成地图元数据，这里不讨论生成过程，假设我们已经得到了地图元数据，其中包含地图上所有的三角形信息。</p>
<h4 id="Step-2-数据预处理"><a href="#Step-2-数据预处理" class="headerlink" title="Step 2. 数据预处理"></a>Step 2. 数据预处理</h4><p>预处理有两个目的:</p>
<ol>
<li>给定一个点，能快速找到其所在的三角形</li>
<li>给定一个三角形，能快速索引到与其相连的其它三角形</li>
</ol>
<p>第一点可以通过将整个地图(假设为方形)组织成四叉树，起初所有的三角形都在根节点下，当节点下的三角形超过某个阈值时，将该节点进一步分为四个节点，各个节点保存其 Rect 区域内的所有三角形，那些在边界处的三角形(存在于多个 Rect 区域内)，则继续挂在根节点上，这样在查找点时，可通过该点是否在节点区域内不断递归缩小查找范围，找到所在三角形。</p>
<p>如下图，我们将三角形网格地图分为了四部分，当我们要寻找 A 点所在的三角形时，只需遍历左上角黑线包围的三角形即可，在地图较大，四叉树层数较深时，能够极大优化三角形查找。</p>
<p><img src="/assets/image/201902/nav_mesh_quad_tree.jpg" alt=""></p>
<center> 图7 组织为四叉树的网络地图 </center>

<p>现在来解决如何存储三角形相邻关系，如果将三角形看做点，本质上我们要做的其实是要保存一张图，保存图的方式通常有邻接矩阵，邻接图等，一个地图可能有上万网格，而每个三角形相邻的三角形通常是个位数，在这种情况下，用邻接表是个不错的选择，具体的实现不再罗列，本质上该部分预处理数据提供网格的通路信息。</p>
<h4 id="Step-3-寻路"><a href="#Step-3-寻路" class="headerlink" title="Step 3. 寻路"></a>Step 3. 寻路</h4><p>到这里我们开始阐述寻路的具体过程，我们有了以上的预处理数据，并且给定地图上的两个点 A，B，求 A, B 之间的寻路路径:</p>
<p><img src="/assets/image/201902/nav_mesh_demo.jpg" alt=""></p>
<center> 图8 找 A 点到 B 点的寻路路径 </center>

<p>我们将寻路算法分为如下步骤:</p>
<h5 id="3-1-找到-A-B-两点所在的三角形"><a href="#3-1-找到-A-B-两点所在的三角形" class="headerlink" title="3.1 找到 A, B 两点所在的三角形"></a>3.1 找到 A, B 两点所在的三角形</h5><p>基于前面我们创建的四叉树，我们可以得到 A,B 两点所在的三角形</p>
<h5 id="3-2-找到两个三角形之间的最短三角形路径"><a href="#3-2-找到两个三角形之间的最短三角形路径" class="headerlink" title="3.2 找到两个三角形之间的最短三角形路径"></a>3.2 找到两个三角形之间的最短三角形路径</h5><p>前面提到，如果将三角形看做基本单位，那么我们的网格图本质上就是个无向图，基于图的寻路算法主要有 A* 和 Dijkstra 算法，通常启发式的 A* 是更好地选择，我们可以用三角形的中心点(三条边中线的交点)到目标三角形的中心点的距离作为启发函数 h值。</p>
<h5 id="3-3-将三角形路径转换为最短线路径"><a href="#3-3-将三角形路径转换为最短线路径" class="headerlink" title="3.3 将三角形路径转换为最短线路径"></a>3.3 将三角形路径转换为最短线路径</h5><p>假设我们现在得到了A，B 间的网格路径:</p>
<p><img src="/assets/image/201902/nav_mesh_grid_path.jpg" alt=""></p>
<center> 图9 A B 两点间的网格路径 </center>

<p>现在我们要将其转换为角色最终行走的线路径，一种简单的算法是直接将沿途三角形的中心点联结起来，得到如上图所示的线路，但一来是路线存在不必要的折现，不是最短线路。二来返回给客户端的点过多，不适合作为服务器寻路结果。理想的最短路线如下图所示:</p>
<p><img src="/assets/image/201902/nav_mesh_line_path.jpg" alt=""></p>
<center> 图10 A B 两点间的最短线路径 </center>

<p>其中只有三个拐点，我们只需要将这三个拐点返回给客户端即可(这里不讨论平滑转弯)。接下来我们来尝试将网格路径推演为最短线路径。</p>
<p>首先我们知道，拐点必然出现在三角形路径上某两个三角形共同边的端点，因此我们尝试遍历三角形路径上所有的共同边，得到拐点。如上图所示，A，B 两点间一共有9条共同边，我们称这9条边为临边或者穿出边，我们以 A 点为起点，对第一条临边作两个向量:</p>
<p><img src="/assets/image/201902/nav_mesh_line_path_1.jpg" alt=""></p>
<p>我们将这两个向量通过向量叉乘的方式分为左向量和右向量，设为 vLeft1，vRight1，我们可以非正式地将 vLeft1 和 vRight 1之间的夹角看做角色的当前视野(之后我们用<code>&#123;vLeft, vRight&#125;</code>表示)。然后对第二条临边做向量，vLeft2 和 vRight2，发现新视野{vLeft2，vRight2}在当前视野{vLeft1，vRight1}之间，因此更新当前视野为{vLeft1, vRight2}:</p>
<p><img src="/assets/image/201902/nav_mesh_line_path_2.jpg" alt=""></p>
<p>同样，继续从出发点对第三条临边锻炼做向量得到新视野 {vLeft3, vRight3}，仍然在当前视野{vLeft1, vRight2}内，如此迭代:</p>
<p><img src="/assets/image/201902/nav_mesh_line_path_3.jpg" alt=""></p>
<p><img src="/assets/image/201902/nav_mesh_line_path_4.jpg" alt=""></p>
<p>直到我们对第五条临边做向量得到的视野{vLeft4, vRight4}，发现vRight4不在当前视野{vLeft1, vRight4}内，即视野不是包含关系:</p>
<p><img src="/assets/image/201902/nav_mesh_line_path_5.jpg" alt=""></p>
<p>此时忽略第五条临边，当前视野不变，仍然是{vLeft1, vRight4}，继续对第六条临边作视野:</p>
<p><img src="/assets/image/201902/nav_mesh_line_path_6.jpg" alt=""></p>
<p>发现新的视野{vLeft6, vRight6}在当前视野{vLeft1, vRight4}左侧，没有重叠部分，即 vLeft6 和 vRight6 均在 vLeft1 的左侧，换句话说，我们无法从起点直接到达第6条临边，需要在某个点转弯，这个点就是拐点，也就是这里的 Left1 的非起点端点。此时记录该拐点 C，将当前起点从 A 点更新到 C 点，重新找到与 C 点不相邻的第一条临边，也就是整条路径的第5条临边，重新初始化当前视野，递归寻找从 C 点到达 B 的路径拐点。</p>
<p><img src="/assets/image/201902/nav_mesh_line_path_7.jpg" alt=""></p>
<p>如此递归，直到找到最后一个拐点P:</p>
<p><img src="/assets/image/201902/nav_mesh_line_path_8.jpg" alt=""></p>
<p>从 P 点的视野可以直接连到最后一个三角形，也就是与目标点B所在的三角形，由于 B 在 P 点的视野内，因此 P，B 可直接连线到达。如果 B 点不在 P 的视野内，则还需一个拐点，通常我们将目标点作为一条特殊的边来处理即可，即长度为0的边，这样可以用同样的拐点算法来计算。至此，我们就得到了 A, B 两点间的最短路径。</p>
<h3 id="其它细节"><a href="#其它细节" class="headerlink" title="其它细节"></a>其它细节</h3><p>到此我们就得到了基于拐点的寻路路径，本文只讨论了大概思路，实际上寻路还有很多有意思的问题值得探讨，如:</p>
<ol>
<li>如何在寻路时考虑到单位的半径？Tips: 在寻路算法找出三角形路径时，比较三角形的临边和角色大小</li>
<li>如何在寻路时考虑到各种地形的权重？Tips: 将地形信息保存在三角形网格中，在 A* 算法的代价函数中考虑三角形权重</li>
<li>如何动态更新寻路？Tips: 可选方案: a. 定时检查 b. 每 N 步检查一次 c. 有障碍物时触发相关寻路更新 d. 寻路局部更新优化</li>
</ol>
<p>由于懒且画工不好，本文图片均出自以下参考文章:</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/24112879">https://zhuanlan.zhihu.com/p/24112879</a></li>
<li><a href="http://gad.qq.com/article/detail/10042">http://gad.qq.com/article/detail/10042</a></li>
</ol>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
      </tags>
  </entry>
  <entry>
    <title>函数式中的延迟计算及惰性求值</title>
    <url>/2019/02/lazy-evaluation/</url>
    <content><![CDATA[<p>本文谈谈在函数式编程中的延迟计算，惰性求值等技术及其应用。</p>
<h2 id="Racket"><a href="#Racket" class="headerlink" title="Racket"></a>Racket</h2><p>本文将以 Racket 为例，以下是 Racket 的概要:</p>
<ol>
<li>更广泛的函数概念: 什么 if define + myfunc 等，统统都是函数</li>
<li>前缀表达式: 同 Lisp, Scheme 等语言一样，Racket 使用前缀表达式，如(myfunc 1 2)，(+ 1 2 3)等</li>
<li>支持可变性: 可修改变量值(不建议)，如 (set! x 2)，并且支持修改 Pair，Map 的指定元素</li>
</ol>
<p>其它关于 Racket 的具体语法和 API 细节请参考<a href="https://github.com/OnRoadZy/RacketGuideInChinese">Raccket 中文文档</a>。</p>
<h2 id="Delay-Evaluation"><a href="#Delay-Evaluation" class="headerlink" title="Delay Evaluation"></a>Delay Evaluation</h2><p>Delay Evaluation 意为延迟计算，即表达式只在必要时才求值，而非被赋给某个变量时立即求值。</p>
<span id="more"></span>
<p>要理解延迟计算，我们先看一个小例子:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(define (my-if e1 e2 e3)</span><br><span class="line">    (if e1 e2 e3))</span><br><span class="line">    </span><br><span class="line">(define (factorial x)</span><br><span class="line">  (my-if (&#x3D; x 0)</span><br><span class="line">         1</span><br><span class="line">         (* x (factorial (- x 1)))))  </span><br></pre></td></tr></table></figure>
<p>上面的代码实现了一个 <code>my-if</code> 函数，它的作用和 if 一样，以及一个计算阶乘的函数 factorial，只不过使用 <code>my-if</code> 替代了 if，如果你运行<code>(factorial 1)</code>，将陷入死循环，因为在对 <code>(factorial 1)</code> 求值时，将会对<code>(my-if e1 e2 e3)</code>求值，而在大多数语言包括 Racket 中，实参表达式是在被传入时即会被求值的，因为 e3 中递归调用了 factorial，然后又会对 <code>(factorial 0)</code> 求值，如此递归，并且没有终止，因为要对 factorial 函数求值完成后，<code>my-if</code> 表达式才能求值，才能终止递归。而 if 则不同，它只有在 x 不为 0 时才会递归对 <code>(factorial (- x 1))</code> 求值，不会形成无限递归。</p>
<p>要解决这种情况，我们需要让 <code>my-if</code> 在求值时，先不对 <code>(factorial (- x 1))</code> 求值，等到 <code>my-if</code> 判断 e1 为 false(x 不等于 0)，即确实需要对e3求值时才求值，这就是延迟计算，因此我们需要将以上函数改成这样:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(define (my-if e1 e2 e3)</span><br><span class="line">    (if e1 (e2) (e3)))</span><br><span class="line">    </span><br><span class="line">(define (factorial x)</span><br><span class="line">  (my-if (&#x3D; x 0)</span><br><span class="line">         (lambda () 1)</span><br><span class="line">         (lambda () (* x (factorial (- x 1))))))</span><br></pre></td></tr></table></figure>
<p><code>my-if</code> 的参数 e2, e3 只是个未被求值的表达式，通过不带参的匿名函数代入，由于函数只会在被调用的时候才会被求值，从而达到延迟计算的目的。这种通过函数传入表达式本身而不是具体值从而达成延迟计算的方式有个专业的计算机术语叫做<a href="https://en.wikipedia.org/wiki/Thunk">Thunk</a>(形实转换程序)。Thunk 的关键点在于将裸表达式 <code>e</code> (会被立即求值)包装为 p: <code>(lambda() e)</code>(将表达式包裹在函数中)，并且在使用时调用 p: <code>(p)</code>(在需要时才计算表达式求值)。</p>
<p>有了 Thunk 之后，我们可以在某些情况下延迟函数参数的计算，但在另一些情况下，Thunk 反而会导致更多的计算:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">; 未使用 Thunk, 通过累加的方式计算 n*e，n &gt;&#x3D; 1</span><br><span class="line"> (define (my-mult1 e n)</span><br><span class="line">  (cond [(&#x3D; n 0) 0]</span><br><span class="line">       [(&#x3D; n 1) e]</span><br><span class="line">       [#t (+ e (my-mult2 e (- n 1)))]))</span><br><span class="line">      </span><br><span class="line">; 使用 Thunk, 通过累加的方式计算 n*(e)，n &gt;&#x3D; 1</span><br><span class="line"> (define (my-mult2 e n)</span><br><span class="line">  (cond [(&#x3D; n 0) 0]</span><br><span class="line">       [(&#x3D; n 1) (e)]</span><br><span class="line">       [#t (+ (e) (my-mult2 e (- n 1)))]))</span><br></pre></td></tr></table></figure>
<p><code>my-mult1</code> 和 <code>my-mult2</code> 实现相同的功能，除了一个是直接传入表达式而另一个传入的是 Thunk，在这种情况下，<code>my-mult1</code> 只会计算表达式一次(即使 n==0)，而 <code>my-mult2</code> 会计算表达式 n 次(n==0时无需计算)。在 n 很大时，<code>my-mult1</code> 将明显优于 <code>my-mult2</code>。</p>
<p>因此实际上我们需要的是这样一种机制，它兼具 <code>my-mult1</code>(不会重复计算表达式) 和 <code>my-mult2</code>(延迟求值，表达式可能无需计算)的优点:</p>
<ol>
<li>延迟计算</li>
<li>避免重复计算，比如计算过一次之后就记住它的值</li>
</ol>
<p>这种机制被称为<em>惰性求值(Lazy Evaluation)</em>，天生具备惰性求值特性的语言称为<em>惰性语言(Lazy Language)</em>(如 Haskell)。。</p>
<h2 id="Lazy-Evaluation"><a href="#Lazy-Evaluation" class="headerlink" title="Lazy Evaluation"></a>Lazy Evaluation</h2><p>下面我们来尝试在 Racket 中自己实现惰性求值，延迟计算的 Thunk 技术前面已经介绍过，现在我们来考虑如何记住表达式的值，避免重复计算，一种可选的方案是在表达式上再封装一层，其中记录了表达式的计算状态和计算值，我们可以用一个 Pair 来记录，其第一个字段为表达式是否已经被计算(bool 值)，另一个字段为计算结果或Thunk。</p>
<p>在 Racket 中，Pair 分为可变和不可变两种，分别用 cons 和 mcons 构建，在这里，我们应该使用可变 Pair:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">; 在 thunk 上再一次封装，加上计算状态</span><br><span class="line">(define (my-delay thunk)</span><br><span class="line">  (mcons #f thunk)) ; 将 thunk 封到 Pair 中，并初始化为未被计算(false)</span><br><span class="line"></span><br><span class="line">; 计算 thunk，如果已经被计算，则不会再被计算  </span><br><span class="line">(define (my-force p)</span><br><span class="line">  (if (mcar p) ; 查看表达式是否已经被计算</span><br><span class="line">    (mcdr p)   ; 如果已经被计算，则直接返回 Pair 第二个元素 </span><br><span class="line">    (begin (set-mcar! p #t) ; 如果未被计算，则标记为已计算</span><br><span class="line">          (set-mcdr! p ((mcdr p))) ; 计算 Pair 中的表达式(第二个元素)，执行计算，并将计算结果存为Pair第二个元素</span><br><span class="line">          (mcdr p)))) ; 直接返回 Pair 中第二个元素</span><br></pre></td></tr></table></figure>
<p>上面代码实现了两个函数 my-delay 和 my-force，与延迟计算中的<code>(lambda () e)</code> 和 <code>(e)</code> 类似，我们将表达式 e 变换为了p: <code>(my-delay (lambda () e))</code> 和 <code>(my-force p)</code>。现在我们可以用 my-delay 和 my-force 来优化 <code>my-mult2</code>，<code>my-mult2</code>无需任何修改，我们只需修改调用处:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">; 以下两个函数调用均为计算 (+ (factorial 2) (factorial 2))，结果均为 4</span><br><span class="line">; 延迟调用版本，会计算(factorial 2) 两次</span><br><span class="line">&gt; (my-mult2 (lambda () (factorial 2)) 2)</span><br><span class="line">&gt; 4</span><br><span class="line">; 惰性求值版本(延迟调用+避免重复计算)，会计算(factorial 2) 一次</span><br><span class="line">&gt; (my-mult2 (let ([p (my-delay (lambda () (factorial 2)))])</span><br><span class="line">              (lambda () (my-force p))) 2)</span><br><span class="line">&gt; 4              </span><br></pre></td></tr></table></figure>
<p>惰性求值版本在最好情况下不会对表达式进行计算(n==0)，最差情况下也只会计算一次，兼具<code>my-mult1</code> 和 <code>my-mult2</code>的优点。</p>
<h2 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h2><p>延迟计算除了优化作用外，另一个应用就是 Stream(流)，Stream 是指一个无限大小的值队列，比如:</p>
<ol>
<li>用户输入事件: 如鼠标点击</li>
<li>Unix Pipes: <code>cmd1 | cmd2</code>，cmd2 从 cmd1 获取的处理结果，可能就是一个 Stream，如 cmd1为<code>tail -f ...</code></li>
<li>数学计算中，可能需要一个无穷大的数队列(如斐波那契队列)，消费者可以不断地获取下一个数进行处理</li>
</ol>
<p>因此生产者无法事先穷举表示出来，另一方面，用多少数据通常由消费者决定，我们也就没有必要事先计算出所有的数据。因此，可以通过延迟计算实现 Stream。</p>
<p>现在我们尝试用 Thunk 实现两个简单的整数队列:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">; 实现一个全是1的Stream [1,1,1,...]</span><br><span class="line">; 正确版本</span><br><span class="line">(define ones (lambda () (cons 1 ones)))</span><br><span class="line">; 错误版本1: 编译错误，在 ones-bad1 定义中使用了 ones-bad1定义</span><br><span class="line">; (define ones-bad1 (cons 1 ones-bad1))</span><br><span class="line">; 错误版本2: 无限递归，ones-bad2的求值需要对ones-bad2求值，没有终止</span><br><span class="line">; (define ones-bad2 (lambda () (cons 1 (ones-bad2))))</span><br><span class="line"></span><br><span class="line">; 实现一个递增的自然数Stream [1,2,3,...]</span><br><span class="line">; 辅助函数，f(x)，返回Pair: (x, Thunk-of-f(x+1))</span><br><span class="line">(define (f x) (cons x (lambda () (f (+ x 1)))))</span><br><span class="line">; 将 f(1) 封装为Thunk</span><br><span class="line">(define nats (lambda () (f 1)))</span><br></pre></td></tr></table></figure>
<p>以下是使用示例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; (nats) ; 调用 nats 将返回一个 Pair，第一个元素是当前获取到的值，第二个元素是一个新的 Stream</span><br><span class="line">&#39;(1 . #&lt;procedure:...era&#x2F;racket&#x2F;a.rkt:29:22&gt;)</span><br><span class="line">&gt; (car (nats)) ; 取出第一个自然数</span><br><span class="line">1</span><br><span class="line">&gt; (car ((cdr (nats)))) ; 取出第二个自然数</span><br><span class="line">2</span><br></pre></td></tr></table></figure>
<p>上面实现了两个Thunk, ones 和 nats，前者没有内部状态(每次返回值是一样的)，后者有内部状态。那么 nats 是如何保存状态的呢？函数式也可以有内部状态？不，函数式中的函数当然没有内部状态，状态是通过辅助函数 f 的参数来传递的，第 n 次调用 nats 会返回一个新的 f(n+1) Thunk，对外表现为调用 Stream 返回的 Pair 的第二个元素始终都是个Thunk(无参匿名函数)，但其实 Stream 每次返回的 Thunk 都是不一样的(封装了不同的 f 调用)，这也是为什么 Stream 每次都要返回 Thunk 的原因。</p>
<p>如果是非函数式语言如 C，我们可以很方便地实现一个 <code>Counter()</code> 函数，通过静态局部变量来保存当前计数，而无需返回一个新的函数。但同时也失去了函数式的诸多好处，如延迟计算，因为程序员和编译器都很难判断<code>Counter()</code>是否有副作用(或者以后会改为具备副作用，比如修改了全局变量)，也就不能保证延迟计算是无痛的。</p>
<h2 id="Memoization"><a href="#Memoization" class="headerlink" title="Memoization"></a>Memoization</h2><p>我最初接触<a href="https://zh.wikipedia.org/wiki/%E8%AE%B0%E5%BF%86%E5%8C%96">Memoization</a>是在动态规划中，指的是如果一个问题具有最优子结构，并且会对多个子问题重复计算，那么我们应该将子问题的结果保存下来(Memoization)，避免对子问题的重复计算。Memoization 适用于很多使用递归并且会有大量重复计算的问题，比如背包问题，找零钱问题，最短路径问题，斐波那契数列问题等等。</p>
<p>这里我们以最简单的斐波那契数列为例，以下是几个求第 n 个斐波那契数的函数:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">; fib1: 原始方案，直接自上而下递归</span><br><span class="line">(define (fib1 x)</span><br><span class="line">  (if (or (&#x3D; x 1) (&#x3D; x 2))</span><br><span class="line">      1</span><br><span class="line">      (+ (fib1 (- x 1))</span><br><span class="line">         (fib1 (- x 2)))))</span><br><span class="line"></span><br><span class="line">; fib2: 自下而上递归，避免子问题重复计算</span><br><span class="line">; 将子问题的计算结果通过函数参数传到上层问题，思路类似于迭代</span><br><span class="line">(define (fib2 x)</span><br><span class="line">  (letrec ([f (lambda (acc1 acc2 y)</span><br><span class="line">                (if (&#x3D; y x)</span><br><span class="line">                    (+ acc1 acc2)</span><br><span class="line">                    (f (+ acc1 acc2) acc1 (+ y 1))))])</span><br><span class="line">    (if (or (&#x3D; x 1) (&#x3D; x 2))</span><br><span class="line">        1</span><br><span class="line">        (f 1 1 3))))</span><br><span class="line"></span><br><span class="line">; fib3: 自上而下递归，使用我们前面的 my-delay my-force 技术</span><br><span class="line">(define (fib3 x)</span><br><span class="line">  (my-delay (lambda () (if (or (&#x3D; x 1) (&#x3D; x 2))</span><br><span class="line">      1</span><br><span class="line">      (+ (my-force (fib3 (- x 1)))</span><br><span class="line">         (my-force (fib3 (- x 2))))))))</span><br><span class="line"></span><br><span class="line">; fib4: 自上而下递归，使用 Memoization 技术</span><br><span class="line">; 用一个 map 保存计算过的子问题结果</span><br><span class="line">(define fib4</span><br><span class="line">  (let ((memo (make-hash &#39;((0 . 0) (1 . 1))))) ; 创建 map，key 为fib4函数参数 n</span><br><span class="line">    (lambda (n)</span><br><span class="line">      (unless (hash-has-key? memo n) ; 查看 memo map，是否已经计算过该子问题</span><br><span class="line">        (hash-set! memo n (+ (fib4 (- n 1)) (fib4 (- n 2))))) ; 如果没有计算过，则计算，并将结果存入 memo map</span><br><span class="line">      (hash-ref memo n)))) ; 此时肯定已经计算过了，直接取出 memo map 中的结果</span><br><span class="line"></span><br><span class="line">; 测试代码执行时间</span><br><span class="line">&gt; (time (fib1 35))</span><br><span class="line">cpu time: 518 real time: 519 gc time: 0</span><br><span class="line">9227465</span><br><span class="line">&gt; (time (fib2 35))</span><br><span class="line">cpu time: 0 real time: 0 gc time: 0</span><br><span class="line">9227465</span><br><span class="line">&gt; (time (my-force(fib3 35)))</span><br><span class="line">cpu time: 2784 real time: 2957 gc time: 912</span><br><span class="line">9227465</span><br><span class="line">&gt; (time (fib4 35))</span><br><span class="line">cpu time: 0 real time: 0 gc time: 0</span><br><span class="line">9227465</span><br></pre></td></tr></table></figure>
<p>现在我们来分析测试结果，fib1 和 fib2 的结果没什么意外，毕竟原始的 fib1 函数是一个指数增长的函数，其复杂度为即O(2^n)，而 fib2 通过自下而上求解，用迭代的思路将其优化为 O(n)，提升效果明显。 </p>
<p>fib3 的运行时间有些意外，它竟然比原始的 fib1 还慢了数倍，my-delay 和 my-force 不是只会计算一次结果么？需要注意的是，我们的 fib3 虽然用了 my-delay，但是却没有真正实现避免重复计算，因为我们没有将 <code>my-delay(fib(x))</code> 作为所有递归 <code>fib(x)</code> 的替代， 而是在每次调用 <code>fib(x)</code> 是生成了一个新的my-delay，已有的计算过的 <code>my-delay(fib(x))</code> 并没有保存下来，因此仍然会递归再次求解，再加上 my-delay 和 my-force 本身的开销，也就出现了比 fib1 还慢的结果。严格意义上说，fib3 不只是没有避免重复计算，就连延迟计算的优势也没有发挥出来，因为 my-force 总是在封装返回后立即被 my-force 使用。</p>
<p>fib4 通过 Memoization 技术来避免重复计算，性能表现和 fib2 一样优秀，当然，实际上会比 fib2 慢一些，毕竟多了 hash map 存取。但 fib2 本身是基于斐波那契数列特性的优化，对类似找零钱问题，背包问题等，自下而上的递归就不那么好用了，并且也会传递更多的计算上下文，而 Memoization 贵在它是一种更通用，甚至可以做进编译器的优化方案，具备更好的可读性和扩展性。</p>
<p>Memoization 和惰性求值虽然都可以避免重复计算，但惰性求值是依靠将单个表达式封装后的结果(如 my-delay 的 Pair)到处传递来实现的，Memoization 则考虑在表达式外部的上下文(闭包)中，对计算结果进行保存，因此对复杂的问题来说，实现 Memoization 要比惰性求值更简单直观。</p>
<h2 id="Lazy-Language"><a href="#Lazy-Language" class="headerlink" title="Lazy Language"></a>Lazy Language</h2><p>我们前面讨论的惰性求值都是以在 Racket 中手动实现来阐述的，而事实上像柯里化一样，某些语言可能内置惰性求值，这类语言被称为惰性语言。最出名的惰性语言如 Haskell，在 Haskell 中你可以用 <code>[1..]</code> 来表示1到无穷大的列表，当你需要时，可以通过<code>[1..] !! 999</code>取出其中第1000个元素(值即为1000)。另外，假如我有一个列表 xs，doubleMe 会将 xs 中的元素<code>*2</code> ，那么在Haskell中，<code>doubleMe(doubleMe(doubleMe(xs)))</code> 只会遍历列表一次。</p>
<p>另外，Racket 语言虽然不是天生的惰性语言，和 Scheme 一样，它也通过内置 delay 和 force 来支持手动惰性，并且使用比my-delay 更简单快捷:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; (define laz (delay (fib1 10))) ; delay 后面只需跟表达式即可，无需是个 Thunk</span><br><span class="line">&gt; laz</span><br><span class="line">#&lt;promise:laz&gt;</span><br><span class="line">&gt; (promise? laz) ; 判断 laz 是否是个 promise，即惰性表达式</span><br><span class="line">#t</span><br><span class="line">&gt; (force laz)</span><br><span class="line">55</span><br></pre></td></tr></table></figure>
<p>有意思的是，Racket 将 delay 封装后的惰性表达式(类似my-delay返回的 Pair) 称作 promise，我猜它的意思是，我在创建时不会立即求值，但是我给你个”承诺”，当你需要值时我会计算给你，并且内部保证不会重复计算。<a href="http://wudaijun.com/2018/07/javascript-async-programing/">JS 异步编程</a>中，用于保存异步执行结果，状态以及回调的结构体也叫 Promise，它的意思是: 你发起一个异步调用，我承诺将来一定会给出个结果(成功/失败)，你挂载上去的回调函数我也会在将来结果揭晓后进行调用。这两个 Promise 的”命名撞衫”非常有意思，它们虽然出自不同的语言，用于不同的领域，但都有延迟意思，只不过本文的 delay 由创建者决定何时取值，而 JS 中的 Promise 由异步过程决定何时返回值。</p>
<h2 id="At-Last"><a href="#At-Last" class="headerlink" title="At Last"></a>At Last</h2><p>前面的讨论各种技术本质上是为了延迟计算和避免重复计算，这些技术绝大部分(除了 Memoization) 都只应用在函数式语言中，因为只有函数式语言才能更好地确保函数没有副作用，从而确保函数求值的时机和次数对整个计算的正确性不会有影响，更进一步甚至将这些技术做到了语言内部。而对于过程式来说，由于其本身的可变性和副作用，这方面的路还很长。本文用 Racket 实现的 my-delay 和 Memozation 技术都用到了可变语义，因为我们需要这样一个上下文来辅助我们优化计算，使用了这些可变语义的函数从计算语义上来说仍然是”无副作用的”(PS: 严格意义上的无副作用不存在，CPU，内存都是有状态的全局上下文)。这主要是指，虽然函数有了自己的状态(通过闭包实现)，但对函数使用者来说，从计算结果上来讲并无区别。</p>
<p>换句话说，过程式羡慕函数式的无状态无副作用带来的优化空间和健壮性，而函数式有时候也未尝不羡慕过程式可变性带来的灵活性和便利。</p>
]]></content>
      <categories>
        <category>programing</category>
      </categories>
      <tags>
        <tag>programing</tag>
      </tags>
  </entry>
  <entry>
    <title>游戏服务器的挑战</title>
    <url>/2019/02/gameserver-challenge/</url>
    <content><![CDATA[<p>聊聊游戏服务器的一些难点，以及它和Web服务器的差异。</p>
<h2 id="一-状态性"><a href="#一-状态性" class="headerlink" title="一. 状态性"></a>一. 状态性</h2><p>游戏服务器是后端，做后端的，每天耳濡目染横向扩展，自动伸缩等炫酷的特性，要说放在以前，这些特性还是巨头的”专利”，我们想要自己实现这些东西挑战性是比较大的，但近几年有了容器生态如k8s的加持，只要你实现了一个无状态应用，你几乎马上就可以得到一个可伸缩的集群，享受无状态本身带来的各种好处，机器挂了自动重启，性能不够了就自动扩展等等。而作为一名游戏服务器开发者，自然也想充分享受容器时代的红利，所以我们来捋捋无状态游戏服务器的可行性。</p>
<span id="more"></span>
<p>我将游戏服务器的状态性分为连接状态性和数据状态性。</p>
<h3 id="1-连接状态性"><a href="#1-连接状态性" class="headerlink" title="1. 连接状态性"></a>1. 连接状态性</h3><p>连接的状态性比较好理解，即我们通常所说的长连接和短连接，游戏服务器通常使用TCP长连接，TCP有如下好处:</p>
<ul>
<li>时序性: 指对请求的顺序性保证，即客户端先发出的请求会被先处理，如果服务器是顺序一致性的，那么响应也满足顺序性。</li>
<li>状态性: 在连接建立时进行鉴权，之后这个连接的所有消息都附带上下文(如玩家ID，权限等)，而不用每次请求都带 Header。</li>
<li>服务器推送: 这个对游戏来说还是比较重要的，邮件/聊天/广播等功能都依赖于服务器主动推送。</li>
</ul>
<p>TCP也有一些问题:</p>
<ul>
<li>双端强耦合: 客户端网络环境切换、游戏场景切换、服务端重启等，都需要重新建立连接，并且服务端很难做透明扩展，负载均衡等</li>
<li>弱网体验: 因为TCP的特性，一旦丢包就会重发，阻塞住后续的数据包，造成较大的瞬时延迟</li>
</ul>
<p>针对这两个问题，部分游戏会选择在C/S交互中放弃TCP方案:</p>
<p>为了避免第一个问题，对延迟、性能和推送要求不是很高的游戏，如部分棋牌，卡牌，C/S会直接使用HTTP通信。</p>
<p>为了避免第二个问题，对延迟非常敏感的游戏，如部分即时动作，MOBA，吃鸡，C/S使用UDP来通信，当然，需要基于UDP封装一层可靠(或部分可靠)传输机制。这方面已经有一些成熟的轮子，如<a href="https://github.com/skywind3000/kcp">kcp</a>，<a href="https://github.com/lucas-clemente/quic-go">QUIC</a>等。</p>
<p>对于其他大部分游戏而言，C/S和服务器内部主要都还是使用TCP，引入网关来做连接管理、心跳检测、断线重连，流控等，并对客户端屏蔽服务器内部网络拓扑，避免切换场景时需要重新建立连接。</p>
<p>至于服务器集群内部节点间的通信，由于局域网网络比较稳定，基本不存在弱网问题，而针对强耦合问题，通常会对各节点的耦合进行分级，比如支付，Auth这类独立服务通常使用HTTP通信，逻辑交互则使用TCP，但当逻辑节点数量和耦合上去后，另一个需要考虑的问题是节点网络拓扑和全联通。此时通常会引入消息中间件来简化内部网络拓扑，我在<a href="https://wudaijun.com/2018/12/gameserver-communication-model/">这里</a>也有讨论。</p>
<h3 id="2-数据状态性"><a href="#2-数据状态性" class="headerlink" title="2. 数据状态性"></a>2. 数据状态性</h3><p>通常游戏服务器都是会先将数据更新到内存中，再定期存盘，这意味着服务器内存数据状态和数据库中的数据状态有一定的不一致窗口，这就是所谓的数据状态。</p>
<p>理想情况下，无数据状态服务器的逻辑节点本身只是 Handler，真正的数据放到DB(或Redis缓存)等数据服务中，由于逻辑服务通常是不稳定的，而数据服务通常是相对稳定的，如此逻辑服务更容易做扩展或者主从，逻辑节点挂掉不会造成数据丢失或不一致，并且可以透明重启(暂不考虑连接状态)。</p>
<p>那么游戏服务器为什么不做成无数据状态呢，在游戏中，玩家单个请求，可能造成数10个关联字段的更新，比如一个使用道具的请求就可能涉及到道具，Buff，任务，活动，排行榜等数据更新。这种数据耦合下，范式化分表会带来极大的事务压力(如果不做事务，那么无状态也就意义不大了，因为无法安全地横向扩展)，而反范式化会带来极大的DB数据吞吐压力(每个请求要加载和更新过多的数据)。</p>
<p>另外，对某些逻辑需求而言，无状态服务相对比较难实现的，比如游戏服务器中海量定时器，事件订阅，跨天处理，地图跑桢等等。</p>
<p>因此游戏服务器中，除了极少部分比较独立的服务尽量实现成无状态之外，大部分业务逻辑仍然是有状态的，有数据状态意味着:</p>
<ol>
<li>横向扩展受限，因此更注重单点性能，需要在逻辑层用并发，异步等各种手段来保证服务器的负载能力。尤其看重异步编程思维。</li>
<li>对服务可用性要求更高，对峰值和边界情况的处理需要更健壮，因为服务不可用的代价很大: 公告+维护+补偿三件套，重新部署，处理意外停机可能导致的数据不一致，玩家流失等。</li>
</ol>
<p>小结一下，游戏服务器的无状态主要受限于连接状态性和数据状态性，连接状态性还能够针对性地解决，数据状态则难得多，这是游戏业务需求复杂的特性决定的，它一方面限制了游戏服务器的横向扩展能力，另一方面也让服务器对健壮性的要求更高，如果出现一些逻辑上的BUG，停服维护的代价是很大的，特别对于静态语言而言，有状态+无热更=如履薄冰。做很多功能的时候一方面要尽可能保证其正确性，另一方面也要考虑到其容错性，比如出错之后如何监控/调试/修复。别到时候服务器出现问题了，重启一次来打印Log/上下文，再重启一次来修复Bug。或者是等到玩家已经利用该漏洞刷了大量道具，最后修了Bug还要修数据。</p>
<h2 id="二-性能"><a href="#二-性能" class="headerlink" title="二. 性能"></a>二. 性能</h2><p>由于数据状态一定程度地限制了并发粒度(或者是并发的难度)，因此性能也是游戏服务器的关键指标，对游戏服务器而言，性能压力主要来自于:</p>
<ol>
<li>强交互玩法: 如MOBA,SLG,MMO, 相关的技术优化方案有: 分区服，分房间，分线，AOI，无缝地图，桢同步，客户端演算等。这类强交互玩法会导致服务器大量的演算和推送，如SLG的上行/下行数据量比平均是1:10左右，多人同屏战斗的情况下，可超过1:100</li>
<li>运营峰值: 游戏非常依赖各种运营活动来聚集玩家维持生态，如开服导量，跨服活动，限时Boss等，服务器的一切资源和优化，都是为可能预估到的最大峰值而非均值而准备的</li>
<li>低延迟容忍: 玩家对游戏的响应延迟容忍度是比较低的，排除C/S网络延迟，通常业务层需要保证绝大部分的请求响应延迟在50ms内</li>
</ol>
<h2 id="三-快速迭代"><a href="#三-快速迭代" class="headerlink" title="三. 快速迭代"></a>三. 快速迭代</h2><p>需求变更快应该是所有互联网行业的共性，但在手游里面会更为突出一些，手游属于内容行业的快消品，讲究唯快不破，频繁地调整玩法体验，然后通过数据分析或AB Test来验证。这非常考验研发<a href="https://wudaijun.com/2021/07/software-engineering-ability/">持续快速稳定交付</a>的能力，大部分团队前期会比较注重短期快速交付，而忽略持续(毕竟游戏能不能成都不知道)与稳定(缺乏测试框架，通过QA/玩家BUG反馈来修复)。一旦游戏上线后，数据不错，业务需求继续向前推进，服务器非常容易举步维艰，因为此时需要考虑到版本兼容，数据兼容，稳定性风险等。比如对于SLG这类游戏而言，一旦成功推广，运营生命周期通常都是5-10年，很可能在运营过程中，出现如跨服活动，跨服联盟这类”伤筋动骨”的需求，那么如何在项目快速迭代的同时，保持游戏服务器的健壮性和灵活性，是我看来区分技术人员和工程师的分水岭。</p>
<p>为了尽可能延缓架构腐化，游戏服务器由于技术架构和业务模型的差异，通常需要自己搭建<a href="通常自己逐步建立[测试框架](https://wudaijun.com/2020/08/gs-testing-practice/">测试框架</a>)，<a href="https://wudaijun.com/2018/08/gs-devops/">DevOps</a>，监控报警(可用性/响应延迟/日志/容器/物理机/CCU等)，以保证持续的稳定交付能力。除此之外，还需要不断提炼和重构业务模型代码(比如我们最近在尝试借鉴领域驱动设计的思维进行模块拆分)，保持服务器代码的健康度，以适应后续灵活的需求变更。</p>
<h2 id="四-总结"><a href="#四-总结" class="headerlink" title="四. 总结"></a>四. 总结</h2><p>本文从状态性，性能和快速迭代三个方面简单谈了谈自己的一些理解，其中状态性讲得比较多，因为我认为状态性是导致游戏服务器比常规Web服务器更复杂的直接原因之一，也导致游戏服务器要做到高性能和高可用，需要付出更多的努力。游戏服务器的另一个特性就是需求变更变速，版本迭代快，这需要更灵活地架构设计，更严格的软件工程实践。在游戏行业，唯一不变的就是变化，唯一可信的就是”这个地方不要写死，可能会改”。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Perf 简单试用</title>
    <url>/2019/04/linux-perf/</url>
    <content><![CDATA[<p>Perf(Performance Event)是Linux 2.6.31后内置的性能分析工具，它相较其它Prof工具最大的优势在于与Linux Kernel紧密结合，可以进行内核甚至硬件级的性能分析。我之前只零散地用一些<code>ptrace</code>,<code>strace</code>之类的小工具，与Perf比起来，确实小巫见大巫。也赶紧花了点时间简单了解和试用一下，添加到工具箱，以备不时之需。</p>
<span id="more"></span>
<p>几乎所有的性能分析工具的基本原理都是对监测目标进行数据采样，Perf也不例外，Perf可以基于各种Event对目标进行测样。如基于时间点(tick)采样，可以得到程序运行时间的分布，即程序中哪些函数最耗时。基于cache miss采样，可以得到程序的cache miss分布，即cache失效经常发生在哪些代码中。通过<code>perf list</code>可以Perf支持的各种Event:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo perf list                                                                                                                                                             List of pre-defined events (to be used in -e):</span><br><span class="line"></span><br><span class="line"> cpu-cycles OR cycles                       [Hardware event]</span><br><span class="line"> instructions                               [Hardware event]</span><br><span class="line"> cache-references                           [Hardware event]</span><br><span class="line"> cache-misses                               [Hardware event]</span><br><span class="line"> branch-instructions OR branches            [Hardware event]</span><br><span class="line"> branch-misses                              [Hardware event]</span><br><span class="line"> bus-cycles                                 [Hardware event]</span><br><span class="line"></span><br><span class="line"> cpu-clock                                  [Software event]</span><br><span class="line"> task-clock                                 [Software event]</span><br><span class="line"> page-faults OR faults                      [Software event]</span><br><span class="line"> minor-faults                               [Software event]</span><br><span class="line"> major-faults                               [Software event]</span><br><span class="line"> context-switches OR cs                     [Software event]</span><br><span class="line"> cpu-migrations OR migrations               [Software event]</span><br><span class="line"> alignment-faults                           [Software event]</span><br><span class="line"> emulation-faults                           [Software event]</span><br><span class="line"></span><br><span class="line"> [...]</span><br><span class="line"></span><br><span class="line"> sched:sched_stat_runtime                   [Tracepoint event]</span><br><span class="line"> sched:sched_pi_setprio                     [Tracepoint event]</span><br><span class="line"> syscalls:sys_enter_socket                  [Tracepoint event]</span><br><span class="line"> syscalls:sys_exit_socket                   [Tracepoint event]</span><br><span class="line"></span><br><span class="line"> [...]</span><br></pre></td></tr></table></figure>
<p>该列表非常长，以上是简化之后的输出结果，可以将Perf Event大致分为三类:</p>
<ol>
<li>Hardware Event: 主要是由CPU或PMU硬件产生的事件，如cache-misses, cpu-cycle, instructions, branch-misses等。</li>
<li>Software Event: 由内核软件产生的事件，如 page-faults, context-switches, cpu-migrations等。</li>
<li>Tracepoints: 散布在内核源码中的各种静态的追踪点(Hook)，Perf可以通过挂载Hook来收集这些事件。如kmalloc, syscall, sched_switch等。</li>
</ol>
<p>PMU(Performance Monitoring Unit) 是各CPU厂商随CPU提供的硬件，它允许软件针对某种CPU硬件事件(如cache miss, branch-misses, instructions)设置counter，并且统计该事件次数，当次数到达counter值后，产生中断。软件通过捕获这些中断来考察CPU使用情况。</p>
<h3 id="perf-top"><a href="#perf-top" class="headerlink" title="perf top"></a>perf top</h3><p><code>perf top</code> 用于实时显示当前系统的性能统计信息，用于观察整个系统的当前状态。我们先写一个简单的死循环程序:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">run_forever</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">                i++;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        run_forever();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译并执行它: <code>gcc -o t1 -g t1.c &amp;&amp; ./t1</code>，然后在另一个窗口执行<code>perf top</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Samples: 249K of event &#39;cycles:ppp&#39;, Event count (approx.): 59571881744</span><br><span class="line">Overhead  Shared Object             Symbol</span><br><span class="line">  92.24%  t1                        [.] run_forever</span><br><span class="line">   0.49%  [kernel]                  [k] menu_select</span><br><span class="line">   0.44%  cadvisor                  [.] runtime.findObject</span><br><span class="line">   0.36%  [kernel]                  [k] nmi</span><br><span class="line">   0.29%  game                      [.] runtime.scanobject</span><br><span class="line">   0.28%  cadvisor                  [.] runtime.scanobject</span><br><span class="line">   0.25%  cadvisor                  [.] runtime.(*mspan).nextFreeIndex</span><br><span class="line">   0.24%  [kernel]                  [k] vsnprintf</span><br><span class="line">   0.21%  [kernel]                  [k] __switch_to</span><br><span class="line">   ...</span><br></pre></td></tr></table></figure>
<p>默认情况下，<code>perf top</code>命令将采样cpu-cycles Event，即每个时钟周期进行采样，对所有CPU正在执行的代码(Symbol)进行统计(包括内核代码)，并按照出现次数降序排列。因此<code>perf top</code>打印的是CPU运行时间分布，即哪些函数最耗时。上图清楚指明了目前该机器上最耗时的进程(Shared Object)为t1，以及其热点函数(Symbol)为<code>run_forever</code>。在<code>perf top</code>界面按[h]键可以呼叫帮助菜单，看到所有可用的功能何对应的快捷键。选中t1一行，按[a]键即可启用Annotate(注释)功能，它可以进一步查看当前符号:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">run_forever  &#x2F;home&#x2F;docker&#x2F;test&#x2F;t1</span><br><span class="line">Percent│</span><br><span class="line">       │</span><br><span class="line">       │</span><br><span class="line">       │    Disassembly of section .text:</span><br><span class="line">       │</span><br><span class="line">       │    00000000000005fa &lt;run_forever&gt;:</span><br><span class="line">       │    run_forever():</span><br><span class="line">       │    void run_forever() &#123;</span><br><span class="line">       │      push   %rbp</span><br><span class="line">       │      mov    %rsp,%rbp</span><br><span class="line">       │            long int i &#x3D; 0;</span><br><span class="line">       │      movq   $0x0,-0x8(%rbp)</span><br><span class="line">       │            while(1) &#123;</span><br><span class="line">       │                    i++;</span><br><span class="line"> 99.95 │ c:   addq   $0x1,-0x8(%rbp)</span><br><span class="line">  0.05 │    ↑ jmp    c</span><br></pre></td></tr></table></figure>
<p>可以看到该函数 99.94% 的时间都在执行 i++ 这一行。</p>
<p>当然，你也通过参数指定<code>perf top</code>采样其它Event(比如cache-misses)并设置其采样速率(比如改为每秒5000次，默认是4000):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ perf top -e cache-misses -c 5000</span><br></pre></td></tr></table></figure>
<p><code>perf top</code> 适用于做系统的整体状态统计，然后初步定位到问题进程。当然，由于我们的示例代码太简单，通过<code>perf top</code>就足以分析出问题进程和问题代码。而当情况更复杂时，我们则需要其它perf工具的配合。</p>
<h3 id="perf-stat"><a href="#perf-stat" class="headerlink" title="perf stat"></a>perf stat</h3><p>当你想要分析指定应用程序各方面性能时，可以用<code>perf stat</code>命令，我们仍然通过一段程序来说明:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static char array[10000][10000];</span><br><span class="line">int main (void)&#123;</span><br><span class="line">        int i, j;</span><br><span class="line">        for (i &#x3D; 0; i &lt; 10000; i++)</span><br><span class="line">            for (j &#x3D; 0; j &lt; 10000; j++)</span><br><span class="line">                 array[i][j]&#x3D;i;</span><br><span class="line">                 return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>现在我们通过<code>perf stat</code>来对这个程序的一些事件进行采样:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ gcc -o t2 t2.c</span><br><span class="line">$ sudo perf stat -r 5 -e cache-misses,cache-references,instructions,cycles,L1-dcache-stores,L1-dcache-store-misses .&#x2F;t</span><br><span class="line"></span><br><span class="line"> Performance counter stats for &#39;.&#x2F;t2&#39; (5 runs):</span><br><span class="line"></span><br><span class="line">         3,340,700      cache-misses              #    2.631 % of all cache refs      ( +-  0.25% )</span><br><span class="line">       126,973,736      cache-references                                              ( +-  0.02% )</span><br><span class="line">     1,471,226,871      instructions              #    0.40  insn per cycle                                              ( +-  0.01% )</span><br><span class="line">     3,643,287,243      cycles                                                        ( +-  0.59% )</span><br><span class="line">       219,156,878      L1-dcache-stores                                              ( +-  0.01% )</span><br><span class="line">       102,035,758      L1-dcache-store-misses                                        ( +-  0.01% )</span><br><span class="line"></span><br><span class="line">       1.026604322 seconds time elapsed                                          ( +-  0.58% )                                        ( +-  0.26% )</span><br></pre></td></tr></table></figure>
<p><code>-r</code>指定重复执行次数，可以保证采样结果的可参考性。<code>-e</code>指定要采样的Event，如果指定了cache-misses/cache-reference,cycles/instructions这类成对的Event时，perf会自动计算相关比例值。另外，cache-references/misses指的是Last Level Cache(LLC) references/misses。</p>
<p>结果显示程序执行时间为1.02s,CPU每个时钟周期可以执行0.4条指令，看这些你可能无法直观地判断程序优劣，但是如果我们善用数据局部性，将<code>array[j][i] = i</code>改为<code>array[i][j] = i</code>，再来看看结果:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Performance counter stats for &#39;.&#x2F;t2&#39; (5 runs):</span><br><span class="line"></span><br><span class="line">        1,693,216      cache-misses              #   96.113 % of all cache refs      ( +-  0.05% )</span><br><span class="line">        1,761,695      cache-references                                              ( +-  0.13% )</span><br><span class="line">    1,470,420,403      instructions              #    1.54  insn per cycle                                              ( +-  0.01% )</span><br><span class="line">      955,043,789      cycles                                                        ( +-  0.03% )</span><br><span class="line">      218,964,664      L1-dcache-stores                                              ( +-  0.01% )</span><br><span class="line">        1,790,183      L1-dcache-store-misses                                        ( +-  0.03% )</span><br><span class="line"></span><br><span class="line">      0.271631085 seconds time elapsed                                          ( +-  0.41% )                                       ( +-  0.27% )</span><br></pre></td></tr></table></figure>
<p>cache-misses数量降了一倍，L1-dcache-store-misses更是降了几十倍，insn per cycle由0.52提升到了1.54，亦即CPU利用率更高了，程序整体运行速度快了接近5倍。但你可能会注意到，程序改动后，<code>cache-misses/cache-references</code>的比例从2.63%提升到96.113%，cache命中率降低了？花了很长时间Google后(perf对各种Event的文档太稀缺了，基本没有一份相对详细的Event文档)，<a href="https://stackoverflow.com/questions/55035313/how-does-linux-perf-calculate-the-cache-references-and-cache-misses-events">这篇问答</a>中提到如果存取在L1-dcache-stores命中，则不会记入cache-references，因此当程序数据局部性提升后，在L1层就已经能取到了，也就导致cache-references急剧减少，相对也就导致<code>cache-misses/cache-references</code>比例反而上升了。</p>
<p><code>perf stat</code>也可以通过<code>-p</code>附加到正在运行中的进程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 附加到指定进程采样3秒</span><br><span class="line">$ perf stat -p PID sleep 3</span><br><span class="line"># 附加到指定进程，直到目标进程结束，或Ctrl+C终止</span><br><span class="line">$ perf stat -p PID</span><br></pre></td></tr></table></figure>
<h3 id="perf-record-report"><a href="#perf-record-report" class="headerlink" title="perf record/report"></a>perf record/report</h3><p><code>perf record</code>可以将指定采样数据采样到文件，参数与<code>perf stat</code>类似，可以接可执行文件或附加到指定进程，只不过没有任何输出，而是将采样数据写入到perf.data文件中。与之相匹配的，<code>perf report</code>可以将文件中采样数据展示出来。我们仍然以t2.c为例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo perf record -e cache-misses:u .&#x2F;t2</span><br><span class="line">sudo perf report</span><br><span class="line">Samples: 1K of event &#39;cache-misses:u&#39;, Event count (approx.): 1627272</span><br><span class="line">Overhead  Command  Shared Object     Symbol</span><br><span class="line">  96.48%  t2       t2                [.] main</span><br><span class="line">   3.27%  t2       [kernel]          [k] page_fault</span><br><span class="line">   0.11%  t2       ld-2.27.so        [.] 0x000000000000d305</span><br><span class="line">   0.11%  t2       ld-2.27.so        [.] 0x00000000000109b8</span><br><span class="line">   0.03%  t2       ld-2.27.so        [.] 0x0000000000018d7d</span><br><span class="line">   0.00%  t2       ld-2.27.so        [.] 0x0000000000002082</span><br><span class="line">   0.00%  t2       ld-2.27.so        [.] 0x0000000000001ea0</span><br></pre></td></tr></table></figure>
<p>96.48的 cache-misses Event都分布在main函数中，同样，可以通过上下键选中main函数Enter进入并选择”Annotate main”，可以看到汇编代码级的cache-misses分布(通过 <code>gcc -g -o t2 t2.c</code> 可以保留汇编到代码的符号映射):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Percent│    Disassembly of section .text:</span><br><span class="line">       │</span><br><span class="line">       │    00000000000005fa &lt;main&gt;:</span><br><span class="line">       │    main():</span><br><span class="line">       │    static char array[10000][10000];</span><br><span class="line">       │    int main (void)&#123;</span><br><span class="line">       │      push   %rbp</span><br><span class="line">       │      mov    %rsp,%rbp</span><br><span class="line">       │            int i, j;</span><br><span class="line">       │            for (i &#x3D; 0; i &lt; 10000; i++)</span><br><span class="line">       │      movl   $0x0,-0x8(%rbp)</span><br><span class="line">       │    ↓ jmp    4d</span><br><span class="line">       │                for (j &#x3D; 0; j &lt; 10000; j++)</span><br><span class="line">       │ d:   movl   $0x0,-0x4(%rbp)</span><br><span class="line">       │    ↓ jmp    40</span><br><span class="line">       │                     array[j][i]&#x3D;i;</span><br><span class="line">  1.16 │16:   mov    -0x8(%rbp),%eax</span><br><span class="line">       │      mov    %eax,%ecx</span><br><span class="line">       │      mov    -0x8(%rbp),%eax</span><br><span class="line">       │      cltq</span><br><span class="line">  0.68 │      mov    -0x4(%rbp),%edx</span><br><span class="line">  0.10 │      movslq %edx,%rdx</span><br><span class="line">       │      imul   $0x2710,%rdx,%rdx</span><br><span class="line">       │      add    %rax,%rdx</span><br><span class="line">  1.06 │      lea    array,%rax</span><br><span class="line">       │      add    %rdx,%rax</span><br><span class="line">       │      mov    %cl,(%rax)</span><br><span class="line">       │                for (j &#x3D; 0; j &lt; 10000; j++)</span><br><span class="line"> 76.54 │      addl   $0x1,-0x4(%rbp)</span><br><span class="line">  0.48 │40:   cmpl   $0x270f,-0x4(%rbp)</span><br><span class="line"> 19.98 │    ↑ jle    16</span><br><span class="line">       │            for (i &#x3D; 0; i &lt; 10000; i++)</span><br><span class="line">       │      addl   $0x1,-0x8(%rbp)</span><br><span class="line">       │4d:   cmpl   $0x270f,-0x8(%rbp)</span><br><span class="line">       │    ↑ jle    d</span><br><span class="line">       │                     return 0;</span><br><span class="line">       │      mov    $0x0,%eax</span><br><span class="line">       │    &#125;</span><br><span class="line">       │      pop    %rbp</span><br><span class="line">       │    ← retq</span><br></pre></td></tr></table></figure>
<p>而如果将代码改成局部友好，main函数将不会出现在<code>perf report</code>的列表中。<code>perf record/report</code>用法与现在的主流prof工具类似，这种方式最灵活，对环境的各种要求也低。</p>
<p>在学习过程中也发现Perf一些不足之处，首先就是文档很少，特别关于各种Event，因为它们很多与具体硬件实现相关。第二就是与Linux内核深度结合，是优点也是缺点，因为这也意味着它的跨平台性不是很好。因此它更像是Linux系统级的Prof工具，对于应用级的分析，Perf可能是有点过于底层和重量级了。</p>
<p>参考资料:</p>
<ol>
<li><a href="https://perf.wiki.kernel.org/index.php/Tutorial">Linux kernel profiling with perf</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/index.html">Perf — Linux下的系统性能调优工具，第 1 部分</a></li>
<li><a href="http://web.eece.maine.edu/~vweaver/projects/perf_events/perf_event_open.html">ManPage of PERF_EVENT_OPEN</a></li>
</ol>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Cache一致性和内存一致性</title>
    <url>/2019/04/cache-coherence-and-memory-consistency/</url>
    <content><![CDATA[<p>本文主要谈谈CPU Cache的设计，内存屏障的原理和用法，最后简单聊聊内存一致性。</p>
<p>我们都知道存储器是分层级的，从CPU寄存器到硬盘，越靠近CPU的存储器越小越快，离CPU越远的存储器越大但越慢，即所谓存储器层级(Memory Hierarchy)。以下是计算机内各种存储器的容量和访问速度的典型值。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>存储器类型</th>
<th>容量</th>
<th>特性</th>
<th>速度</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU寄存器</td>
<td>几十到几百Bytes</td>
<td>数据电路触发器，断电丢失数据</td>
<td>一纳秒甚至更低</td>
</tr>
<tr>
<td>Cache</td>
<td>分不同层级，几十KB到几MB</td>
<td>SRAM，断电丢失数据</td>
<td>几纳秒到几十纳秒</td>
</tr>
<tr>
<td>内存</td>
<td>几百M到几十G</td>
<td>DRAM，断电丢失数据</td>
<td>几百纳秒</td>
</tr>
<tr>
<td>固态硬盘(SDD)</td>
<td>几十到几百G</td>
<td>SSD，断电不丢失数据</td>
<td>几十微秒</td>
</tr>
<tr>
<td>机械硬盘(HDD)</td>
<td>上百G</td>
<td>磁性介质和磁头，断电不丢失数据</td>
<td>几毫秒</td>
</tr>
</tbody>
</table>
</div>
<p>从广义的概念上来说，所有的存储器都是其下一级存储器的Cache，CPU Cache缓存的是内存数据，内存缓存的是硬盘数据，而硬盘缓存的则是网络中的数据。本文只谈CPU Cache，一个简单的CPU Cache示意图如下:</p>
<p><img src="/assets/image/201904/cache-simple.png" alt=""></p>
<p>图中忽略了一些细节，现代的CPU Cache通常分为三层，分别叫L1,L2,L3 Cache, 其中L1,L2 Cache为每个CPU核特有，L3为所有CPU核共有，L1还分为缓存指令的i-cache(只读)和缓存程序数据的d-cache，L2 L3 Cache则不区分指令和程序数据，称为统一缓存(unified cache)。本文主要讨论缓存命中和缓存一致性的问题，因此我们只关注L1 Cache，不区分指令缓存和程序数据缓存。</p>
<span id="more"></span>
<h3 id="Cache-Geometry"><a href="#Cache-Geometry" class="headerlink" title="Cache Geometry"></a>Cache Geometry</h3><p>当CPU加载某个地址上的数据时，会从Cache中查找，Cache由多个Cache Line构成(通常L1 Cache的Cache Line大小为64字节)，因此目标地址必须通过某种转换来映射对应的Cache Line，我们可以很容易想到两种方案:</p>
<ol>
<li>指定地址映射到指定Cache Line，读Cache时对地址哈希(通常是按照Cache Line数量取模，即在二进制地址中取中间位)来定位Cache Line，写Cache时如果有冲突则丢掉老的数据。这种策略叫<strong>直接映射</strong></li>
<li>任何地址都可以映射到任何Cache Line，读Cache时遍历所有Cache Line查找地址，写Cache时，可以按照LFU(最不常使用)或LRU(最近最少使用)等策略来替换。这种策略叫<strong>全相联</strong></li>
</ol>
<p>直接映射的缺点在于在特定的代码容易发生冲突不命中，假设某CPU Cache的Cache Line大小为16字节，一共2个Cache Line，有以下求向量点乘的代码:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 代码片段1</span></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">dotprod</span><span class="params">(<span class="keyword">float</span> x[<span class="number">8</span>], <span class="keyword">float</span> y[<span class="number">8</span>])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">float</span> sum = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">8</span>; i ++)</span><br><span class="line">        sum += x[i] * y[i];</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于x和y在函数栈中是连续存放的，<code>x[0..3]</code>和<code>y[0..3]</code>将映射到同一个Cache Line, <code>x[4..7]</code>和<code>y[4..7]</code>被映射到同一个Cache Line，那么在for循环一次读取<code>x[i]</code>,<code>y[i]</code>的过程中，Cache Line将不断被冲突替换，导致Cache “抖动”(thrashing)。也就是说，在直接映射中，即使程序看起来局部性良好，也不一定能充分利用Cache。</p>
<p>那么同样的例子，换成全相联，则不会有这个问题，因为LRU算法会使得<code>y[0..3]</code>不会替换<code>x[0..3]</code>所在的Cache Line，也就不会造成Cache抖动。全相连的缺点是由于每一次读Cache都需要遍历所有的Cache Line进行地址匹配，出于效率考虑，它不适用于太大的Cache。</p>
<p>So，现代OS的操作系统是取两者折中，即组相连结构: 将若干Cache Line分为S个组，组间直接映射，组内全相连，如下图:</p>
<p><img src="/assets/image/201904/cache-geometry.png" alt=""></p>
<p>通用的Cache映射策略，将目标地址分为t(标记位)，s(组索引)，b(块偏移)三个部分。我在<a href="http://wudaijun.com/2019/04/linux-perf/">Linux Perf 简单试用</a>中也有例子说明程序局部性对效率的影响。</p>
<h3 id="Cache-Coherence"><a href="#Cache-Coherence" class="headerlink" title="Cache Coherence"></a>Cache Coherence</h3><p>前面我们谈的主要是Cache的映射策略，Cache设计的最大难点其实在于Cache一致性: </p>
<ol>
<li>任何CPU所发出的访存操作被存储器所观察到的顺序必须与CPU发出操作的顺序相同</li>
<li>每个读操作所返回的值必须是最后一次对该存储位置的写操作的值</li>
</ol>
<p>以上两点，也可以理解为，如何在多层级(L1、L2、L3)，多核(每个核有自己的局部L1、L2缓存)的共享内存存储系统中，保持缓存的透明性，即对CPU而言，对内存地址的访问就像没有缓存系统一样。</p>
<p>举个例子，某CPU尝试修改某个地址值时，其它CPU可能已有该地址的缓存，甚至可能也在执行修改操作。因此该CPU需要先征求其它CPU的”同意”，才能执行写操作。这需要给各个CPU的Cache Line加一些标记(状态)，辅以CPU之间的通信机制(事件)来完成， 这可以通过MESI协议来完成。MESI是以下四个状态的简称:</p>
<p>M(modified): 该行刚被 CPU 改过，并且保证不会出现在其它CPU的Cache Line中。即CPU是该行的所有者。CPU持有该行的唯一正确参照。<br>E(exclusive): 和M类似，但是未被修改，即和内存是一致的，CPU可直接对该行执行修改(修改之后为modified状态)。<br>S(shared): 该行内容至少被一个其它CPU共享，因此该CPU不能直接修改该行。而需要先与其它CPU协商。<br>I(invalid): 该行为无效行，即为空行，前面提到Cache策略会优先填充Invalid行。</p>
<p>除了状态之外，CPU还需要一些消息机制:</p>
<p>Read: CPU发起读取数据请求，请求中包含需要读取的数据地址。<br>Read Response: 作为Read消息的响应，该消息可能是内存响应的，也可能是某CPU响应的(比如该地址在某CPU Cache Line中为Modified状态，该CPU必须返回该地址的最新数据)。<br>Invalidate: 该消息包含需要失效的地址，所有的其它CPU需要将对应Cache置为Invalid状态<br>Invalidate Ack: 收到Invalidate消息的CPU在将对应Cache置为Invalid后，返回Invalid Ack<br>Read Invalidate: 相当于Read消息+Invalidate消息，即取得数据并且独占它，将收到一个Read Response和所有其它CPU的Invalid Ack<br>Writeback: 写回消息，即将状态为Modified的行写回到内存，通常在该行将被替换时使用。现代CPU Cache基本都采用”写回(Write Back)”而非”直写(Write Through)”的方式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">思考: 为什么要有专门的Read Invalidate消息，而不直接用Read + Invalidate消息的方式呢？</span><br></pre></td></tr></table></figure>
<p>具体MESI状态机的转换不再赘述，本质上来说，CPU体系结构依赖消息传递的方式来共享内存。</p>
<p>下面举个例子，假设我们有个四核CPU系统，每个CPU只有一个Cache Line，每个Cache Line包含一个字节，内存地址空间为0x0-0xF，一共两个字节的数据，有如下操作序列:</p>
<p><img src="/assets/image/201904/mesi-example.png" alt=""></p>
<p>上图第一列代表操作发生的时序，第二列是执行操作的CPU，第三列是CPU执行的操作，后面四列是各个CPU的Cache Line状态，最后两列是地址0和地址8在内存中的数据是是最新的(V)还是过期的(I)。初始状态下，每个CPU Cache Line都是未填充(Invalid)的。</p>
<ol>
<li>CPU0 加载地址0x0的数据，发送Read消息，对应Cache Line被标记为Shared</li>
<li>CPU3 加载地址0x0的数据，同样，Cache Line标记为Shared</li>
<li>CPU0 加载地址0x8的数据，导致Cache Line被替换，由于Cache Line之前为Shared状态，即与内存中数据一致，可直接覆盖Cache Line，而无需写回</li>
<li>CPU2 加载地址0x0的数据，并且之后将要修改它，因此CPU2发出Read Invalidate消息以获取该地址的独占权，导致CPU3的Cache Line被置为Invalid，CPU2 Cache Line为Exclusive</li>
<li>CPU2 修改地址0x0的数据，由于此时Cache Line为Exclusive，因此它可以直接修改Cache Line，此时Cache Line状态为Modified。此时内存中的0x0内存为过期数据(I)</li>
<li>CPU1 对地址0x0的数据执行原子(atomic)递增操作，将发出Read Invalidate消息，CPU2将返回Read Response(而不是内存)，然后CPU1将持有地址0x0的Cache Line，状态为Modified，数据为递增后的数据，CPU2的Cache Line为Invalid，内存中的数据仍然是过期(I)状态</li>
<li>CPU1 加载地址0x0的数据，此时CPU1 Cache Line将被替换，由于其状态为Modified，因此需要先执行写回操作将Cache Line写回内存，此时内存中的数据才是最新(V)的</li>
</ol>
<h3 id="Store-Buffers"><a href="#Store-Buffers" class="headerlink" title="Store Buffers"></a>Store Buffers</h3><p>MESI协议足够简单，并且能够满足我们对Cache一致性的需求，它在单个CPU对指定地址的反复读写方面有很好的性能表现，但在某个CPU尝试修改在其它CPU Cache Line中存在的数据时，性能表现非常糟糕，因为它需要发出Invalidate消息并等待Ack，这个延迟(Stall)对CPU来说对难以忍受的并且有时是无必要的，比如执行写入的CPU可能只是简单的给这个地址赋值(而不关心它的当前值是什么)。解决这类不必要的延迟的一个方案就是在CPU和Cache之间加一个Store Buffer: CPU可以先将要写入的数据写到Store Buffer，然后继续做其它事情。等到收到其它CPU发过来的Cache Line(Read Response)，再将数据从Store Buffer移到Cache Line。结构如下所示:</p>
<p><img src="/assets/image/201904/cache-with-store-buffer.png" alt=""></p>
<p>然后加了Store Buffer之后，会引入另一个问题，比如有如下代码:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 代码片段2</span></span><br><span class="line">a = <span class="number">1</span>;</span><br><span class="line">b = a + <span class="number">1</span>;</span><br><span class="line">assert(b == <span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<p>初始状态下，假设a,b值都为0，并且a存在CPU1的Cache Line中(Shared状态)，可能出现如下操作序列:</p>
<ol>
<li>CPU0 要写入A，发出Read Invalidate消息，并将a=1写入Store Buffer</li>
<li>CPU1 收到Read Invalidate，返回Read Response(包含a=0的Cache Line)和Invalidate Ack</li>
<li>CPU0 收到Read Response，更新Cache Line(a=0)</li>
<li>CPU0 开始执行 <code>b = a + 1</code>，从Cache Line中加载a，得到a=0</li>
<li>CPU0 将Store Buffer中的a=1应用到Cache Line</li>
<li>CPU0 得到 b=0+1，断言失败</li>
</ol>
<p>造成这个问题的根源在于对同一个CPU存在对a的两份拷贝，一份在Cache，一份在Store Buffer，前者用于读，后者用于写，因而出现CPU执行顺序与程序顺序(Program Order)不一致(先执行了<code>b=a+1</code>，再执行<code>a=1</code>)。</p>
<h3 id="Store-Forwarding"><a href="#Store-Forwarding" class="headerlink" title="Store Forwarding"></a>Store Forwarding</h3><p>Store Buffer可能导致破坏程序顺序(Program Order)的问题，硬件工程师在Store Buffer的基础上，又实现了”Store Forwarding”技术: CPU可以直接从Store Buffer中加载数据，即支持将CPU存入Store Buffer的数据传递(forwarding)给后续的加载操作，而不经由Cache。结构如图:</p>
<p><img src="/assets/image/201904/cache-with-store-forwarding.png" alt=""></p>
<p>现在解决了同一个CPU读写数据的问题，再来看看并发程序:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 代码片段3</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    a = <span class="number">1</span>;</span><br><span class="line">    b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">    assert(a == <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>假设初始状态下，<code>a=0; b=0;</code>，a存在于CPU1的Cache中，b存在于CPU0的Cache中，均为Exclusive状态，CPU0执行foo函数，CPU1执行bar函数，上面代码的预期显然为断言为真。那么来看下执行序列:</p>
<ol>
<li>CPU1执行<code>while(b == 0)</code>，由于CPU1的Cache中没有b，发出<code>Read b</code>消息</li>
<li>CPU0执行<code>a = 1</code>，由于CPU0的Cache中没有a，因此它将<code>a(当前值1)</code>写入到Store Buffer并发出<code>Read Invalidate a</code>消息</li>
<li>CPU0执行<code>b = 1</code>，由于b已经存在在Cache中(Exclusive)，因此可直接执行写入</li>
<li>CPU0收到<code>Read b</code>消息，将Cache中的b(当前值1)返回给CPU1，将b写回到内存，并将Cache Line状态改为Shared</li>
<li>CPU1收到包含b的Cache Line，结束<code>while (b == 0)</code>循环</li>
<li>CPU1执行<code>assert(a == 1)</code>，由于此时CPU1 Cache Line中的a仍然为0并且有效(Exclusive)，断言失败</li>
<li>CPU1收到<code>Read Invalidate a</code>消息，返回包含a的Cache Line，并将本地包含a的Cache Line置为Invalid(已经晚了)</li>
<li>CPU0收到CPU1传过来的Cache Line，然后将Store Buffer中的a(当前值1)刷新到Cache Line</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">思考: 为什么CPU0执行&#96;a&#x3D;1&#96;时要发送Read Invalidate而不直接发送Invalidate?</span><br></pre></td></tr></table></figure>
<p>出现这个问题的原因在于CPU不知道a, b之间的数据依赖，CPU0对a的写入走的是Store Buffer(有延迟)，而对b的写入走的是Cache，因此b比a先在Cache中生效，导致CPU1读到<code>b=1</code>时，a还存在于Store Buffer中。</p>
<h3 id="Memory-Barrier"><a href="#Memory-Barrier" class="headerlink" title="Memory Barrier"></a>Memory Barrier</h3><p>对于上面的内存不一致，很难从硬件层面优化，因为CPU不可能知道哪些值是相关联的，因此硬件工程师提供了一个叫内存屏障的东西，开发者可以用它来告诉CPU该如何处理值关联性。我们可以在<code>a=1</code>和<code>b=1</code>之间插入一个内存屏障:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 代码片段4</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    a = <span class="number">1</span>;</span><br><span class="line">    smp_mb()</span><br><span class="line">    b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">    assert(a == <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当CPU看到内存屏障<code>smp_mb()</code>时，会先刷新当前(屏障前)的Store Buffer，然后再执行后续(屏障后)的Cache写入。这里的”刷新Store Buffer”有两种实现方式: 一是简单地刷新Store Buffer(需要挂起等待相关的Cache Line到达)，二是将后续的写入也写到Store Buffer中，直到屏障前的条目全部应用到Cache Line(可以通过给屏障前的Store Buffer中的条目打个标记来实现)。这样保证了屏障前的写入一定先于屏障后的写入生效，第二种方案明显更优，以第二种方案为例:</p>
<ol>
<li>CPU1执行<code>while(b == 0)</code>，由于CPU1的Cache中没有b，发出<code>Read b</code>消息</li>
<li>CPU0执行<code>a = 1</code>，由于CPU0的Cache中没有a，因此它将<code>a(当前值1)</code>写入到Store Buffer并发出<code>Read Invalidate a</code>消息</li>
<li>CPU0看到<code>smp_mb()</code>内存屏障，它会标记当前Store Buffer中的所有条目(即<code>a = 1</code>被标记)</li>
<li>CPU0执行<code>b = 1</code>，尽管b已经存在在Cache中(Exclusive)，但是由于Store Buffer中还存在被标记的条目，因此b不能直接写入，只能先写入Store Buffer中</li>
<li>CPU0收到<code>Read b</code>消息，将Cache中的b(当前值0)返回给CPU1，将b写回到内存，并将Cache Line状态改为Shared</li>
<li>CPU1收到包含b的Cache Line，继续<code>while (b == 0)</code>循环</li>
<li>CPU1收到<code>Read Invalidate a</code>消息，返回包含a的Cache Line，并将本地的Cache Line置为Invalid</li>
<li>CPU0收到CPU1传过来的包含a的Cache Line，然后将Store Buffer中的a(当前值1)刷新到Cache Line，并且将Cache Line状态置为Modified</li>
<li>由于CPU0的Store Buffer中被标记的条目已经全部刷新到Cache，此时CPU0可以尝试将Store Buffer中的<code>b=1</code>刷新到Cache，但是由于包含B的Cache Line已经不是Exclusive而是Shared，因此需要先发<code>Invalid b</code>消息</li>
<li>CPU1收到<code>Invalid b</code>消息，将包含b的Cache Line置为Invalid，返回<code>Invalid Ack</code></li>
<li>CPU1继续执行<code>while(b == 0)</code>，此时b已经不在Cache中，因此发出Read消息</li>
<li>CPU0收到<code>Invalid Ack</code>，将Store Buffer中的<code>b=1</code>写入Cache</li>
<li>CPU0收到Read消息，返回包含b新值的Cache Line</li>
<li>CPU1收到包含b的Cache Line，可以继续执行<code>while(b == 0)</code>，终止循环</li>
<li>CPU1执行<code>assert(a == 1)</code>，此时a不在其Cache中，因此发出Read消息</li>
<li>CPU0收到Read消息，返回包含a新值的Cache Line</li>
<li>CPU1收到包含a的Cache Line，断言为真</li>
</ol>
<p>上面的步骤看起来很多，其实比较简单，由于内存屏障的存在，导致<code>b=1</code>只能随<code>a=1</code>一起进入到Store Buffer，即b的新值不会先于a的新值出现在CPU0的Cache中，对于应用程序而言，内存屏障前的写入会先于内存屏障后的写入生效。</p>
<h3 id="Invalid-Queue"><a href="#Invalid-Queue" class="headerlink" title="Invalid Queue"></a>Invalid Queue</h3><p>引入了Store Buffer，再辅以Store Forwarding，Memory Barrier，看起来好像可以自洽了，然而还有一个问题没有考虑: Store Buffer的大小是有限的，所有写入操作的Cache Missing都会使用Store Buffer，特别是出现内存屏障时，后续的所有写入操作(不管是否Cache Miss)都会挤压在Store Buffer中(直到Store Buffer中屏障前的条目处理完)，因此Store Buffer很容易会满，当Store Buffer满了之后，CPU还是会卡在等对应的Invalid Ack以处理Store Buffer中的条目。因此还是要回到Invalid Ack中来，Invalid Ack耗时的主要原因是CPU要先将对应的Cache Line置为Invalid后再返回Invalid Ack，一个很忙的CPU可能会导致其它CPU都在等它回Invalid Ack。解决思路还是化同步为异步: CPU不必要处理了Cache Line之后才回Invalid Ack，而是可以先将Invalid消息放到某个请求队列Invalid Queue，然后就返回Invalid Ack。CPU可以后续再处理Invalid Queue中的消息，大幅度降低Invalid Ack响应时间。此时的CPU Cache结构图如下:</p>
<p><img src="/assets/image/201904/cache-with-invalid-queue.png" width = "500" height = "400" alt="" align=center /></p>
<p>和Store Buffer类似，Invalid Queue有两个问题要考虑，一是CPU在处理任何Cache Line的MSEI状态前，都必须先看Invalid Queue中是否有该Cache Line的Invalid消息没有处理。这一点在CPU数据竞争不是很激烈时是可以接受的。这方面的一个极端是<a href="http://wudaijun.com/2015/01/false-sharing/">false sharing</a>。</p>
<p>Invalid Queue的另一个要考虑的问题是它也增加了破坏内存一致性的可能，即可能破坏我们之前提到的内存屏障:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 代码片段5</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    a = <span class="number">1</span>;</span><br><span class="line">    smp_mb()</span><br><span class="line">    b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">    assert(a == <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>仍然假设a, b的初始值为0，a在CPU0,CPU1中均为Shared状态，b为CPU0独占(Exclusive状态)，CPU0执行foo，CPU1执行bar:</p>
<ol>
<li>CPU0执行<code>a = 1</code>，由于其有包含a的Cache Line，将a写入Store Buffer，并发出<code>Invalidate a</code>消息</li>
<li>CPU1执行<code>while(b == 0)</code>，它没有b的Cache，发出<code>Read b</code>消息</li>
<li>CPU1收到CPU0的<code>Invalidate a</code>消息，将其放入Invalidate Queue，返回<code>Invalidate Ack</code></li>
<li>CPU0收到<code>Invalidate Ack</code>，将Store Buffer中的<code>a=1</code>刷新到Cache Line，标记为Modified</li>
<li>CPU0看到<code>smp_mb()</code>内存屏障，但是由于其Store Buffer为空，因此它可以直接跳过该语句</li>
<li>CPU0执行<code>b = 1</code>，由于其Cache独占b，因此直接执行写入，Cache Line标记为Modified，</li>
<li>CPU0收到CPU1发的<code>Read b</code>消息，将包含b的Cache Line写回内存并返回该Cache Line，本地的Cache Line标记为Shared</li>
<li>CPU1收到包含b(当前值1)的Cache Line，结束while循环</li>
<li>CPU1执行<code>assert(a == 1)</code>，由于其本地有包含a旧值的Cache Line，读到a初始值0，断言失败</li>
<li>CPU1这时才处理Invalid Queue中的消息，将包含a旧值的Cache Line置为Invalid</li>
</ol>
<p>问题在于CPU1在读取a的Cache Line时，没有先处理Invalid Queue中该Cache Line的Invalid操作，解决思路仍然是内存屏障，我们可以通过内存屏障让CPU标记当前Invalid Queue中所有的条目，所有的后续加载操作必须先等Invalid Queue中标记的条目处理完成再执行。因此我们可以在<code>while</code>和<code>assert</code>之间插入<code>smp_mb()</code>。这样CPU1在看到<code>smp_mb()</code>后，会先处理Invalidate Queue，然后发现本地没有包含a的Cache Line，重新从CPU0获取，得到a的值为1，断言成立。具体操作序列不再赘述。</p>
<p>前面我们说的内存屏障可以同时作用于Store Buffer和Invalidate Queue，而实际上，CPU0(foo函数)只有写操作，因此只关心Store Buffer，同样的CPU1(bar函数)都是读操作，只关心Invalidate Queue，因此，大多数CPU架构将内存屏障分为了读屏障(Read Memory Barrier)和写屏障(Write Memory Barrier):</p>
<ul>
<li>读屏障: 任何读屏障前的读操作都会先于读屏障后的读操作完成</li>
<li>写屏障: 任何写屏障前的写操作都会先于写屏障后的写操作完成</li>
<li>全屏障: 同时包含读屏障和写屏障的作用</li>
</ul>
<p>因此前面的例子中，foo函数只需要写屏障，bar函数需要读屏障。实际的CPU架构中，可能提供多种内存屏障，比如可能分为四种:</p>
<ul>
<li>LoadLoad: 相当于前面说的读屏障</li>
<li>LoadStore: 任何该屏障前的读操作都会先于该屏障后的写操作完成</li>
<li>StoreLoad: 任何该屏障前的写操作都会先于该屏障后的读操作完成</li>
<li>StoreStore: 相当于前面说的写屏障</li>
</ul>
<p>实现原理类似，都是基于Store Buffer和Invalidate Queue，不再赘述。</p>
<h3 id="Instruction-Reordering"><a href="#Instruction-Reordering" class="headerlink" title="Instruction Reordering"></a>Instruction Reordering</h3><p>到目前为止我们只考虑了CPU按照程序顺序执行指令，而实际上为了更好地利用CPU，CPU和编译器都可能会对指令进行重排(reordering):</p>
<ol>
<li>编译期间重排: 编译器在编译期间，可能对指令进行重排，以使其对CPU更友好</li>
<li>运行期间重排: CPU在执行指令的过程中，可能乱序执行以更好地利用流水线</li>
</ol>
<p>不管是CPU架构，VM，还是编译器，在对指令进行重排时都要遵守一个约束: 不管指令如何重排，对单线程来说，结果必然是一致的。即不会改变单线程程序的行为。比如:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 代码片段6</span></span><br><span class="line">a = <span class="number">1</span>;</span><br><span class="line">b = <span class="number">2</span>;</span><br><span class="line">c = a + b;</span><br></pre></td></tr></table></figure>
<p>编译器/CPU/VM 可以对<code>a = 1;</code>和<code>b = 2;</code>进行对换，而不能将<code>c = a + b</code>与前面两句对换，在实现上来说，对指定地址的操作(读写)序列，CPU是会保证和程序顺序一致的(比如a是先写后读)，并且CPU的读写对自己总是可见的(Store Forwarding)，对于不同的地址，CPU不能解析其依赖关系，可能会乱序执行，比如如果有其它线程依赖于a先于b赋值这个事实，那么就必须要应用程序告诉CPU/编译器，a和b有依赖关系，不要重排。前面提到的内存屏障，一直谈的是它的可见性(visibility)功能，它能够让屏障前的操作(读/写)即时刷新，被其它CPU看到。而内存屏障还有个功能就是限制指令重排(读/写指令)，否则即使在<code>a = 1</code>和<code>b = 2</code>之间加了内存屏障，b也有可能先于a赋值，前面的<code>foo()</code>和<code>bar()</code>的例子也会断言失败。</p>
<h3 id="Programing"><a href="#Programing" class="headerlink" title="Programing"></a>Programing</h3><p>对应用层而言，各种语言提供的并发相关关键字和工具，底层都会使用内存屏障。</p>
<h4 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h4><p>java中可以通过volatile关键字来保证变量的可见性，并限制局部的指令重排。它的实现原理是在每个volatile变量写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障，在每个volatile变量读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障来完成。</p>
<h4 id="atomic"><a href="#atomic" class="headerlink" title="atomic"></a>atomic</h4><p>以C++的atomic为例，atomic本身的职责是保证原子性，与volatile定位不太一样，后者本身是不保证原子性的，C++ atomic允许在保证原子的基础上，指定内存顺序，即使用哪种内存屏障。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 代码片段7</span></span><br><span class="line"><span class="comment">// memory_order_relaxed 松散的内存模型，不要求任何顺序性，只要求原子性。通常用于计数器自增</span></span><br><span class="line"><span class="comment">// Thread A:</span></span><br><span class="line">r1 = y.load(memory_order_relaxed); <span class="comment">// A</span></span><br><span class="line">x.store(r1, memory_order_relaxed); <span class="comment">// B</span></span><br><span class="line"><span class="comment">// Thread B:</span></span><br><span class="line">r2 = x.load(memory_order_relaxed); <span class="comment">// C </span></span><br><span class="line">y.store(<span class="number">42</span>, memory_order_relaxed); <span class="comment">// D</span></span><br></pre></td></tr></table></figure>
<p>在这种情况下，可能出现全局执行序列为: D A B C，出现r1=r2=42的情况。<code>memory_order_relaxed</code>相当于没有加内存屏障。除了<code>memory_order_relaxed</code>外，还有:</p>
<ul>
<li><code>memory_order_acquire</code>: 在该原子变量的读操作前插入LoadLoad屏障，在读操作后插入LoadStore。即Load之后的所有读写操作不能重排到Load之前</li>
<li><code>memory_order_consume</code>: acquire限制了Load之后的所有读写操作向前重排，而consume则只限制相关联的读写操作(单线程语义内)</li>
<li><code>memory_order_release</code>: 在该原子变量的写操作前插入LoadStore屏障，在写操作后插入StoreStore屏障。即Store之前的所有读写操作不能重排到Store之后</li>
<li><code>memory_order_acq_rel</code>: 相当于 <code>memory_order_acquire</code> + <code>memory_order_release</code></li>
<li><code>memory_order_seq_cst</code>: 最强的顺序一致性，在<code>memory_order_acq_rel</code>的基础上，支持单独全序，即所有线程以同一顺序观测到该原子变量的所有修改</li>
</ul>
<p>这里也引申出关于内存屏障的两个常用语义:</p>
<ul>
<li>acquire语义：Load 之后的读写操作无法被重排至 Load 之前。即 相当于LoadLoad和LoadStore屏障。</li>
<li>release语义：Store 之前的读写操作无法被重排至 Store 之后。即 相当于LoadStore和StoreStore屏障。</li>
</ul>
<p>注意acquire和release语义没有提到StoreLoad屏障，StoreLoad屏障是四种屏障中开销最大的，这个在后面会提到。</p>
<h4 id="mutex"><a href="#mutex" class="headerlink" title="mutex"></a>mutex</h4><p>mutex的实现通常是在mutex lock时加上acquire屏障(LoadLoad+LoadStore)，在mutex unlock时加上release屏障(StoreStore+StoreLoad)，例如:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 代码片段8</span></span><br><span class="line"><span class="comment">// -&gt; LoadLoad</span></span><br><span class="line">mutex_lock(a);</span><br><span class="line"><span class="comment">// -&gt; LoadStore</span></span><br><span class="line">x = x+<span class="number">1</span>;</span><br><span class="line"><span class="comment">// -&gt; StoreStore</span></span><br><span class="line">mutex_unlock(a);</span><br><span class="line"><span class="comment">// -&gt; StoreLoad</span></span><br></pre></td></tr></table></figure>
<p>由于mutex任意时刻只能被一个线程占有，因此A线程拿到mutex必然在B线程释放mutex之后，由于内存屏障的存在，<code>mutex_lock</code>和<code>mutex_unlock</code>之间的指令只能在mutex里面(无法越过mutex)，并且A线程能即时看到B线程mutex中作出的更改。</p>
<p>注意，这里列举的volatile, atomic, mutex的具体实现和语义可能在不同的语言甚至同种语言不同的编译平台中有所区别(如C++不同的VS版本对volatile关键字的内存屏障使用有所区别)。对开发者而言，编写并发程序需要理解三个东西: 原子性，可见性和顺序性。</p>
<ul>
<li>原子性: 尽管在如今大部分平台下，对一个字的数据进行存取(int,指针)的操作本身就是原子性的，但为了更好地跨平台性，通过atomic操作来实现原子性是更好的方法，并且不会造成额外的开销。C++的atomic还提供可见性和顺序性选项</li>
<li>可见性: 数据同步相关，前面讨论的CPU Cache设计主要关注的就是可见性，即每个读操作所返回的值必须是最后一次对该存储位置的写操作的值。Cache一致性主要解决的就是数据可见性的问题</li>
<li>顺序性: 内存屏障的另一个功能就是可以限制局部的指令重排(一些文章将内存屏障定义为限制指令重排工具，我认为是不准确的，如前面所讨论的，即使没有指令重排，有时也需要内存屏障来保证可见性)。内存屏障保证屏障前的某些操作必定限于屏障后的操作<strong>发生且可见</strong>。但屏障前或屏障后的指令，CPU/编译器仍然可以在不改变单线程结果的情况下进行局部重排。每个硬件平台有自己的基础内存一致性(强/弱内存模型)</li>
</ul>
<h3 id="Memory-Consistency"><a href="#Memory-Consistency" class="headerlink" title="Memory Consistency"></a>Memory Consistency</h3><p>有了前面的讨论，我们可以引出内存一致性的概念了，前面讨论的Cache一致性，内存屏障，指令重排，乱序执行等，都属于内存一致性的范畴。内存一致性也叫做内存模型(Memory Model)或内存一致性模型(Memory Consistency Model)，内存一致性模型规定了程序员和系统之间的契约，其中系统保证，如果程序员遵循内存操作规则，内存将是一致的，读取、写入或更新内存的结果将是可预测的。</p>
<p>Cache一致性(Conherence)和内存一致性(Consistency)中的”一致性”意义是不一样的，前者关注多个CPU对同一内存地址的读写预期，后者关注多个CPU对所有内存地址的读写预期。事实上，Cache一致性的另一种定义(<a href="https://en.wikipedia.org/wiki/Cache_coherence">From WIKI</a>)就是基于顺序一致性内存模型的:</p>
<p>缓存一致性系统必须以遵循每个线程的程序顺序的总顺序来执行所有线程的加载和存储到单个内存位置。缓存一致系统和顺序一致系统之间的唯一区别是地址位置的数量(缓存一致系统的单个内存位置，顺序一致系统的所有内存位置)。因此可以说Cache一致性是内存一致性的一部分。</p>
<p>PS: 前面讨论的Cache Coherence(MESI，StoreBuffer, InvalidQueue)本质是满足多个CPU对单个内存地址读写的顺序一致性的。之所以会用到内存屏障，是因为那是针对多个内存地址有关联的情况，这属于Memory Consistency考虑的范畴。</p>
<p>以下是几种常见的内存一致性模型:</p>
<ul>
<li><code>Weak Memory Model</code>: 如DEC Alpha是弱内存模型，它可能经历所有的四种内存乱序(LoadLoad, LoadStore, StoreLoad, StoreStore)，任何Load和Store操作都能与任何其它的Load或Store操作乱序，只要其不改变单线程的行为。</li>
<li><code>Weak With Date Dependency Ordering</code>: 如ARM, PowerPC, Itanium，在Aplpha的基础上，支持数据依赖排序，如C/C++中的<code>A-&gt;B</code>，它能保证加载B时，必定已经加载最新的A</li>
<li><code>Strong Memory Model</code>: 如X86/64，强内存模型能够保证每条指令<code>acquire and release</code>语义，换句话说，它使用了LoadLoad/LoadStore/StoreStore三种内存屏障，即避免了四种乱序中的三种，仍然保留StoreLoad的重排，对于代码片段7来说，它仍然可能出现r1=r2=42的情况</li>
<li><code>Sequential Consistency</code>: 最强的一致性，理想中的模型，在这种内存模型中，没有乱序的存在。如今很难找到一个硬件体系结构支持顺序一致性，因为它会严重限制硬件对CPU执行效率的优化(对寄存器/Cache/流水线的使用)。</li>
</ul>
<p>前面说到C++ atomic内存模型属于语言级的约束定义，它建立在处理器平台内存模型之上，如果处理器平台是SC(Sequential Consistency)的，那么语言级无论如何定义也无法将硬件改为更松散的内存模型。语言级的内存模型还有一个重要作用就是限制编译器reorder，即生成编译器屏障(fence)。因此即使处理器平台是SC的，语言层面定义为relaxed也可能因为编译器reorder导致结果不如预期。</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>本文比较杂乱，前面主要介绍CPU Cache结构和Cache一致性问题，引出内存屏障的概念。后面顺便简单谈了谈指令乱序和内存一致性。</p>
<p>实际的CPU Cache结构比上面阐述的要复杂得多，其核心的优化理念都是化同步为异步，然后再去处理异步下的一致性问题(处理不了就交给开发者…)。尽管异步会带来一些理解和开发负担，但它仍然是达成高吞吐量的必经之路。硬件方面的结构优化到一定程度了，CPU/编译器就开始打应用层代码的主意: 如指令重排和乱序执行。</p>
<p>对开发者来说，想要完整掌握和理解内存一致性是非常困难的，其中包括系统架构、语言、编译器等多个层面的实现细节，以及不同语言版本和系统架构之间的差异。实践中，应用程序可以通过封装好的mutex完成大部分的并发控制，而无需关注内存一致性实现细节和不同平台的差异。但是在使用比mutex更底层的同步机制(如atomic, volatile, memory-barrier, lock-free等)时，就要务必小心。从原子性，可见性，顺序性等方面确保代码执行结果如预期。</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ol>
<li><a href="http://www.rdrop.com/~paulmck/scalability/paper/whymb.2010.06.07c.pdf">Memory Barriers: a Hardware View for Software Hackers</a></li>
<li><a href="http://www.parallellabs.com/2010/03/06/why-should-programmer-care-about-sequential-consistency-rather-than-cache-coherence/">为什么程序员需要关心顺序一致性而不是Cache一致性？</a></li>
<li><a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/">浅谈Memory Reordering</a></li>
<li><a href="http://0xffffff.org/2017/02/21/40-atomic-variable-mutex-and-memory-barrier/">聊聊原子变量、锁、内存屏障那点事</a></li>
<li><a href="https://preshing.com/20120913/acquire-and-release-semantics/">Acquire and Release Semantics</a></li>
<li><a href="https://wudaijun.com/2018/09/consistency/">一致性杂谈</a></li>
</ol>
]]></content>
      <categories>
        <category>os</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title>编程范式游记</title>
    <url>/2019/05/programing-paradigm/</url>
    <content><![CDATA[<p>这段时间学习OOP对语言和编程范式有一些新的理解，之前系统整理过<a href="https://wudaijun.com/2018/05/understand-functional-programing/">函数式编程</a>，因此先从OOP谈起。我们先回顾下面向对象(OOP)的核心思想:</p>
<ol>
<li>所有的值都是对象</li>
<li>对象与对象之间通过方法调用(或者说是发消息)进行通信</li>
<li>对象可以有自己的私有字段/状态，只有对象的方法可以访问和更新这些字段</li>
<li>每个对象都是一个类(Class)的实例，类定义了对象的行为(内部数据和方法实现)</li>
</ol>
<p>与函数式的”一切皆函数”一样，OOP也有一个宏大的目标”一切皆对象”。</p>
<span id="more"></span>
<h3 id="oop-with-dynamic-type"><a href="#oop-with-dynamic-type" class="headerlink" title="oop with dynamic type"></a>oop with dynamic type</h3><p>动态OOP语言，以Ruby为例，它是一种”纯度比较高”的OOP语言，它有一些比较有意思的特性:</p>
<ol>
<li>null,3,true等都是对象，对象的类也是对象，当然也有例外，如Blocks</li>
<li>由于对象的类也是对象(类型为Class)，因此你可以像更改对象一样动态更改类的定义，如添加新方法</li>
<li>对象与对象之间只能通过方法通信，即对象不能直接访问其它对象的字段</li>
</ol>
<h4 id="subclass"><a href="#subclass" class="headerlink" title="subclass"></a>subclass</h4><p>除了基于对象的封装之外，另一个OOP需要考虑的问题就是复用，以Ruby为例，比如我们有个Point类:</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span></span></span><br><span class="line">    <span class="keyword">attr_accessor</span> <span class="symbol">:x</span>, <span class="symbol">:y</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initialize</span><span class="params">(x,y)</span></span></span><br><span class="line">        <span class="variable">@x</span> = x</span><br><span class="line">        <span class="variable">@y</span> = y</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">distFromOrigin</span></span></span><br><span class="line">        Math.sqrt(<span class="variable">@x</span> * <span class="variable">@x</span> + <span class="variable">@y</span> * <span class="variable">@y</span>)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">distFromOrigin2</span></span></span><br><span class="line">        Math.sqrt(x * x + y * y)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>现在我们要创建一个ColorPoint类，它除了多个Color字段外，其它属性和行为与Point一模一样，这个时候我们有以下几种做法:</p>
<ol>
<li>在ColorPoint类定义中，将Point相关的代码拷贝过来或重写，ColorPoint成为了与Point不相关的两个类</li>
<li>在ColorPoint类中定义一个Point类的成员，然后将distFromOrigin和distFromOrigin2等方法都转调(forwarding)到该成员上</li>
<li>通过将ColorPoint声明为Point的子类(subclass)，这样ColorPoint就继承Point的所有属性和方法，并且仍然可以自己扩展属性，覆盖或新增方法</li>
</ol>
<p>以上三种实现方式导致的ColorPoint和Point耦合度依次递增，在大多数场景下，该问题的最佳方案应该是方案3，因为它能够最大程度达成代码复用，并且在此例子，ColorPoint “is-a” Point。</p>
<p>但是，在OOP中，subclass通常是很容易被过度使用，比如我们现在要实现一个Point3D类，它多了个z属性，那么它的<code>distFromOrigin</code>和<code>distFromOrigin2</code>都需要override，它真正能够复用的只有<code>x</code>，<code>y</code>两个存取器，这个时候就会有一些争议(复用程度太低)，特别是如果Point还有个方法<code>distance(p)</code>，用于求出两点距离时，此时Point3D需要override该方法，并且参数为Point3D，此时将Point对象传给Point3D的distance将得到运行时错误。因此在用subclass时，需要谨慎评估类之间的关系，以及类扩展和重写带来的影响。</p>
<h4 id="duck-typing"><a href="#duck-typing" class="headerlink" title="duck typing"></a>duck typing</h4><p>由于Ruby是动态语言，前面我们讨论的ColorPoint的三种实现方式都不影响ColorPoint和Point的使用，如我们有个函数:</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">def mirror_update pt</span><br><span class="line">    pt.x = pt.x * -<span class="number">1</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>三种方式实现的ColorPoint都可以作为<code>mirror_update</code>的参数，因为<code>mirror_update</code>对参数pt的要求是:</p>
<ol>
<li>pt实现了<code>x()</code>方法</li>
<li><code>pt.x()</code>方法的返回值实现了<code>*</code>方法，可接受<code>-1</code>为参数</li>
<li>pt实现了<code>x=</code>方法，可接受<code>pt.x*-1</code>的结果作为参数</li>
</ol>
<p>三种方式实现的Point和ColorPoint都满足以上要求，因此它们都可以使用<code>mirror_update</code>函数。这就是所谓的<a href="https://zh.wikipedia.org/wiki/%E9%B8%AD%E5%AD%90%E7%B1%BB%E5%9E%8B">Duck Typing</a>。在Ruby这类动态类型OOP语言中，代码复用非常灵活。当然这也不是免费的，由于少了静态类型检查，如果调用<code>mirror_update(Point.new(1,&quot;haha&quot;))</code>会”正确”得到<code>-1</code>，而调用<code>mirror_update(Point.new(&quot;haha&quot;,-1))</code>则会得到<code>negative argument (ArgumentError)</code>运行时错误(string没有实现<code>*</code>方法)，两种调用报错的时机和报错的形式取决与业务代码。尽管它们从逻辑上来说都是错误的。</p>
<h4 id="dynamic-dispatch"><a href="#dynamic-dispatch" class="headerlink" title="dynamic dispatch"></a>dynamic dispatch</h4><p>再举一个例子，如果我们要以subclass创建一个极坐标点类PolarPoint(包含一个半径属性和一个角度属性)，为了保证继承的语义，PolarPoint不得不重写来自于Point的<code>x</code>，<code>y</code>属性，我们不再讨论这里使用继承的合理性，而是想引出一个有意思的地方: PlarPoint的<code>distFromOrigin2</code>无需重写，已经可以正常工作！这得益于ruby的<strong>dynamic dispatch</strong>: 用subclass的对象调用superclass的方法时，将优先动态dispatch到subclass的方法上。dynamic dispatch在其它语言中也叫做虚函数(virtual function)或延迟绑定(late bingding)，核心思路是基于对象的方法调用，总是优先从对象实际所属类(动态)上动态查找，而不是方法所属类(静态)。</p>
<p>dynamic dispatch让代码复用更上了一个层次，比如你可能有一些GUI相关的基类，它已经实现绘图，缩放等操作，你在子类中只需要实现必要的形状信息，就可以基类的方法绘制定制图形，而无需自己再重写绘图相关操作。</p>
<h4 id="mutiple-inheritance"><a href="#mutiple-inheritance" class="headerlink" title="mutiple inheritance"></a>mutiple inheritance</h4><p>回到我们的ColorPoint，随着功能迭代，ColorPoint的颜色相关API越来越多，如加深/调色等，你可能希望将这部分代码单独抽象为一个Color类，以达成更好的代码复用。然后ColorPoint再从Color类和Point类继承，这就是多重继承。在OOP中，多重继承的名声不是太好，因为它有一些”哲学上的问题”无法达成统一: 当两个superclass有相同的字段和方法时，subclass应该如何继承？</p>
<p><img src="/assets/image/201905/mutiple-inheritance.png" alt=""></p>
<p>假如B和C有相同的属性和方法，那么有如下可能:</p>
<ol>
<li>D希望同时继承B和C的同名方法: 即D同时有B和C的能力，这是继承的本意，名字碰撞应该通过其它作用域来限制</li>
<li>D希望只继承B或C的方法: 比如B为ColorPoint，C为Point3D，D为ColorPoint3D，那么显然，D应该继承C的distFromOrigin方法</li>
<li>B,C相同的方法在A中也有，D想直接从A中继承…</li>
</ol>
<p>这就像在现实中，子女的长相可能随父亲，身高可能随母亲，脾气可能谁也不像。多重继承的这些问题很容易造成歧义和理解负担。Ruby选择不支持多重继承，但提供一个叫<strong>mixins</strong>的机制: 尝试通过include module的方式来消除对多重继承的需要。比如ColorPoint:</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">module</span> <span class="title">Color</span></span></span><br><span class="line">    <span class="keyword">attr_accessor</span> <span class="symbol">:color</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">darken</span></span></span><br><span class="line">        <span class="keyword">self</span>.color = <span class="string">&quot;dark &quot;</span> + <span class="keyword">self</span>.color</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ColorPoint</span> &lt; Point</span></span><br><span class="line">    <span class="keyword">include</span> Color</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>module和class的主要区别在于它不能实例化对象且不能派生子类，它可以有属性，但用得更多地场景是它只提供方法，然后引用一些它本身未定义的方法交给子类去实现(当然，这里又要用到dynamic dispatch)，比如Ruby的<strong>Enumerable</strong>模块:</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyRange</span></span></span><br><span class="line">    <span class="keyword">include</span> Enumerable</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initialize</span><span class="params">(low,high)</span></span></span><br><span class="line">        <span class="variable">@low</span> = low</span><br><span class="line">        <span class="variable">@high</span> = high</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">each</span></span></span><br><span class="line">        i=@low</span><br><span class="line">        <span class="keyword">while</span> i &lt;= @high</span><br><span class="line">            <span class="keyword">yield</span> i</span><br><span class="line">            i=i+<span class="number">1</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>包含Enumerable的class只需要实现each方法，即可调用<code>MyRange.new(4,8).inject &#123;|x,y| x+y&#125;</code>，<code>MyRange.new(5,12).count &#123;|i| i.odd?&#125;</code>等方法。mixins通过更像组合(i can)而不是继承(i am)的方式来处理需要多重继承的情形。在方法查找(lookup)规则中，mixins优于subclass，后包含的module优于先包含的。</p>
<p>很多文章说mixins有多重继承的优点，同时也规避了多重继承的问题，我认为mixins的好处非常有限:</p>
<ol>
<li>module可以有属性，方法，除了不能实例对象，和普通superclass没有本质区别，也满足<code>is_a?</code>语义</li>
<li>module之间，module与superclass仍然有命名冲突的问题，只不过Ruby将lookup规则定死了</li>
<li>module可以include一个或多个module,这是换了种形式的多重继承</li>
</ol>
<p>总的来说，由于动态语言的duck typing特性，subclass主要是用在代码复用上，动态语言通常不关心某个对象是否是某个类(或其子类)的实例(<code>is_a?</code>)，它只关心某个对象有没有实现某个方法，对方法的查找是基于dynamic dispath的。</p>
<h3 id="oop-with-static-type"><a href="#oop-with-static-type" class="headerlink" title="oop with static type"></a>oop with static type</h3><p>聊完动态OOP语言，再来看看静态OOP语言，我们先抛开OOP，静态语言中所有的数据结构，函数参数/返回值都有静态类型，为了阐述方便，我们用伪代码表示某种虚拟的静态语言，它的描述格式为:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; distFromOrigin的参数为两个字段x(类型为double)和y(类型为double)的record(或者叫struct)</span><br><span class="line">fun distFromOrigin (p:&#123;x:double,y:double&#125;) double -&gt;</span><br><span class="line">    Math.sqrt(p.x*p.x + p.y*p.y)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 通过val声明变量pythag类型并赋值</span><br><span class="line">val pythag : &#123;x:double,y:double&#125; &#x3D; &#123;x&#x3D;3.0, y&#x3D;4.0&#125;</span><br><span class="line">&#x2F;&#x2F; 调用函数并接收返回值，由于pythag与distFromOrigin的参数类型一致，因此静态类型检查通过，函数调用成功</span><br><span class="line">val five : double &#x3D; distFromOrigin(pythag)</span><br><span class="line">&#x2F;&#x2F; 调用函数失败，静态类型检查(实参类型int，形参类型&#123;x:doule, y:double&#125;)，编译不通过</span><br><span class="line">val _ &#x3D; distFromOrigin(2)</span><br></pre></td></tr></table></figure>
<p>注意，在我们用于举例的语言中，record不只是数据结构的概念，它也可以包含function类型的字段，它可以推广到OOP中的Class。</p>
<h4 id="subtype"><a href="#subtype" class="headerlink" title="subtype"></a>subtype</h4><p>现在假设我们有个描述带颜色的点的record: <code>&#123;x:double, y:double, color:string&#125;</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">val cp : &#123;x:double,y:double,color:string&#125; &#x3D; &#123;x&#x3D;3.0, y&#x3D;4.0, color&#x3D;&quot;red&quot;&#125;</span><br><span class="line">&#x2F;&#x2F; 静态类型检查失败, &#123;x:double,y:double,color:string&#125; 与 &#123;x:double,y:double&#125; 类型不匹配</span><br><span class="line">var five : double &#x3D; distFromOrigin(cp)</span><br></pre></td></tr></table></figure>
<p>而事实上，我们是希望cp能够调用distFromOrigin函数的，因为多color字段既不影响函数计算过程(函数需要的字段都有)，也不影响逻辑上的正确性。因此在这里，为了达成更好地代码复用，我们需要静态类型检查做一些扩展: 如果recordA去掉或交换某些字段后变为recordB，那么能用recordB的地方都应该能用recordA。在这种情况下，我们称recordA是recordB的子类型(subtype，注意和子类subclass区分)，记 B &lt;: A。有了这个规则后，由于<code>&#123;x:double,y:double,color:string&#125;</code>是<code>&#123;x:double,y:double&#125;</code>的子类型，子类型实参可以匹配父类型形参，因此cp可使用distFromOrigin函数。</p>
<h4 id="depth-subtype"><a href="#depth-subtype" class="headerlink" title="depth subtype"></a>depth subtype</h4><p>现在考虑如下情况，即recordA的某个字段是recordB的某个字段的子类型，那么有recordA&lt;:recordB 吗？听起来是可以的，因为如果一个函数以recordB为形参，那么传入recordA，该函数需要的所有字段都能正确访问到。然而还要考虑到字段可变性:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fun setToOrigin (c:&#123;center:&#123;x:double,y:double&#125;, r:double&#125;) -&gt; </span><br><span class="line">    c.center &#x3D; &#123;x&#x3D;0.0, y&#x3D;0.0&#125;</span><br><span class="line">    </span><br><span class="line">val sphere:&#123;center:&#123;x:double,y:double,z:double&#125;, r:double&#125;) &#x3D; &#123;center&#x3D;&#123;x&#x3D;3.0,y&#x3D;4.0,z&#x3D;0.0&#125;, r&#x3D;1.0&#125;</span><br><span class="line"></span><br><span class="line">val _ &#x3D; setToOrigin(sphere)</span><br><span class="line">val _ &#x3D; sphere.center.z</span><br></pre></td></tr></table></figure>
<p>由于setToOrigin不会知道外部传入的supertype还有哪些额外字段，它对center的重置导致center.z字段丢失了，也就破坏了函数本来的语义。因此通常来说: type checker，field setter，depth subtype只能三选二。</p>
<p>那么实际的编程语言对depth subtype的取舍如何？以Array为例，假如我们有ColorPoint &lt;: Point，那么是否有ColorPoint[] &lt;: Point[]呢？在C++/Go中，是不支持depth subtype的，比如在Go中你不能将[]int实参用于[]interface{}形参(在Go中，interface{}相当于没有任何字段的record，它是任意类型的supertype)，因为函数可能将[]interface{}某个元素改为string类型。而在Java/C#中，却是支持的，比如在Java中，以下代码却能静态检查通过正常编译:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span> </span>&#123; ... &#125; <span class="comment">// has fields double x, y</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ColorPoint</span> <span class="keyword">extends</span> <span class="title">Point</span> </span>&#123; ... &#125; <span class="comment">// adds field String color</span></span><br><span class="line">...</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">m1</span><span class="params">(Point[] pt_arr)</span> </span>&#123;</span><br><span class="line">    pt_arr[<span class="number">0</span>] = <span class="keyword">new</span> Point(<span class="number">3</span>,<span class="number">4</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">String <span class="title">m2</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">    ColorPoint[] cpt_arr = <span class="keyword">new</span> ColorPoint[x];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; x; i++)</span><br><span class="line">        cpt_arr[i] = <span class="keyword">new</span> ColorPoint(<span class="number">0</span>,<span class="number">0</span>,<span class="string">&quot;green&quot;</span>);</span><br><span class="line">    m1(cpt_arr);</span><br><span class="line">    <span class="keyword">return</span> cpt_arr[<span class="number">0</span>].color;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是运行时执行m2函数，却会得到ArrayStoreException异常，因为Java/C#选择了可变性和depth subtype，放弃了type checker，放宽了类型检查的限制，它在运行时记录m1中<code>pt_arr</code>的真实类型(ColorPoint[])，并在执行类型不匹配的写入时，抛出异常。</p>
<h4 id="function-subtype"><a href="#function-subtype" class="headerlink" title="function subtype"></a>function subtype</h4><p>这里讨论当函数参数/返回值也是函数，那么这些作为参数的函数的subtype规则。假如我们有如下函数:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fun callWithOrigin(f: &#123;x:double,y:double&#125;-&gt;&#123;x:double,y:double&#125;) -&gt;</span><br><span class="line">    f(&#123;x:0.0,y:0.0&#125;)</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<p>callWithOrigin的参数类型为<code>&#123;x:double,y:double&#125;-&gt;&#123;x:double,y:double&#125;</code>，现在我们来考虑哪些函数实参允许调用callWithOrigin:</p>
<ul>
<li><code>&#123;x:double,y:double&#125; -&gt; &#123;x:double,y:double&#125;</code>: ok, 类型完全匹配</li>
<li><code>&#123;x:double,y:double&#125; -&gt; &#123;x:double,y:double,color:string&#125;</code>: ok, callWithOrigin传入f的函数参数匹配，只不过返回的参数多了个color，callWithOrigin可以正常调用和使用f，只不过它不关心返回的color字段</li>
<li><code>&#123;x:double,y:double&#125; -&gt; &#123;x:double&#125;</code>: error, callWithOrigin可能用到f返回值中的y字段</li>
<li><code>&#123;x:double,y:double,z:double&#125; -&gt; &#123;x:double,y:double&#125;</code>: error, callWithOrigin传给f的参数不包含z字段，那么f执行过程就会出错</li>
<li><code>&#123;x:double&#125; -&gt; &#123;x:double,y:double&#125;</code>: ok, callWithOrigin传给f函数的参数包括x,y字段，只是f函数只用到了x，f函数可以正常执行</li>
<li><code>&#123;x:double&#125; -&gt; &#123;x:double,y:double,z:double&#125;</code>: ok，由前面的分析可知，实参函数(即subtype function)参数字段不能多，返回值字段不能少。</li>
</ul>
<p>因此，有如下结论，对于 t3 &lt;: t1 并且 t2 &lt;: t4, 有 t1-&gt;t2 &lt;: t3-&gt;t4。</p>
<h4 id="subtype-vs-subclass"><a href="#subtype-vs-subclass" class="headerlink" title="subtype vs subclass"></a>subtype vs subclass</h4><p>我们在讨论Ruby时用的subclass(子类)，而在讨论静态OOP语言时用的是subtype(子类型)，因为它们本质上不是一个东西:</p>
<ul>
<li>class定义对象的全部行为，subclass是通过继承来解决class与class之间<strong>代码复用</strong>的问题，子类可以通过重写(override)或扩展(extension)来完善自己的行为</li>
<li>type关注对象的部分对外接口(字段or方法)，subtype用于定义类型之间<strong>可替换关系</strong>，关注type checker和语义复用</li>
</ul>
<p>Ruby是动态语言，它有更为灵活的duck typing，因此不需要subtype。对静态语言而言，subtype不一定要通过subclass来实现，理论上你可以有两个完全不相关的类A和B，但他们提供一致的方法，然后你可以声明A是B的subtype。然后任何用B的地方都可以用A。subtype不care这些方法是通过继承得来的还是独立实现的。</p>
<p>但在大多数静态OOP语言，如Java/C#/C++中，type和class的边界很模糊，绝大多数时候，你可以认为它们是一个东西，这是因为这些语言主要依赖subclass来实现subtype，因此当你创建一个class时，相当于创建了一个type，它的名字和class名字一样，当你声明subclass关系时，也声明了subtype关系。</p>
<p>另一点是我们在虚拟语言中以record作为对象的type，这个record可以包含字段，方法等，然后这个record的字段还可以修改，而实际上大多数静态OOP语言中，方法字段是不能修改的，比如你不能拿到一个对象，然后修改它的某个方法，因为方法实现是属于类而不是对象的。</p>
<p>理解了以上两点，我们就能将虚拟语言与现实世界的OOP语言映射起来了，如C++:</p>
<ol>
<li>type和class大部分时候是一个东西，声明一个class也就声明了一个type</li>
<li>subclass可以基于superclass之上添加字段/方法但是不能移除已有字段/方法</li>
<li>subclass可以override superclass的方法</li>
</ol>
<p>为了阐述方便，以下探讨C++/Java这类主流编程语言时，不再严格区分subclass和subtype的概念。</p>
<h4 id="dynamic-dispath"><a href="#dynamic-dispath" class="headerlink" title="dynamic dispath"></a>dynamic dispath</h4><p>这里我们进一步讨论静态OOP语言中的dynamic dispatch和this指针，以C++为例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Point &#123;&#125;; &#x2F;&#x2F; include double x, y field</span><br><span class="line">class ColorPoint: public Point &#123;...&#125;; &#x2F;&#x2F; adds string color field</span><br><span class="line"></span><br><span class="line">class B &#123;</span><br><span class="line">public:</span><br><span class="line">    virtual void showX(Point* p) &#123; cout &lt;&lt; &quot;B showX: &quot; &lt;&lt; p-&gt;x &lt;&lt; endl; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class D: public B &#123;</span><br><span class="line">public:</span><br><span class="line">    virtual void showX(Point* p) &#123; cout &lt;&lt; &quot;D showX: &quot; &lt;&lt; p-&gt;x &lt;&lt; endl; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">int main(void)&#123;</span><br><span class="line">     Point* p &#x3D; new Point(1.0,2.0);</span><br><span class="line">     ColorPoint* cp &#x3D;  new ColorPoint(3.0,4.0,&quot;red&quot;);</span><br><span class="line">     D* d &#x3D; new D();</span><br><span class="line">     d-&gt;showX(p);   &#x2F;&#x2F; D showX: 1  原生调用，不涉及subtype转换</span><br><span class="line">     d-&gt;showX(cp);  &#x2F;&#x2F; D showX: 3  ColorPoint作为Point的subtype，可以替换Point参数</span><br><span class="line">     B* b &#x3D; d;      &#x2F;&#x2F; 将subtype D对象转换为supertype B</span><br><span class="line">     b-&gt;showX(cp);  &#x2F;&#x2F; D showX: 3, dynamic dispath，以对象实际类型(D*)而不是当前类型(B*)来查找方法实现</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面定义了四个类，ColorPoint是Point的subtype，D是B的subtype。以下是一些你需要注意的点:</p>
<ol>
<li>如果D是B的subtype,那么D*也是B*的subtype</li>
<li>C++中的dynamic dispatch不是默认开启的，而是通过为指定方法<code>virtual</code>关键字手动开启的</li>
<li>对象d上调用showX(声明为virtual)方法，总能找到其对应类D的showX实现，而不管d是否被转换为supertype B*</li>
</ol>
<p>现在来考虑一个问题，如果B的showX函数声明为<code>virtual void showX(ColorPoint* p)</code>，实现不变，那么上面的<code>b-&gt;showX(cp)</code>会输出什么？答案是<code>B showX: 3</code>。熟悉C++的同学会知道这是因为C++支持重载，编译认识的函数符号是如<code>_showX_Point_</code>这种编码了参数类型的，修改函数参数类型后，将被编译器认为是另一个函数，而非override。但有一门不支持重载的静态OOP语言L，这个修改能够正常的dynamic dispatch吗？我的理解是可以的，传递给<code>B::showX</code>的ColorPoint总能被<code>D::showX</code>正确使用(<code>D:::showX</code>&lt;:<code>B::showX</code>)，这是因为静态OOP语言中的对象不能修改方法(方法属于类)，只能修改字段，也就是在前面说的depth subtype中，舍弃了mehotd field setter，得到method field depth subtyping。</p>
<p>然后来看看this指针，对C++有一定理解的同学通常将this指针看做类方法的一个隐藏参数，它由编译器自动传入。这种看法确实能更好地理解OOP，将类方法与普通函数统一起来。但有了subtype这个概念，再来看showX方法，B和D的showX方法类型分别为: <code>void showX(B* this, Point* p)</code> 以及 <code>void showX(D* this, Point* p)</code>，这里就出现一个很奇怪的现象，D的showX不再是B的showX的subtype,我只传给了showX B的对象，但可能调用到D的showX(需要D对象，而D对象包含比B对象更多的字段，可能引发未定义错误)。这是因为this参数是特殊处理的，虽然传给showX的实参只是B对象的地址，但它同时也是D对象的地址，编译器会透明地完成这层转换，保证D的showX拿到的是正确的D对象。这也是为什么多态要在指针下才能生效的原因(值拷贝只会拷贝值的静态类型对应内容，后面多余的派生类数据以及虚函数表信息会丢失)。</p>
<p>结合C++对象内存布局来回顾一下:</p>
<p><img src="/assets/image/201905/cpp-object-model.png" alt=""></p>
<ol>
<li>ColorPoint对象只会基于Point对象增加字段，本身是满足subtype语义的</li>
<li>ColorPoint向后追加新增字段，而不会变更基类对象的内存布局，这样可以让对象地址转换更轻量(不必做任何额外操作)</li>
<li>vtable指针会在对象创建时即初始化好，不管该对象地址被转换为何种类型，vtable总是指向对象实际类型的虚函数实现(如果没实现，则指向父类该函数)</li>
</ol>
<p>如果我们省掉vtable这些细节，将这个对象模型扩展一下，结合function depth subtype，它应该是这样:</p>
<p><img src="/assets/image/201905/static-object-model.png" alt=""></p>
<h4 id="mutiple-inheritance-1"><a href="#mutiple-inheritance-1" class="headerlink" title="mutiple inheritance"></a>mutiple inheritance</h4><p>C++支持多重继承，为了解决多重继承的命名冲突和冗余数据的问题，它可以在subclass构造函数中指定要哪些字段用哪个superclass的。另外它提供一个叫虚继承(virtual interitance)的机制来解决菱形继承的数据冗余问题，即D继承自B,C，B,C有个共同父类A，那么C只会有一份继承自A的数据。</p>
<p>Java/C#不支持多重继承，它们的类只能有一个直接父类，但是可以实现多个接口(Interface)，Interface是一堆方法的集合，它没有任何实现，当然也不能实例化。相比Ruby的mixins这种”实现继承”言，这种”声明继承”更安全，因为Interface没有任何的字段，即使方法声明有冲突，子类也只需要提供一份实现，并以此为准，没有歧义。</p>
<p>C++还提供纯虚函数的概念，即方法本身只包含声明，没有实现，在Java中的抽象方法也提供类似的机制，包含抽象方法或纯虚函数的类就和Ruby中的mixins很像，它既可包含声明，也可包含实现，并且不能实例化对象。当类中的所有方法都为抽象方法并且不包含任何字段时，这个类也就变成了Interface。</p>
<h4 id="generics"><a href="#generics" class="headerlink" title="generics"></a>generics</h4><p>前面我们所说的<strong>subtyping(子类化)</strong>，也叫做 <strong>subtype polymorphism(子类型多态)</strong> ，而另一种静态语言中常见的用于放宽type checker，提高灵活性和复用性的方案叫 <strong>parametric polymorphism(参数多态)</strong> ，也叫做<strong>generics(泛型)</strong> ，generics是很多静态语言都要考虑的一个特性，不只是OOP。比如ML就有强大的类型推导，可以实现很灵活的泛型编程。</p>
<p>generics用在那些需要表述<strong>任何类型</strong>的地方，即不关心对象的实际类型，通常出现在容器结构和通用算法中，比如大名鼎鼎的C++ STL，它其实就是对泛型的极致运用，封装了各类常用的容器以及各种常用算法，比如如下是一个 STL 中的 reduce 实现:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">InputIt</span>, <span class="keyword">class</span> <span class="title">T</span>, <span class="keyword">class</span> <span class="title">BinaryOperation</span>&gt;</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="comment">// since C++20</span></span><br><span class="line"><span class="function">T <span class="title">accumulate</span><span class="params">(InputIt first, InputIt last, T init, BinaryOperation op)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (; first != last; ++first) &#123;</span><br><span class="line">        init = op(<span class="built_in">std</span>::move(init), *first); <span class="comment">// std::move since C++20</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> init;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这几行代码充分展示了STL的一些基础特性:</p>
<ol>
<li>通过迭代器抽象对容器元素的基本操作: 借鉴于函数式编程，上例的<code>InputIt</code>提供元素类型<code>T</code>的容器的操作(<code>++</code>,<code>!=</code>,<code>*</code>等)接口，容器本身并不出现在泛型中，它可以是任意Stack, List, Pair等提供了迭代器的标准甚至自定义容器</li>
<li>函数本身亦可泛型: 已经有函数是第一类对象的雏形，上例中的BinaryOperation既可是一个函数，也可是一个函数对象(重载了<code>()</code>的对象)，STL提供了很多函数对象，如加减乘除</li>
<li>大量的运算符重载: 双刃剑(方便vs隐晦)，主要是为了兼容C，比如迭代器<code>++</code>操作本身相当于<code>Next()</code></li>
<li>泛型声明本身不包含对class的任何约束说明: 依赖于编译时对泛型代码的生成来检查，并且运算符重载，隐式构造函数等特性让算法在理解和使用在有一些负担。这是个人认为还不够好的地方，对应的解决方案有: <strong>bounded generic types</strong>，下一节会提到</li>
</ol>
<p>C++/Java/C#都提供了泛型机制，但它们的实现方式有些区别，Java的实现方式是”类型擦除(Type Erasure)”，即在编译时将<code>List&lt;T&gt;</code>变为<code>List&lt;Object&gt;</code>，然后加上一些类型检查和类型提取转换，Java运行时没有关于泛型的任何信息，它只会看到Object(动态类型语言的思路)，这样最大的好处在于兼容性，即老的Java运行时也可以运行泛型代码，缺点是由于运行时不知道T的具体类型，因此无法对T进行诸如instanceof,new等操作。C#/C++的泛型则被称为”模板泛型”，即有运行时的支持，对使用者来说像是为每个类型T都生成了对应的ListT类，因此克服了Java这方面的缺点，是语义完整的。C++的template则更强大，它可以实现所谓的元编程，即在模板语法中可以使用分支(偏特化)，递归等特性达到图灵完全性，如你可以通过模板语法求斐波那契数列(写法和函数式语言类似)，并将运算结果或错误在编译器就吐出来，因此C++被戏称”两层语言”，一层是生成C++目标代码的函数式语言(使用模板语法)，另一层才是命令式语言(C++本身)。当然这并不是C++的初衷，这里不再展开。</p>
<p>Go目前没有对开发者提供泛型(据说Go2.0会加入泛型)，它的代码复用主要靠interface+reflect(额外运行时type check开销)或code generator(额外的复杂度和开发成本)来实现，它们只能解决很少一部分对泛型的需求，因此Go在这方面被广为诟病，比如知乎上<a href="https://www.zhihu.com/question/62991191">Go有什么泛型的实现方法？</a>的高票答案，相信大部分Gopher都深有体会:</p>
<p><img src="/assets/image/201905/go-generics.gif" alt=""></p>
<blockquote>
<blockquote>
<p>2022.1.22更新: <a href="https://wudaijun.com/2020/12/go-generics/">Go1.18中已经实现了泛型</a></p>
</blockquote>
</blockquote>
<h4 id="generics-vs-subtyping"><a href="#generics-vs-subtyping" class="headerlink" title="generics vs subtyping"></a>generics vs subtyping</h4><p>那么有了generics后，我们还需要subtyping么？比如前面的Pair类，如果使用subtype来完成:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LamePair</span> </span>&#123;</span><br><span class="line">    Object x;</span><br><span class="line">    Object y;</span><br><span class="line">    LamePair(Object _x, Object _y)&#123; x=_x; y=_y; &#125;</span><br><span class="line">    <span class="function">LamePair <span class="title">swap</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">new</span> LamePair(y,x); &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line">String s = (String)(<span class="keyword">new</span> LamePair(<span class="string">&quot;hi&quot;</span>,<span class="number">4</span>).y); <span class="comment">// error caught only at run-time</span></span><br></pre></td></tr></table></figure>
<p>由于在构建LamePair时，进行了向上转换(将传入的参数转换为共同的supertype Object)，因此这里实际会有类型信息丢失，当外部想要再次获取LamePair中的元素时，就不得不进行一次向下转换(downcast)，如<code>(String)e</code>，这类转换属于run-time check，即将一部分本应在静态类型检查时暴露的错误放到了运行时，这是有悖静态类型语言的初衷的。所有的对象都属于Object，将所有的方法参数返回值都声明为Object，这是动态类型语言的思路。</p>
<p>因此subtyping在某些场景下不能替换generics，那反过来呢，如果我们用C++的template来实现distFromOrigin2:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span> &#123;</span></span><br><span class="line">	<span class="keyword">float</span> x;</span><br><span class="line">	<span class="keyword">float</span> y;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="keyword">float</span> <span class="title">X</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123; <span class="keyword">return</span> x; &#125;</span><br><span class="line">	<span class="function"><span class="keyword">float</span> <span class="title">Y</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123; <span class="keyword">return</span> y; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ColorPoint</span> &#123;</span></span><br><span class="line">	<span class="keyword">float</span> x;</span><br><span class="line">	<span class="keyword">float</span> y;</span><br><span class="line">	<span class="built_in">string</span> color;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="keyword">float</span> <span class="title">X</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123; <span class="keyword">return</span> x; &#125;</span><br><span class="line">	<span class="function"><span class="keyword">float</span> <span class="title">Y</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123; <span class="keyword">return</span> y; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">distFromOrigin2</span><span class="params">(T b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sqrt</span>(b.X()*b.X() + b.Y()*b.Y());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，仍然是一种很蹩脚的写法，由于泛型函数本身对类型缺乏认识，通常需要一堆辅助函数(<code>X()</code>,<code>Y()</code>)来帮忙完成算法的运作，前面的STL accumulate中的迭代器类型参数也是这个作用，即便如此虽然<code>distFromOrigin2</code>复用了，但并没解决Point/ColorPoint的其它字段和方法的复用问题。当然，就本例而言，即便这里的ColorPoint是Point的subtype，C++ template额外生成的函数以及丢失的dynamic dispatch也提示着将distFromOrigin2实现为Point方法是更好的选择。</p>
<p>综上，subtype和generics各自有自己的适用情形，它们作用于不同维度。subtype是基于supertype上的操作复用，强调类与类的复用关系。而generics基于任意类型T，对T之上的容器封装(如Stack,List,Pair,Swap等)和算法复用(如Sort,Find,Reduce等)，强调类通用的扩展。从另一个角度来讲，subtype可以实现运行时多态(dynamic dispatch)，而generics则是编译期多态(编译期生成新的类/函数)。</p>
<p>事实上，Java/C#同时支持subtyping和generics，因此它们支持一种将两种结合的polymorphism: <strong>bounded generic types</strong>，核心思想是通过subtype来限制generics可接受的类型，想要鱼和熊掌兼得。比如:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bound</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">Point</span>&gt; </span></span><br><span class="line"><span class="class"></span>&#123; </span><br><span class="line">    <span class="keyword">private</span> T objRef; </span><br><span class="line">       </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Bound</span><span class="params">(T obj)</span></span>&#123; </span><br><span class="line">        <span class="keyword">this</span>.objRef = obj; </span><br><span class="line">    &#125; </span><br><span class="line">       </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">doRunTest</span><span class="params">()</span></span>&#123; </span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.objRef.distFromOrigin(); </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样，通过subtype让Bound对传入的T有一定的基本认知，可以调用Point的方法(无需外部传入)，通过generics让这些基于Point类之上的算法可复用。</p>
<h4 id="oop-in-golang"><a href="#oop-in-golang" class="headerlink" title="oop in golang"></a>oop in golang</h4><p>我将Go单独放到一节，因为它与我们熟知的C++/Java/C#/Ruby等OOP语言很不一样，它有一些创新的地方，用来解决那些困扰了OOP几十年的难题。</p>
<p>如果按照我们前面给出来的OOP定义，Go是OOP语言，或者说它可以实现OOP编程范式。但是Go没有继承(<code>is-a</code>)的概念，即没有subclass的概念，如果一门OOP语言没有subclass，那么我们会考虑两个问题: 1. Go如何实现class代码复用？2. Go如何实现subtype? 下面分别讨论这两个问题。</p>
<p>Go没有<code>is-a</code>的概念，它推崇<a href="https://en.wikipedia.org/wiki/Composition_over_inheritance">composition over inheritance principle</a>原则，即组合胜于继承，用<code>has-a</code>替代<code>is-a</code>:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> A <span class="keyword">struct</span> &#123;</span><br><span class="line">	Name <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(a *A)</span> <span class="title">Print</span><span class="params">()</span></span> &#123;</span><br><span class="line">	fmt.Println(<span class="string">&quot;Print A Name: &quot;</span>, a.Name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> B <span class="keyword">struct</span> &#123;</span><br><span class="line">	A</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *B)</span> <span class="title">Print</span><span class="params">()</span></span> &#123;</span><br><span class="line">	fmt.Println(<span class="string">&quot;Print B Name: &quot;</span>, b.Name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	a1 := A&#123;Name: <span class="string">&quot;Name A1&quot;</span>&#125;</span><br><span class="line">	b := &amp;B&#123;A: a1&#125;</span><br><span class="line">	a2 := A&#123;Name: <span class="string">&quot;Name A2&quot;</span>&#125;</span><br><span class="line">	b.A = a2</span><br><span class="line">	b.Print()   <span class="comment">// Print B Name:  Name A2</span></span><br><span class="line">	b.A.Print() <span class="comment">// Print A Name:  Name A2</span></span><br><span class="line">	<span class="comment">// a := (*A)(b) // cannot convert expression of type *B to type *A</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上代码展示了Go如何通过组合而非继承来实现代码复用，当B需要复用A的代码时，它将A声明为类的一个匿名字段，之后就可以通过B来访问A中的方法和字段，当然这里也需要一套名字查找规则: 1. 先查找B中有没有对应的方法和字段 2. 再从后往前查找B中的匿名字段有无该方法和字段。因此可以通过B调用A的方法实际上是编译器的语法糖，并不是dynamic dispatch，因为Go只能通过子类对象调用子类方法，而不能通过父类对象调用子类方法。事实上，Go的子类对象无法转换为父类对象，从实现上来说，它们就是组合关系，你可以动态将B中的A字段赋为其它A对象。当然，这里的”父类””子类”叫法是不严谨的，因为Go没有subclass。</p>
<p>解决了面向对象的代码复用问题，我们再来看Go如何实现subtype，Go的subtype不是通过subclass来实现的，而是通过Interface来实现的:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type Printer interface &#123;</span><br><span class="line">	Print()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func test(p Printer) &#123;</span><br><span class="line">	p.Print()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func test2(a *A) &#123;</span><br><span class="line">    a.Print()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">test(&amp;a1)</span><br><span class="line">test(b)</span><br><span class="line">test2(b) &#x2F;&#x2F; error: cannot use b (type *B) as type *A in argument to test2</span><br></pre></td></tr></table></figure>
<p>在Java/C#/Go中，都有Interface的概念，但Java/C#的接口实现是需要显式声明的(即类在定义时就知道自己实现了哪些接口)，但是Go的接口不需要显式声明implement，可以在运行时动态判断(实现细节参考<a href="https://wudaijun.com/2018/01/go-interface-implement/">这里</a>)，这个特性为程序提供了极大的灵活性。A,B并不知道自己实现了Printer接口，它在定义的时候甚至还没有出现Printer接口，或者只有个类似Ouputter之类的接口包含相同的方法，Interface将类如何定义和类如何被使用分离开，比如你只要实现了<code>Read(p []byte) (n int, err error)</code>方法，就实现了<code>io.Reader</code>接口，就可以使用<code>ioutil.Read/ReadAll</code>等lib API。</p>
<p>总结一下，Go通过组合加编译器的一些静态查找规则来实现代码复用，通过Interface来实现subtype，而如C++/Java/C#等语言用subclass来同时提供两种功能，因此导致类关系错综复杂，甚至一度被戏称COP(Class-oriented programing)而非OOP。虽然Interface实现的subtype不如subclass实现的subtype一样强大(Interface只是方法声明集合，而superclass还包含字段)，但Interface的灵活性远胜于需要显式指定的superclass，并且避免了OOP继承长久以来的痛点。</p>
<h3 id="dynamic-type-vs-static-type"><a href="#dynamic-type-vs-static-type" class="headerlink" title="dynamic type vs static type"></a>dynamic type vs static type</h3><p>简单来说，静态语言的设计宗旨是尽可能在静态检查中多做事情，通过静态检查来过滤大部分的类型错误，优点是程序运行更稳定，Debug也更容易，缺点是会一定程度限制代码设计的灵活性，因此通常需要subtype来在通过规则放宽type check的限制。</p>
<p>而动态语言的设计宗旨是优先支持更灵活的代码设计(如duck typing)，将type check放到了run-time，优点是程序更灵活，开发效率通常更高，但程序运行的稳定性会差一些，遇到问题的调试也要更复杂。毕竟没有静态类型检查，允许了更灵活的设计，也放行了很多类型错误。</p>
<h3 id="oop-vs-fp"><a href="#oop-vs-fp" class="headerlink" title="oop vs fp"></a>oop vs fp</h3><p>计算机业界有句古老的名言: “程序=数据结构+算法”。</p>
<p>OOP(Object-oriented programming)偏向数据结构，函数只是数据结构的行为(对象的方法)，通过class来封装对象，通过subclass来复用对象。OOP的终极奥义是: 一切皆对象，甚至对象的类也是对象。</p>
<p>FP(Functional programming)偏向算法(函数)，即函数为第一类值，数据只是函数的参数或者执行环境(闭包)。用闭包，柯里化，高阶函数等去完成函数的封装和复用。FP的终极奥义是: 一切皆函数，连数据也可以是函数。</p>
<p>举个例子，我们可以将数据结构和算法分为两个维度，做成一个表格:</p>
<p><img src="/assets/image/201905/data-func-grid.png" alt=""></p>
<p>表的行表示各种数据类型，列为对应的操作。每个编程语言必须要做的就是定义每种数据类型执行每种操作时的行为。</p>
<p>OOP的做法是按照各个行划分，定义各个数据结构的类，然后在类上面实现该类型所支持的各个方法。而FP的做法是按照各个列划分，定义各个函数，如toString，然后在函数中去区分各个数据类型并实现。</p>
<p>从这个角度来说，FP和OOP只是以不同的方式来组织你的代码，OOP按照数据来聚合，FP按照函数来聚合，如果使用OOP，那么添加数据类型很方便，你只需要在新定义的类中去实现它支持的操作，无需影响其它已有类。同理如果使用FP，则新添加一个函数很方便。</p>
<p>另一个比较有意思的点是，FP的二元操作要比OOP更直观，比如我们的add操作:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fun add (v1,v2) &#x3D;</span><br><span class="line">    case (v1,v2) of</span><br><span class="line">      (Int i, Int j) &#x3D;&gt; Int (i+j)</span><br><span class="line">    | (Int i, Point(x,y)) &#x3D;&gt; Point(x+i, y+i)</span><br><span class="line">    | (Point(x,y), Int i) &#x3D;&gt; add(v2, v1) &#x2F;&#x2F; 代码复用</span><br><span class="line">    | (Point(x1,y1), Point(x2,y2)) &#x3D;&gt; Point(x1+x2, y1+y2)</span><br></pre></td></tr></table></figure>
<p>在FP中，二元操作很直观，<code>add(Point, Int)</code>和<code>add(Int, Point)</code>可以复用，而在OOP中:</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Int</span></span></span><br><span class="line">    def add v</span><br><span class="line">        <span class="keyword">if</span> v.is_a? Int</span><br><span class="line">            addInt(v)</span><br><span class="line">        <span class="keyword">elsif</span> v.is_a? Point</span><br><span class="line">            addPoint(v)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addInt</span><span class="params">(v)</span></span></span><br><span class="line">        ...</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>上面的代码虽然也算直观，但有两个问题，一是代码复用不好，<code>Int.addPoint</code>和<code>Point.addInt</code>的实现其实是一样的，即使想要复用代码，只用一份实现，那这份实现应该放在Int类还是Point类呢？第二个问题是这里其实是将FP和OOP混着用，在OOP中，应该尽量避免通过运行时判断对象属于哪个类，纯正的OOP应该通过函数调用+dynamic dispatch来避免类型判断:</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Int</span></span></span><br><span class="line">    <span class="keyword">attr_reader</span> <span class="symbol">:i</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(v)</span></span> <span class="comment"># first dispatch</span></span><br><span class="line">        v.addInt(<span class="keyword">self</span>)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addInt</span><span class="params">(v)</span></span> <span class="comment"># second dispatch: v is Int</span></span><br><span class="line">        Int.new(v.i + i)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addPoint</span><span class="params">(v)</span></span> <span class="comment"># second dispatch: v is Point</span></span><br><span class="line">        Point.new(v.x+i, v.y+i)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span></span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(v)</span></span> <span class="comment"># first dispatch</span></span><br><span class="line">        v.addPoint(<span class="keyword">self</span>)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addInt</span><span class="params">(v)</span></span> ... <span class="keyword">end</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addPoint</span><span class="params">(v)</span></span> ... <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>现在虽然是纯正的OOP了，但实际上维护这些代码却很麻烦，假设我们增加一个String类型，它也可以参与add运算，那么除了定义String类型本身以外，我们还需要去已有所有类型中添加addString方法，在这种情况下，OOP增加一个数据类型也不那么方便了。</p>
<ol>
<li>静态OOP语言如C++/Java/C#可能会提供一种重载的机制，允许同一个方法名不同的类型参数，编译器会自动选择匹配的函数调用。这能够避免运行时的类型检查，也不用二次分发，但复用性和扩展性仍然不好。</li>
<li>在Java/C#中，可以通过Interface来声明所有的addInt/Point方法，让Int,Point实现这个接口，这样在添加String类型时，在Interface中添加addString方法，静态类型检查能够保证所有的子类都实现了addString</li>
</ol>
<p>PS: 这里只是从程序结构的角度对比FP和OOP，事实上FP的一些理念还来自于lamda演算和数学领域，因此大部分的FP语言还有不可变语义，纯函数等特性。</p>
<p>FP或OOP或其它的编程范式，本质上是以不同的方式对现实问题进行建模，不管是”一切皆函数”还是”一切皆对象”，都是理想化的解决方案。现实中可能没有编程语言完美实现了某一编程范式，更多地是借鉴和吸收，同时支持多种编程范式，毕竟语言是用来解决问题的。</p>
]]></content>
      <categories>
        <category>programing</category>
      </categories>
      <tags>
        <tag>programing</tag>
      </tags>
  </entry>
  <entry>
    <title>如何给GS做压测</title>
    <url>/2019/09/gs-pressure-test/</url>
    <content><![CDATA[<p>简单谈谈我们最近是如何给GS做压测的。</p>
<h3 id="1-压测机器人"><a href="#1-压测机器人" class="headerlink" title="1. 压测机器人"></a>1. 压测机器人</h3><p>压测机器人需要满足如下几个条件:</p>
<ol>
<li>异步请求: 异步才能模拟真实的客户端请求和压力</li>
<li>数据同步: 像客户端一样缓存和处理服务器响应数据，这样才能做好有效请求和可重入</li>
<li>可重入: 机器人应该可以在任何时候关闭/重启，而不应该假设初始状态(比如只有注册的时候能跑)</li>
<li>随机性: 机器人行为尽可能随机分布，并且每次重启重新初始化随机种子</li>
</ol>
<span id="more"></span>
<h3 id="2-压测用例"><a href="#2-压测用例" class="headerlink" title="2. 压测用例"></a>2. 压测用例</h3><p>压测用例可以从这几个方面来考虑:</p>
<ol>
<li>服务器比较耗时的API: 如寻路，战斗等</li>
<li>玩家越多越耗时的逻辑: 如视野同步，消息广播等</li>
<li>玩家日常操作频繁的行为: 如城建升级，联盟加入退出，以尽可能覆盖如任务，BUFF，排行榜等支撑系统</li>
</ol>
<h3 id="3-压测统计"><a href="#3-压测统计" class="headerlink" title="3. 压测统计"></a>3. 压测统计</h3><p>在做压测中，我们会从如下几个方面来获取性能指标:</p>
<ol>
<li>函数级分析: go prof简单易用，参考<a href="https://wudaijun.com/2018/04/go-pprof/">go pprof性能分析</a></li>
<li>消息级统计: 统计每个逻辑Actor(如地图，玩家)对单次请求的处理时间(最大/平均/次数)，消息是Actor之间交互的最小单位，每个消息处理过程是一条函数调用链</li>
<li>服务器请求统计: 统计每条客户端请求从网关层收到请求到网关层发出响应的时间差(最大/平均/次数)，相比消息级统计，服务器请求统计包含了多个Actor处理请求相关若干消息的时间，以及Actor之间的路由和通信开销</li>
<li>客户端请求统计: 统计从请求发出到收到响应的处理时间(最大/平均/次数)，相比服务器消息统计，多了网络层的时延和机器人本身的处理时间，这是最接近客户端实际体验的指标</li>
</ol>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊Go内存优化和相关底层机制</title>
    <url>/2019/09/go-performance-optimization/</url>
    <content><![CDATA[<p>最近做的优化比较多，整理下和Go内存相关的一些东西。</p>
<h2 id="一-不要过早优化"><a href="#一-不要过早优化" class="headerlink" title="一. 不要过早优化"></a>一. 不要过早优化</h2><p>虽是老生常谈，但确实需要在做性能优化的时候铭记在心，个人的体会:</p>
<ol>
<li>first make it work, then measure, then optimize</li>
<li>二八原则</li>
<li>需求变更快</li>
<li>对性能的主观直觉不靠谱</li>
</ol>
<span id="more"></span>
<h2 id="二-内存优化"><a href="#二-内存优化" class="headerlink" title="二. 内存优化"></a>二. 内存优化</h2><p>Golang运行时的内存分配算法主要源自 Google 为 C 语言开发的TCMalloc算法，全称Thread-Caching Malloc。核心思路是层级管理，以降低锁竞争开销。Golang内存管理大概分为三层，每个线程(GPM中的P)都会自行维护一个独立的内存池(mcache)，进行内存分配时优先从mcache中分配(无锁)，当mcache内存不足时才会向全局内存池(mcentral)申请(有锁)，当mcentral内存不足时再向全局堆空间管理(mheap)中申请(有锁+按照固定大小切割)，最后mheap如果不足，则向OS申请(SysCall)。mcache -&gt; mcentral -&gt; mheap -&gt; OS 代价逐层递增，Golang运行时的很多地方都有这种层级管理的思路，比如GPM调度模型中对G的分配，这种层级在并发运行时下，通常有比较好的性能表现。</p>
<p>以下讨论下内存优化(主要是优化分配和GC开销，而非内存占用大小)常用的手段。</p>
<h3 id="1-内存复用"><a href="#1-内存复用" class="headerlink" title="1. 内存复用"></a>1. 内存复用</h3><p>关于内存复用最常见的手段就是内存池了，它缓存已分配但不再使用的对象，在下次分配时进行复用，以避免频繁的对象分配。</p>
<h4 id="1-1-sync-Pool"><a href="#1-1-sync-Pool" class="headerlink" title="1.1 sync.Pool"></a>1.1 sync.Pool</h4><p>Go的<code>sync.Pool</code>包是Go官方提供的内存池，在使用sync.Pool时，需要注意:</p>
<ol>
<li>sync.Pool是goroutine safe的，并发控制会带来少部分开销(经过多级缓存已经无锁优化，这部分开销大部分时候都不用过多关注)</li>
<li>sync.Pool无法设置大小，所以理论上只受限于GC临界值大小</li>
<li>sync.Pool中的对象不支持自定义过期时间及策略，go1.13前sync.Pool中的对象会在GC开始前全部清除，在go1.13中有优化，会留一部分Object，相当于延缓了收缩扩张的速度</li>
</ol>
<p>sync.Pool适用于跨goroutine且需要动态伸缩的场景，典型的如网络层或日志层，每个连接(goroutine)都需要Pool，并且连接数是不稳定的。</p>
<h4 id="1-2-leakybuf"><a href="#1-2-leakybuf" class="headerlink" title="1.2 leakybuf"></a>1.2 leakybuf</h4><p>有时为了达成更轻量，更可控的复用，我们可能会根据应用场景自己造轮子，比如实现一个固定大小，不会被GC的内存池。比如shadowsocks-go的<a href="https://github.com/shadowsocks/shadowsocks-go/blob/master/shadowsocks/leakybuf.go">LeakyBuf</a>就用channel巧妙实现了个[]byte Pool。</p>
<p>leakybuf这类Pool相较于sync.Pool的主要优势是不会被GC，但缺点是少了收缩性，设置大了浪费内存，设置小了复用作用不明显。因此它适用于能够提前预估池子大小的场景，在实践中，我们将其用在DB序列化层，其Worker数量固定，单个[]byte较大，也相对稳定。</p>
<h4 id="1-3-逻辑对象复用"><a href="#1-3-逻辑对象复用" class="headerlink" title="1.3 逻辑对象复用"></a>1.3 逻辑对象复用</h4><p>复用的粒度不仅限于简单struct或slice，也可以是逻辑实体。比如我们游戏中每次生成地图NPC时，会根据配置初始化大量的属性和BUFF，涉及到很多小对象的分配，这里我们选择将整个NPC作为复用粒度，在NPC倒计时结束或被击败消失时，将NPC整理缓存在池子中，并重置其战斗状态和刷新时间。这种逻辑实体的复用不通用但往往有用，必要的时候可以派上用场。</p>
<h4 id="1-4-原地复用"><a href="#1-4-原地复用" class="headerlink" title="1.4. 原地复用"></a>1.4. 原地复用</h4><p>除了内存池这种”有借有还”的复用外，另一种常用的内存复用思路是就地复用，它主要用于切片这类容易重置的数据结构，比如下面是一个过滤切片中所有奇数的操作:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">s := []<span class="keyword">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;</span><br><span class="line">ret := s[:<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i:=<span class="number">0</span>; i&lt;<span class="built_in">len</span>(s); i++ &#123;</span><br><span class="line">    <span class="keyword">if</span> s[i] &amp; <span class="number">1</span> == <span class="number">1</span>&#123;</span><br><span class="line">        ret = <span class="built_in">append</span>(ret, s[i])</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另一个”黑科技”操作是[]byte to string:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">bs := <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">1000</span>)</span><br><span class="line"><span class="comment">// 175 ns/op 底层会拷贝bs，保证string的字符常量语义</span></span><br><span class="line">ss2 = <span class="keyword">string</span>(bs)</span><br><span class="line"><span class="comment">// 2.48 ns/op 直接地址转换，慎用，破坏了string的字符常量语义，更改bs将影响到ss1 ！</span></span><br><span class="line">ss1 = *(*<span class="keyword">string</span>)(unsafe.Pointer(&amp;bs))</span><br></pre></td></tr></table></figure>
<p>切片的这类技巧经常用在网络层和算法层，有时候也能起到不错的效果。</p>
<h3 id="2-预分配"><a href="#2-预分配" class="headerlink" title="2. 预分配"></a>2. 预分配</h3><p>预分配主要针对map, slice这类数据结构，当你知道它要分配多大内存时，就提前分配，一是为了避免多次内存分配，二是为了减少space grow带来的数据迁移(map evacuate or slice copy)开销。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">n := <span class="number">10</span></span><br><span class="line">src := <span class="built_in">make</span>([]<span class="keyword">int</span>, n)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 无预分配: 162 ns/op</span></span><br><span class="line"><span class="keyword">var</span> dst []<span class="keyword">int</span></span><br><span class="line"><span class="keyword">for</span> i:=<span class="number">0</span>; i&lt;n; i++ &#123;</span><br><span class="line">	dst = <span class="built_in">append</span>(dst, src[i])</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 预分配，32.3 ns/op，提升了5倍</span></span><br><span class="line">dst2 := <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">0</span>, n)</span><br><span class="line"><span class="keyword">for</span> i:=<span class="number">0</span>; i&lt;n; i++ &#123;</span><br><span class="line">	dst2 = <span class="built_in">append</span>(dst2, src[i])</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 预分配+append...: 30.1 ns/op</span></span><br><span class="line">dst2 = <span class="built_in">append</span>(dst2, src...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 预分配+copy: 26.0 ns/op</span></span><br><span class="line"><span class="built_in">copy</span>(dst2, src)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>可以看到，slice预分配对性能的提升是非常大的，这里为了简单起见，以纯粹的拷贝切片为例，而对于切片拷贝，应该使用go专门为优化slice拷贝提供的内置函数copy，如果抛开分配dst2的开销，<code>copy(dst2, src)</code>的运算速度达到0.311ns，是<code>append(dst, src...)</code>的20倍左右！</p>
<p>平时编码中养成预分配的习惯是有利而无害的，Go的一些代码分析工具如<a href="https://github.com/alexkohler/prealloc">prealloc</a>可以帮助你检查可做的预分配优化。</p>
<p>有时候预分配的大小不一定是精确的，也可能模糊的，比如要将一个数组中所有的偶数选出来，那么可以预分配1/2的容量，在不是特别好估算大小的情况下，尽可能保守分配。</p>
<p>预分配的另一个思路就是对于一些频繁生成的大对象，比如我们逻辑中打包地图实体，这是个很大的pb协议，pb默认生成的内嵌消息字段全是指针，给指针赋值的过程中为了保证深拷贝语义需要频繁地分配这些各级字段的内存，为了优化分配内存次数，我们使用<a href="https://github.com/gogo/protobuf">gogoproto</a>的nullable生成器选项来对这类消息生成嵌套的值字段而非指针字段，这样可以减少内存分配次数(但分配的数量是一样的)。</p>
<h3 id="3-避免不必要的分配"><a href="#3-避免不必要的分配" class="headerlink" title="3. 避免不必要的分配"></a>3. 避免不必要的分配</h3><p>Go的逃逸分析+GC会让Gopher对指针很青睐，receiver，struct field, arguments, return value等，却容易忽略背后的开销(当然，大部分时候开发者确实不需要操心)。</p>
<h4 id="3-1-减少返回值逃逸"><a href="#3-1-减少返回值逃逸" class="headerlink" title="3.1 减少返回值逃逸"></a>3.1 减少返回值逃逸</h4><p>为了避免引用必要的时候也可以化切片为数组:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建并返回了一个切片，切片是引用语义，导致ret逃逸</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetNineGrid1</span><span class="params">()</span> []<span class="title">int</span></span> &#123;</span><br><span class="line">	ret := <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">9</span>)</span><br><span class="line">	<span class="keyword">return</span> ret</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建了一个数组但返回了它的切片(相当于它的引用)，导致数组逃逸</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetNineGrid2</span><span class="params">()</span> []<span class="title">int</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> ret [<span class="number">9</span>]<span class="keyword">int</span></span><br><span class="line">	<span class="keyword">return</span> ret[:]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建并返回数组，数组是值语义，因此不会逃逸</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetNineGrid3</span><span class="params">()</span> [9]<span class="title">int</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> [<span class="number">9</span>]<span class="keyword">int</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这还不够，有时候还需要对计算流程进行优化:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Coord <span class="keyword">struct</span>&#123;</span><br><span class="line">	X   <span class="keyword">int32</span></span><br><span class="line">	Z   <span class="keyword">int32</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f1</span><span class="params">(c *Coord)</span> *<span class="title">Coord</span></span> &#123;</span><br><span class="line">	ret := Coord&#123;</span><br><span class="line">		X: 	c.X/<span class="number">2</span>,</span><br><span class="line">		Z: 	c.Z/<span class="number">2</span>,</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> &amp;ret</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f2</span><span class="params">()</span> <span class="title">int32</span></span> &#123;</span><br><span class="line">	c := &amp;Coord&#123;</span><br><span class="line">		X: <span class="number">2</span>,</span><br><span class="line">		Z: <span class="number">4</span>,</span><br><span class="line">	&#125;</span><br><span class="line">	c2 := f1(c)</span><br><span class="line">	<span class="keyword">return</span> c2.X</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 优化后</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">new_f1</span><span class="params">(c *Coord, ret *Coord)</span></span> &#123;</span><br><span class="line">	ret.X = c.X/<span class="number">2</span>,</span><br><span class="line">	ret.Z = c.Z/<span class="number">2</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">new_f2</span><span class="params">()</span> <span class="title">int32</span></span> &#123;</span><br><span class="line">    c := &amp;Coord&#123;</span><br><span class="line">        X:  <span class="number">2</span>,</span><br><span class="line">        Z:  <span class="number">4</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    ret := &amp;Coord&#123;&#125;</span><br><span class="line">    new_f1(c, ret)</span><br><span class="line">    <span class="keyword">return</span> ret.X</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上面的代码中，Go编译器会分析到f1的变量ret地址会返回，因此它不能分配在栈在(调用完成后，栈就回收了)，必须分配在堆上，这就是逃逸分析(escape analyze)。而对于f2中的变量c来说，虽然函数中用了c的地址，但都是用于其调用的子函数(此时f1的栈还有效)，并未返回或传到函数栈有效域外，因此f2中的c会分配到栈上。</p>
<p>在默认编译参数下，f1的ret并不会逃逸，这是因为f1会被内联的，f1的调用并不会有新的函数栈的扩展和收缩，都会在f2的函数栈上进行，由于f2中的变量都没有逃逸到f2之外，因此对f2的调用也不会有任何内存分配，可以通过<code>-gcflags -N -l</code>编译选项来禁用内联，并通过<code>-gcflags -m</code>打印逃逸分析信息。但内联也是有条件的(函数足够简单，不涉及Interface)，我们将在后面再聊到内联。</p>
<h4 id="3-2-化指针为值"><a href="#3-2-化指针为值" class="headerlink" title="3.2 化指针为值"></a>3.2 化指针为值</h4><p>可以将使用频繁并且简单的结构体比如前面的地图坐标Coord，使用值而不是指针，这样可以减少不必要的变量逃逸带来的GC开销。</p>
<h4 id="3-3-字符串操作优化"><a href="#3-3-字符串操作优化" class="headerlink" title="3.3 字符串操作优化"></a>3.3 字符串操作优化</h4><p>以下是一个简单的测试，并注有其benchmark性能数据:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1834 ns/op	     880 B/op	      29 allocs/op</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stringSprintf</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> s <span class="keyword">string</span></span><br><span class="line">	v := <span class="string">&quot;benmark&quot;</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">		s = fmt.Sprintf(<span class="string">&quot;%s[%s]&quot;</span>, s, v)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> s</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 616 ns/op	     576 B/op	      10 allocs/op</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stringPlus</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> s <span class="keyword">string</span></span><br><span class="line">	v := <span class="string">&quot;benmark&quot;</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">		s = s + <span class="string">&quot;[&quot;</span> + v + <span class="string">&quot;]&quot;</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> s</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 395 ns/op	     304 B/op	       3 allocs/op</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stringBuffer</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> buffer bytes.Buffer</span><br><span class="line">	v := <span class="string">&quot;benmark&quot;</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">		buffer.WriteString(<span class="string">&quot;[&quot;</span>)</span><br><span class="line">		buffer.WriteString(v)</span><br><span class="line">		buffer.WriteString(<span class="string">&quot;]&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> buffer.String()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 218 ns/op	     248 B/op	       5 allocs/op</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stringBuilder</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> builder strings.Builder</span><br><span class="line">	v := <span class="string">&quot;benmark&quot;</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">		builder.WriteString(<span class="string">&quot;[&quot;</span>)</span><br><span class="line">		builder.WriteString(v)</span><br><span class="line">		builder.WriteString(<span class="string">&quot;]&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> builder.String()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>导致内存分配差异如此大的主要原因是string是常量语义，每次在构造新的string时，都会将之前string的底层[]byte拷贝一次，在执行多次string拼接时，<code>strings.Builder</code>和<code>bytes.Buffer</code>会缓存中间生成的[]byte，直到真正需要string结果时再调用它们的<code>String()</code>返回，避免了生成不必要的string中间结果，因此在多次拼接字符串的场景，<code>strings.Builder</code>和<code>bytes.Buffer</code>是更好的选择。</p>
<p>简单总结下:</p>
<ul>
<li><code>fmt.Sprintf</code>: 适用于将其它类型格式化为字符串，灵活性高，但由于逃逸会导致大量的内存分配(后面讲逃逸会再次提到)</li>
<li><code>+</code>: 适用于少量的的常量字符串拼接，易读性高</li>
<li><code>bytes.Buffer</code>: 有比slice默认更激进的cap分配，它的<code>String()</code>方法需要拷贝。适用于大量的字符串的二进制拼接，如网络层。</li>
<li><code>strings.Builder</code>: 底层使用slice默认cap分配，主要的优点是调用<code>String()</code>不需要拷贝(直接地址转换)，适用于要求输出结果是string的地方</li>
</ul>
<h2 id="三-逃逸和内联"><a href="#三-逃逸和内联" class="headerlink" title="三 逃逸和内联"></a>三 逃逸和内联</h2><h3 id="1-逃逸分析"><a href="#1-逃逸分析" class="headerlink" title="1. 逃逸分析"></a>1. 逃逸分析</h3><p>前面简单提了下逃逸分析，这里我们再深入讨论下，逃逸分析虽然好用，却并不免费，只有理解其内部机制，才能将收益最大化(开发效率vs运行效率)。逃逸分析的本质是当编译器发现函数变量将脱离函数栈有效域或被函数栈有效域外的变量所引用时时，将变量分配在堆上而不是栈在。也可以用两个不变性约束来描述:</p>
<ol>
<li>指向栈对象的指针不能存放在堆中</li>
<li>指向栈对象的指针的生命周期不能超过该栈对象</li>
</ol>
<p>典型导致逃逸的情形有:</p>
<ol>
<li>函数返回变量地址，或返回包含变量地址的struct，刚才已经讨论过</li>
<li>将变量地址写入channel或sync.Pool，编译器无法获悉其它goroutine如何使用这个变量，也就无法在编译时决议变量的生命周期</li>
<li>闭包也可能导致闭包上下文逃逸</li>
<li>将变量地址赋给可扩容容器(如map,slice)时，slice/map超过cap重新分配时，将在堆上进行，栈的大小毕竟是固定和有限的</li>
<li>涉及到Interface的很多逃逸优化都比较保守，如<code>reflect.ValueOf(x)</code>会显式调用<code>escapes(x)</code>导致x逃逸</li>
</ol>
<p>第4点和第5点单独说下，以slice和空接口为例:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">example</span><span class="params">()</span></span> &#123;</span><br><span class="line">	s1 := <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">10</span>)</span><br><span class="line">	s2 := <span class="built_in">make</span>([]*<span class="keyword">int</span>, <span class="number">10</span>)</span><br><span class="line">	s3 := <span class="built_in">make</span>([]<span class="keyword">interface</span>&#123;&#125;, <span class="number">10</span>)</span><br><span class="line">	a, b, c, d := <span class="number">456</span>, <span class="number">456</span>, <span class="number">456</span>, <span class="number">456</span></span><br><span class="line">	e := <span class="number">123</span></span><br><span class="line">	f := <span class="keyword">struct</span>&#123;X <span class="keyword">int</span>; Z <span class="keyword">int</span>&#125;&#123;&#125;</span><br><span class="line">	<span class="comment">// 值语义slice, a将分配在栈上</span></span><br><span class="line">	s1[<span class="number">1</span>] = a</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 引用语义slice, 引用b的地址，b将分配在堆上</span></span><br><span class="line">	s2[<span class="number">2</span>] = &amp;b</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 引用语义slice, 引用c的值，c将分配在栈上，但s3[3]对应interface&#123;&#125;中的data会分配一个int的空间，然后将c值赋给该堆内存</span></span><br><span class="line">	s3[<span class="number">3</span>] = c</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 引用语义slice，引用d的地址，d将分配在堆上，s3[4]对应interface&#123;&#125;的data值即为d的地址</span></span><br><span class="line">	s3[<span class="number">4</span>] = &amp;d</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 引用语义slice，引用e的值，e同样将分配在栈上，但s3[5]本身也不再分配int堆内存(go1.15专门为0~255的小整数转interface作了[staticuint64s预分配优化](https://github.com/golang/go/blob/dev.boringcrypto.go1.15/src/runtime/iface.go#L532))</span></span><br><span class="line">	s3[<span class="number">5</span>] = e</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 引用语义slice，引用f的值，f将分配在栈上，s3[6]对应interface&#123;&#125;的data会分配一个新的16B的空间，并拷贝f的值</span></span><br><span class="line">	s3[<span class="number">6</span>] = f</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 通过println打印不会导致逃逸</span></span><br><span class="line">	<span class="built_in">println</span>(&amp;a, &amp;b, &amp;c, &amp;d, &amp;e, &amp;f, s3[<span class="number">3</span>], s3[<span class="number">4</span>])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于栈空间是在编译期确定的，slice重分配只能发生在堆上。目前golang逃逸分析还不能完全分析slice的生命周期和扩容可能性，它会保守地保证slice元素只能指向堆内存(否则重分配后，浅拷贝会导致堆内存引用了栈内存)，因此可能会发生逃逸。</p>
<p>当slice元素为interface时，情况和s2类似，interface{}本质为引用语义，即为typ + pointer，这个pointer指向实际的data，参考我之前写的<a href="https://wudaijun.com/2018/01/go-interface-implement/">go interface实现</a>。interface的pointer总是指针(不会类似Erlang Term一样对立即数进行优化，就地存储)，因此执行<code>s3[3] = c</code>时，本质会新分配一个对应空间，然后拷贝值，最后让pointer指向它。不让这个int值直接逃逸的原因是，执行该赋值后，本质上c和s3[3]是相互独立的，s3[3]为一个只读的int，而c的值是可以随时变化的，不应该相互影响，因此不能直接引用c的地址。虽然没有立即数优化，但是Go1.15之后，对小整数转interface{}进行了优化，也算聊胜于无。</p>
<p>Go官方一直在做interface逃逸相关的优化:</p>
<p>Go1.10开始提出的<a href="https://github.com/golang/go/issues/19361">devirtualization</a>，编译器在能够知晓Interface具体对象的情况下(如<code>var i Iface = &amp;myStruct&#123;&#125;</code>)，可以直接生成对象相关代码调用(通过插入类型断言)，而无需走Interface方法查找，同时助力逃逸分析。devirtualization还在不断完善(最初会导致receiver和参数逃逸，<a href="https://github.com/golang/go/issues/33160#issuecomment-512653356">这里</a>有讨论，该问题2020年底已经在Go1.16中<a href="https://go-review.googlesource.com/c/go/+/264837/5">Fix</a>)。</p>
<p>Go1.15的<a href="https://github.com/golang/go/blob/dev.boringcrypto.go1.15/src/runtime/iface.go#L532">staticuint64s预分配优化</a>避免了小整数转换为interface{}的内存分配。目前Go的逃逸分析策略还相对保守，比如前面代码的s2，既slice变量本身没有逃逸，也没有发生扩容，那么让slice以及其元素都在栈上应该是安全的。当然，好的逃逸分析需要在编译期更深入地理解程序，这本身也是在保证安全的前提下循序渐进的。</p>
<p>整体来说，目前的逃逸分析还在逐渐完善，还远没到真正成熟的地步，比如strings.Builder的源码:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; noescape hides a pointer from escape analysis.  noescape is</span><br><span class="line">&#x2F;&#x2F; the identity function but escape analysis doesn&#39;t think the</span><br><span class="line">&#x2F;&#x2F; output depends on the input. noescape is inlined and currently</span><br><span class="line">&#x2F;&#x2F; compiles down to zero instructions.</span><br><span class="line">&#x2F;&#x2F; USE CAREFULLY!</span><br><span class="line">&#x2F;&#x2F; This was copied from the runtime; see issues 23382 and 7921.</span><br><span class="line">&#x2F;&#x2F;go:nosplit</span><br><span class="line">&#x2F;&#x2F;go:nocheckptr</span><br><span class="line">func noescape(p unsafe.Pointer) unsafe.Pointer &#123;</span><br><span class="line">	x :&#x3D; uintptr(p)</span><br><span class="line">	return unsafe.Pointer(x ^ 0)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (b *Builder) copyCheck() &#123;</span><br><span class="line">	if b.addr &#x3D;&#x3D; nil &#123;</span><br><span class="line">		&#x2F;&#x2F; This hack works around a failing of Go&#39;s escape analysis</span><br><span class="line">		&#x2F;&#x2F; that was causing b to escape and be heap allocated.</span><br><span class="line">		&#x2F;&#x2F; See issue 23382.</span><br><span class="line">		&#x2F;&#x2F; TODO: once issue 7921 is fixed, this should be reverted to</span><br><span class="line">		&#x2F;&#x2F; just &quot;b.addr &#x3D; b&quot;.</span><br><span class="line">		b.addr &#x3D; (*Builder)(noescape(unsafe.Pointer(b)))</span><br><span class="line">	&#125; else if b.addr !&#x3D; b &#123;</span><br><span class="line">		panic(&quot;strings: illegal use of non-zero Builder copied by value&quot;)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>noescape通过一个无用的位运算，切断了逃逸分析对指针的追踪(解除了参数与返回值的关联)，noescape被大量应用到Go Runtime源码中。</p>
<p>另一个饱受诟病的就是fmt.Printf系列(包括logrus.Debugf等所有带<code>...interface&#123;&#125;</code>参数的函数)，它也很容易导致逃逸，原理前面已经提过，<code>...interface&#123;&#125;</code>是<code>[]interface&#123;&#125;</code>的语法糖，逃逸分析不能确定<code>args []interface&#123;&#125;</code>切片是否会在函数中扩容，因此它要保证切片中的内容拷贝到堆上是安全的，那么就要保证切片元素不能引用栈内存，因此interface{}中的pointer只能指向堆内存。</p>
<p>虽然noescape能解决部分问题，但不建议轻易使用，除非是明确性能瓶颈的场景。</p>
<h3 id="2-内联"><a href="#2-内联" class="headerlink" title="2. 内联"></a>2. 内联</h3><p>前面说过，逃逸分析+GC好用但不免费，但如果没有内联这个最佳辅助的话，前两者的代价怕是昂贵得用不起，所有函数返回的地方，都会树立起一道”墙”，任何想要从墙内逃逸到墙外的变量都会被分配在堆上，如:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewCoord</span><span class="params">()</span> *<span class="title">Coord</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;Coord&#123;</span><br><span class="line">		X: 	<span class="number">1</span>,</span><br><span class="line">		Z: <span class="number">2</span>,</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">foo</span><span class="params">()</span></span> &#123;</span><br><span class="line">	c := NewCoord()</span><br><span class="line">	<span class="keyword">return</span> c.x</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>NewCoord</code>这类简单的构造函数都会导致返回值分配在堆上，抽离函数的代价也更大。因此Go的内联，逃逸分析，GC是名副其实的三剑客，它们共同将其它语言避之不及的指针变得”物美价廉”。</p>
<p>Go1.11开始对内联做了比较大的运行时优化，开始支持<a href="https://go.googlesource.com/proposal/+/master/design/19348-midstack-inlining.md">mid-stack inline</a>，talk链接在<a href="https://docs.google.com/presentation/d/1Wcblp3jpfeKwA0Y4FOmj63PW52M_qmNqlQkNaLj0P5o/edit#slide=id.g1d00ad65a7_2_17">这里</a>。并且支持通过<code>-l</code>编译参数指定内联等级(参数定义参考<a href="https://github.com/golang/go/blob/71a6a44428feb844b9dd3c4c8e16be8dee2fd8fa/src/cmd/compile/internal/gc/inl.go#L10-L17">cmd/compile/internal/gc/inl.go</a>)。并且只在<code>-l=4</code>中提供了mid-stack inline，据Go官方统计，这大概可以提升9%的性能，也增加了11%左右的二进制大小。Go1.12开始默认支持了mid-stack inline。Go1.17中，包含闭包的函数也可以被内联了。</p>
<p>我们目前还没有调整过内联参数，因为这是有利有弊的，过于激进的内联会导致生成的二进制文件更大，CPU instruction cache miss也可能会增加。默认等级的内联大部分时候都工作得很好并且稳定。</p>
<p>到Go1.17为止，虽然对Interface方法的调用还不能被内联(即使编译器知晓具体类型)，但是由于devirtualization优化的存在，已经和直接调用方法性能差距不大:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> I <span class="keyword">interface</span> &#123;</span><br><span class="line">	F() <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> A <span class="keyword">struct</span>&#123;</span><br><span class="line">	x <span class="keyword">int</span></span><br><span class="line">	y <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(a *A)</span> <span class="title">F</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">	z := a.x + a.y</span><br><span class="line">	<span class="keyword">return</span> z</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">BenchmarkX</span><span class="params">(b *testing.B)</span></span> &#123;</span><br><span class="line">	b.ReportAllocs()</span><br><span class="line">	<span class="keyword">for</span> i:=<span class="number">0</span>; i&lt;b.N; i++ &#123;</span><br><span class="line">		<span class="comment">// F() 会被内联 0.36 ns/op</span></span><br><span class="line">		<span class="comment">// var a = &amp;A&#123;&#125;</span></span><br><span class="line">		<span class="comment">// a.F()</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">// before go1.16 接口方法的receiver &amp;A&#123;&#125;会逃逸 18.4 ns/op</span></span><br><span class="line">		<span class="comment">// go1.16+ &amp;A&#123;&#125;不再逃逸 2.51 ns/op 消耗主要在方法调用和接口方法查找上</span></span><br><span class="line">		<span class="keyword">var</span> iface I = &amp;A&#123;&#125;</span><br><span class="line">		iface.F()</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>针对目前Go Interface 内联做得不够好的情况，一个实践是，在性能敏感场景，让你的公用API返回具体类型而非Interface，如<code>etcdclient.New</code>，<code>grpc.NewServer</code>等都是如此实践的，它们通过私有字段加公开方法让外部用起来像Interface一样，但数据逻辑层可能实践起来会有一些难度，因为Go的访问控制太弱了…</p>
<p>总的来说，golang 的 GC，内联，逃逸仍然在不断优化和完善，关注和升级最新golang版本，可能是最廉价的性能提升方式。</p>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang GC核心要点和度量方法</title>
    <url>/2020/01/go-gc-keypoint-and-monitor/</url>
    <content><![CDATA[<h3 id="一-Go-GC-要点"><a href="#一-Go-GC-要点" class="headerlink" title="一. Go GC 要点"></a>一. Go GC 要点</h3><p>先来回顾一下GC的几个重要的阶段:</p>
<h4 id="Mark-Prepare-STW"><a href="#Mark-Prepare-STW" class="headerlink" title="Mark Prepare - STW"></a>Mark Prepare - STW</h4><p>做标记阶段的准备工作，需要停止所有正在运行的goroutine(即STW)，标记根对象，启用内存屏障，内存屏障有点像内存读写钩子，它用于在后续并发标记的过程中，维护三色标记的完备性(三色不变性)，这个过程通常很快，大概在10-30微秒。</p>
<h4 id="Marking-Concurrent"><a href="#Marking-Concurrent" class="headerlink" title="Marking - Concurrent"></a>Marking - Concurrent</h4><p>标记阶段会将大概25%(gcBackgroundUtilization)的P用于标记对象，逐个扫描所有G的堆栈，执行三色标记，在这个过程中，所有新分配的对象都是黑色，被扫描的G会被暂停，扫描完成后恢复，这部分工作叫后台标记(<a href="https://github.com/golang/go/blob/dev.boringcrypto.go1.13/src/runtime/mgc.go#L1817">gcBgMarkWorker</a>)。这会降低系统大概25%的吞吐量，比如<code>MAXPROCS=6</code>，那么GC P期望使用率为<code>6*0.25=1.5</code>，这150%P会通过专职(Dedicated)/兼职(Fractional)/懒散(Idle)三种工作模式的Worker共同来完成。</p>
<span id="more"></span>
<p>这还没完，为了保证在Marking过程中，其它G分配堆内存太快，导致Mark跟不上Allocate的速度，还需要其它G配合做一部分标记的工作，这部分工作叫辅助标记(mutator assists)。在Marking期间，每次G分配内存都会更新它的”负债指数”(gcAssistBytes)，分配得越快，gcAssistBytes越大，这个指数乘以全局的”负载汇率”(assistWorkPerByte)，就得到这个G需要帮忙Marking的内存大小(这个计算过程叫<a href="https://github.com/golang/go/blob/dev.boringcrypto.go1.13/src/runtime/mgc.go#L484">revise</a>)，也就是它在本次分配的mutator assists工作量(<a href="https://github.com/golang/go/blob/dev.boringcrypto.go1.13/src/runtime/mgcmark.go#L363">gcAssistAlloc</a>)。</p>
<h4 id="Mark-Termination-STW"><a href="#Mark-Termination-STW" class="headerlink" title="Mark Termination - STW"></a>Mark Termination - STW</h4><p>标记阶段的最后工作是Mark Termination，关闭内存屏障，停止后台标记以及辅助标记，做一些清理工作，整个过程也需要STW，大概需要60-90微秒。在此之后，所有的P都能继续为应用程序G服务了。</p>
<h4 id="Sweeping-Concurrent"><a href="#Sweeping-Concurrent" class="headerlink" title="Sweeping - Concurrent"></a>Sweeping - Concurrent</h4><p>在标记工作完成之后，剩下的就是清理过程了，清理过程的本质是将没有被使用的内存块整理回收给上一个内存管理层级(mcache -&gt; mcentral -&gt; mheap -&gt; OS)，清理回收的开销被平摊到应用程序的每次内存分配操作中，直到所有内存都Sweeping完成。当然每个层级不会全部将待清理内存都归还给上一级，避免下次分配再申请的开销，比如Go1.12对mheap归还OS内存做了<a href="https://ms2008.github.io/2019/06/30/golang-madvfree/">优化</a>，使用<a href="https://go-review.googlesource.com/c/go/+/135395/">NADV_FREE</a>延迟归还内存。</p>
<h4 id="STW"><a href="#STW" class="headerlink" title="STW"></a>STW</h4><p>在<a href="https://wudaijun.com/2018/01/go-scheduler/">Go调度模型</a>中我们已经提到，Go没有真正的实时抢占机制，而是一套协作式抢占(cooperative preemption)，即给G(groutine)打个标记，等待G在调用函数时检查这个标记，以此作为一个安全的抢占点(GC safe-point)。但如果其它P上的G都停了，某个G还在执行如下代码:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">add</span><span class="params">(numbers []<span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">     <span class="keyword">var</span> v <span class="keyword">int</span></span><br><span class="line">     <span class="keyword">for</span> _, n := <span class="keyword">range</span> numbers &#123;</span><br><span class="line">         v += n</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span> v</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>add函数的运行时间取决于切片的长度，并且在函数内部是没有调用其它函数的，也就是没有抢占点。就会导致整个运行时都在等待这个G调用函数(以实现抢占，开始处理GC)，其它P也被挂起。这就是Go GC最大的诟病: GC STW时间会受到G调用函数的时机的影响并被延长，甚至如果某个G在执行无法抢占的死循环(即循环内部没有发生函数调用的死循环)，那么整个Go的runtime都会挂起，CPU 100%，节点无法响应任何消息，连正常停服都做不到。pprof这类调试工具也用不了，只能通过gdb，delve等外部调试工具来找到死循环的goroutine正在执行的堆栈。如此后果比没有被defer的panic更严重，因为那个时候的节点内部状态是无法预期的。</p>
<p>因此有Gopher开始倡议Go使用非协作式抢占(non-cooperative preemption)，通过堆栈和寄存器来保存抢占上下文，避免对抢占不友好的函数导致GC STW延长(毕竟第三方库代码的质量也是参差不齐的)。相关的Issue在<a href="https://github.com/golang/go/issues/24543">这里</a>。好消息是，<strong><a href="https://tip.golang.org/doc/go1.14">Go1.14</a>(目前还是Beta1版本，还未正式发布)已经支持异步抢占</strong>，也就是说:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 简单起见，没用channel协同</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;()</span><br><span class="line"></span><br><span class="line">  time.Sleep(time.Millisecond)</span><br><span class="line">  runtime.GC()</span><br><span class="line">  <span class="built_in">println</span>(<span class="string">&quot;OK&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码在Go1.14中终于能输出<code>OK</code>了。这个提了近五年的Issue: <a href="https://github.com/golang/go/issues/10958">runtime: tight loops should be preemptible #10958</a>前几天终于关闭了。不得不说，这是Go Runtime的一大进步，它不止避免了单个goroutine死循环导致整个runtime卡死的问题，更重要的是，它为STW提供了最坏预期，避免了GC STW造成了性能抖动隐患。</p>
<h3 id="二-Go-GC-度量"><a href="#二-Go-GC-度量" class="headerlink" title="二. Go GC 度量"></a>二. Go GC 度量</h3><h4 id="1-go-tool-prof"><a href="#1-go-tool-prof" class="headerlink" title="1. go tool prof"></a>1. go tool prof</h4><p>Go 基础性能分析工具，pprof的用法和启动方式参考<a href="https://wudaijun.com/2018/04/go-pprof/">go pprof性能分析</a>，其中的heap即为内存分配分析，go tool默认是查看正在使用的内存(<code>inuse_heap</code>)，如果要看其它数据，使用<code>go tool pprof --alloc_space|inuse_objects|alloc_objects</code>。</p>
<p>需要注意的是，go pprof本质是数据采样分析，其中的值并不是精确值，适用于性能热点优化，而非真实数据统计。</p>
<h4 id="2-go-tool-trace"><a href="#2-go-tool-trace" class="headerlink" title="2. go tool trace"></a>2. go tool trace</h4><p>go tool trace可以将GC统计信息以可视化的方式展现出来。要使用go tool trace，可以通过以下方式生成采样数据:</p>
<ol>
<li>API: <code>trace.Start</code></li>
<li>go test: <code>go test -trace=trace.out pkg</code></li>
<li>net/http/pprof: <code>curl http://127.0.0.1:6060/debug/pprof/trace?seconds=20</code></li>
</ol>
<p>得到采样数据后，之后即可以通过 <code>go tool trace trace.out</code> 启动一个HTTP Server，在浏览器中查看可视化trace数据:</p>
<p><img src="/assets/image/202001/trace-index.jpg" alt=""></p>
<p>里面提供了各种trace和prof的可视化入口，点击第一个View trace可以看到追踪总览:</p>
<p><img src="/assets/image/202001/trace-view.jpg" alt=""></p>
<p>包含的信息量比较广，横轴为时间线，各行为各种维度的度量，通过A/D左右移动，W/S放大放小。以下是各行的意义:</p>
<ul>
<li>Goroutines: 包含GCWaiting，Runnable，Running三种状态的Goroutine数量统计</li>
<li>Heap: 包含当前堆使用量(Allocated)和下次GC阈值(NextGC)统计</li>
<li>Threads: 包含正在运行和正在执行系统调用的Threads数量</li>
<li>GC: 哪个时间段在执行GC</li>
<li>ProcN: 各个P上面的goroutine调度情况</li>
</ul>
<p>除了<strong>View trace</strong>之外，trace目录的第二个<strong>Goroutine analysis</strong>也比较有用，它能够直观统计Goroutine的数量和执行状态:</p>
<p><img src="/assets/image/202001/trace-goroutines.jpg" alt=""></p>
<p><img src="/assets/image/202001/trace-goroutines2.jpg" alt=""></p>
<p>通过它可以对各个goroutine进行健康诊断，各种network,syscall的采样数据下载下来之后可以直接通过<code>go tool pprof</code>分析，因此，实际上pprof和trace两套工具是相辅相成的。</p>
<h4 id="3-GC-Trace"><a href="#3-GC-Trace" class="headerlink" title="3. GC Trace"></a>3. GC Trace</h4><p>GC Trace是Golang提供的非侵入式查看GC信息的方案，用法很简单，设置<code>GCDEBUG=gctrace=1</code>环境变量即可:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GODEBUG&#x3D;gctrace&#x3D;1 bin&#x2F;game</span><br><span class="line">gc 1 @0.039s 3%: 0.027+4.5+0.015 ms clock, 0.11+2.3&#x2F;4.0&#x2F;5.5+0.063 ms cpu, 4-&gt;4-&gt;2 MB, 5 MB goal, 4 P</span><br><span class="line">gc 2 @0.147s 1%: 0.007+1.2+0.008 ms clock, 0.029+0.15&#x2F;1.1&#x2F;2.0+0.035 ms cpu, 5-&gt;5-&gt;3 MB, 6 MB goal, 4 P</span><br><span class="line">gc 3 @0.295s 0%: 0.010+2.3+0.013 ms clock, 0.040+0.14&#x2F;2.1&#x2F;4.3+0.053 ms cpu, 7-&gt;7-&gt;4 MB, 8 MB goal, 4 P</span><br></pre></td></tr></table></figure>
<p>下面是各项指标的解释:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gc 1 @0.039s 3%: 0.027+4.5+0.015 ms clock, 0.11+2.3&#x2F;4.0&#x2F;5.5+0.063 ms cpu, 4-&gt;4-&gt;2 MB, 5 MB goal, 4 P</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 通用参数</span><br><span class="line">gc 2: 程序运行后的第2次GC</span><br><span class="line">@0.147s: 到目前为止程序运行的时间</span><br><span class="line">3%: 到目前为止程序花在GC上的CPU%</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Wall-Clock 流逝的系统时钟</span><br><span class="line">0.027ms+4.5ms+0.015 ms   : 分别是 STW Mark Prepare，Concurrent Marking，STW Mark Termination 的时钟时间</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; CPU Time 消耗的CPU时间</span><br><span class="line">0.11+2.3&#x2F;4.0&#x2F;5.5+0.063 ms : 以+分隔的阶段同上，不过将Concurrent Marking细分为Mutator Assists Time, Background GC Time(包括Dedicated和Fractional Worker), Idle GC Time三种。其中0.11&#x3D;0.027*4，0.063&#x3D;0.015*4。</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 内存相关统计</span><br><span class="line">4-&gt;4-&gt;2 MB: 分别是开始标记时，标记结束后的堆占用大小，以及标记结束后真正存活的(有效的)堆内存大小</span><br><span class="line">5 MB goal: 下次GC Mark Termination后的目标堆占用大小，该值受GC Percentage影响，并且会影响mutator assist工作量(每次堆大小变更时都动态评估，如果快超出goal了，就需要其它goroutine帮忙干活了, https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;go&#x2F;blob&#x2F;dev.boringcrypto.go1.13&#x2F;src&#x2F;runtime&#x2F;mgc.go#L484)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Processors</span><br><span class="line">4 P : P的数量，也就是GOMAXPROCS大小，可通过runtime.GoMaxProcs设置</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 其它</span><br><span class="line">GC forced: 如果两分钟内没有执行GC，则会强制执行一次GC，此时会换行打印 GC forced</span><br></pre></td></tr></table></figure>
<h4 id="4-MemStats"><a href="#4-MemStats" class="headerlink" title="4. MemStats"></a>4. MemStats</h4><p><a href="https://github.com/golang/go/blob/dev.boringcrypto.go1.13/src/runtime/mstats.go#L147">runtime.MemStats</a>记录了内存分配的一些统计信息，通过<code>runtime.ReadMemStats(&amp;ms)</code>获取，它是<a href="https://github.com/golang/go/blob/dev.boringcrypto.go1.13/src/runtime/mstats.go#L24">runtime.mstats</a>的对外版(再次可见Go单一访问控制的弊端)，MemStats字段比较多，其中比较重要的有:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// HeapSys </span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 以下内存大小字段如无特殊说明单位均为bytes</span></span><br><span class="line"><span class="keyword">type</span> MemStats <span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="comment">// 从开始运行到现在累计分配的堆内存数</span></span><br><span class="line">    TotalAlloc <span class="keyword">uint64</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 从OS申请的总内存数(包含堆、栈、内部数据结构等)</span></span><br><span class="line">    Sys <span class="keyword">uint64</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 累计分配的堆对象数量 (当前存活的堆对象数量=Mallocs-Frees)</span></span><br><span class="line">    Mallocs <span class="keyword">uint64</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 累计释放的堆对象数量</span></span><br><span class="line">    Frees   <span class="keyword">uint64</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 正在使用的堆内存数，包含可访问对象和暂未被GC回收的不可访问对象</span></span><br><span class="line">    HeapAlloc <span class="keyword">uint64</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 虚拟内存空间为堆保留的大小，包含还没被使用的(还没有映射物理内存，但这部分通常很小)</span></span><br><span class="line">    <span class="comment">// 以及已经将物理内存归还给OS的部分(即HeapReleased)</span></span><br><span class="line">    <span class="comment">// HeapSys = HeapInuse + HeapIdle</span></span><br><span class="line">    HeapSys <span class="keyword">uint64</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 至少包含一个对象的span字节数</span></span><br><span class="line">    <span class="comment">// Go GC是不会整理内存的</span></span><br><span class="line">    <span class="comment">// HeapInuse - HeapAlloc 是为特殊大小保留的内存，但是它们还没有被使用</span></span><br><span class="line">    HeapInuse <span class="keyword">uint64</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 未被使用的span中的字节数</span></span><br><span class="line">    <span class="comment">// 未被使用的span指没有包含任何对象的span，它们可以归还OS，也可以被重用，或者被用于栈内存</span></span><br><span class="line">    <span class="comment">// HeapIdle - HeadReleased 即为可以归还OS但还被保留的内存，这主要用于避免频繁向OS申请内存</span></span><br><span class="line">    HeapIdle <span class="keyword">uint64</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// HeapIdle中已经归还给OS的内存量</span></span><br><span class="line">    HeapReleased <span class="keyword">uint64</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">// ....</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>程序可以通过定期调用<code>runtime.ReadMemStats</code>API来获取内存分配信息发往时序数据库进行监控。另外，该API是会STW的，但是很短，Google内部也在用，用他们的话说:”STW不可怕，长时间STW才可怕”，该API通常一分钟调用一次即可。</p>
<h4 id="5-ReadGCStats"><a href="#5-ReadGCStats" class="headerlink" title="5. ReadGCStats"></a>5. ReadGCStats</h4><p><code>debug.ReadGCStats</code>用于获取最近的GC统计信息，主要是GC造成的延迟信息:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// GCStats collect information about recent garbage collections.</span></span><br><span class="line"><span class="keyword">type</span> GCStats <span class="keyword">struct</span> &#123;</span><br><span class="line">	LastGC         time.Time       <span class="comment">// 最近一次GC耗费时间</span></span><br><span class="line">	NumGC          <span class="keyword">int64</span>           <span class="comment">// 执行GC的次数</span></span><br><span class="line">	PauseTotal     time.Duration   <span class="comment">// 所有GC暂停时间总和</span></span><br><span class="line">	Pause          []time.Duration <span class="comment">// 每次GC的暂停时间，最近的排在前面</span></span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>和ReadMemStats一样，ReadGCStats也可以定时收集，发送给时序数据库做监控统计。</p>
<h3 id="三-Go-GC-调优"><a href="#三-Go-GC-调优" class="headerlink" title="三. Go GC 调优"></a>三. Go GC 调优</h3><p>Go GC相关的参数少得可怜，一如既往地精简:</p>
<h4 id="1-debug-SetGCPercent"><a href="#1-debug-SetGCPercent" class="headerlink" title="1. debug.SetGCPercent"></a>1. debug.SetGCPercent</h4><p>一个百分比数值，决定即本次GC后，下次触发GC的阈值，比如本次GC Sweeping完成后的内存占用为200M，GC Percentage为100(默认值)，那么下次触发GC的内存阈值就是400M。这个值通常不建议修改，因为优化GC开销的方法通常是避免不必要的分配或者内存复用，而非通过调整GC Percent延迟GC触发时机(Go GC本身也会根据当前分配速率来决定是否需要提前开启新一轮GC)。另外，debug.SetGCPercent传入&lt;0的值将关闭GC。</p>
<h4 id="2-runtime-GC"><a href="#2-runtime-GC" class="headerlink" title="2. runtime.GC"></a>2. runtime.GC</h4><p>强制执行一次GC，如果当前正在执行GC，则帮助当前GC执行完成后，再执行一轮完整的GC。该函数阻塞直到GC完成。</p>
<h4 id="3-debug-FreeOSMemory"><a href="#3-debug-FreeOSMemory" class="headerlink" title="3. debug.FreeOSMemory"></a>3. debug.FreeOSMemory</h4><p>强制执行一次GC，并且尽可能多地将不再使用的内存归还给OS。</p>
<p>严格意义上说，以上几个API预期说调优，不如说是补救，它们都只是把Go GC本身就会做的事情提前或者延后了，通常是治标不治本的方法。真正的GC调优主要还是在应用层面。我在<a href="https://wudaijun.com/2019/09/go-performance-optimization/">这篇文章</a>聊了一些Go应用层面的内存优化。</p>
<p>以上主要从偏应用的角度介绍了Golang GC的几个重要阶段，STW，GC度量/调试，以及相关API等。这些理论和方法能在在必要的时候派上用场，帮助更深入地了解应用程序并定位问题。</p>
<p>推荐文献:</p>
<ol>
<li><a href="https://www.ardanlabs.com/blog/2018/12/garbage-collection-in-go-part1-semantics.html">Garbage Collection In Go</a></li>
<li><a href="https://github.com/qcrao/Go-Questions/blob/master/GC/GC.md">GC 20 问</a></li>
<li><a href="https://blog.learngoprogramming.com/a-visual-guide-to-golang-memory-allocator-from-ground-up-e132258453ed">A visual guide to Go Memory Allocator from scratch</a></li>
</ol>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title>编程语言杂记</title>
    <url>/2020/04/language-mindmap/</url>
    <content><![CDATA[<p><img src="/assets/image/202004/language.png" alt=""></p>
]]></content>
      <categories>
        <category>mindmap</category>
      </categories>
      <tags>
        <tag>mindmap</tag>
      </tags>
  </entry>
  <entry>
    <title>GS 测试规范实践</title>
    <url>/2020/08/gs-testing-practice/</url>
    <content><![CDATA[<p>在之前的博客中几次简单提及过给GS做测试，关于测试的必要性不用再多说，但在实际实践过程中，却往往会因为如下原因导致想要推进测试规范困难重重:</p>
<p>-. Q1: 写测试代码困难: 代码耦合重，各种相互依赖，全局依赖，导致写测试代码”牵一发而动全身”，举步维艰<br>-. Q2: 测试时效性低: 需求变更快，数值变更频繁，可能导致今天写好的测试代码，明天就”过时”了<br>-. Q3: 开发进度紧: 不想浪费过多时间来写测试代码，直接开发感觉开发效率更高</p>
<p>要想推进测试规范，上面的三个问题是必须解决的。这里简单聊聊我们在Golang游戏后端中的测试实践和解决方案。我们在GS中尝试的测试方案主要分为四种: 单元测试，集成测试，压力测试，以及模拟测试。</p>
<span id="more"></span>
<h3 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h3><p>单元测的优点是与业务逻辑和外部环境关联度最小，同时go test也很容易集成到CI/CD流程中。单元测试的缺点就是上面提到的Q1(耦合依赖问题)，对此，我们的解决方案是:</p>
<ol>
<li>持续重构，解耦降低依赖。有点废话，但是写易于测试的代码确实是一种修行</li>
<li>通过<a href="https://github.com/smartystreets/goconvey">goconvey</a>测试框架简化单元测试的编写</li>
<li>通过<a href="https://github.com/golang/mock">gomock</a> Mock掉接口依赖</li>
<li>实在Mock不掉的，通过<a href="https://github.com/agiledragon/gomonkey">gomonkey</a> Hack掉依赖，不过要记得禁用内联</li>
<li>对于一些复杂的单元测试，如涉及到发消息，创建玩家，启动定时器等，可以创建通用的Mock组件和环境，便于使用</li>
</ol>
<p>goconvey+gomonkey+gomock 三件套在实践中足够灵活强大，具体使用参考文档即可，比较简单，就不展示了。</p>
<h3 id="集成测试"><a href="#集成测试" class="headerlink" title="集成测试"></a>集成测试</h3><p>集成测试我们又称之为用例测试，它是一种黑盒测试，以C/S交互协议为边界，站在客户端视角来测试服务器运行结果，黑盒测试本质上是消息流测试。它的优点是覆盖面广，网络层，集群管理，消息路由等细节都被会覆盖到。黑盒测试的难点在于易变性，协议变更，配置更新等都可能造成测试用例不可用，即上面提到的Q2(用例时效性问题)。对此，我们的实践是:</p>
<ol>
<li>将消息流测试离线化，即封装基本原语(Send,Wait,Expect,Select等)，化编译型为解释型，让测试用例可以通过类似配置文件的方式来描述，简化与服务器的交互细节，甚至理论做到交付给非技术人员使用。技术上除了对模拟客户端的封装外，主要是对json的处理: <a href="https://github.com/thedevsaddam/gojsonq">gojsonq</a>, <a href="https://github.com/nsf/jsondiff">jsondiff</a>, <a href="https://github.com/mkideal/pkg/tree/master/encoding/jsonx">jsonx</a></li>
<li>写可重入的测试用例，可重入即用例不应该依赖于当前服务器和用例机器人的初始状态，做到可重复执行</li>
<li>保存一份专用于用例测试策划配置快照，避免频繁的数值调整导致测试用例不可用。服务器和测试客户端都使用这份配置。即GS需要支持不同的配置源(如DB/File)</li>
</ol>
<p>以下是一个省掉很多细节的测试用例(yml格式描述):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 封装一个Function，从预定义变量varRole[n]中提取字段放到自定义变量中</span><br><span class="line">InitAttackCmds:</span><br><span class="line">  - find LoginAck.city.coord.X from varRole1 to varCity1X</span><br><span class="line">  - find LoginAck.city.coord.Z from varRole1 to varCity1Z</span><br><span class="line">  - find LoginAck.city.cityID from varRole1 to varCity1ID</span><br><span class="line"></span><br><span class="line"># 单个测试用例</span><br><span class="line">AttackPersonCityWinTest:</span><br><span class="line">  # 创建两个Robot，以Rbt1 Rbt2 标识</span><br><span class="line">  - newrobot 2</span><br><span class="line">  # 此时机器人已经登录完成，初始化自定义变量</span><br><span class="line">  - call InitAttackCmds</span><br><span class="line">  # 获取Rbt1初始化城防值</span><br><span class="line">  - Rbt1 send CityDefenseReq &#123;&#125;</span><br><span class="line">  # wait 后面的消息支持json局部字段比较(包含匹配)</span><br><span class="line">  - Rbt1 wait CityDefenseAck &#123;isCombustion:false&#125;</span><br><span class="line">  - Rbt1 find cityDefense from varLastAck to varCityDefensePreVal</span><br><span class="line">  # Rbt2 向 Rbt1 城池行军</span><br><span class="line">  - Rbt2 send NewTroopReq &#123;&quot;Action&quot;:1,&quot;Soldiers&quot;:&#123;&quot;11211001&quot;:500,&quot;11211301&quot;:500&#125;,&quot;EndCoord&quot;:&#123;&quot;X&quot;:%v,&quot;Z&quot;:%v&#125;,&quot;Mission&quot;:&#123;&quot;IsCampAfterHunt&quot;:false,&quot;IsRally&quot;:false&#125;,&quot;TargetID&quot;:%v&#125; varCity1X varCity1Z varCity1ID</span><br><span class="line">  - Rbt2 wait NewTroopAck &#123;errCode:0,action:1&#125;</span><br><span class="line">  # 防守失败后被烧城</span><br><span class="line">  - Rbt1 wait CombustionStateNtf &#123;isCombustion:true&#125;</span><br><span class="line">  - Rbt1 find cityDefense from varLastAck to varCityDefensePostVal</span><br><span class="line">  # 掉城防值</span><br><span class="line">  - should varCityDefensePostVal &lt; varCityDefensePreVal</span><br></pre></td></tr></table></figure>
<h3 id="压力测试"><a href="#压力测试" class="headerlink" title="压力测试"></a>压力测试</h3><p>压力测试也是黑盒测试的一种，它的目标是放大服务器的性能问题以及并发状态下的正确性问题。我在<a href="https://wudaijun.com/2019/09/gs-pressure-test/">如何给GS做压测</a>中简单地阐述过压测的一些注意事项。简单来说，用例测试注重特例和自动化，而压力测试注重随机和覆盖率。</p>
<h3 id="模拟测试"><a href="#模拟测试" class="headerlink" title="模拟测试"></a>模拟测试</h3><p>模拟测试是指通过类似console的方式来模拟客户端，它的功能主要分为两部分:</p>
<ol>
<li>动态构造消息并返回响应数据</li>
<li>支持一些简单的GM，如查看/修改自身数据</li>
</ol>
<p>它最大的优点在于灵活性，主要有两个作用:</p>
<ol>
<li>服务器新功能开发完成进行快速自测验证(脱离客户端)，提升开发效率</li>
<li>出现某些疑似服务器的BUG时，登录已有角色进行数据验证和Debug</li>
</ol>
<p>以下是我们的模拟测试的样子:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 注: FC[...]# 为输入行，其余为输出行    &quot;&#x2F;&#x2F;...&quot;表示省略消息具体内容</span><br><span class="line">FakeClient connect successed</span><br><span class="line">FC[NotAuth]# auth test</span><br><span class="line">send msg: AuthReq:type:&quot;anonymous&quot; passport:&quot;user_fakeclienttest&quot; password:&quot;user_fakeclienttest&quot;</span><br><span class="line">recv msg: AuthAck &#x2F;&#x2F;... </span><br><span class="line">FC[Authed:281474976712031]#</span><br><span class="line">FC[Authed:281474976712031]# char login 11</span><br><span class="line">send msg: LoginReq: &#x2F;&#x2F; ...</span><br><span class="line">recv msg: LoginAck playerID:27113 &#x2F;&#x2F; ...</span><br><span class="line">FC[Logined:27113]#</span><br><span class="line">FC[Logined:27113]#send HeartBeatReq &#123;ClientTs:111&#125;</span><br><span class="line">send msg: HeartBeatReq:clientTs:111 </span><br><span class="line">recv msg: HeartBeatAck clientTs:111 serverTs:1597664509306</span><br><span class="line">FC[Logined:27113]#</span><br><span class="line">FC[Logined:27113]# self all</span><br><span class="line">&#123;&quot;ID&quot;:27113,&quot;name&quot;:&quot;Newbie 27113&quot;, &#x2F;&#x2F; ...</span><br></pre></td></tr></table></figure>
<h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>集成测试，压力测试，模拟测试，核心都需要一个模拟客户端，因此完全可以构建一套通用的fakeclient逻辑，包含基础网络通信，登录流程，数据状态同步等等。比如我们还基于fakeclient搭建了用于监控线上服务器可用性的监控机器人。</p>
<p>前面分别提到Q1，Q2的解决方案，至于Q3，我们的经验是，同学们之所以不愿意写测试，大部分原因都是测试框架还不够完善易用。另外，应该达成共识的是，开发效率并不只算单方面当前的开发时间，还应该包括客户端联调，QA验证反馈，后续重构负担等的时间，从这个角度来说，良好的测试规范起到的作用毋容置疑。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊GS引入MQ的一些实践</title>
    <url>/2021/02/gs-mq-practice/</url>
    <content><![CDATA[<p>在目前这套项目架构诞生初期，基于当时的游戏类型和项目需求，架构做得相对简单，设计上尽可能通过goroutine而不是节点来并发，节点间用ETCD做服务发现，用gRPC做节点通信，在单向依赖，弱藕合的情况下，基本能够满足需求。对于个别强耦合的节点交互，使用gRPC Stream来建立双工连接。</p>
<p>随着游戏类型和业务需求的变更，跨服功能增多，节点划分越来越细，藕合越来越重，网络拓扑也越来越复杂。gRPC Stream不再能很好地胜任。</p>
<p>因此我们考虑用一套新的节点交互方案，大概有两个思路:</p>
<ol>
<li>写一套完备的TCP网络库(包含服务发现，自动重连，编解码，心跳，流控等)，用于统一节点间甚至Gateway与Client间的网络交互</li>
<li>使用MQ解耦集群内节点交互，将网状网络化为星形网络，简化网络拓扑</li>
</ol>
<span id="more"></span>
<p>在对方案一进行几天的尝试后，我们最终放弃了TCP方案，主要有以下几个问题:</p>
<ol>
<li>网络拓扑完全交给了应用层去维护，开发者需要谨慎规划和约束，避免形成全联通</li>
<li>由于不是全联通网络，A-&gt;B的消息可能需要经由一个甚至多个中间节点路由才能到达，并且这类路由信息只能逻辑层维护</li>
<li>某些业务场景下，节点路由和依赖可能是动态的，如跨服匹配战场，此时需要动态建立/销毁连接以维护动态路由</li>
</ol>
<p>就前面几个问题来说，MQ是更好的解决方案，相比TCP，它有以下优势:</p>
<ol>
<li>将 0-N 跳的路由网络的模型，统一为一跳，即通过中间件即可直达任意节点，在路由和全联通之间找到一个平衡点</li>
<li>发布订阅模型，为应用层提供了非常大的灵活度: 单向依赖/双向依赖，扇入/扇出，负载均衡，批量发布(主题匹配)等</li>
</ol>
<p>消息中间件能够比较好地向应用层屏蔽节点路由的问题，但它并不能完全替代ETCD+gRPC，两套方案可以在不同的应用场景搭配使用。</p>
<p>在对几种主流消息中间件进行评估之后，我们目前选定<a href="https://github.com/nats-io/nats-server">nats</a>，它的优点是基于golang编写，轻量级，高性能，低延迟，缺点是不支持消息持久化，即最多一次投递语义，<a href="https://github.com/nats-io/nats-streaming-server">nats-streaming</a>基于nats增加了消息持久化，即最少一次投递语义，相应的也有更完备的流控机制。由于游戏服务器对消息时延敏感，并且大部分消息有状态和时效性，因此目前打算直接用nats，关键逻辑自己做消息QoS或容错机制(官方也推荐nats，由应用层而不是中间件去做QoS)。</p>
<p>从设计上而言，在nats之上封装应用层MQ API，不依赖nats特有功能(如Request-Reply)，只使用消息中间件的通用语义(Publish/Subscribe)，解耦组件以实现必要时透明替换，应用层对MQ API的使用主要分两种:</p>
<ol>
<li>节点通信: 应用在藕合较强的逻辑节点间，在这里Topic类似于节点公开通信地址，MQ起到的作用类似TCP。这情况情形下，对MQ封装通用消息语义: Send / Request / Async-Request，前两种语义容易理解，即异步投递和同步请求，第三种是异步请求，通过回调的方式处理响应，并统一保存请求上下文，适用于异步RPC情景。更进一步，这一层消息语义封装不应该依赖于MQ封装，即可以透明将这层语义的底层实现由MQ换成TCP或其它传输层，同时应该向应用层屏蔽掉Topic，提供类似EndPoint或Peer的抽象概念。</li>
<li>发布订阅: 消息中间件的常规应用，但是也需要封装，一方面是为了解耦屏蔽nats，另一方面是构建应用层对订阅分发的优化，就我们目前的实践而言，建立了一个固定大小的mq worker pool，以Topic Hash为请求分配worker，每个worker内部做二级分发(优化同一个节点对同一个Topic的多次订阅)，序列化/反序列化等，worker底层复用同一个nats client，对逻辑层提供足够易用的异步发布订阅接口。</li>
</ol>
<p>关于MQ的进一步实践我们还在摸索，目前的体会是，消息中间件和网关一样，都是游戏服务器架构的基础设施，前者对内简化服务器节点网络拓扑，后者对外屏蔽服务器内部网络拓扑，共同提升服务器的可扩展性。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
        <tag>mq</tag>
      </tags>
  </entry>
  <entry>
    <title>软件设计的一些理解</title>
    <url>/2021/06/software-design-mindmap/</url>
    <content><![CDATA[<p><img src="assets/image/202106/软件设计.png" alt=""></p>
]]></content>
      <categories>
        <category>design</category>
      </categories>
      <tags>
        <tag>software design</tag>
      </tags>
  </entry>
  <entry>
    <title>领域驱动设计的一些小结</title>
    <url>/2021/07/domain-driven-design-mindmap/</url>
    <content><![CDATA[<p><img src="assets/image/202107/ddd.png" alt=""></p>
]]></content>
      <categories>
        <category>design</category>
      </categories>
      <tags>
        <tag>domain driver design</tag>
        <tag>DDD</tag>
      </tags>
  </entry>
  <entry>
    <title>SLG游戏服务器随想</title>
    <url>/2022/03/slg-server-mindmap/</url>
    <content><![CDATA[<p><img src="/assets/image/202203/slg-server.png" alt=""></p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang性能分析</title>
    <url>/2022/04/golang-performance-analysis/</url>
    <content><![CDATA[<p><img src="/assets/image/202204/Golang性能分析.png" alt=""></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>Go 泛型特性速览</title>
    <url>/2020/12/go-generics/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>2022.1.22 更新: 最近一年，Go泛型已经从草案，过渡到提案，并开始实现。<a href="https://tip.golang.org/doc/go1.18">Go1.18</a>实现了初版泛型，最终方案相较之前的泛型草案，将<strong>类型列表约束(type list in constraint)</strong>进一步丰富完善为<strong>类型集约束(type sets of constraints)</strong>的概念，本文内容已随最新文档更新。</p>
</blockquote>
</blockquote>
<p>之前我在<a href="https://wudaijun.com/2019/05/programing-paradigm/">编程范式游记</a>中介绍了OOP中的子类化(subtype，也叫子类型多态subtype polymorphism)和泛型(generics，也叫参数多态parametric polymorphism或类型参数type parameters)，关于两者的区别和比较可以参考那篇文章，在其中我吐槽了Go目前对泛型支持的匮乏，Go泛型最初在<a href="https://github.com/golang/go/wiki/Go">Go 2</a>中讨论，目前已经在Go1.18中正式实现，随着Go泛型设计和实现的细节也越来越清晰，我们从最新的<a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/43651-type-parameters.md">Go泛型文档</a>来了解下Go泛型设计上有哪些考量和取舍。</p>
<p>PS. 虽然Go官方文档仍然沿用社区惯用的”泛型(generics)”术语，由于主流语言都有自己不同的泛型支持，如Java基于<strong>编译期类型擦除</strong>的泛型(伪泛型)，C++的<strong>图灵完备</strong>的模板机制(支持模板元编程的真泛型)等，为了避免概念混淆，将Go泛型理解为<strong>类型参数(type parameters)</strong>更精确，它不支持C++那样灵活的模板元编程，但比Java这种运行时擦除类型信息的补丁实现更优，另外，关于运算符泛型，Go也提出了一套新的解决方案。</p>
<h4 id="1-最简原型"><a href="#1-最简原型" class="headerlink" title="1. 最简原型"></a>1. 最简原型</h4><p>先从最简单的泛型定义开始:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Define</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Print</span>[<span class="title">T</span>] <span class="params">(s []T)</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> _, v := <span class="keyword">range</span> s &#123;</span><br><span class="line">		fmt.Println(v)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Call</span></span><br><span class="line">Print[<span class="keyword">int</span>]([]<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>语法上和其它语言泛型大同小异，泛型的本质是将<strong>类型参数化</strong>，Go中用函数名后的<code>[]</code>定义类型参数。以上声明对C++开发者来说非常亲切的(只是换了一种语法形式)，实际上这在Go中是错误的泛型函数声明，因为它没有指明类型参数约束(constraints)。</p>
<span id="more"></span>
<h4 id="2-类型约束"><a href="#2-类型约束" class="headerlink" title="2. 类型约束"></a>2. 类型约束</h4><p>与C++不同，Go在一开始就确定要引入泛型的类型参数约束(bounded generic types，subtype与generics的有机结合)，并且借机吐槽了C++的无约束泛型类型参数，因为这会带来非常难调试的编译时报错。在上例中，即使Print内部没有调用T的任何方法，也需要通过新引入的<code>any</code>关键字来表示任意类型约束(考虑下不能未显示指定约束则缺省即为<code>any</code>的原因)。因此正确的Print声明方式为:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Print</span>[<span class="title">T</span> <span class="title">any</span>] <span class="params">(s []T)</span></span> &#123; ...</span><br></pre></td></tr></table></figure>
<p>PS: 任意类型不代表不能执行任意操作，如声明变量，赋值，取地址(<code>&amp;</code>)，取类型(<code>.(type)</code>)等。</p>
<p>那么除去<code>any</code>，如何表示一个有效的类型约束，参考其它支持bounded generic types语言的做法，如C#/Java，自然go interface是不二之选，因为go interface本质就是做subtype，而subtype本身主要就是服务于静态语言的type checker的。因此subtype也可以辅助编译器完善对类型参数的检查。使用interface做类型参数约束的函数看起来是这个样子:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Stringify</span>[<span class="title">T</span> <span class="title">fmt</span>.<span class="title">Stringer</span>]<span class="params">(s []T)</span> <span class="params">(ret []<span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> _, v := <span class="keyword">range</span> s &#123;</span><br><span class="line">		ret = <span class="built_in">append</span>(ret, v.String()) D</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> ret</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里有一个有意思的问题，为什么Go编译器不直接用Stringify函数中对T的各种函数调用，自动推敲生成一个匿名interface呢，如此对Stringify来说，外部满足<code>fmt.Stringer</code>的类型，仍然能够使用Stringify，并且这本身也是Go隐式接口的一大便利(不依赖于subclass来实现subtype，Go没有subclass)，其它像C++/C#/Java依赖于显示接口/基类继承声明得语言，是无法做到的。关于这一点，Go官方的解释是，如果接口隐式推敲，少了显式接口这层”契约”，那么Stringify的一个很小的改动都可能导致上层调用不可用，这不利于构建大型项目。调用方只需要关心它是否满足接口约束，而不应该也不需要去阅读Stringify的代码来知道它可能调用T的哪些函数。</p>
<p>既然选定了用interface来做类型参数约束，那么再来看<code>any</code>，它实际上就和<code>interface&#123;&#125;</code>没有区别的，任意类型都满足<code>interface&#123;&#125;</code>接口，因此实际上Print也可以声明为 <code>func Print[T interface&#123;&#125;] (s []T)</code>，但是官方觉得在写任意类型的泛型的时候，每次写<code>interface&#123;&#125;</code>太麻烦了(符合golang的极简思维)，因此还是觉得应该保留<code>any</code>关键字，作为<code>interface&#123;&#125;</code>的别名，但是在除了泛型类型约束之外，常规空接口仍然用<code>interface&#123;&#125;</code>而不能用<code>any</code>，解释是不希望新增的泛型给以前的代码带来影响…</p>
<h4 id="3-泛型类型"><a href="#3-泛型类型" class="headerlink" title="3. 泛型类型"></a>3. 泛型类型</h4><p>除了泛型函数外，基于泛型也可以构建新的类型，如:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 定义一个可保存任意类型的切片</span></span><br><span class="line"><span class="keyword">type</span> Vector[T any] []T</span><br><span class="line"><span class="comment">// 实现泛型类Vector方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *Vector[T])</span> <span class="title">Push</span><span class="params">(x T)</span></span> &#123; *v = <span class="built_in">append</span>(*v, x) &#125;</span><br><span class="line"><span class="comment">// 实例化泛型类型 Vecter[int] t</span></span><br><span class="line"><span class="keyword">var</span> v Vector[<span class="keyword">int</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 与前面的Vector[int]等价，事实上编译器也会生成类似的类</span></span><br><span class="line"><span class="keyword">type</span> VecterInt []<span class="keyword">int</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *VectorInt)</span> <span class="title">Push</span><span class="params">(x <span class="keyword">int</span>)</span></span> &#123; *v = <span class="built_in">append</span>(*v, x) &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个可保存两个任意类型值的Pair</span></span><br><span class="line"><span class="keyword">type</span> Pair[T1, T2 any] <span class="keyword">struct</span> &#123;</span><br><span class="line">	val1  T1</span><br><span class="line">    val2  T2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义Pair List</span></span><br><span class="line"><span class="comment">// 注意next字段引用了自身，目前这种相互直接或间接引用，要求参数类型(以及顺序)一致，后面可能会放宽此要求</span></span><br><span class="line"><span class="keyword">type</span> List[T1, T2 any] <span class="keyword">struct</span> &#123;</span><br><span class="line">	next *List[T1, T2] <span class="comment">// 如果改成 List[T2, T1] 则不行</span></span><br><span class="line">	val  Pair[T1, T2] </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="4-类型集约束"><a href="#4-类型集约束" class="headerlink" title="4. 类型集约束"></a>4. 类型集约束</h4><p>前面提到Go通过interface完成对参数类型的约束，理论上来说已经是完备的了(毕竟interface用作subtype已经证明了这点)，但是还不够方便，比如:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// This function is INVALID.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Smallest</span>[<span class="title">T</span> <span class="title">any</span>]<span class="params">(s []T)</span> <span class="title">T</span></span> &#123;</span><br><span class="line">	r := s[<span class="number">0</span>] <span class="comment">// panic if slice is empty</span></span><br><span class="line">	<span class="keyword">for</span> _, v := <span class="keyword">range</span> s[<span class="number">1</span>:] &#123;</span><br><span class="line">		<span class="keyword">if</span> v &lt; r &#123; <span class="comment">// INVALID</span></span><br><span class="line">			r = v</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>Smallest</code>函数中，我们希望求出一个切片中的最小元素，但是这个函数声明本身是无效的，因为不是所有的类型都支持<code>&lt;</code>运算符，事实上，在Go中，仅有限的内置类型支持<code>&lt;</code>，其它自定义类型均不支持通过方法定义自己的<code>&lt;</code>运算(此处开始怀念C++的运算符，但是其带来的”一切皆有可能”的代码理解负担也确实头疼…)，诚然这里可以通过定义类似的Comparable interface来进行类型约束和比较，将<code>v &lt; r</code>替换为<code>v.Less(r)</code>，但你也需要为原生支持比较的类型(int/float/string)定义一个新的类型并实现Comparable接口，反而让Smallest使用起来更复杂。因此，这里Go有必要为基础运算符定义一套泛型类型约束，使得调用方可以直接通过<code>Smallest[int]([]int&#123;3,1,4&#125;)</code>即可使用。</p>
<p>这里有两种实现方式，一种方案是预定义基础运算的约束，并且让满足条件的基础类型自动适配而无需手动实现，如<code>&lt;</code>，<code>&gt;</code>，<code>==</code>，<code>&lt;&lt;</code>，<code>&amp;&amp;</code>，<code>range</code>，<code>size</code>等。另一种方式是基于Go几乎所有的逻辑运算符(唯二的例外在后面会讨论)都仅支持内置基础类型，并且内置基础类型是有限的这两点事实，从另一个角度出发: 让类型约束可以直接指定其需要包含的基础类型。Go优先选择了第二种方案，提供所谓<strong>类型集约束(type sets of contraints)</strong>机制。</p>
<h5 id="类型集"><a href="#类型集" class="headerlink" title="类型集"></a>类型集</h5><p>Go新增了类型集(type sets)的概念，每个类型都有自己的类型集，对于非接口类型T而言，其类型集为<code>&#123;T&#125;</code>，即为它自身。对于接口类型而言，如下面的接口T:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> T <span class="keyword">interface</span> &#123;</span><br><span class="line">	io.Reader</span><br><span class="line">	Foo()</span><br><span class="line">	Bar() <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 语义上等价于</span></span><br><span class="line"><span class="keyword">type</span> E1 <span class="keyword">interface</span> &#123; Foo() &#125;</span><br><span class="line"><span class="keyword">type</span> E2 <span class="keyword">interface</span> &#123; Bar() <span class="keyword">int</span> &#125;</span><br><span class="line"><span class="keyword">type</span> T <span class="keyword">interface</span> &#123;</span><br><span class="line">	io.Reader</span><br><span class="line">	E1</span><br><span class="line">	E2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接口本质是若干方法签名 + 内嵌接口的组合，而方法签名很容易转换为对应方法的interface(上例的E1和E2)，而接口T的类型集，本质是<code>io.Reader</code>的类型集和E1，E2的类型集的交集，这个定义，既能阐述接口本身概念(满足接口所定义的所有方法)，也能阐述接口作为类型约束的概念(满足T所定义的所有约束)。这个交集的概念是贯穿Go接口和Go泛型约束的。</p>
<h5 id="类型集约束"><a href="#类型集约束" class="headerlink" title="类型集约束"></a>类型集约束</h5><p>但是，Go接口只支持方法签名和内嵌接口，对于作为泛型类型约束来说，功能弱了一些(比如不能完成前面提到的类型枚举)，因此Go对interface进行了功能扩展，添加了三个特性，使用了这三个特性的interface，将只能作为类型约束，而不能再作为接口:</p>
<ol>
<li>类型枚举: 允许类型约束的interface中，直接枚举任意类型，如<code>type Integer inteface&#123; int &#125;</code></li>
<li>类型近似: 类型枚举不能解决类型重定义的问题，如<code>type MyInt int</code>，也应该满足<code>Integer</code>约束，因此类型约束interface可以通过<code>~T</code>来表达T的近似类型(approximation constraint)，对于约束<code>type Integer2 interface &#123;~int&#125;</code>而言，任何底层类型为int的类型，均满足该约束，包括MyInt</li>
<li>类型联合: 可以通过<code>A|B</code>来表达”A或B类型”的概念，对于约束<code>type PredeclaredSignedInteger interface &#123; int | int8 | int16 | int32 | int64 &#125;</code>而言，任意以上5个整数类型之一，均满足其约束条件</li>
</ol>
<p>现在再来看前面的Smallest函数，它的完整正确约束应该为:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Ordered is a type constraint that matches any ordered type.</span></span><br><span class="line"><span class="comment">// An ordered type is one that supports the &lt;, &lt;=, &gt;, and &gt;= operators.</span></span><br><span class="line"><span class="keyword">type</span> Ordered <span class="keyword">interface</span> &#123;</span><br><span class="line">	~<span class="keyword">int</span> | ~<span class="keyword">int8</span> | ~<span class="keyword">int16</span> | ~<span class="keyword">int32</span> | ~<span class="keyword">int64</span> |</span><br><span class="line">		~<span class="keyword">uint</span> | ~<span class="keyword">uint8</span> | ~<span class="keyword">uint16</span> | ~<span class="keyword">uint32</span> | ~<span class="keyword">uint64</span> | ~<span class="keyword">uintptr</span> |</span><br><span class="line">		~<span class="keyword">float32</span> | ~<span class="keyword">float64</span> |</span><br><span class="line">		~<span class="keyword">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>考虑到<code>Ordered</code>这类约束可能会在很多地方用到，因此可能需要将其归到官方库中提供，该package为<code>contraints</code>，如此<code>Smallest</code>即可定义为<code>func Smallest[T constraints.Ordered](s []T) T</code>。</p>
<p>这里再提一下Go泛型的显示声明原则，有了类型列表约束之后，函数可以直接使用类型列表中所有类型都支持的运算，但<strong>不能直接使用类型列表都支持的方法，即使这些类型都提供了该方法</strong>:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> MyInt <span class="keyword">int</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(i MyInt)</span> <span class="title">String</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> strconv.Itoa(<span class="keyword">int</span>(i))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> MyFloat <span class="keyword">float64</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f MyFloat)</span> <span class="title">String</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> strconv.FormatFloat(<span class="keyword">float64</span>(f), <span class="string">&#x27;g&#x27;</span>, <span class="number">-1</span>, <span class="number">64</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> MyIntOrFloat <span class="keyword">interface</span> &#123;</span><br><span class="line">	MyInt | MyFloat</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ToString</span>[<span class="title">T</span> <span class="title">MyIntOrFloat</span>]<span class="params">(v T)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> v.String() <span class="comment">// Error: 泛型函数只能使用类型约束显式声明的方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样是为了避免当类型和接口嵌套较深时，调用方很难搞清楚函数到底依赖了约束的哪些方法(因为没了类型约束这层契约)，因此在<code>MyIntOrFloat</code>中显式添加<code>String() string</code>接口是一个更明智的选择。</p>
<p>综上，Go泛型约束基于接口，但其功能是接口的父集，在扩展了interface功能后，完整的作为类型约束的interface语法如下:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// InterfaceTypeName 即为内嵌接口，MethodSpec 为方法签名，均为Go接口本身的概念</span></span><br><span class="line">InterfaceType  = <span class="string">&quot;interface&quot;</span> <span class="string">&quot;&#123;&quot;</span> &#123;(MethodSpec | InterfaceTypeName | ConstraintElem) <span class="string">&quot;;&quot;</span> &#125; <span class="string">&quot;&#125;&quot;</span> .</span><br><span class="line">ConstraintElem = ConstraintTerm &#123; <span class="string">&quot;|&quot;</span> ConstraintTerm &#125; .</span><br><span class="line">ConstraintTerm = [<span class="string">&quot;~&quot;</span>] Type .</span><br></pre></td></tr></table></figure>
<h4 id="5-预定义约束"><a href="#5-预定义约束" class="headerlink" title="5. 预定义约束"></a>5. 预定义约束</h4><p><strong>几乎所有的运算符都仅支持内置类型</strong>，这其中有两个例外的运算符，等于(==)和不等于(!=)，比如我们知道，在Go中，struct，array是可以直接比较的，Go需要特殊处理这两个运算符，因此还是提出了<code>comparable</code>这个特殊的预定义类型约束:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Index</span>[<span class="title">T</span> <span class="title">comparable</span>]<span class="params">(s []T, x T)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> i, v := <span class="keyword">range</span> s &#123;</span><br><span class="line">		<span class="keyword">if</span> v == x &#123;</span><br><span class="line">			<span class="keyword">return</span> i</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于Go同时支持了预定义类型约束和类型集约束，因此开发者可能定义出一个永远无法满足的类型约束:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> ImpossibleConstraint <span class="keyword">interface</span> &#123;</span><br><span class="line">	comparable</span><br><span class="line">	[]<span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于<code>[]int</code>无法被比较，因此没有任何类型能满足<code>ImpossibleConstraint</code>约束，定义这个约束本身不会报错，但是在尝试调用使用该约束的任意泛型函数和泛型类时，会得到编译错误。</p>
<p>有了预定义类型约束和类型集约束之后，Go关于运算符的泛型补丁算是打完了，这里再简单梳理下作为interface接口和interface约束的区别:</p>
<ol>
<li>Go预定义了两个类型约束: <code>any</code>(等价于interface{}) 和 <code>comparable</code></li>
<li>约束在接口的基础上，扩展了类型集的支持，包括类型枚举(<code>type T interface &#123;int&#125;</code>)，或类型(<code>int8|int16</code>)，近似类型(<code>~int</code>)三种特性</li>
<li>接口的本质是一种类型，可定义值，可为nil(表示没有值，但有类型信息)，类型约束本身描述类型的元信息(类型的类型)，它用来定义值通常没有意义，并且不能为nil</li>
<li>约束本身可以泛型化，这个在之后会提到</li>
</ol>
<h4 id="6-复合类型的类型集约束"><a href="#6-复合类型的类型集约束" class="headerlink" title="6. 复合类型的类型集约束"></a>6. 复合类型的类型集约束</h4><p>如果类型集约束中可以存在复合类型，再结合索引<code>[]</code>，求大小<code>len</code>，遍历<code>range</code>，字段访问<code>.</code>等针对复合类型的操作符时，有意思的问题就来了。由于不同复合类型的操作符的参数和返回值类型可能是不同的，比如如果类型集约束中包含<code>[]int</code>和<code>[]int64</code>，它们的索引操作<code>[]</code>会分别返回<code>int</code>和<code>int64</code>，那么此时编译器有两种做法:</p>
<ol>
<li>支持<code>[]</code>操作，但是需要有一个类型联合(<code>type union</code>)的新类型，来保存<code>[]</code>的返回值。比如在这里，编译器会生成<code>int</code>和<code>int64</code>的联合来保存<code>[]</code>的返回值</li>
<li>仅当<code>[]</code>对类型列表中所有的类型的参数和返回值都一致时，才允许使用<code>[]</code>，否则不允许使用<code>[]</code>并报编译错误</li>
</ol>
<p>Go目前选择第二种，因为直观上它更容易理解，具体以例子来说:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> structField <span class="keyword">interface</span> &#123;</span><br><span class="line">		<span class="keyword">struct</span> &#123; a <span class="keyword">int</span>; x <span class="keyword">int</span> &#125; |</span><br><span class="line">		<span class="keyword">struct</span> &#123; b <span class="keyword">int</span>; x <span class="keyword">float64</span> &#125; |</span><br><span class="line">		<span class="keyword">struct</span> &#123; c <span class="keyword">int</span>; x <span class="keyword">uint64</span> &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">IncrementX</span>[<span class="title">T</span> <span class="title">structField</span>]<span class="params">(p *T)</span></span> &#123;</span><br><span class="line">	v := p.x <span class="comment">// Error: 对structField type list来说，操作p.x的返回值类型不一样</span></span><br><span class="line">	v++</span><br><span class="line">	p.x = v</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> sliceOrMap <span class="keyword">interface</span> &#123;</span><br><span class="line">	[]<span class="keyword">int</span> | <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Entry</span>[<span class="title">T</span> <span class="title">sliceOrMap</span>]<span class="params">(c T, i <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">	c[i] <span class="comment">// OK. []int和map[int]int的索引操作的参数和返回值均为int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> sliceOrFloatMap <span class="keyword">interface</span> &#123;</span><br><span class="line">	[]<span class="keyword">int</span> | <span class="keyword">map</span>[<span class="keyword">float64</span>]<span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FloatEntry</span>[<span class="title">T</span> <span class="title">sliceOrFloatMap</span>]<span class="params">(c T)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> c[<span class="number">1.0</span>] <span class="comment">// Error: 对[]int和map[float64]int来说，[]操作的参数类型不一致</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>目前来说，这应该能够应付绝大部分复合类型type list的应用场景。</p>
<h4 id="7-类型参数的相互引用"><a href="#7-类型参数的相互引用" class="headerlink" title="7. 类型参数的相互引用"></a>7. 类型参数的相互引用</h4><p>Go支持同一个类型参数列表间的相互引用，如下面的泛型图类型:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> graph</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建了一个泛型接口约束来表示图的节点，该约束限制类型必须提供一个返回任意类型切片的Edges()函数</span></span><br><span class="line"><span class="keyword">type</span> NodeConstraint[Edge any] <span class="keyword">interface</span> &#123;</span><br><span class="line">	Edges() []Edge</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建了一个泛型接口约束来表示图的边，该约束限制类型必须提供一个返回两个相同的任意类型值的Nodes()函数</span></span><br><span class="line"><span class="keyword">type</span> EdgeConstraint[Node any] <span class="keyword">interface</span> &#123;</span><br><span class="line">	Nodes() (from, to Node)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 重点在这里，对泛型图类的类型约束列表中，存在相互引用</span></span><br><span class="line"><span class="comment">// 即限制了NodeConstraint的泛型类型(Edges返回的切片边类型)必须满足另一个EdgeConstraint约束</span></span><br><span class="line"><span class="comment">// EdgeConstraint 的泛型类型(Nodes返回的节点类型)必须满足NodeConstraint</span></span><br><span class="line"><span class="comment">// 即将两个接口约束相互关联了起来</span></span><br><span class="line"><span class="keyword">type</span> Graph[Node NodeConstraint[Edge], Edge EdgeConstraint[Node]] <span class="keyword">struct</span> &#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建图，由于约束本身也是泛型，所以看起来复杂一些</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span>[<span class="title">Node</span> <span class="title">NodeConstraint</span>[<span class="title">Edge</span>], <span class="title">Edge</span> <span class="title">EdgeConstraint</span>[<span class="title">Node</span>]] <span class="params">(nodes []Node)</span> *<span class="title">Graph</span>[<span class="title">Node</span>, <span class="title">Edge</span>]</span> &#123;</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 求图最短路径的方法，由于New的时候，编译器已经检查过了。因此方法中不再需要复填Node/EdgeConstraint，直接使用类型参数即可。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(g *Graph[Node, Edge])</span> <span class="title">ShortestPath</span><span class="params">(from, to Node)</span> []<span class="title">Edge</span></span> &#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p>我们可以用以下Vertex和FromTo类来实例化Graph泛型类:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Vertex <span class="keyword">struct</span> &#123; ... &#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *Vertex)</span> <span class="title">Edges</span><span class="params">()</span> []*<span class="title">FromTo</span></span> &#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> FromTo <span class="keyword">struct</span> &#123; ... &#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ft *FromTo)</span> <span class="title">Nodes</span><span class="params">()</span> <span class="params">(*Vertex, *Vertex)</span></span> &#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> g = graph.New[*Vertex, *FromTo]([]*Vertex&#123; ... &#125;)</span><br></pre></td></tr></table></figure>
<p>除了相互引用以外，类型约束还可以引用自身，比如定义类型自己的<code>Equal</code>函数:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 查找并返回e的下标，官方给出的写法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Index</span>[<span class="title">T</span> <span class="title">interface</span></span> &#123; Equal(T) <span class="keyword">bool</span> &#125;](s []T, e T) <span class="keyword">int</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 以下是等价写法</span></span><br><span class="line"><span class="keyword">type</span> Equaler[T any] <span class="keyword">interface</span> &#123; </span><br><span class="line">	Equal(T) <span class="keyword">bool</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查找并返回e的下标</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Index</span>[<span class="title">T</span> <span class="title">Equaler</span>[<span class="title">T</span>]]<span class="params">(s []T, e T)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Go编译器会推导类型参数相互引用的合理性，这进一步提升了泛型的灵活性。</p>
<h4 id="8-函数参数类型推导"><a href="#8-函数参数类型推导" class="headerlink" title="8. 函数参数类型推导"></a>8. 函数参数类型推导</h4><p>回到前面的Print，该泛型函数的调用方式形如: <code>Print[int]([]int&#123;3,1,2&#125;)</code>，但前面的类型参数相互引用中提到，编译器需要支持一定的类型推导(type inference)能力，因此实际上大部分时候，我们都不需要显式指定类型参数，直接通过<code>Print([]int&#123;3,1,2&#125;)</code>调用即可，编译器会通过实参<code>[]int&#123;3,1,2&#125;</code>匹配<code>[]T</code>，推导出T为int。</p>
<p>这种根据泛型函数调用时传入的实参类型，推敲得到泛型函数类型参数的类型的能力就是函数参数类型推导。</p>
<p>Go类型推导基于底层的类型一致(type unification)机制，本质上来说是一套类型匹配机制，对了类型A和类型B:</p>
<ol>
<li>如果A，B均不包含类型参数，那么A和B一致当且仅当A和B相同</li>
<li>仅一方包含类型参数: 如A为<code>[]map[int]bool</code>，B为<code>[]T</code>，那么称A和B是类型一致的，并且此时T为<code>map[int]bool</code></li>
<li>双方都包含类型参数: 如A为<code>[]map[T1]bool</code>，B为<code>[]map[int]T2</code>，那么A B也是类型一致的，并且T1为<code>int</code>，T2为<code>bool</code></li>
</ol>
<p>Go对泛型函数的类型参数推导是在函数调用而不是实例化的时候发生的，并且函数类型参数推导本身不包含类型约束检查和形实参赋值检查(像普通函数调用的检查一样)，这些是在类型推导完成之后才开始的。类型推导分为两个阶段:</p>
<ol>
<li>第一阶段，忽略所有的无类型(untype)实参(如字面常量<code>5</code>)，先依次推导参数列表中其它的包含类型参数的形参，如果一个类型参数在形参中出现了多次，那么它每次匹配的类型必须是相同的。注: 对于函数的类型参数推导，编译器<strong>只能对出现在函数参数列表中的类型参数进行推导</strong>，而对于那些只用于函数体或函数返回值的类型参数，编译器是无法推导的。</li>
<li>第二阶段，再开始处理无类型实参的匹配，因为其对应形参中的类型参数，可能在第一遍的时候被推敲出来了，如果对应形参还没被推导出来，给无类型实参赋予默认类型(如<code>5</code>对应<code>int</code>)，再开始推导对应形参。</li>
</ol>
<p>分为两个阶段是为了延迟无类型实参的类型推导，使泛型对于无类型实参更友好易用。举个例子:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewPair</span>[<span class="title">F</span> <span class="title">any</span>]<span class="params">(f1, f2 F)</span> *<span class="title">Pair</span>[<span class="title">F</span>]</span> &#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// OK, 第一阶段完成后(F类型仍然未知)，开始给无类型实参赋予默认类型int，两次匹配均得到F为int，前后一致，推导完成，F为int</span></span><br><span class="line">NewPair(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// OK, 第一阶段完成后，根据int64(2)推导得到F为int64，第二阶段时，所有无类型实参的类型都已经确定，推导完成，F为int64</span></span><br><span class="line"><span class="comment">// 如果不是两阶段推导，那么这种情况就无法被支持</span></span><br><span class="line">NewPair(<span class="number">1</span>, <span class="keyword">int64</span>(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// Failed，第一阶段完成后(F未知)，开始分别给无类型参数赋予默认值int和float64，F前后匹配两次的类型不一致，推导失败，编译器报错</span></span><br><span class="line">NewPair(<span class="number">1</span>, <span class="number">2.5</span>)</span><br></pre></td></tr></table></figure>
<h4 id="9-约束类型推导"><a href="#9-约束类型推导" class="headerlink" title="9. 约束类型推导"></a>9. 约束类型推导</h4><p>约束类型推导，提供了基于一个类型参数，推导出另一个类型参数的能力，通常应用在多个类型参数之间有关联时。如前面定义Graph泛型类时，用到了泛型接口约束:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> NodeConstraint[Edge any] <span class="keyword">interface</span> &#123;</span><br><span class="line">	Edges() []Edge</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>泛型接口约束允许定义泛型类型参数之间的关系，但是由于约束本身也是泛型的，因此对接口约束中的类型参数也需要推导，这个步骤发生在函数类型参数推导之后，具体的推导规则仍然是根据已知的具象的实参推导未知的类型参数。具体推导规则描述起来比较抽象，仍然以官方例子来说:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 将数字切片中所有元素翻倍并返回</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Double</span>[<span class="title">E</span> <span class="title">constraints</span>.<span class="title">Number</span>]<span class="params">(s []E)</span> []<span class="title">E</span></span> &#123;</span><br><span class="line">	r := <span class="built_in">make</span>([]E, <span class="built_in">len</span>(s))</span><br><span class="line">	<span class="keyword">for</span> i, v := <span class="keyword">range</span> s &#123;</span><br><span class="line">		r[i] = v + v</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> MySlice []<span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回值是[]int，而不是MySlice</span></span><br><span class="line"><span class="keyword">var</span> V1 = Double(MySlice&#123;<span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>为了<code>Double</code>函数更易用，我们需要为<code>Double</code>的参数即切片本身定义一个类型参数(这样才能定义相同类型的返回值)，但是我们同时需要约束这个切片的元素类型，因此这里需要定义泛型接口约束:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> SC[E any] <span class="keyword">interface</span> &#123;</span><br><span class="line">	[]E</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义泛型约束 SC[E]，并且约束E的类型为数字</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DoubleDefined</span>[<span class="title">S</span> <span class="title">SC</span>[<span class="title">E</span>], <span class="title">E</span> <span class="title">constraints</span>.<span class="title">Number</span>]<span class="params">(s S)</span> <span class="title">S</span></span> &#123;</span><br><span class="line">	<span class="comment">// Note that here we pass S to make, where above we passed []E.</span></span><br><span class="line">	r := <span class="built_in">make</span>(S, <span class="built_in">len</span>(s))</span><br><span class="line">	<span class="keyword">for</span> i, v := <span class="keyword">range</span> s &#123;</span><br><span class="line">		r[i] = v + v</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> MySlice []<span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// V3的类型是MySlice</span></span><br><span class="line"><span class="keyword">var</span> V3 = DoubleDefined(MySlice&#123;<span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>上例再一次说明了泛型接口约束存在的必要性，按照我的理解，泛型接口约束允许<strong>对一个类型分层次的约束，以及完成约束与约束之间的关联</strong>。回到对约束的类型推导上来，在<code>DoubleDefined</code>中，函数的类型参数推导没有办法推导<code>E</code>的类型(因为它没有出现在函数参数列表中)，它只能推导得到<code>S -&gt; MySlice</code>，这个时候就需要约束类型参数推导来完成剩下的工作了，<code>MySlice</code>是已知的具象的类型，从它对应的<code>SC[E]</code>约束开始推导，<code>SC[E]</code>类型列表中只有一个类型<code>[]E</code>，因此<code>MySlice</code>只能<code>[]E</code>类型一致，推出<code>E -&gt; int</code>。</p>
<p>约束的类型推导的时机在函数参数类型推导之后，但是仍然在约束检查之前。</p>
<h4 id="10-小结"><a href="#10-小结" class="headerlink" title="10. 小结"></a>10. 小结</h4><p>以上主要是简单归纳了Go泛型文档中，偏应用层面的一些特性，简单小结一下:</p>
<ol>
<li>和其它语言的泛型类似，本质是将类型参数化，支持函数泛型和类型泛型，但目前<a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/43651-type-parameters.md#no-parameterized-methods">暂不支持方法泛型</a></li>
<li>通过基于接口的类型约束来描述和限制类型参数(bounded generic types)</li>
<li>类型约束对接口扩展了类型枚举、类型近似、类型联合等元素，用以支持运算符的泛型操作</li>
<li>类型约束对外描述类型参数所需实现的方法或允许的类型集</li>
<li>类型约束对内定义了类型参数所允许调用的方法和支持的操作</li>
<li>类型约束本身也可以泛型化，用以类型参数的相互引用或自引用</li>
<li>类型推导使得大部分时候调用方无需显式指定类型参数</li>
<li>本质上是编译期泛型，泛型类型的反射包括完整的编译时类型信息</li>
<li>不支持元编程、偏特化、变参等高级特性</li>
</ol>
<p>在大部分的设计取舍上，Go官方会优先考虑构建大型项目所必需的实用性(可读+易用)，类型约束不只是type checker，更是一层设计上不可缺少的契约层，尽可能地将大部分信息都明确地内聚到这层契约上。有时候为了实用性，Go会选择牺牲一定的灵活性，类型集约束就是一个例子。</p>
<p>这里顺便再提下类型集约束，它是把双刃剑，一方面很大程度解决了Go没有运算符重载的问题(这里并不是说有运算符重载就一定香，它带来的代码理解负担也需要慎重考虑)，但另一方面，类型集约束也带来了如下问题:</p>
<ol>
<li>打破了接口类型约束的封装，甚至允许将泛型约束”降级”为具体类型(只有一个类型的类型列表约束)</li>
<li>接口约束和类型列表约束两者组合可能定义出永远不能被实例化的约束</li>
<li>类型列表约束没有根治没有运算符重载的问题，还加了个预定义约束<code>comparable</code>补丁</li>
</ol>
<p>因此个人觉得，类型列表约束需要慎用，特别是对于自定义类型。</p>
<p>总的来说，这次的Go泛型可以说是众望所归，整体上还是比较实用易用。我已经有点跃跃欲试了，准备在实践中重写部分代码，增强复用性、扩展性以及运行性能。</p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>软件工程能力</title>
    <url>/2021/07/software-engineering-ability/</url>
    <content><![CDATA[<p>启发于<a href="https://mp.weixin.qq.com/s/hJS5LJRZkMZmHm6g2R_jpw">漫谈软件工程能力</a></p>
<p><img src="assets/image/202107/软件工程能力.png" alt=""></p>
]]></content>
      <categories>
        <category>mindmap</category>
      </categories>
      <tags>
        <tag>engineer</tag>
      </tags>
  </entry>
  <entry>
    <title>初识 Rust</title>
    <url>/2020/02/rust-basic/</url>
    <content><![CDATA[<p>之前被同事安利了很多次Rust，周末没事去<a href="https://kaisery.github.io/trpl-zh-cn/title-page.html">Rust官方文档</a>学习了下，记录一些对Rust语言粗浅理解。</p>
<h3 id="一-所有权系统"><a href="#一-所有权系统" class="headerlink" title="一. 所有权系统"></a>一. 所有权系统</h3><p>要说Rust语言的核心优势，应该就是运行效率+内存安全了，这两者都与其独树一帜的所有权系统有关。要谈所有权系统，GC是个不错的切入点，众所周知，编程语言GC主要包含两种: 手动GC和自动GC，它们各有利弊，总的来说是运行效率和内存安全之间的权衡取舍。而Rust则尝试两者兼顾，Rust的GC，我将其理解为半自动GC或编译期GC，即开发者配合编译器通过所有权约束来明确变量的生命周期，这样Rust在编译期就已经知道内存应该何时释放，不需要运行时通过复杂的<a href="https://wudaijun.com/2017/12/gc-study/">GC算法</a>去解析变量的引用关系，也无需像C/C++让开发者对各种内存泄露、越界访问等问题如履薄冰。这也是Rust敢号称可靠的系统级编程语言，运行时效率叫板C/C++的底气来源。</p>
<span id="more"></span>
<p>Rust GC的核心就是所有权系统，它基于以下事实:</p>
<ol>
<li>编译器能够解析局部变量的生命周期，正确管理栈内存的收缩扩张</li>
<li>堆内存最终都是通过栈变量来读取和修改</li>
</ol>
<p>那么，我们能否让堆内存管理和栈内存管理一样轻松，成为编译期就生成好的指令呢？Rust就是沿着这个思路走的，它将堆内存的生命周期和栈变量绑定在一起，当函数栈被回收，局部变量失效时，其对应的堆内存也会被回收。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="keyword">let</span> s = <span class="built_in">String</span>::from(<span class="string">&quot;hello&quot;</span>); <span class="comment">// 从此处起，s 是有效的</span></span><br><span class="line">    <span class="comment">// 使用 s</span></span><br><span class="line">&#125;                               <span class="comment">// 此作用域已结束，</span></span><br><span class="line">                                <span class="comment">// s 不再有效</span></span><br></pre></td></tr></table></figure>
<p>如代码所示，局部变量s和对应的字符串堆内存绑定在了一起，称s对这块堆内存具备所有权，当s无效时，对应String堆内存也会回收。编译器知道s的作用域，也就自然知道何时执行对String执行回收。</p>
<p>Rust所有权系统的核心规则如下:</p>
<ol>
<li>Rust 中的每一个值都有一个被称为其 所有者（owner）的变量。</li>
<li>值有且只有一个所有者。</li>
<li>当所有者（变量）离开作用域，这个值将被丢弃。</li>
</ol>
<p>规则需要简单，要达成这套规则的完备性，还需要其它系统方方面面的协助和完善。下面展开聊聊。</p>
<h4 id="1-控制权转移"><a href="#1-控制权转移" class="headerlink" title="1. 控制权转移"></a>1. 控制权转移</h4><p>当发生局部变量赋值，如执行 <code>let s = String::from(&quot;big str&quot;); let s1 = s;</code> 时，Rust要么执行深拷贝，代价是运行时开销，要么浅拷贝，代价是s和s1只能有其中一个对String有所有权(否则会导致对堆内存的二次回收)。Rust选择了第二种方案，即s1拥有String的所有权，s在赋值给s1后不再有效，这之后对s的访问将会导致编译错误。在Rust中，这叫做<strong>控制权转移</strong>，此时也称<code>let s1 = s;</code>是<strong>转移语义</strong>，在Rust中，变量与值的交互方式分为以下几种:</p>
<ol>
<li>移动(Move)语义: 浅拷贝，且会发生控制权转移，这是Rust的默认行为</li>
<li>克隆(Clone)语义: 深拷贝，通过<strong>显式</strong>调用clone()来避免控制权转移，如 <code>let s1 = s.clone();</code>，如此s1和s均可继续使用</li>
<li>复制(Copy)语义: 浅拷贝，主要针对值语义这类浅拷贝安全的场景，Rust默认为整型、布尔、字符、浮点、以及元组(当且仅当其包含的类型也都实现Copy的时候)实现了复制语义，因此对于<code>let a = 5; let b = a;</code>，不需要显式Clone，也不会发生控制转移，a和b可继续使用</li>
<li>引用(Borrowing)语义: 也叫借用语义，Rust引用类似其它语言的指针，Rust创建引用的过程也称为借用，它允许你使用值但不获取其所有权</li>
</ol>
<p>Clone是比Copy更基础的概念，对支持Copy语义的对象，它必然也是支持Clone的(值语义的浅拷贝就是它的深拷贝)。实现上来说，Clone，Copy均是Rust提供的trait(类似OOP接口，但可包含默认实现，后面Rust OOP编程中再详说)，其中Clone trait依赖Copy trait，简单来说: 所有想要实现Copy trait的类，都需要同时实现Clone trait。这样从实现层保证了所有可Copy的对象，必然是可Clone的。</p>
<p>小结下Copy和Clone的区别和联系:</p>
<ul>
<li>Clone是显式的，Rust不会在任何地方自动调用clone()执行深拷贝。Copy是隐式的，编译期识别到Copy语义对象的复制时，会自动执行简单浅拷贝，并且不会发生控制转移</li>
<li>Clone是可重写的，各个类型可以自定义自己的clone()方法。Copy是不可重写的，因为编译器直接执行栈内存拷贝就行了，如果某个类型需要重写Copy，那么它就不应该是Copy语义的</li>
<li>支持Copy语义的类型必然支持Clone语义</li>
</ul>
<p>下面这个例子进一步说明几种赋值语义，引用语义的细节将单独在下一节展开讨论。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="comment">// === Case1: 移动 ===</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">MyStruct</span></span> &#123;</span><br><span class="line">    part: <span class="built_in">i32</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> a = MyStruct &#123;part: <span class="number">123</span>&#125;;</span><br><span class="line">    <span class="keyword">let</span> b = a;</span><br><span class="line">    <span class="comment">// 编译错误: a的数据控制权转移到了b，a将无法再被使用</span></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;&quot;</span>, i.part, j.part)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// === Case2: 克隆 ===</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">MyStruct</span></span> &#123;</span><br><span class="line">    part: <span class="built_in">i32</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现Clone trait</span></span><br><span class="line"><span class="keyword">impl</span> <span class="built_in">Clone</span> <span class="keyword">for</span> MyStruct &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">clone</span></span>(&amp;<span class="keyword">self</span>) -&gt; <span class="keyword">Self</span> &#123;</span><br><span class="line">    	 <span class="comment">// 等价于 MyStruct &#123; part: self.part &#125;，因为i32是满足复制语义的(浅拷贝即深拷贝)</span></span><br><span class="line">        MyStruct &#123; part: <span class="keyword">self</span>.part.clone() &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> a = MyStruct &#123;part: <span class="number">123</span>&#125;;</span><br><span class="line">    <span class="keyword">let</span> b = a.clone();	<span class="comment">// 显式指明clone()，执行深拷贝</span></span><br><span class="line">    <span class="comment">// OK. 之后a和b都具有各自独立的数据所有权，因此均可使用</span></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;&quot;</span>, a.part, b.part)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// === Case3: 复制 ===</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// derive是Rust中的属性，类似类型注解的概念</span></span><br><span class="line"><span class="comment">// #[derive(Copy, Clone)] 表示在 MyStruct 上实现Copy，Clone两个trait，并使用这两个trait的默认实现</span></span><br><span class="line"><span class="comment">// Clone trait默认实现会逐个调用struct的字段的clone()方法来实现深拷贝，类似前面Case2手动重写的clone()方法</span></span><br><span class="line"><span class="comment">//            如果有字段未实现Clone trait(比如包含另一个自定义Struct)，则编译错误</span></span><br><span class="line"><span class="comment">// Copy trait不需要也不允许重写，如果有字段未实现Copy trait(比如包含String字段)，同样会触发编译错误</span></span><br><span class="line"><span class="comment">// 对于MyStruct而言，由于它实现了Copy trait，因此它的clone()方法完全可以直接写成:</span></span><br><span class="line"><span class="comment">// fn clone(&amp;self) -&gt; Self &#123;</span></span><br><span class="line"><span class="comment">// 		*self</span></span><br><span class="line"><span class="comment">// &#125; </span></span><br><span class="line"><span class="meta">#[derive(Clone, Copy)]</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">MyStruct</span></span> &#123;</span><br><span class="line">    part: <span class="built_in">i32</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> a = MyStruct &#123;part: <span class="number">123</span>&#125;;</span><br><span class="line">    <span class="comment">// 等价于 let mut b = a.clone();</span></span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> b = a;</span><br><span class="line">    b.part = <span class="number">456</span>;</span><br><span class="line">    <span class="comment">// OK. a和b具有独立的数据所有权</span></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;&quot;</span>, a.part, b.part)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// === Case4: 引用 ===</span></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">	<span class="keyword">let</span> a = MyStruct&#123;part: <span class="number">123</span>&#125;;</span><br><span class="line">	<span class="keyword">let</span> b = &amp;a;</span><br><span class="line">	<span class="comment">// OK. b只是引用了a，并不会发生控制权转移</span></span><br><span class="line">	<span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;&quot;</span>, a.part, b.part)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Rust编译器会识别和检查变量类型是否实现或调用了指定trait，从而决定变量赋值是什么语义，以确定控制权归属。</p>
<h4 id="2-使用引用来避免控制权转移"><a href="#2-使用引用来避免控制权转移" class="headerlink" title="2. 使用引用来避免控制权转移"></a>2. 使用引用来避免控制权转移</h4><p>按照局部变量赋值的控制权转移规则，函数返回值和函数参数的隐式赋值也会导致控制权转移:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">        <span class="keyword">let</span> s1 = <span class="built_in">String</span>::from(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">        <span class="comment">// 调用calculate_length后，s1的控制权转移给了函数实参，在这之后s1就失效了</span></span><br><span class="line">        <span class="comment">// 为了后续能够继续访问String数据，需要通过返回值将控制权又转移回来</span></span><br><span class="line">        <span class="keyword">let</span> (s2, len) = calculate_length(s1); </span><br><span class="line">        <span class="comment">// 这里就不能继续访问s1了，只能使用s2</span></span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;The length of &#x27;&#123;&#125;&#x27; is &#123;&#125;.&quot;</span>, s2, len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">calculate_length</span></span>(s: <span class="built_in">String</span>) -&gt; (<span class="built_in">String</span>, <span class="built_in">usize</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> length = s.len();</span><br><span class="line">        (s, length)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，在控制权转移规则下，这种控制权转来转去的方式非常麻烦。这种情况下，更合适的做法是使用引用，在不转移控制权的前提下传递参数，但这里我们以另一个函数<code>first_word</code>为例，该函数求字符串内空格分隔的第一个单词:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="comment">// first_word 通过引用借用了 s1，不发生控制权转移，函数返回后也不会回收形参s指向的值</span></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">first_word</span></span>(s: &amp;<span class="built_in">String</span>) -&gt; &amp;<span class="built_in">str</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> bytes = s.as_bytes();</span><br><span class="line">    <span class="keyword">for</span> (i, &amp;item) <span class="keyword">in</span> bytes.iter().enumerate() &#123;</span><br><span class="line">        <span class="keyword">if</span> item == <span class="string">b&#x27; &#x27;</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> &amp;s[<span class="number">0</span>..i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &amp;s[..]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> s = <span class="built_in">String</span>::from(<span class="string">&quot;hello world&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> word = first_word(&amp;s);</span><br><span class="line">    s.clear();</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;the first word is: &#123;&#125;&quot;</span>, word);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>选用<code>fist_word</code>是因为它展示了Rust引用的另一个有意思的特性。由于<code>first_word</code>返回的引用结果是基于引用参数的局部引用，因此当main调用<code>s.clear()</code>时，事实上也导致word引用失效了，导致得到非预期的结果。这在其它语言是指针/引用带来的难点之一，即要依靠开发者去解析内存引用关系，确保对内存的修改不会有非预期的副作用。而在Rust中，上面的代码不会通过编译！</p>
<p>和变量一样，Rust中的引用分为可变引用和不可变引用，可变引用需要在可变变量的基础上再显式声明: 如<code>let r = &amp;mut s;</code> Rust编译器会想尽办法保证<strong>引用的两大原则</strong>:</p>
<ol>
<li>在任意给定时间，要么只能有一个可变引用，要么只能有多个不可变引用</li>
<li>引用必须总是有效的 (例如函数返回一个局部变量的引用将会得到编译错误)</li>
</ol>
<p>结合上面的规则，<code>s.clear</code>需要清空string，因此它会尝试获取s的一个可变引用(函数原型为:<code>clear(&amp;mut self)</code>)，而由于s已经有一个不可变引用word，这破坏了规则1，因此编译器会报错。</p>
<p>对于规则2，编译器的<strong>借用检查器</strong>会比较引用和被引用数据的生命周期，确保不会出现悬挂引用，如以下代码不会编译通过:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="comment">// rust不允许存在空值，确切地说是不允许使用空值，这里只是声明r，在第一次使用r前必须先初始化它，否则编译器会报错</span></span><br><span class="line">    <span class="keyword">let</span> r;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">let</span> x = <span class="number">5</span>;</span><br><span class="line">        r = &amp;x;</span><br><span class="line">    &#125; <span class="comment">// 这之后 r 引用的 x 已经脱离作用域失效了，而 r 还在有效作用域内，继续访问 r 将会导致非预期结果</span></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;r: &#123;&#125;&quot;</span>, r);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上对引用的限制，有个非常显著的好处就是避免并发数据竞争问题:</p>
<ol>
<li>两个或更多指针同时访问同一数据</li>
<li>至少有一个指针被用来写入数据</li>
<li>没有同步数据访问的机制</li>
</ol>
<p>Rust可以在编译期就避免大部分的数据竞争！</p>
<h4 id="3-生命周期注解"><a href="#3-生命周期注解" class="headerlink" title="3. 生命周期注解"></a>3. 生命周期注解</h4><p>有Rust编译器的殚精竭虑，开发者就能安全使用这套所有权系统而高枕无忧了么，当然不是，编译器所知也仅限于编译期就能获得的信息，比如以下代码:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">longest</span></span>(x: &amp;<span class="built_in">str</span>, y: &amp;<span class="built_in">str</span>) -&gt; &amp;<span class="built_in">str</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> x.len() &gt; y.len() &#123;</span><br><span class="line">        x</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        y</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> string1 = <span class="built_in">String</span>::from(<span class="string">&quot;abcd&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> string2 = <span class="string">&quot;xyz&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> result = longest(string1.as_str(), string2);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;The longest string is &#123;&#125;&quot;</span>, result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码无法通过编译，因为longest函数的参数和返回值都是引用，编译器无法获悉函数返回的引用是来自于x还是来自于y(这是运行时的东西)，那么前面说的借用检查器也就无法通过分析作用域保证引用的有效性了。</p>
<p>这个时候就需要建立一套额外的规则来辅助借用检查器，将本来应该在运行时决议的事情放到编译器来完成，Rust把这套规则叫做<strong>生命周期注解</strong>，生命周期注解本身不影响引用的生命周期，它用来指定函数的引用参数和引用返回值之间的生命周期对应关系，这样编译器就可以按照这种关系进行引用生命周期推敲，生命周期注释的语法和泛型类似(这也是比较有意思的一点，将引用生命周期像类型一样来抽象):</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="comment">// &#x27;a 和泛型中的T一样，这里的注解表示:  &#x27;a 的具体生命周期等同于 x 和 y 的生命周期中较小的那一个</span></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">longest</span></span>&lt;<span class="symbol">&#x27;a</span>&gt;(x: &amp;<span class="symbol">&#x27;a</span> <span class="built_in">str</span>, y: &amp;<span class="symbol">&#x27;a</span> <span class="built_in">str</span>) -&gt; &amp;<span class="symbol">&#x27;a</span> <span class="built_in">str</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> x.len() &gt; y.len() &#123;</span><br><span class="line">        x</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        y</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 下面是一些例子，说明Rust编译器是如何依靠注解来保证引用的有效性的</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 例1 </span></span><br><span class="line"><span class="comment">// 根据longest的生命周期注解，result的生命周期应该等于string1,string2中较短的那个</span></span><br><span class="line"><span class="comment">// 而这里result的生命周期明显大于string2，因此借用检查器会报错</span></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> string1 = <span class="built_in">String</span>::from(<span class="string">&quot;long string is long&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> result;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">let</span> string2 = <span class="built_in">String</span>::from(<span class="string">&quot;xyz&quot;</span>);</span><br><span class="line">        result = longest(string1.as_str(), string2.as_str());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;The longest string is &#123;&#125;&quot;</span>, result);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例2</span></span><br><span class="line"><span class="comment">// 这里的result虽然早于string2声明，但由于Rust不能使用未赋值的变量，因此result的生命周期其实是从第一次赋值开始的</span></span><br><span class="line"><span class="comment">// 从而满足longest引用返回值生命周期&lt;=任一引用参数生命周期，能够正常运行</span></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> string1 = <span class="built_in">String</span>::from(<span class="string">&quot;long string is long&quot;</span>);</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">let</span> result;</span><br><span class="line">        <span class="keyword">let</span> string2 = <span class="built_in">String</span>::from(<span class="string">&quot;xyz&quot;</span>);</span><br><span class="line">        result = longest(string1.as_str(), string2.as_str());</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;The longest string is &#123;&#125;&quot;</span>, result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 例3</span></span><br><span class="line"><span class="comment">// 如果我们将longest改成这样，它将不能通过编译</span></span><br><span class="line"><span class="comment">// 因为编译器看到了longest函数返回了y，然而生命周期注解中，输入引用y和返回值引用是两个独立的生命周期，互不关联。编译器觉得自己被欺骗了。</span></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">longest</span></span>&lt;<span class="symbol">&#x27;a</span>,<span class="symbol">&#x27;b</span>&gt;(x: &amp;<span class="symbol">&#x27;a</span> <span class="built_in">str</span>, y: &amp;<span class="symbol">&#x27;b</span> <span class="built_in">str</span>) -&gt; &amp;<span class="symbol">&#x27;a</span> <span class="built_in">str</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> x.len() &gt; y.len() &#123;</span><br><span class="line">        x</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        y</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>生命周期注解也可用于结构体中，用于声明结构体与其字段的生命周期关系:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这个标注意味着 ImportantExcerpt 的实例不能比其 part 字段中的引用存在的更久</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ImportantExcerpt</span></span>&lt;<span class="symbol">&#x27;a</span>&gt; &#123;</span><br><span class="line">    part: &amp;<span class="symbol">&#x27;a</span> <span class="built_in">str</span>,</span><br><span class="line">    <span class="comment">// 如果part是String的引用，则会编译错误，因为String拥有自己数据的所有权</span></span><br><span class="line">    <span class="comment">// 生命周期注解只用来标注引用与引用间的生命周期关系(以保证引用的有效性)，而不能用于强行关联两个独立的生命周期</span></span><br><span class="line">    <span class="comment">// part: &#x27;a String,</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> i = ImportantExcerpt &#123; part: <span class="string">&quot;123&quot;</span>&#125;;</span><br><span class="line">    &#123;</span><br><span class="line">    	  <span class="comment">// 编译错误: 结构体实例i的生命周期比其引用字段part所引用的String s更长，违反了生命周期注解约束</span></span><br><span class="line">        <span class="keyword">let</span> s = <span class="built_in">String</span>::from(<span class="string">&quot;123456&quot;</span>);</span><br><span class="line">        <span class="keyword">let</span> part = s.as_str();</span><br><span class="line">        <span class="comment">// 编译成功: 这里part是字面量的不可变引用，而字面量存储二进制程序的特定位置，因此满足生命周期注解约束</span></span><br><span class="line">        <span class="comment">// let part = &quot;123456&quot;;</span></span><br><span class="line">        </span><br><span class="line">        i.part = part;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, i.part)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="4-智能指针"><a href="#4-智能指针" class="headerlink" title="4. 智能指针"></a>4. 智能指针</h4><p>前面讨论的控制权转移(确保一个值只有一个所有者，它负责这个值的回收)，引用(也就是指针，用于避免不必要的控制权转移)，生命周期注解(用于协助编译期保证引用的有效性)，主要都是围绕栈内存来的，只有String是个特例，它的实际内存会分配在堆上，以满足可变动态长度字符串的需求。在Rust中，栈内存和堆内存是被明确指定和分配的，Rust开发者通常会在出现以下情况时考虑用堆:</p>
<ol>
<li>当有一个在编译时未知大小的类型，而又想要在需要确切大小的上下文中使用这个类型值的时候: 比如在String，链表</li>
<li>当有大量数据并希望在确保数据不被拷贝的情况下转移所有权的时候</li>
<li>当希望拥有一个值并只关心它的类型是否实现了特定 trait 而不是其具体类型的时候</li>
</ol>
<p>在Rust中，有如下几种指针:</p>
<ol>
<li><code>Box&lt;T&gt;</code>: 运行将数据分配在堆上，留在栈上的是指向堆数据的指针。<code>Box&lt;T&gt;</code>会在智能指针作用域结束时回收对应堆内存。<code>Box&lt;T&gt;</code>本身的是移动语义的，类似C++ <code>auto_ptr</code>。<code>Box&lt;T&gt;</code>与Rust引用的区别在于，前者指向的是堆内存，因此总能保证是有效的，而后者通常指向的是栈内存，因此需要借用检查器，生命周期注解等机制来确保引用是有效的。</li>
<li><code>Rc&lt;T&gt;</code>: <code>Rc&lt;T&gt;</code>类似C++<code>shared_ptr</code>，基于引用计数而非控制权+作用域来回收堆内存，但<code>Rc&lt;T&gt;</code>对共享数据是只能读的(仍然受限于借用器检查，用于避免数据竞争)。<code>Rc&lt;T&gt;</code>默认也是移动语义的，可以调用<code>Rc::Clone(rc)</code>方法(比<code>rc.clone()</code>方法更轻量)以获得独立的<code>Rc&lt;T&gt;</code>并增加引用计数。</li>
<li><code>RefCell&lt;T&gt;</code>: 能够基于不可变值修改其内部值，对<code>RefCell&lt;T&gt;</code>的借用检查将<strong>发生运行时而非编译期</strong>。如以下代码会导致运行Panic:</li>
</ol>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="comment">// RefCell&lt;T&gt;例子，以下代码会编译成功，但是运行Panic</span></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> x = RefCell::new(<span class="number">123</span>);</span><br><span class="line">    <span class="keyword">let</span> a = x.borrow();</span><br><span class="line">    <span class="keyword">let</span> b = x.borrow();</span><br><span class="line">    <span class="comment">// OK. 运行时借用检查允许多个不可变引用</span></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;&quot;</span>, a, b);</span><br><span class="line">    <span class="comment">// Panic here! 运行时检查发现同时存在可变引用和不可变引用</span></span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> c = x.borrow_mut();</span><br><span class="line">    *c = <span class="number">456</span>;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>RefCell&lt;T&gt;</code>在天生保守的Rust编译规则下，为开发者提供了更高的灵活性，但也需要承担更大的运行时风险。一个<code>RefCell&lt;T&gt;</code>的应用场景是，通过Mock将原本的外部IO行为(<code>&amp;self</code>参数的trait)，替换为内部数据变更(<code>&amp;self</code>参数不变，但MockStruct通过持有<code>RefCell&lt;T&gt;</code>实现内部数据可变性)。</p>
<p>另外，由于<code>Rc&lt;T&gt;</code>支持对相同数据同时存在多个所有者，但是只能读数据，而<code>RefCell&lt;T&gt;</code>允许在不可变语义下实现内部可变性，那么<code>Rc&lt;RefCell&lt;T&gt;&gt;</code>就可以实现基于引用计数，可存在多个具有读写数据权限的智能指针(完整版C++ <code>shared_ptr</code>):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fn main() &#123;</span><br><span class="line">    let x &#x3D; &amp;Rc::new(RefCell::new(123));</span><br><span class="line">    let a &#x3D; Rc::clone(x);</span><br><span class="line">    let b &#x3D; Rc::clone(x);</span><br><span class="line">    let c &#x3D; Rc::clone(x);</span><br><span class="line">    *b.borrow_mut() &#x3D; 456;</span><br><span class="line">    *c.borrow_mut() &#x3D; 789;</span><br><span class="line">    &#x2F;&#x2F; Output:</span><br><span class="line">    &#x2F;&#x2F; RefCell &#123; value: 789 &#125;, RefCell &#123; value: 789 &#125;, RefCell &#123; value: 789 &#125;</span><br><span class="line">    println!(&quot;&#123;:?&#125;, &#123;:?&#125;, &#123;:?&#125;&quot;, a, b, c)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h4><p>先总结下前面提到的Rust的各种机制是如何配合所有权系统来实现通过栈内存来管理堆内存，做到运行时零GC负担的:</p>
<ol>
<li>浅拷贝对象: 如i32，float，plain struct，默认直接执行栈拷贝，不涉及控制权转移，和常规语言无二</li>
<li>深拷贝对象: 比如String，通过控制权转移来保证单所有者，在所有者退出作用域时，通过Drop trait确保数据被正确回收</li>
<li>引用: 本质只是指针地址，借助编译器的借用检查器来避免数据竞态并保证引用的有效性，有时还需要开发者通过生命周期注解进行协助</li>
<li>智能指针: 和String类似，也是深拷贝对象，但提供了更灵活的内存控制，包括避免深拷贝和控制权转移，动态大小，引用计数共享数据，内部可变性等</li>
</ol>
<p>总之，Rust编译器是天生保守的，它会尽全力拒绝那些可能不正确的程序，Rust确实能在编译期检查到很多大部分语言只能在运行期暴露的错误，这是Rust最迷人的地方之一。但是，与此同时，Rust编译器也可能会拒绝一些正确的程序，此时就需要如生命周期注解，<code>Rc&lt;T&gt;</code>等工具来辅助编译器，甚至通过<code>RefCell&lt;T&gt;</code>，unsafe等方案来绕过编译器检查。把<strong>编译器做厚</strong>，把<strong>运行时做薄</strong>，是Rust安全且高效，能够立足于系统级编程语言的根本。</p>
<h3 id="二-函数式特性"><a href="#二-函数式特性" class="headerlink" title="二. 函数式特性"></a>二. 函数式特性</h3><p>我在<a href="https://wudaijun.com/2018/05/understand-functional-programing/">理解函数式编程</a>中提到，现在的语言不再受限于各种编程范式的约束，而是更偏实用主义，Rust也是这样的语言，它受函数式语言的影响颇深。</p>
<h4 id="1-函数是第一类对象"><a href="#1-函数是第一类对象" class="headerlink" title="1. 函数是第一类对象"></a>1. 函数是第一类对象</h4><p>函数可作为参数，返回值，动态创建，并且动态创建的函数具备捕获当前作用域上下文的能力，也就是闭包，提供标准库容器迭代器模式并支持开发者扩展等，这些都是如今大部分语言的标配，无需过多解释。</p>
<p>有一点需要提一下，Rust的闭包如果要捕获上下文的话，也要考虑到所有权转移的问题(转移，引用，可变引用)，并且Rust编译器会尝试自动推测你的闭包希望以那种方式来捕获环境。</p>
<h4 id="2-变量可变性"><a href="#2-变量可变性" class="headerlink" title="2. 变量可变性"></a>2. 变量可变性</h4><p>Rust中的变量默认是不可变的，但也支持通过<code>let mut x = 5;</code>声明可变变量。合理使用不可变变量能够利用编译器检查使代码易于推导，可重入，无副作用。</p>
<h4 id="3-模式匹配"><a href="#3-模式匹配" class="headerlink" title="3. 模式匹配"></a>3. 模式匹配</h4><p>模式匹配我最早在Erlang中接触，这个起初不是很适应的功能在用习惯之后，会发现它可以为程序提供更多对程序控制流的支配权，写出强大而简洁的代码。Rust也支持模式匹配:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Point</span></span> &#123;</span><br><span class="line">    x: <span class="built_in">i32</span>,</span><br><span class="line">    y: <span class="built_in">i32</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> p = Point &#123; x: <span class="number">7</span>, y: <span class="number">2</span> &#125;; <span class="comment">// 构造一个Point值匹配给命名变量p</span></span><br><span class="line">    <span class="keyword">match</span> p &#123;</span><br><span class="line">        Point &#123; x :<span class="number">0</span>, y&#125; =&gt; <span class="built_in">println!</span>(<span class="string">&quot;case 1: &#123;&#125;&quot;</span>, y), 	<span class="comment">// 匹配p.x==0</span></span><br><span class="line">        Point &#123; x, y: <span class="number">0</span>..=<span class="number">2</span> &#125; =&gt; <span class="built_in">println!</span>(<span class="string">&quot;case 2: &#123;&#125;&quot;</span>, x), <span class="comment">// 匹配0&lt;=p.y&lt;=2</span></span><br><span class="line">        Point &#123; x: a, y: _ &#125; =&gt; <span class="built_in">println!</span>(<span class="string">&quot;case 3: &#123;&#125;&quot;</span>, a), <span class="comment">// 匹配其它情况，并将字段x的值赋给变量a</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> Point &#123;x: <span class="number">7</span>, y: b&#125; = p &#123; <span class="comment">// 匹配 x==7，并取出y值</span></span><br><span class="line">    	<span class="built_in">println!</span>(<span class="string">&quot;case 4: &#123;&#125;&quot;</span>, b)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="三-面向对象特性"><a href="#三-面向对象特性" class="headerlink" title="三. 面向对象特性"></a>三. 面向对象特性</h3><h4 id="1-Object"><a href="#1-Object" class="headerlink" title="1. Object"></a>1. Object</h4><p>Rust提供基本的结构体字段封装和字段访问控制(可见性)，并且允许在此之上扩展结构体方法及方法的可见性:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">MyStruct</span></span> &#123;</span><br><span class="line">    x : <span class="built_in">i32</span>     <span class="comment">// 默认为私有字段</span></span><br><span class="line">    <span class="keyword">pub</span> name : <span class="built_in">String</span> <span class="comment">// 指定为公有字段</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> MyStruct &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">getx</span></span>(&amp;<span class="keyword">self</span>) -&gt; <span class="built_in">i32</span> &#123;</span><br><span class="line">        <span class="keyword">self</span>.x</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-继承"><a href="#2-继承" class="headerlink" title="2. 继承"></a>2. 继承</h4><p>传统OOP的继承(subclass)主要有两个作用，<strong>代码复用</strong> 和 <strong>子类化(subtype)</strong> ，如C++的继承就同时实现了这两点，继承是一把双刃剑，因为传统继承不只是有代码复用和子类化的功能，它还做到了字段复用，即对象父子内存模型的一致性，当引入对象内存模型之后，各种多重继承，菱形继承所带来的问题不堪其扰。<strong>虚基类</strong>，<strong>显式指定父类作用域</strong>或者干脆<strong>不允许多重继承</strong>等方案也是头痛医头，脚痛医脚。</p>
<p>近年兴起的新语言，如Golang就没有继承，它通过内嵌匿名结构体来实现代码复用，但丢失了dynamic dispatch，通过interface{}(声明式接口，隐式implement)来实现子类化，但也带来了运行时开销。</p>
<p>关于subclass, subtype, dynamic dispatch等概念，可以参考我之前的<a href="https://wudaijun.com/2019/05/programing-paradigm/">编程范式游记</a>)。</p>
<p>在Rust中，是通过trait来实现这两者的，trait本质上是<strong>实现式接口</strong>，用于对不同类型的相同方法进行抽象。Rust的trait有如下特性:</p>
<ol>
<li>trait是需要显式指明实现的</li>
<li>trait可以提供默认实现，但不能包含字段(部分subclass)</li>
<li>trait的默认实现可以调用trait中的其它方法，哪怕这些方法没有提供默认实现(dynamic dispatch)</li>
<li>trait可以用做参数或返回值用于表达满足该接口的类型实例抽象(subtype)</li>
<li>trait本身也可以定义依赖(supertrait)，如Copy trait依赖Clone trait</li>
<li>作为泛型约束时trait可通过+号实现拼接，表示同时满足多个接口</li>
</ol>
<p>以下代码简单展示了Rust trait的基本特性:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">Summary</span></span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">summarize_author</span></span>(&amp;<span class="keyword">self</span>) -&gt; <span class="built_in">String</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">summarize</span></span>(&amp;<span class="keyword">self</span>) -&gt; <span class="built_in">String</span> &#123;</span><br><span class="line">        <span class="built_in">format!</span>(<span class="string">&quot;(Read more from &#123;&#125;...)&quot;</span>, <span class="keyword">self</span>.summarize_author())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">Title</span></span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">title</span></span>(&amp;<span class="keyword">self</span>) -&gt; <span class="built_in">String</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Tweet</span></span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> username: <span class="built_in">String</span>,</span><br><span class="line">    <span class="keyword">pub</span> title: <span class="built_in">String</span>,</span><br><span class="line">    <span class="keyword">pub</span> content: <span class="built_in">String</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> Summary <span class="keyword">for</span> Tweet &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">summarize_author</span></span>(&amp;<span class="keyword">self</span>) -&gt; <span class="built_in">String</span> &#123;</span><br><span class="line">        <span class="built_in">format!</span>(<span class="string">&quot;@&#123;&#125;&quot;</span>, <span class="keyword">self</span>.username)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> Title <span class="keyword">for</span> Tweet &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">title</span></span>(&amp;<span class="keyword">self</span>) -&gt; <span class="built_in">String</span> &#123;</span><br><span class="line">        <span class="built_in">format!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, <span class="keyword">self</span>.title)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 函数声明等价于 pub fn notify&lt;T: Summary + Title&gt;(item: T) &#123;</span></span><br><span class="line"><span class="comment">// 即本质是bounded generic types的语法糖</span></span><br><span class="line"><span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">notify</span></span>(item: <span class="keyword">impl</span> Summary + Title) &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;1 new tweet: &#123;&#125;, &#123;&#125;&quot;</span>, item.title(), item.summarize());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">        <span class="keyword">let</span> t = Tweet &#123;</span><br><span class="line">        	username: <span class="built_in">String</span>::from(<span class="string">&quot;wudaijun&quot;</span>),</span><br><span class="line">        	title: <span class="built_in">String</span>::from(<span class="string">&quot;study rust&quot;</span>),</span><br><span class="line">        	content: <span class="built_in">String</span>::from(<span class="string">&quot;rust is the best language&quot;</span>)</span><br><span class="line">        &#125;;</span><br><span class="line">        notify(t)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>总的来说，Rust对OOP的支持是比较完善的，舍弃了继承和字段复用，通过trait来完成代码复用和子类化，避免了OOP继承的各种坑。</p>
<h3 id="四-泛型和元编程"><a href="#四-泛型和元编程" class="headerlink" title="四. 泛型和元编程"></a>四. 泛型和元编程</h3><p>Rust的泛型和元编程赋予语言更强大的灵活性。这里只列举个人目前学习到的一些要点。</p>
<p>Rust泛型的一些特性:</p>
<ol>
<li>模板泛型: 在编译期填充具体类型，实现单态化</li>
<li>支持枚举泛型: 如: <code>enum Option&lt;T&gt; &#123; Some(T), None, &#125;</code></li>
<li>Trait Bound: <code>fn notify(item: impl Summary) &#123;...</code> 等价于 <code>fn notify&lt;T: Summary&gt;(item: T) &#123;...</code> 等价于 <code>fn notify&lt;T&gt;(item: T) where T: Summary &#123;...</code></li>
<li>blanket implementations: 对实现了特定 trait 的类型有条件地实现方法，如标准库为任何实现了<code>Display</code> trait的类型实现了<code>ToString</code> trait: <code>impl&lt;T: Display&gt; ToString for T &#123;</code>。这意味着你实现了A trait，标准库/第三方库就可以为你实现B trait。这是trait和泛型的一种特殊结合，也是Rust trait和传统OOP不同的地方之一</li>
</ol>
<p>元编程能够生成代码的代码，如C++的模板由于其在预编译期处理，并且图灵完备，完全可以作为另一种语言来看待，它的执行结果就是另一种语言的代码。Rust的元编程通过宏来实现，宏的语法类似于这样:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="meta">#[macro_export]</span></span><br><span class="line"><span class="built_in">macro_rules!</span> vec &#123;</span><br><span class="line">    ( $( $x:expr ),* ) =&gt; &#123;</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="keyword">mut</span> temp_vec = <span class="built_in">Vec</span>::new();</span><br><span class="line">            $(</span><br><span class="line">                temp_vec.push($x);</span><br><span class="line">            )*</span><br><span class="line">            temp_vec</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码能将<code>let v: Vec&lt;u32&gt; = vec![1, 2, 3];</code>转换成:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="keyword">mut</span> temp_vec = <span class="built_in">Vec</span>::new();</span><br><span class="line">temp_vec.push(<span class="number">1</span>);</span><br><span class="line">temp_vec.push(<span class="number">2</span>);</span><br><span class="line">temp_vec.push(<span class="number">3</span>);</span><br><span class="line">temp_vec</span><br></pre></td></tr></table></figure>
<p>由于宏编程日常开发中使用较少，这里不再展开讨论。</p>
<h3 id="五-并发编程"><a href="#五-并发编程" class="headerlink" title="五. 并发编程"></a>五. 并发编程</h3><p>基于Rust本身系统级编程语言的定位，Rust标准库本身只提供对OS Thread的基础抽象，即运行时本身不实现<strong>轻量级线程</strong>及其调度器，以保持其运行时的精简高效。</p>
<p>Rust的所有权系统设计之初是为了简化运行时的内存管理，解决内存安全问题，而Rust作为系统级编程语言，并发自然也是绕不过去的传统难题，起初Rust觉得这是两个独立的问题，然而随着所有权系统的完善，Rust发现<strong>所有权系统也能解决一系列的并发安全问题</strong>。相较于并发领域佼佼者Erlang前辈的口号”任其崩溃(let it crash)”，Rust的并发口号也是不输分毫: “无畏并发(fearless concurrency)”。下面我们来看看Rust为何如此自信，Rust支持消息交互和共享内存两种并发编程范式。</p>
<h4 id="1-消息交互"><a href="#1-消息交互" class="headerlink" title="1. 消息交互"></a>1. 消息交互</h4><p>Rust消息交互CSP模型，但也与Go这类CSP语言有一些区别。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> (tx, rx) = mpsc::channel();</span><br><span class="line">    <span class="keyword">let</span> val = <span class="built_in">String</span>::from(<span class="string">&quot;hi&quot;</span>);</span><br><span class="line">    thread::spawn(<span class="keyword">move</span> || &#123;</span><br><span class="line">        tx.send(val).unwrap();</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">let</span> received = rx.recv().unwrap();</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Got: &#123;&#125;&quot;</span>, received);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个小例子有如下需要关注的细节:</p>
<ol>
<li>Rust 在创建 channel 时无需指定其大小，因为Rust Channel的大小是没有限制的，并且明确区分发送端和接收端，对channel的写入是永远不会阻塞的</li>
<li>Rust 在创建 channel 时也无需指定其类型，这是因为 tx 和 rx 是泛型对象，编译器会根据其实际发送的数据类型来实例化泛型(如这里的<code>std::sync::mpsc::Sender&lt;std::string::String&gt;</code>)，如果尝试对同一个 channel 发送不同类型，或者代码中没有调用<code>tx.send</code>函数都将会导致编译错误</li>
<li>Rust编译器本身会尝试推测闭包以何种方式捕获外部变量，但通常是保守的借用。这里 move 关键字强制闭包获取其使用的环境值的所有权，因此main函数在创建线程后对val和tx的任何访问都会导致编译错误</li>
<li><code>tx.send</code>也会导致val变量发生控制权转移，因此在新创建线程在<code>tx.send(val)</code>之后对val的任何访问也会导致编译错误</li>
<li>Rust通过Send trait标记类型所有权是否能在线程间传递(只是标记，无需实现)，几乎所有Rust类型的所有权都是Send的(除了像<code>Rc&lt;T&gt;</code>这种为了性能刻意不支持的并发的，跨线程传递会导致编译错误。应该使用线程安全的<code>Arc&lt;T&gt;</code>)</li>
</ol>
<p>上面的3,4其实就是我们在并发编程常犯的错误：对相同变量的非并发安全访问，由于闭包的存在，使得这类”犯罪”的成本异常低廉。而Rust的所有权系统则巧妙地在编译器就发现了这类错误，因为变量所有权只会同时在一个线程中，也就避免了数据竞争。</p>
<h4 id="2-共享内存"><a href="#2-共享内存" class="headerlink" title="2. 共享内存"></a>2. 共享内存</h4><p>受Rust所有权系统的影响，Rust中的内存共享初看起来有点繁杂:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> std::sync::&#123;Mutex, Arc&#125;;</span><br><span class="line"><span class="keyword">use</span> std::thread;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> counter = Arc::new(Mutex::new(<span class="number">0</span>));</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> handles = <span class="built_in">vec!</span>[];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="number">0</span>..<span class="number">10</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> counter = Arc::clone(&amp;counter);</span><br><span class="line">        <span class="keyword">let</span> handle = thread::spawn(<span class="keyword">move</span> || &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="keyword">mut</span> num = counter.lock().unwrap();</span><br><span class="line"></span><br><span class="line">            *num += <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line">        handles.push(handle);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> handle <span class="keyword">in</span> handles &#123;</span><br><span class="line">        handle.join().unwrap();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Result: &#123;&#125;&quot;</span>, *counter.lock().unwrap());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同样，这里面也有一些细节:</p>
<ol>
<li>和channel一样，<code>Mutex&lt;T&gt;</code>也是泛型的，并且只能通过<code>lock</code>才能得到其中的<code>T</code>值，确保不会忘记加锁</li>
<li>Mutex会在脱离作用域时，会自动释放锁，确保不会忘记释放锁</li>
<li>这里有多个线程需要共享Mutex的所有权，因此需要用到并发安全的引用计数智能指针<code>Arc&lt;T&gt;</code>(<code>RC&lt;T&gt;</code>不是线程安全的)</li>
</ol>
<h3 id="六-体会"><a href="#六-体会" class="headerlink" title="六 体会"></a>六 体会</h3><p>本文主要从所有权系统和编程范式的角度理解Rust，总的来说，这门语言给我的印象是很不错的。</p>
<p>从系统级编程语言的角度来说，它确实兼顾了安全和高效，这中间是Rust编译器在”负重前行”，其它语言的编译器更多关注语法正确性，而Rust编译器还会想尽办法分析和保证代码安全性，这也是所有权系统及其相关机制的本意，这些规则前期可能要多适应下，但遵循这些约束能够换来巨大的健壮性和运行效率收益。</p>
<p>从高级编程语言的角度来说，Rust从多种编程范式(过程式、函数式、面向对象、泛型、元编程等)中取其精华去其糟粕，属于编程范式融合得比较好的，比如要面向对象不要继承，要函数式编程也要控制流，可变性和性能，这让Rust具有强大的灵活性和抽象能力，在图形、音视频、Web/应用前后端等各个应用领域全面发力，包括对游戏服务器这类看重性能的应用场景而言，Rust也很有潜力。</p>
<p>同时，由于Rust本身的多编程范式融合，以及独有的所有权系统，初学者上手Rust学习成本还是比较高的。由于对Rust缺乏实践，本文更多还是提炼汇总，如果有合适的应用场景，倒是很愿意用Rust实践下，增强理解。</p>
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>rust</tag>
      </tags>
  </entry>
  <entry>
    <title>C#/Unity中的异步编程</title>
    <url>/2021/11/c-sharp-unity-async-programing/</url>
    <content><![CDATA[<p>这段时间学习Unity，顺便系统性地了解了下C#和Unity异步编程的各种机制和实现细节。本文是这些学习资料和个人理解的汇总。会先介绍下C# yield，Task，async/await，同步上下文等机制。然后聊聊其在Unity上的一些变体和应用。</p>
<span id="more"></span>
<h3 id="C-yield"><a href="#C-yield" class="headerlink" title="C# yield"></a>C# yield</h3><p><code>yield</code>是C#提供的快速创建枚举器的机制:</p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> IEnumerable&lt;<span class="built_in">int</span>&gt; <span class="title">TestYield</span>(<span class="params"><span class="built_in">int</span> a</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">return</span> a+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (a % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="built_in">string</span>[] args</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    IEnumerator&lt;<span class="built_in">int</span>&gt; enumerator = TestYield(<span class="number">4</span>).GetEnumerator();</span><br><span class="line">    <span class="keyword">while</span> (enumerator.MoveNext())</span><br><span class="line">    &#123;</span><br><span class="line">        Console.WriteLine(enumerator.Current);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Output:</span></span><br><span class="line"><span class="comment">// 5</span></span><br></pre></td></tr></table></figure>
<p>实现上来说，C#编译器会为TestYield函数生成一个状态机类，将函数执行体通过yield分为几个部分，内部通过一个state字段(通常是个整数)来标识当前迭代到哪一步了，并实现了IEnumerable、IEnumerator枚举器接口。因此可以将TestYield返回值作为一个可枚举对象。介绍关于yield语法糖实现机制的文章很多，这里就不赘述了。</p>
<p>C# 枚举器和JS Generator机制上非常类似，不过只具备单向传值的能力(yield-&gt;MoveNext)。我在<a href="http://wudaijun.com/2018/07/javascript-async-programing/">JS异步编程</a>和<a href="https://wudaijun.com/2015/01/lua-coroutine/">Lua协程</a>中有介绍关于协程和生成器的区别，在我的理解中，C#枚举器和JS生成器一样，都不能算作协程。</p>
<h3 id="Unity-Coroutine"><a href="#Unity-Coroutine" class="headerlink" title="Unity Coroutine"></a>Unity Coroutine</h3><p>C#没有协程，而Unity C#中则经常看到协程的概念(Unity Coroutine)，本质上来说，Unity Coroutine是和JS Generator类似的通过生成器/枚举器实现异步的编程模型。Unity基于C# yield进行了进一步完善:</p>
<ol>
<li>Unity协程通过Unity Engine提供的<code>StartCoroutine(myEnumerableFunc)</code>启动，Unity Engine会驱动枚举器的迭代，无需开发者关心</li>
<li>Unity协程基于yield返回的对象，只能是YieldInstruction的子类(它最重要的方法是bool IsDone()，用于判断异步操作是否已经完成)，如此Unity Engine会在YieldInstruction完成后，通过MoveNext迭代枚举器</li>
<li>Unity Engine预实现了部分YieldInstruction，如WaitForSeconds，WaitForEndOfFrame等，以实现常用的协程控制</li>
<li>Unity Engine完善了协程(枚举器)生命周期管理(Start/Stop)和嵌套机制(如一个协程yield另一个协程)，并将协程的生命周期与GameObject绑定</li>
</ol>
<p>关于Unity Coroutine的更深入实现原理推荐<a href="https://sunweizhe.cn/2020/05/08/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90Unity%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/">这篇博客</a>。如此，对于Unity开发者而言，使用yield就能完成简单的异步控制。当然，还达不到JS Generator异步那样的灵活度(如C# yield不能像JS yield一样双向传值)。我们可以从<a href="http://wudaijun.com/2018/07/javascript-async-programing/">JS 异步编程</a>中提到的Generator异步编程的四要素，来对比看看Unity Coroutine是如何工作的:</p>
<ul>
<li>Generator: C#的yield相当于JS Generator的阉割版，支持执行权转移，单向传值</li>
<li>Thunk: Thunk的本质目的是让Iterator能以一种标准化的方式挂接回调(如此才能回到yield语句)，而Unity YieldInstruction本身就是一种标准，Unity会在YieldInstruction完成(IsDone()==true)后，调用对应协程的的MoveNext回到yield语句，这也就相当于完成了Thunk的职责</li>
<li>AsyncOp: Unity Engine和它的标准库提供了大量适配了YieldInstruction的异步操作，包括帧控制、定时、网络IO等，并且支持开发者扩展</li>
<li>Iterator: Unity Engine统一管理所有通过StartCoroutine启动的协程，并基于帧驱动检查它们的状态，在YieldInstruction异步操作完成后继续驱动协程(MoveNext)，直至协程生命周期结束。</li>
</ul>
<p>由于C# yield是单向传值，Unity协程自然也就不支持yield语句返回值。如此看来，Unity C#确实具备部分的异步编程能力，不过如前面所说，基于个人对狭义的协程概念的理解，我认为程JS、C#、Unity支持协程是不合适的。类似的还有Golang的抢占式轻量级线程goroutine也被翻译为协程。</p>
<h3 id="C-Task"><a href="#C-Task" class="headerlink" title="C# Task"></a>C# Task</h3><p>C#中的Task本质上类似JS中的Promise，表示一个异步任务，通常运行在其他线程而非创建Task的当前线程中。Task在启动(Task.Start/Task.Run/TaskFactory.StartNew)和ContinueWith的时候，可以选择指定其对应的TaskScheduler(对于ContinueWith而言，指定的是执行异步回调的任务调度器)，默认的TaskScheduler只会将任务放到线程池中去执行。</p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="built_in">string</span>[] args</span>)</span> &#123;</span><br><span class="line">    <span class="built_in">int</span> a = <span class="number">888</span>;</span><br><span class="line">    <span class="built_in">int</span> b = <span class="number">111</span>;</span><br><span class="line">    <span class="keyword">var</span> task = <span class="keyword">new</span> Task&lt;<span class="built_in">int</span>&gt;(() =&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        Console.WriteLine(<span class="string">&quot;add task, on thread&#123;0&#125;&quot;</span>, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">        <span class="keyword">return</span> a + b;</span><br><span class="line">    &#125;);</span><br><span class="line">    Console.WriteLine(<span class="string">&quot;main thread&#123;0&#125;, task&#123;1&#125; init status: &#123;2&#125;&quot;</span>, Thread.CurrentThread.ManagedThreadId, task.Id, task.Status);</span><br><span class="line">    task.Start();</span><br><span class="line">    task.ContinueWith((task, arg) =&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        Console.WriteLine(<span class="string">&quot;continue with 1, got result: &#123;0&#125;, got arg: &#123;1&#125;, on thread&#123;2&#125;&quot;</span>, task.Result, arg, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">    &#125;, <span class="string">&quot;Arg1&quot;</span>).</span><br><span class="line">    ContinueWith((task) =&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        Console.WriteLine(<span class="string">&quot;continue with 2, on thread&#123;0&#125;&quot;</span>, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">    &#125;).Wait();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Output:</span></span><br><span class="line"><span class="comment">// main thread1, task1 init status: Created</span></span><br><span class="line"><span class="comment">// add task, on thread3</span></span><br><span class="line"><span class="comment">// continue with 1, got result: 999, got arg: Arg1, on thread4</span></span><br><span class="line"><span class="comment">// continue with 2, on thread5</span></span><br></pre></td></tr></table></figure>
<p>以上代码展示了Task的几个特性:</p>
<ol>
<li>任务内部有个简单的状态机，其他线程可通过<code>Task.Status</code>获取任务当前状态</li>
<li><code>Task.ContinueWith</code>返回值是一个新的Task，可以像<code>JS promise.then</code>一样，以可读性较好的方式(相比回调地狱)书写异步调用链</li>
<li><code>task.ContinueWith</code>中的回调可以取到到task的返回值，并且可以为其附加额外的参数</li>
<li><code>task.Wait</code>可以让当前线程同步阻塞等待该任务完成，除此之外，还可以通过<code>Task.WaitAny</code>和<code>Task.WaitAll</code>来等待一个任务数组</li>
<li>在任务执行完成后，通过<code>task.Result</code>可以取得异步任务的返回值，注意，如果此时任务未完成，将会同步阻塞等待任务完成</li>
<li>如果没有指定TaskScheduler，默认的任务调度器只是在线程池中随机选一个线程来执行异步任务和对应回调</li>
</ol>
<p>有时候我们在线程A中将某些耗时操作，如网络IO，磁盘IO等封装为Task放到线程B异步执行之后，希望Task的回调在A线程执行(最典型的如UI线程，因为通常UI框架的API都不是线程安全的)，以实现A-&gt;B-&gt;A的线程上下文切换效果。要实现这种效果，我们需要为Task显式指定TaskScheduler，TaskScheduler本质只是接口，它的派生类主要有两个:</p>
<ul>
<li>thread pool task scheduler: 基于线程池的任务调度器，即任务(及其continuewith产生的新任务)会被分配到线程池中的某个工作线程，这也是默认的调度器，通过<code>TaskScheduler.Default</code>获取默认线程池调度器</li>
<li>synchronization context task scheduler: 同步上下文调度器，即任务会在指定的同步上下文上执行，比如在GUI框架中，通常会将控件操作全部放到GUI线程中执行。通过<code>TaskScheduler.FromCurrentSynchronizationContext</code>获取与当前同步上下文绑定的任务调度器</li>
</ul>
<p>那么什么是同步上下文？SynchronizationContext代表代码的执行环境，提供在各种同步模型中传播同步上下文的功能，为各个框架的线程交互提供统一的抽象。它最重要的是以下两个方法。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 获取当前线程的同步上下文</span><br><span class="line">public static System.Threading.SynchronizationContext? Current &#123; get; &#125;</span><br><span class="line">&#x2F;&#x2F; 派发一个异步到消息到当前同步上下文</span><br><span class="line">public virtual void Post (System.Threading.SendOrPostCallback d, object? state);</span><br><span class="line">&#x2F;&#x2F; 派发一个同步消息到当前同步上下文</span><br><span class="line">public virtual void Send (System.Threading.SendOrPostCallback d, object? state);</span><br></pre></td></tr></table></figure>
<p>SynchronizationContext提供了默认的实现，对Post而言，它只会通过QueueUserWorkItem将任务丢给ThreadPool，对于Send而言，它会立即在当前线程上同步执行委托。</p>
<p>各个框架可以重载SynchronizationContext实现自己的同步上下文行为，如Windows Froms实现了<code>WindowsFormsSynchronizationContext</code>，它的Post会通过<code>Control.BeginInvoke</code>实现，而WPF的<code>DispatcherSynchronizationContext</code>则通过框架的<code>Dispatcher.BeginInvoke</code>实现，它们都实现了将委托异步投递给UI线程执行。正因为不同的平台，不同的线程，有不同的消息泵和交互方式，因此才需要SynchronizationContext来封装抽象这些差异性，以增强代码的可移植性。</p>
<p>每个线程都有自己的SynchronizationContext(通过<code>SynchronizationContext.Current</code>获取，默认为null)，但SynchronizationContext与线程不一定是一一对应的，比如默认的<code>SynchronizationContext.Post</code>是通过线程池来执行任务。SynchronizationContext本质上想要封装的是一个执行环境以及与该环境进行任务交互的方式。</p>
<p>对Task，TaskScheduler，SynchronizationContext有一定了解后，我们将这些概念结合起来:</p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="built_in">string</span>[] args</span>)</span> &#123;</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 创建并设置当前线程的SynchronizationContext</span></span><br><span class="line">    <span class="comment">// 否则TaskScheduler.FromCurrentSynchronizationContext()调用会触发System.InvalidOperationException异常</span></span><br><span class="line">    <span class="keyword">var</span> context = <span class="keyword">new</span> SynchronizationContext();</span><br><span class="line">    SynchronizationContext.SetSynchronizationContext(context);</span><br><span class="line">    Console.WriteLine(<span class="string">&quot;main thread&#123;0&#125;&quot;</span>, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">    Task&lt;<span class="built_in">int</span>&gt; task = <span class="keyword">new</span> Task&lt;<span class="built_in">int</span>&gt;(() =&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        Console.WriteLine(<span class="string">&quot;task thread&#123;0&#125;&quot;</span>, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;);</span><br><span class="line">    task.Start();</span><br><span class="line">    task.ContinueWith(t =&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        Console.WriteLine(<span class="string">&quot;continuewith result: &#123;0&#125;, thread&#123;1&#125;&quot;</span>, t.Result, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line"></span><br><span class="line">    &#125;, TaskScheduler.FromCurrentSynchronizationContext()).Wait();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Output:</span></span><br><span class="line"><span class="comment">// main thread1</span></span><br><span class="line"><span class="comment">// task thread3</span></span><br><span class="line"><span class="comment">// continuewith result: 1, thread4</span></span><br></pre></td></tr></table></figure>
<p>上面代码中，使用<code>TaskScheduler.FromCurrentSynchronizationContext()</code>来指定<code>task.ContinueWith</code>任务的调度器(注意，我们并没有为<code>task.Start</code>指定调度器，因为我们希望task本身使用默认的线程池调度器，当执行完成之后，再回到主线程执行ContinueWith任务)，输出结果并不如我们预期，<code>task.ContinueWith</code>中的回调委托仍然在线程池中执行，而不是在主线程。</p>
<p>这个结果其实很容易解释，<code>task.ContinueWith(delegate, TaskScheduler.FromCurrentSynchronizationContext())</code>表示: 当task执行完成后，通过<code>SynchronizationContext.Post(delegate, task)</code>将任务异步投递到指定的同步上下文(在上例中，即为主线程创建的上下文)。但是一来我们创建的是默认的SynchronizationContext，它的Post本身就是投递到线程池的，二来我们并没有在主线程中集成消息泵(message pump)。</p>
<p>类比Actor模型，我们要实现 Actor A 向 Actor B 通信，我们需要: </p>
<ol>
<li>定义一个消息通道: channel/mailbox</li>
<li>集成channel/mailbox到B消息泵</li>
<li>将channel/mailbox暴露给A</li>
</ol>
<p>因此，上例中，我们即没有定义消息的传输方式，也没有定义消息的处理方式。SynchronizationContext本质只是提供了一层同步上下文切换交互抽象，传输方式，消息泵，甚至线程模型都需要我们自己实现。这里就不再展示SynchronizationContext的扩展细节，更多关于SynchronizationContext的文档:</p>
<ol>
<li><a href="https://hamidmosalla.com/2018/06/24/what-is-synchronizationcontext/">what is synchronizationcontext</a></li>
<li><a href="https://docs.microsoft.com/en-us/archive/msdn-magazine/2011/february/msdn-magazine-parallel-computing-it-s-all-about-the-synchronizationcontext">synchronizationcontext doc on MSDN</a></li>
</ol>
<h3 id="C-async-await"><a href="#C-async-await" class="headerlink" title="C# async/await"></a>C# async/await</h3><p>async/await是C# .NET4.5推出的更高级的异步编程模型:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static async void AsyncTask()</span><br><span class="line">&#123;</span><br><span class="line">    Console.WriteLine(&quot;before await, thread&#123;0&#125;&quot;, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">    var a &#x3D; await Task.Run(() &#x3D;&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        Thread.Sleep(500);</span><br><span class="line">        Console.WriteLine(&quot;in task, thread&#123;0&#125;&quot;, Thread.CurrentThread.ManagedThreadId); </span><br><span class="line">        return 666;</span><br><span class="line">    &#125;);</span><br><span class="line">    Console.WriteLine(&quot;after await, got result: &#123;0&#125;, thread&#123;1&#125;&quot;, a, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">&#125;</span><br><span class="line">static void Main(string[] args)</span><br><span class="line">&#123;</span><br><span class="line">    Console.WriteLine(&quot;Main: before AsyncTask thread&#123;0&#125;&quot;, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">    var r &#x3D; AsyncTask().Result;</span><br><span class="line">    Console.WriteLine(&quot;Main: after AsyncTask result: &#123;0&#125; thread&#123;1&#125;&quot;, r, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; Output:</span><br><span class="line">AsyncTask: before await, thread1</span><br><span class="line">AsyncTask: in task, thread3</span><br><span class="line">AsyncTask: after await, got result: 666, thread3</span><br><span class="line">Main: after AsyncTask result: 667 thread1</span><br></pre></td></tr></table></figure>
<p>可以看到async/await进一步简化了异步编程的书写方式，达到更接近同步编程的可读性和易用性(这一点后面会再探讨下)。</p>
<h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p>在进一步了解它的用法之前，我们先大概了解下它的实现机制(可以看看<a href="https://zhuanlan.zhihu.com/p/197335532">这篇文章</a>提到了不少实现细节)，async/await本质也是编译器的语法糖，编译器做了以下事情:</p>
<ol>
<li>为所有带async关键字的函数，生成一个状态机类，它满足IAsyncStateMachine接口，await关键字本质生成了状态机类中的一个状态，状态机会根据内部的state字段(通常-1表示开始，-2表示结束，其他状态依次为0,1,2…)，一步步执行异步委托。整个状态机由<code>IAsyncStateMachine.MoveNext</code>方法驱动，类似迭代器</li>
<li>代码中的<code>await xxx</code>，xxx返回的对象都需要实现GetAwaiter方法，该方法返回一个Awaiter对象，编译器不关心这个对象Awaiter对象类型，它只关心这个Awaiter对象需要满足三个条件: a. 实现INotifyCompletion(只有一个<code>OnCompleted(Action continuation)</code>方法)，b. 实现IsCompleted属性，c. 实现GetResult方法，如此编译器就能知道如何与该异步操作进行交互，比如最常见的Task对象，就实现了GetAwaiter方法返回一个<a href="https://referencesource.microsoft.com/#mscorlib/system/threading/Tasks/Task.cs,2935">TaskAwaiter</a>对象，但除了TaskAwaiter，任何满足以上三个条件的对象均可被await</li>
<li>有了stateMachine和TaskAwaiter之后，还需要一个工具类将它们组合起来，以驱动状态机的推进，这个类就是<code>AsyncTaskMethodBuilder/AsyncTaskMethodBuilder&lt;TResult&gt;</code>，是Runtime预定义好的，每个async方法，都会创建一个Builder对象，然后通过<a href="https://referencesource.microsoft.com/#mscorlib/system/runtime/compilerservices/AsyncMethodBuilder.cs,67">AsyncTaskMethodBuilder.Start</a>方法绑定对应的IAsyncStateMachine，并进行状态首次MoveNext驱动，MoveNext执行到await处(此时实际上await已经被编译器去掉了，只有TaskAwaiter)，会调用<code>TaskAwaiter.IsCompleted</code>判断任务是否已经立即完成(如<code>Task.FromResult(2)</code>)，如果已完成，则将结果设置到builder(此时仍然在当前线程上下文)，并之后跳转到之后的代码(直接goto，无需MoveNext)，否则，更新state状态，通过<a href="https://referencesource.microsoft.com/#mscorlib/system/runtime/compilerservices/AsyncMethodBuilder.cs,154">AsyncTaskMethodBuilder.AwaitUnsafeOnCompleted</a>(最终调到<code>Awaiter.OnCompleted</code>)挂接(对<code>TaskAwaiter.OnCompleted</code>而言，是<a href="https://referencesource.microsoft.com/#mscorlib/system/runtime/compilerservices/TaskAwaiter.cs,339">挂接到Continuation</a>上)异步回调(此回调包含整个状态机的后续驱动方式，通过<a href="https://referencesource.microsoft.com/#mscorlib/system/runtime/compilerservices/AsyncMethodBuilder.cs,ac92075576570beb">GetCompletionAction</a>生成)并返回(此时当前函数堆栈已结束)，当taskAwaiter完成(不同的Awaiter完成方式也不同，对Task而言，即Task执行完成)后，buildier会通过GetCompletionAction生成的回调再次调用到<code>stateMachine.MoveNext</code>驱动状态机(此时可能已经不在当前线程，state状态也不一样了，可通过TaskAwaiter.GetResult拿到异步结果)，如此完成状态机的正常驱动。</li>
<li>除了驱动状态机外，AsyncTaskMethodBuilder的另一个作用是将整个async函数，封装为一个新的Task(wrapper task)，该Task可通过<code>AsyncTaskMethodBuilder.Task</code>属性获取。当stateMachine通过MoveNext走完每个状态后，会将最终结果，通过builder.SetResult写入到builder中的Task，如果中途出现异常，则通过builder.SetExpection保存，如此发起方可通过<code>try &#123;await xxx;&#125; catch (e Exception)&#123;...&#125;</code>捕获异常，最终整个编译器改写后的async函数，返回的实际上就是这个<code>builder.Task</code>。</li>
</ol>
<h4 id="基础用法"><a href="#基础用法" class="headerlink" title="基础用法"></a>基础用法</h4><p>除了直接跟Task外，<code>.NET</code>和Windows运行时也封装了部分关于网络IO，文件，图像等，这些方法通常都以Async结尾，可直接用于await。以下代码说明了跟在await后面的常见的几种函数，以便进一步理解其中的差异和原理。</p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 因为没有async标注，所以编译器不会为该函数生成状态机，但由于该函数返回的是Task，因此可以直接用于await</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Task&lt;<span class="built_in">int</span>&gt; <span class="title">F1Async</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Task.Run(() =&gt; &#123; <span class="keyword">return</span> <span class="number">2</span>; &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只要标记了async 就会生成对应状态机，但这里有几点需要注意:</span></span><br><span class="line"><span class="comment">// 1. 如果方法声明为 async，那么可以直接 return 异步操作返回的具体值，不再用创建Task，由编译器通过builder创建Task</span></span><br><span class="line"><span class="comment">// 2. 由于该函数体内没有使用await，整个状态机相当于直接builder.SetResult(2)，其中不涉及异步操作和线程切换(没有await异步切换点)，因此整个过程实际上都是在主线程同步进行的(虽然经过了一层builder.Task封装)</span></span><br><span class="line"><span class="comment">// 3. 编译器也会提示Warning CS1998: This async method lacks &#x27;await&#x27; operators and will run synchronously.</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">async</span> Task&lt;<span class="built_in">int</span>&gt; <span class="title">F2Async</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 该方法在Task上套了一层空格子Task，看起来好像和F1Async没区别</span></span><br><span class="line"><span class="comment">// 但实际上，编译器仍然会生成对应的builder和wrapper task，这个wrapper task在原task完成之后，只是做了简单的return操作</span></span><br><span class="line"><span class="comment">// 因此 await F3Async() 实际上可能导致两次线程上下文切换，如果是在UI线程上执行await，用法不当则可能触发&quot;async/await 经典UI线程卡死&quot;场景，因为await会默认捕获SynchronizationContext。这个后面说。</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">async</span> Task&lt;<span class="built_in">int</span>&gt; <span class="title">F3Async</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> Task.Run(() =&gt; &#123; <span class="keyword">return</span> <span class="number">2</span>; &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="线程切换"><a href="#线程切换" class="headerlink" title="线程切换"></a>线程切换</h4><p>理解async/await基本原理后，不难发现，async/await本质上是不创建线程的，它只是一套状态机封装，以及通过回调驱动状态机的异步编程模型。await默认会捕获当前的执行上下文ExecuteContext，但是并不会捕获当前的同步上下文SynchronizationContext(关于ExcuteContext和SynchronizationContext的区别联系参考<a href="https://devblogs.microsoft.com/pfxteam/executioncontext-vs-synchronizationcontext/">executioncontext-vs-synchronizationcontext on MSDN</a>，强烈建议阅读)，同步上下文的捕获是由TaskAwaiter实现(见<a href="https://referencesource.microsoft.com/#mscorlib/system/runtime/compilerservices/TaskAwaiter.cs,93">TaskAwaiter.OnCompleted</a>)，它会先获取<code>SynchronizationContext.Current</code>，如果没有或者是默认的，会再尝试获取Task对应的TaskScheduler上的SynchronizationContext。也就是说对TaskAwaiter而言，设置默认的SynchronizationContext和没有设置效果是一样的(为了少一次QueueWorkItem，对应源码在<a href="https://referencesource.microsoft.com/#mscorlib/system/threading/Tasks/Task.cs,2976">这里</a>，我们可以结合前面的AsyncTask，以及下面的进一步测试来验证:</p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">class</span> <span class="title">MySynchronizationContext</span> : <span class="title">SynchronizationContext</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">override</span> <span class="keyword">void</span> <span class="title">Post</span>(<span class="params">SendOrPostCallback d, <span class="built_in">object</span> state</span>)</span> &#123;</span><br><span class="line">        Console.WriteLine(<span class="string">&quot;MySynchronizationContext Post, thread&#123;0&#125;&quot;</span>, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">        <span class="keyword">base</span>.Post(d, state);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">async</span> <span class="keyword">void</span> <span class="title">AsyncTask</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	 <span class="comment">// 创建并使用自定义的SynchronizationContext</span></span><br><span class="line">    <span class="keyword">var</span> context = <span class="keyword">new</span> MySynchronizationContext();</span><br><span class="line">    SynchronizationContext.SetSynchronizationContext(context);</span><br><span class="line">    Console.WriteLine(<span class="string">&quot;AsyncTask: before await, thread&#123;0&#125;&quot;</span>, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">    <span class="keyword">var</span> a = <span class="keyword">await</span> Task.Run(() =&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        Thread.Sleep(<span class="number">500</span>);</span><br><span class="line">        Console.WriteLine(<span class="string">&quot;AsyncTask: in task, thread&#123;0&#125;&quot;</span>, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">666</span>;</span><br><span class="line">    &#125;);</span><br><span class="line">    Console.WriteLine(<span class="string">&quot;AsyncTask: after await, got result: &#123;0&#125;, thread&#123;1&#125;&quot;</span>, a, Thread.CurrentThread.ManagedThreadId);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="built_in">string</span>[] args</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    AsyncTask();</span><br><span class="line">    Console.ReadKey();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Output (使用自定义的SynchronizationContext):</span></span><br><span class="line"><span class="comment">// AsyncTask: before await, thread1</span></span><br><span class="line"><span class="comment">// AsyncTask: in task, thread3</span></span><br><span class="line"><span class="comment">// MySynchronizationContext Post, thread3</span></span><br><span class="line"><span class="comment">// AsyncTask: after await, got result: 666, thread4</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Output2 (使用默认的SynchronizationContext):</span></span><br><span class="line"><span class="comment">// AsyncTask: before await, thread1</span></span><br><span class="line"><span class="comment">// AsyncTask: in task, thread3</span></span><br><span class="line"><span class="comment">// AsyncTask: after await, got result: 666, thread3</span></span><br></pre></td></tr></table></figure>
<p>这说明了如果当前线程没有或者设置的默认的SynchronizationContex，那么await之后的回调委托实际上是在await的Task所在的线程上执行的(这一点和ContinueWith的默认行为不大一样，后者总是会通过QueueWorkItem跑在一个新的线程中)。</p>
<p>如果设置了非默认的SynchronizationContex，那么回调委托将通过<code>SynchronizationContex.Post</code>方法封送(由于SynchronizationContex本质也只是接口，我们这里并不能草率地说，会回到Caller线程)。如对于WPF这类UI框架而言，它实现的<code>DispatcherSynchronizationContext</code>最终通过<code>Dispatcher.BeginInvoke</code>将委托封送到UI线程。而如果你是在UI线程发起await，其后又在UI线程上使用<code>task.Result</code>同步等待执行结果，就可能解锁前面F3Async中提到的<a href="https://zhuanlan.zhihu.com/p/371362645">UI线程卡死场景</a>，这也是新手最常犯的问题。你可以通过<code>task.ConfigureAwait(bool continueOnCapturedContext)</code>指定false来关闭指定Task捕获SynchronizationContex的能力，如此委托回调的执行线程就和没有SynchronizationContex类似了。</p>
<p>总结下，async/await本身不创建线程，<code>aaa; await bbb; ccc;</code> 这三行代码，可能涉及到一个线程(比如没有await，或任务立即完成，甚至await线程自己的异步操作)，两个线程(比如没有自定义SynchronizationContex，或有自己实现消息泵的的SynchronizationContex)，三个线程(有其他线程实现消息泵的自定义SynchronizationContex)。但具体涉及几个线程，GetAwaiter(通常返回的是TaskAwaiter，但是你也可以自定义)，SynchronizationContex等外部代码和环境决定的。</p>
<h4 id="一些补充"><a href="#一些补充" class="headerlink" title="一些补充"></a>一些补充</h4><h5 id="await与yield的区别"><a href="#await与yield的区别" class="headerlink" title="await与yield的区别"></a>await与yield的区别</h5><p>yield和await都是语法糖，最后都会被生成一个状态机，每行yield/await都对应其中一个状态。</p>
<ul>
<li>本质用途: yield用于快速构造枚举器，而await用于简化异步编程模型，两者都会生成状态机，但前对外表现为可枚举类，用于手动迭代，后者主要用于AsyncTaskMethodBuilder自动迭代(从调用async函数起，Builder就通过异步回调不断调用MoveNext，直至走完每个await状态)</li>
<li>线程切换: yield不涉及线程上下文的切换，而await通常涉及(前面说了，不是因为它会创建线程，而是依赖具体的异步操作，以及同步上下文)</li>
</ul>
<h5 id="C-async-await-vs-JS-Generator异步"><a href="#C-async-await-vs-JS-Generator异步" class="headerlink" title="C# async/await vs JS Generator异步"></a>C# async/await vs JS Generator异步</h5><p>既然async/await也是异步编程模型，同样的，我们也将C# async/await用Generator异步编程四要素来分析下:</p>
<ul>
<li>Generator: C# yield是由编译器生成状态机类并实现IEnumerable，类似的，C# async/await也是编译器生成的可迭代状态机IAsyncStateMachine，不过它只有MoveNext()方法，看起来甚至不能单向传值。不过事实上，它的双向传值机制都封装在状态机类内部了</li>
<li>Thunk: await也有Awaitable标准，它需要实现INotifyCompletion的<code>OnCompleted(Action continuation)</code>方法，这也就提供了统一的挂载回调标准。C# Task和JS Promise一样，都实现了异步执行和回调挂接分离</li>
<li>AsyncOp: C#的Task原生适配了Awaitable，并且Awaitable也非常易于开发者扩展(后面讲UniTask还会详述)</li>
<li>Iterator: 整个状态机的驱动，由前面提到的AsyncTaskMethodBuilder来完成，它负责将await之后的执行路径通过OnCompleted挂载到异步操作上</li>
</ul>
<p>强行将C# async/await映射到四要素可能不是很合适，因为C# async/await的Generator和Iterator是一体生成的，严格上不涉及所谓的执行权转移。C# async/await 是在async function外部直接生成一个状态机Wrapper类，对函数执行入口、返回值等进行了”魔改”。而JS Generator异步，是通过自定义的run函数或第三方co库驱动迭代。因此C#的async/await可以进行任意函数层级嵌套，而无需像JS一样每一个Generator都要单独驱动，另外C# async/await 可能涉及到线程切换，而JS则通常都是在单线程。</p>
<h5 id="async-await是Task-状态机的语法糖"><a href="#async-await是Task-状态机的语法糖" class="headerlink" title="async/await是Task+状态机的语法糖"></a>async/await是Task+状态机的语法糖</h5><p>这个要从两方面看，一方面，async函数在经过编译器处理后，最终返回给调用方的，是builder中的Task对象(这也是为何async方法的返回值只能是<code>void</code>, <code>Task</code>, <code>Task&lt;TResult&gt;</code>)。而另一方面，await本身不关注Task，它支持所有提供异步相关接口的对象(GetAwaiter)，这样的好处在于除了Task，它还可以集成更多来自框架(比如<code>.NET</code>已经提供的各种Async API)，甚至自定义的异步对象，已有的异步操作也可以通过适配GetAwaiter移植到新的async/await异步编程模型。</p>
<h5 id="出现await的地方，当前线程就会返回，或发生线程上下文切换"><a href="#出现await的地方，当前线程就会返回，或发生线程上下文切换" class="headerlink" title="出现await的地方，当前线程就会返回，或发生线程上下文切换"></a>出现await的地方，当前线程就会返回，或发生线程上下文切换</h5><p>这个前面也解释过了，出现await的地方未必会涉及线程上下文切换，比如前面的<code>await F2Async()</code>，对它的整个调用都是同步的。异步编程和线程无关，线程切换取决于异步操作的实现细节，而await本身只关注与异步操作交互的接口。</p>
<h3 id="Unity-async-await"><a href="#Unity-async-await" class="headerlink" title="Unity async/await"></a>Unity async/await</h3><p>Unity也引入了C# async/await机制，并对其进行了适配:</p>
<ol>
<li>Unity本身也是UI框架，因此它实现了自己的同步上下文<a href="https://github.com/Unity-Technologies/UnityCsReference/blob/master/Runtime/Export/Scripting/UnitySynchronizationContext.cs">UnitySynchronizationContext</a>以及主线程的消息泵，如此await的异步委托会默认会回到Unity主线程执行(可通过task.ConfigureAwait配置)</li>
<li>Unity社区提供了针对大部分常见YieldInstruction(如WaitForSeconds)，以及其他常用库(如UnityWebRequest、ResourceRequest)的GetAwaiter适配(如<a href="https://github.com/svermeulen/Unity3dAsyncAwaitUtil">Unity3dAsyncAwaitUtil</a>)</li>
</ol>
<p><a href="https://github.com/svermeulen/Unity3dAsyncAwaitUtil">Unity3dAsyncAwaitUtil</a>这个库及其相关Blog: <a href="http://www.stevevermeulen.com/index.php/2017/09/using-async-await-in-unity3d-2017/">Async-Await instead of coroutines in Unity 2017</a>，非常值得了解一下，以适配大家最熟悉的YieldInstruction WaitForSeconds(3)为例，来大概了解下如何通过将它适配为可以直接<code>await WaitForSeconds(3);</code></p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="comment">// GetAwaiter</span></span><br><span class="line"><span class="comment">// 适配WaitForSeconds类的GetAwaiter方法，通过GetAwaiterReturnVoid返回其Awaiter对象</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SimpleCoroutineAwaiter <span class="title">GetAwaiter</span>(<span class="params"><span class="keyword">this</span> WaitForSeconds instruction</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> GetAwaiterReturnVoid(instruction);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// GetAwaiterReturnVoid</span></span><br><span class="line"><span class="comment">// 创建和返回Awaiter: SimpleCoroutineAwaiter</span></span><br><span class="line"><span class="comment">// 并在Unity主线程执行InstructionWrappers.ReturnVoid(awaiter, instruction)</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> SimpleCoroutineAwaiter <span class="title">GetAwaiterReturnVoid</span>(<span class="params"><span class="built_in">object</span> instruction</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">var</span> awaiter = <span class="keyword">new</span> SimpleCoroutineAwaiter();</span><br><span class="line">    RunOnUnityScheduler(() =&gt; AsyncCoroutineRunner.Instance.StartCoroutine(</span><br><span class="line">        InstructionWrappers.ReturnVoid(awaiter, instruction)));</span><br><span class="line">    <span class="keyword">return</span> awaiter;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// InstructionWrappers.ReturnVoid</span></span><br><span class="line"><span class="comment">// 这里其实已经在Unity主线程，所以这里本质是将await最终换回了yield，由Unity来驱动WaitForSeconds的完成</span></span><br><span class="line"><span class="comment">// 只不过yield完成之后，通过awaiter.Complete回到Awaiter.OnCompleted流程去</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> IEnumerator <span class="title">ReturnVoid</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">            SimpleCoroutineAwaiter awaiter, <span class="built_in">object</span> instruction</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// For simple instructions we assume that they don&#x27;t throw exceptions</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">return</span> instruction;</span><br><span class="line">    awaiter.Complete(<span class="literal">null</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 确保Action在Unity主线程上运行</span></span><br><span class="line"><span class="comment">// SyncContextUtil.UnitySynchronizationContext在插件Install的时候就初始化好了</span></span><br><span class="line"><span class="comment">// 如果发现当前已经在Unity主线程，就直接执行Action，无需自己Post自己</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">RunOnUnityScheduler</span>(<span class="params">Action action</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (SynchronizationContext.Current == SyncContextUtil.UnitySynchronizationContext)</span><br><span class="line">    &#123;</span><br><span class="line">        action();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        SyncContextUtil.UnitySynchronizationContext.Post(_ =&gt; action(), <span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 真正的Awaiter，它是无返回值的，对应还有一个SimpleCoroutineAwaiter&lt;T&gt;版本</span></span><br><span class="line"><span class="comment">// 它的实现比较简单，就是适配接口，记录委托回调(_continuation)，并在Compele()任务完成时，通过RunOnUnityScheduler封送委托回调</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">SimpleCoroutineAwaiter</span> : <span class="title">INotifyCompletion</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">bool</span> _isDone;</span><br><span class="line">    Exception _exception;</span><br><span class="line">    Action _continuation;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">bool</span> IsCompleted</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">get</span> &#123; <span class="keyword">return</span> _isDone; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">GetResult</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>    &#123;</span><br><span class="line">        Assert(_isDone);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (_exception != <span class="literal">null</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            ExceptionDispatchInfo.Capture(_exception).Throw();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Complete</span>(<span class="params">Exception e</span>)</span></span><br><span class="line"><span class="function"></span>    &#123;</span><br><span class="line">        Assert(!_isDone);</span><br><span class="line"></span><br><span class="line">        _isDone = <span class="literal">true</span>;</span><br><span class="line">        _exception = e;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Always trigger the continuation on the unity thread when awaiting on unity yield</span></span><br><span class="line">        <span class="comment">// instructions</span></span><br><span class="line">        <span class="keyword">if</span> (_continuation != <span class="literal">null</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            RunOnUnityScheduler(_continuation);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">void</span> INotifyCompletion.OnCompleted(Action continuation)</span><br><span class="line">    &#123;</span><br><span class="line">        Assert(_continuation == <span class="literal">null</span>);</span><br><span class="line">        Assert(!_isDone);</span><br><span class="line"></span><br><span class="line">        _continuation = continuation;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如此我们就可以直接使用<code>await WaitForSeconds(3);</code>了，深入细节可以发现，不管是WaitForSeconds本身，还是之后的回调委托，其实都是在Unity主线程中执行的，并且结合RunOnUnityScheduler的优化，整个过程既不会创建线程，也不会产生额外的消息投递，只是在yield上加了一层壳子而已。这也再次说明了，async/await本身只是异步编程模型，具体的线程切换情况，Awaiter，SynchronizationContext，ConfigureAwait等综合控制。</p>
<p>这个工具库还有一些有意思的小特性，比如Task到IEnumerator的转换(原理就是轮询Task完成状态)，通过<code>await new WaitForBackgroundThread();</code>切换到后台线程(原理其实就是对<code>task.ConfigureAwait(false)</code>的封装)，这些在理解整个async/await，Unity协程，SynchronizationContext等内容后，都应该不难理解了。</p>
<p>另外，这里有篇关于<a href="https://www.linkedin.com/pulse/unity-async-vs-coroutine-jo%C3%A3o-borks">Unity中async/await与coroutine的性能对比</a>，可以看看。</p>
<h3 id="Unity-UniTask"><a href="#Unity-UniTask" class="headerlink" title="Unity UniTask"></a>Unity UniTask</h3><p>通过前面的了解，可以发现，在Unity中，Coroutine可以用来实现单线程内的异步操作，Task可用来实现多线程的并发、异步和协同操作。而async/await是一种比Coroutine和Task更抽象易用的异步编程模型，C#完成了Task和async/await的适配，Unity3dAsyncAwaitUtil完成了Coroutine和async/await的适配，但对Unity开发者而言，还是不够方便，开发者面临过多方案选择: yield Coroutine or await Coroutine or await Task，因此，Unity社区又有大神出手，出了一套新方案: <a href="https://github.com/Cysharp/UniTask">UniTask</a>，它的目的是整合Coroutine的轻量、Task的并发、async/await的易用于一体，为开发者提供高性能、可并发、易使用的接口。</p>
<p>它的主要特性包括:</p>
<ul>
<li>基于值类型的 UniTask<T> 和自定义的 AsyncMethodBuilder 来实现0GC</li>
<li>使所有 Unity 的 AsyncOperations 和 Coroutines 可等待 (类似Unity3dAsyncAwaitUtil的适配)</li>
<li>基于 PlayerLoop 的任务(UniTask.Yield, UniTask.Delay, UniTask.DelayFrame…)可以替代所有协程操作</li>
<li>对 MonoBehaviour 消息事件和 uGUI 事件进行 可等待/异步枚举 拓展</li>
<li>与C#原生 Task/ValueTask/IValueTaskSource 行为高度兼容</li>
<li>…</li>
</ul>
<p>更详细UniTask功能介绍，推荐<a href="https://www.lfzxb.top/unitask_reademe_cn/">这篇博客</a>，UniTask一方面保留和适配 Unity Coroutine的轻量单线程异步模型，另一方面，将Coroutine的惯用场景(如WaitForSeconds)全部移植到性能更优的UniTask上实现了一遍(受益于async/await异步模型的抽象性)，并且保持UniTask与Task语义兼容，保留大部分的Task并发和交互模型能力。</p>
<p>从实现上来说，以<code>UniTask.Delay</code>为例，它的功能类似于WaitForSeconds，它会返回一个<code>UniTask</code>对象，UniTask对象本身只是一层可await的壳子，真正起作用的对象是其持有的<code>DelayPromise</code>对象(<code>IUniTaskSource source</code>字段)，DelayPromise的有两个核心方法:</p>
<ul>
<li><code>OnCompleted</code>: AsyncUniTaskMethodBuilder挂接异步回调会通过UniTask Awaiter调到这里，它只是简单转调用<code>core.OnCompleted</code>，<code>UniTaskCompletionSourceCore core</code>是UniTask Promise都有的字段，做一些核心代码复用</li>
<li><code>MoveNext() bool</code>: 它会检查时间是否到期，未到期返回true，到期则通过<code>core.TrySetResult(null)</code>设置完成状态，并返回true。注意，<code>core.TrySetResult</code>中，会调用并执行continuation</li>
</ul>
<p>异步挂接和回调机制有了，谁来驱动<code>IUniTaskSource.MoveNext</code>，注意，这个MoveNext和C#中的<code>IAsyncStateMachine.MoveNext</code>是不同的:</p>
<ul>
<li><code>IAsyncStateMachine.MoveNext</code>: 通过AsyncTaskMethodBuilder来驱动async/await语法糖生成的状态机，对于<code>await Task.Run</code>而言，Task在线程池中执行完成了，那么一个状态机的状态就完成了，并且由Task的ContinueWith机制负责调用continuation继续驱动状态机(继续调用MoveNext)</li>
<li><code>IUniTaskSource.MoveNext</code>: 用于确定状态机的某个状态是否已经完成，<code>UniTask.Delay</code>本质是不切换线程的，如Unity Coroutine一样，必然需要额外的Ticker/Event/Poll这类机制，来检查状态变更(如Delay到期)，设置Awaiter Result，并回调continuation(通过<code>core.TrySetResult(null)</code>)</li>
</ul>
<p>驱动<code>IUniTaskSource.MoveNext</code>的工作是由<a href="https://github.com/Cysharp/UniTask/blob/master/src/UniTask/Assets/Plugins/UniTask/Runtime/Internal/PlayerLoopRunner.cs">PlayerLoopRunner</a>来完成的，DelayPromise创建之后，就会被立即添加到PlayerLoop Action中，PlayerLoopRunner穿插在Unity的各个执行Timing，驱动/检查所有IPLayerLoopItem任务的MoveNext。</p>
<p>对于<code>UniTask.Yield(PlayerLoopTiming.FixedUpdate);</code>这类场景，UniTask的实现更为简单，直接在<code>YieldAwaitable.OnCompleted(continuation)</code>挂接异步回调时，将continuation挂在PlayerLoop上即可，PlayerLoop会在对应timing(如FixedUpdate)触发时，调用continuation。</p>
<p>另外，<code>UniTask.Run/RunOnThreadPool</code>不使用默认的UnitySynchronizationContext和ExecutionContext，而是自己做同步上下文切换，这一点可能会容易和原生Task行为混淆，虽然它也提供<code>UniTask.SwitchToMainThread</code>、<code>UniTask.SwitchToThreadPool</code>、<code>UniTask.ReturnToCurrentSynchronizationContext</code>等API进行精确的同步上下文控制。</p>
<p>UniTask将Unity单线程异步编程诸多实践与async/await异步编程模型有机整合，并对Unity Coroutine与C# Task的诸多痛点进行优化和升级，看起来确实有一统Unity异步编程模型的潜力，应该离整合进Unity官方包也不远了。</p>
<h3 id="一点体会"><a href="#一点体会" class="headerlink" title="一点体会"></a>一点体会</h3><p>首先我是个C#和Unity的门外汉，只是谈谈自己的体会，异步编程尤其是并发编程从来都不是一件简单的事，无论它看起来多么”简洁优雅”。学习各语言/框架的异步演进史，是一件非常有意思的事情:</p>
<ul>
<li>C#: Thread(关注实现) -&gt; Task(关注任务) -&gt; async/await(关注可读性和扩展性)</li>
<li>Unity: Coroutine(Engine做大量支持，算半个异步编程模型) -&gt; Unity3DAsyncAwaitUtil(将Coroutine适配到async/await) -&gt; 到UniTask(整合Coroutine和Task，兼并性能更高、可读性更高、更适合Unity)</li>
<li>JS: Callback(最原始) -&gt; Generator+Thunk+AsyncOp+Iterator异步(初步四件套) -&gt; Promise(统一规范异步操作) -&gt; Generator+Promise+co(标准三件套) -&gt; async/await+Promise(终极两件套)</li>
</ul>
<p>异步编程模型一直在演进，看起来写越来越”简单”，可读性越来越”高”，代价是编译器和运行时做了更多的工作，并且这些工作和原理是作为开发者必须要了解的，以C# async/await为例，如果不能充分了解底层原理，就容易引发: </p>
<ul>
<li>异步回调闭包引用可变上下文的问题</li>
<li>async “无栈编程”本身带来的理解负担和调试难度</li>
<li>代码的线程上下文难以分析，容易引发并发安全访问的问题</li>
<li>同一段代码在不同的线程执行可能具有完全不同的行为(SynchronizationContext和ExecuteContext不同)</li>
</ul>
<p>等问题。语言和框架本身只提供选择，作为使用者的我们，在并发越来越”容易”的同时，保持对原理的理解，才能充分发挥工具的作用(享受上限高的好处，避免下限低的问题)。</p>
]]></content>
      <categories>
        <category>c#</category>
      </categories>
      <tags>
        <tag>coroutine</tag>
        <tag>async programing</tag>
        <tag>unity</tag>
        <tag>c#</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊Golang游戏服务器的热更</title>
    <url>/2022/08/golang-gameserver-hotfix/</url>
    <content><![CDATA[<p>从Erlang过渡到Golang以来，一直陆续会有同学问: “Golang能不能做代码热更呢？”，”游戏服务器不能热更会不会经常停服？”之类的问题，我的一贯看法是，抛开成本和风险谈收益的意义是不大的，所以在回答以上问题之前，先聊聊主流的Golang热更方案，它们都是基于<a href="https://pkg.go.dev/plugin">Go Plugin</a>机制的，这里讨论其中的两种，这里我将其称为plugin package swap方案和plugin function patch方案。</p>
<h4 id="plugin-package-swap"><a href="#plugin-package-swap" class="headerlink" title="plugin package swap"></a>plugin package swap</h4><p>该方案的思路是，将业务package编译为plugin，动态加载和替换，再通过<code>plugin.Lookup</code>来动态查找和使用函数。这也是最主流的Go Plugin应用方案，不过该方案有以下缺点:</p>
<ol>
<li>受 Go Plugin 本身的限制，如第三方依赖需要一致、不能引用插件package、插件内数据类型共享、插件无法释放、调试相对困难、跨平台问题等</li>
<li>对业务代码侵入式较强，包括 plugin main package限制、Lookup调用方式、发布流程等</li>
</ol>
<p>Go Plugin从2016年发布以来一直不温不火，Go官方对Plugin的维护升级更谈不上上心(两者互为因果)，对于大部分开发者而言，面临Plugin的诸多限制，还是要花一些时间踩坑的。因此，有一套弱侵入性的热更方案，减少对已有框架代码的影响，减轻对开发者的理解负担(比如不要为热更单独写业务代码)，并且提供快速切换静态编译和热更版本的支持，在我看来对线上服务是比较重要的。有一些开源库能解决部分问题，如<a href="https://github.com/edwingeng/hotswap">hotswap</a>能解决 main package 限制(通过正则临时替换)、不同版本plugin数据类型问题、Plugin生命周期管理问题等，并且也提供了动态链接(走plugin Lookup)和静态链接(对外暴露相同的接口，不过底层不走plugin Lookup，而是package函数调用)两种集成方式，一定程度降低了热更的侵入性。</p>
<span id="more"></span>
<p>更进一步降低侵入式的方案是使用条件编译来区分静态编译版本和热更版本，对静态编译版本而言，它除了多个几个no-op hook外，不耦合任何热更相关的东西。将插件相关代码对框架的侵入式降到最低。每次发布主体或插件，基于同一套代码同时构建热更主体、热更插件以及静态编译版本，如此在需要时，可以很方面地切换或者对照。</p>
<p>另一种较为Geek的方案是不使用条件编译对静态编译和热更版本做编译期区分，而是做运行时区分。服务器每次都以静态编译启动(无需so插件)，但是开启插件热更机制，一旦自动检测或手动启动热加载，就用so插件的代码替换掉原本的package实现，从而实现热更。这种方案的优点是在服务器没有BUG无需热更的情况下，它的运行时表现和静态编译版本基本一致。缺点是代码层面对热更机制有一定的耦合。</p>
<p>另外，Go Plugin 的诸多限制也影响了该方案的应用范围，对游戏服务器而言，首要就是得有合理的package拆分，这方面可以借助DDD和洋葱架构对业务领域进行拆分和隔离，理想中的plugin package需要满足:</p>
<ol>
<li>无全局变量</li>
<li>不被其他package依赖</li>
<li>所有数据和接口依赖，都通过外部依赖注入</li>
<li>无后台goroutine</li>
<li>尽量不要暴露plugin内的数据类型</li>
<li>…</li>
</ol>
<p>满足如上条件的package其实更偏向提供类似纯函数的Handler实现，这较大程度限制了Plugin代码热修复的覆盖度和能力。</p>
<h4 id="plugin-function-patch"><a href="#plugin-function-patch" class="headerlink" title="plugin function patch"></a>plugin function patch</h4><p>另一种在其他项目应用过的方案也是基于Plugin，但不是将Plugin作为整个package的可替换实现，而是只通过Plugin实现要替换的函数补丁:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func GetPatchFuncs() map[string]string &#123;</span><br><span class="line">	&#x2F;&#x2F;map的key是新函数在本补丁文件中的名称(以便通过plugin.Lookup找到该函数地址)</span><br><span class="line">	&#x2F;&#x2F;map的value是旧函数在旧可执行文件中的名称(应该用nm来查，以便通过CGO dlsym找到该函数地址) </span><br><span class="line">	list :&#x3D; map[string]string&#123;</span><br><span class="line">		&quot;TestHandlerHotFix&quot;: &quot;main.TestHandler&quot;,</span><br><span class="line">	&#125;</span><br><span class="line">	return list</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在加载Plugin后，借助<code>plugin.Lookup(&quot;GetPatchFuncs&quot;)</code>拿到Patch映射，再通过<code>plugin.Lookup</code>和<code>CGO dlsym</code>分别找到新旧函数地址，最后借助<code>mprotect</code>+<code>memcpy</code>+<code>hardcode asm</code>修改旧函数地址入口内容为: <code>jmpq 新函数地址</code>。</p>
<p>这套方案借鉴经典的C函数补丁热更方案，它的好处是，业务代码不需要大的调整，缺点也有不少:</p>
<ol>
<li>相较package swap，函数补丁灵活性没有那么高</li>
<li>需要为了热更，暴露package过多的类型和函数</li>
<li>Patch函数修复后，还需要在业务逻辑中再修复一次</li>
<li>由于是函数地址替换，因此还会受到编译器内联优化的影响</li>
<li>由于用了C和汇编，与底层耦合过重，跨平台和跨系统可移植性只能自己保证</li>
</ol>
<h4 id="代码热更的价值"><a href="#代码热更的价值" class="headerlink" title="代码热更的价值"></a>代码热更的价值</h4><p>在大概了解Go热更的两种实现方式和相对应的成本和风险之后，现在来聊聊代码热更的价值和收益。首要仍然要强调的是，代码热更如同设计模式中的适配器，本质都是一种补救措施。如果一个线上服务器频繁使用代码热更来修复BUG，这不能说明代码热更很有用，反倒是说明服务器的线上交付质量有问题，工作重心应该更多地考虑保障线上交付质量。同时，为热更付出的开发成本以及带来的风险性都要谨慎评估，否则就会有点舍本逐末了(提升可用性的措施，引入了新的风险或花了过高的成本反而降低了可用性)。这也是我前面提到非侵入性和共存方案的初衷之一。</p>
<p>现在回到最开始的两个问题:</p>
<ol>
<li>“Golang能否做代码热更?”: 能支持一定程度的代码热更，但目前已知的代码热更方案，都有一定的技术风险(坑)，限制也比较多，并且只能覆盖部分业务代码，可能还需要做前置代码重构</li>
<li>“没有热更会不会经常停服？”: 在我们近年的Golang服务器实践经验中，能否代码热更还不算是服务器的可用性瓶颈，服务器停服的原因包括版本更新、意外故障以及紧急修复等，代码热更只能解决紧急修复中的一部分BUG，这个”部分”取决于BUG复杂程度、是否需要停服止损、修复数据、是否被热更覆盖等</li>
</ol>
<p>综上，代码热更是否值得做，最终还是取决于对各项目对这一块的成本风险和收益的权衡，而每个项目在这一块上面临的技术挑战和风险是不一样的。对我们而言，由于之前借助一些DDD思想对业务领域进行了拆分和重组(基于可维护、可测试、可扩展性考量)，目前的业务package粒度和组织方式，都比较适合hotswap方案，因此目前我们开始尝试 hotswap + domain package + 条件编译 + 并存构建的热更方案，其前置业务重构成本、侵入性、风险性都很低，目前的想法是小范围逐步推进，比如先用在活动这类最常出问题的系统上。</p>
<h4 id="非代码热修复"><a href="#非代码热修复" class="headerlink" title="非代码热修复"></a>非代码热修复</h4><p>一个完整的有状态游戏服务器主要包含三部分: 代码、数据和配置，因此除了代码热更之外，这里顺便提一下配置热更和数据热修复。</p>
<p>配置问题是游戏服务器线上问题的主要来源之一，大部分的游戏服务器都会提供一定的配置热更能力，这个实现起来不难，由于我们使用全容器部署，为了做到宿主机隔离，配置热更是通过将配置导入到DB然后Reload来实现的，并借助<code>atomic.Value</code>保证配置的并发读写安全性。对于逻辑层而言，尽可能不要缓存配置，而是每次都从配置中读取最新值。</p>
<p>至于数据热修复，SLG游戏服务器基于性能、响应延迟、逻辑耦合强等各种原因，通常都是有状态+定时落地的，尽管我们尽可能从防御性编程、架构可靠性、线上监控、快速部署恢复等手段来尽可能提升服务器可用性，但各种预期之外的错误和故障仍然可能导致处理流程中断，引发各种数据不一致性问题。而按照经验，处理这些故障导致的数据修复，往往比服务恢复更可能成为”可用性瓶颈”。因此，为了最大程度提升玩家体验，一种或多种不停服修复数据方案是需要被考虑并长期维护的。按照我们的经验，大概可以从以下几个维度来考虑:</p>
<ul>
<li>Normal Fix: 对于常见的数据不一致，做一套Fix流程，并且手动(如通过GM)或者自动(如服务器启动、玩家上线时)开启</li>
<li>Lua Fix: 接入Lua(如<a href="https://github.com/yuin/gopher-lua">gopher-lua</a>)并暴露核心的数据API以便通过Lua做一些临时的数据诊断和修复</li>
<li>Reflect Fix: 基于Go Reflect实现一套简单的DSL，支持结构体嵌套字段的读取和赋值</li>
<li>DB Fix: 强制带LRU的数据刷盘，修改DB，最后Reload</li>
</ul>
<p>由于这一块和业务框架耦合较重，不再展开，仅仅提供一些思路。</p>
]]></content>
      <categories>
        <category>gameserver</category>
      </categories>
      <tags>
        <tag>gameserver</tag>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>领域驱动设计之柔性设计</title>
    <url>/2022/10/ddd-suple-design/</url>
    <content><![CDATA[<p>本文为《领域驱动设计-软件核心复杂性应对之道》中关于柔性设计和重构相关内容学习笔记，之前总结的<a href="https://wudaijun.com/2021/06/software-design-mindmap/">软件设计</a>更多偏向于技术实现层面，而柔性设计更强调领域模型，属于非结构化建模。前者教你修房子(设计之术)，后者教你设计建筑(设计之道)。虽曰”道可道，非常道”。但反复学习品味相关内容，结合之前的重构实践，相互印证，确实诸多共鸣，受益匪浅，逐整理之。</p>
<p><img src="assets/image/202210/柔性设计.png" alt=""></p>
]]></content>
      <categories>
        <category>design</category>
      </categories>
      <tags>
        <tag>domain driver design</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统理论基础</title>
    <url>/2022/12/distributed-system-basic/</url>
    <content><![CDATA[<p>起意是想梳理下分布式系统的一些基本概念和理论，做一张知识脉络图，后来发现内容太多，图片不适合，因此整理成了文字版本。不过整体框架结构仍然类似思维导图，用作知识联结与发散。</p>
<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><h3 id="什么是分布式系统？"><a href="#什么是分布式系统？" class="headerlink" title="什么是分布式系统？"></a>什么是分布式系统？</h3><p>系统中有若干独立自治的计算实体，每个实体有自己的内存状态，实体之间通过传递消息相互通信。整个系统对用户提供一致、统一的服务。</p>
<h3 id="为什么要使用分布式系统？"><a href="#为什么要使用分布式系统？" class="headerlink" title="为什么要使用分布式系统？"></a>为什么要使用分布式系统？</h3><p>使用分布式而不是单机的原因有很多，总的来说大概分为三类: </p>
<ul>
<li>解决业务问题: 如复杂度瓶颈、系统对接、成本考量等</li>
<li>解决扩展性问题: 如计算瓶颈、存储瓶颈、延迟优化等</li>
<li>解决可用性问题: 通过冗余提升可用性</li>
</ul>
<h2 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h2><p>分布式系统关注哪些指标？或者说我们通过哪些指标来衡量一个分布式系统？</p>
<h3 id="可伸缩性"><a href="#可伸缩性" class="headerlink" title="可伸缩性"></a>可伸缩性</h3><p>定义: 系统通过添加资源来应对不断增长(或变更)的工作量的能力。</p>
<p>伸缩的维度有很多，包括规模伸缩、地理伸缩、功能伸缩、异构伸缩等。</p>
<p>理想情况下，期望系统处理能力随资源投入线性增长。而实际上，还要权衡通信成本和延迟、可用性、数据一致性等诸多方面。</p>
<h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><p>定义: 系统处于正常工作状态的时间比例。</p>
<p>这里有两个个相关概念:</p>
<ul>
<li>MTBF(Mean Time Between Failure)：平均无故障时间，MTBF越长表示可靠性越高</li>
<li>MTTR(Mean Time To Repair):平均修复时间，MTTR越短表示易恢复性越好</li>
</ul>
<p>可用性 = 正常运行时间/(正常运行时间+故障时间) = MTBF/(MTBF+MTTR)。</p>
<span id="more"></span>
<p>注意可用性和可靠性的区别，可用性关注时间比例，可靠性关注时间间隔。假设一个系统每小时崩溃1ms，可用性高达99.9999%，但它仍然高度不可靠。</p>
<p>在实践中，可用性很难如它定义那般能明确度量，如部分功能可用、部分入口可用等。另外，用户感知的可用性与系统可用性也可能有差异(受用户本地缓存、重试机制、用户使用功能范围等影响)。</p>
<p>分布式系统可以通过容错来提升可用性，最常见的容错方案就是冗余(并行可用性)。不做额外容错的分布式系统，其可用性上限为其组成部分的可用性(串行可用性)。</p>
<p>基于不可靠的硬件和网络，打造高可用的系统和服务，是分布式系统的重要目标之一。</p>
<h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>定义: 有效工作量与所用时间和资源的比值。</p>
<p>提升性能的方式: 提升吞吐量(如并发)、降低响应延迟(受光速制约)、降低资源占用(性能优化)。</p>
<p>将响应延迟归入性能是比较有意思的，一方面，响应延迟当然受处理性能的影响，另一方面，响应延迟也受设计(如同步or异步)和架构(如异地多活)的影响。并且站在用户的角度上看，响应延迟是最直观的性能属性。</p>
<h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>一致性这个概念用得很广(有点过度重载)，在我的理解中，分布式系统的一致性本质指预期一致性，即由多台计算机组成的分布式系统，能否像一台计算机一样，行为符合预期且容易理解，这是分布式系统的理想目标之一。但现实中，分布式系统与单机系统相比，要额外考虑部分故障、网络最小延迟、网络不可靠、没有全局时钟等因素，想到完全达到单机一样的可理解可预期是不可能的。但是我们可以通过技术手段和不同的一致性模型，增强用户对分布式系统行为的预期。</p>
<p>我将分布式中的一致性分为读写一致性和事务一致性。而这两者又分别和复制、分片这两个分布式基础技术相关。因此这两种具体的一致性，放到后面的复制与分片中再谈。</p>
<h2 id="现实"><a href="#现实" class="headerlink" title="现实"></a>现实</h2><p>在实践中，分布式系统受到哪些限制？或者说，哪些因素影响我们获得可伸缩、高可用、高性能、强一致性？</p>
<h3 id="各个节点独立并行运行"><a href="#各个节点独立并行运行" class="headerlink" title="各个节点独立并行运行"></a>各个节点独立并行运行</h3><p>分布式系统中的程序在独立的节点上并行运行，这里面有两个关键字”独立”和”并行”。</p>
<p>“独立运行”意味着独立失败，也就意味着分布式系统有比单机系统更高的硬件故障概率，这种部分故障，是分布式系统首先要考虑的问题。如系统如何检测到节点故障？如何在部分故障时仍然保持整个系统的可用性和数据一致性？</p>
<p>“并行运行”意味着时间、顺序、和一致性的问题，不同于节点内并发可以通过锁来做互斥同步，分布式系统实现锁的代价要大很多，比如使用Redis实现分布式锁，要考虑Redis本身的可用性问题，和Redis的网络通信的稳定性问题，节点故障后的锁释放问题等等。</p>
<h3 id="节点之间通过不可靠且有速度上限的网络通信"><a href="#节点之间通过不可靠且有速度上限的网络通信" class="headerlink" title="节点之间通过不可靠且有速度上限的网络通信"></a>节点之间通过不可靠且有速度上限的网络通信</h3><p>更多的节点，意味着更复杂的网络拓扑，也就会带来更高的管理和通信成本。这会影响影响分布式系统的性能(包括响应延迟)和扩展性问题。</p>
<p>更复杂的网络拓扑也意味着网络(部分)故障的概率更高，在不可靠网络下，我们甚至无法区分节点故障和网络分区。这极大增加了分布式系统容错的难度，如网络分区之后脑裂和一致性问题，网络恢复之后的数据冲突问题。</p>
<p>网络速度受光速限制，意味着每个节只能快速访问局部状态(内存状态)，任何关于全局的状态都是过时的，这对数据一致性也带来了挑战。</p>
<h3 id="没有全局时钟"><a href="#没有全局时钟" class="headerlink" title="没有全局时钟"></a>没有全局时钟</h3><p>秩序源于顺序，人对分布式一致性的理解离不开对顺序的假设，而最自然的顺序就是时间先后顺序。但分布式系统没有全局时钟，节点本地的时钟是不一致甚至不可靠(可人为篡改的)的，这使得并发分布式系统的行为很难理解，且很难察觉。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>针对现实中的节点故障、网络不可靠、以及全局时钟问题，有哪些相关的模型或假设？</p>
<h3 id="故障模型"><a href="#故障模型" class="headerlink" title="故障模型"></a>故障模型</h3><ul>
<li>node crash-stop failures: 节点崩溃-终止模型，该模型假定节点只会因为崩溃失败，失败后停止发送和接受消息，且不会恢复</li>
<li>node crash-recover failures: 节点崩溃-恢复模型，在crash-stop的基础上，假定节点可能随后恢复服务。这里还要分健忘和非健忘两种情况，即节点是否持久化了crash前的状态信息</li>
<li>byzantine failures: 拜占庭故障模型，在crash-recover模型上，进一步放宽约束，假定节点可能因为因为逻辑错误或其他原因导致不可信，即它可能伪造信息或输出错误信息。拜占庭故障基本是分布式系统最难的故障模型，解决它通常需要假设同步网络模型。拜占庭将军问题是拜占庭故障模型下衍生的共识问题</li>
<li>network partition failures: 网络分区故障模型，即是否假设节点间网络可能无限延迟或者不可达，这种情况和节点崩溃有所区别，因为网络分区下，不可达的节点可能已经崩溃或者仍在接受客户端请求(并且无法区分)。CAP定理中的P就表示网络分区故障容忍度</li>
</ul>
<h3 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h3><ul>
<li>Synchrony: 同步网络模型，假定节点消息传输延迟有一个已知的上限值Δ，如此进程可以以锁步(lock-step)的方式执行(类似流水线作业)。同步网络模型易于分析和解决分布式问题，但实践中很难保证该假设的成立</li>
<li>Asynchrony: 异步网络模型，只保证消息最终会被投递，但消息传输延迟无上限。基于它而设计的分布式算法鲁棒性很强，但解决方案也更复杂，而FLP不可能定理(后面会提到)更是指明了全异步的网络模型下，想要在确定时间内让节点达成共识是不可能的。因此异步网络模型的共识算法，在极限网络状况下，有可能丧失活性</li>
<li>Partial synchrony: 部分同步/半同步网络模型，介于同步和异步之间，指存在一个网络传输延迟上限Δ，和一个特殊的事件GST(Global Stabilization Time，全局稳定时间)，如果一条消息在时间x被发出，那么它必然在<code>Δ+max(x,GST)</code>内投递。即网络模型在GST前是异步的，在GST后是同步的。但是这个GST何时发生无法预测。这个定义稍微晦涩一些，可以映射到现实中的网络状况，99%的时候传输延迟有上限，但是少数情况出现网络波动，或者对方受到DDos攻击时，传输延迟不可预估，不过最终网络还是会稳定下来，又回到正常有界传输的状态。GST风格的部分同步网络模型，允许构建在大多数情况(网络稳定)表现很好(可以使用比较保守的Δ值)，在少数情况(网络不稳定)时，也保证安全性(但可能丧失活性)的共识算法</li>
</ul>
<p>关于半同步网络模型的另一个定义是UL(Unknown Latency)风格: 网络始终是同步的，只是协议设计者不知道消息传输的最大延迟界限。它的核心思路是协议设计者需要动态调整传输上限Δ(按照系统最坏的延迟情况)，以逼近真正的网络延迟。<a href="https://decentralizedthoughts.github.io/2019-09-14-flavours-of-partial-synchrony/">这篇文章</a>尝试阐述基于GST和UL风格的定义在理论上是等价的。</p>
<p>目前主流的分布式算法，都是基于部分同步网络模型的，如Paxos，Raft，PBFT等。</p>
<h3 id="时间和顺序"><a href="#时间和顺序" class="headerlink" title="时间和顺序"></a>时间和顺序</h3><p>对单台计算机系统而言，确定操作的执行时间和顺序是比较容易的，这也使得系统的行为比较容易预测。而对于分布式系统而言，则需要重新理解时钟和顺序。</p>
<p>分布式系统中的顺序分为偏序和全序，偏序是每个节点看到的操作执行顺序，是对局部操作的局部视角。而全序则是整个系统所有事件的执行顺序，在分布式系统中，想要维护全序是比较困难的，因为网络是异步的，并且没有全局时钟。</p>
<p>分布式系统中的时钟分为物理时钟和逻辑时钟，物理时钟对应绝对时间，如各个节点的机器时间，想要完全同步各个节点的物理时钟是非常困难的(网络时间协议NTP、原子时钟本质都是减少误差而不能消除误差)。而逻辑时钟则对应相对时间，它关注分布式事件的相对顺序，如Lamport逻辑时钟(vector clock，矢量时间)可以用来维护事件因果关系的偏序，而大部分时候，我们期望的也是就”事件发生顺序”达成一致，而不是就”事件绝对时间”达成一致，换个角度来说，”时间”这个概念本身就没有绝对。在分布式系统中，对时间/顺序的假设和依赖越少，就越能充分发挥分布式系统的优势。</p>
<h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>分布式系统中有哪些经典的理论和问题？</p>
<h3 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h3><p>CAP定理主要阐述线性一致性(C)、高可用性(A)、网络分区故障容忍(P)不得兼得(三选二)。理解CAP定理的前提是认识到它作为理论模型的绝对(只考虑了最强的线性一致性和高可用)和局限(只关注了三个指标，其他还有性能、延迟、硬件故障、可读可写等)。不过CAP定理仍是分布式系统最重要的理论之一，它指出了分布式系统中一致性和可用性的权衡参考线，在此之上的分布式系统，要么加强假设(假设没有网络分区)，要么削弱保证(如提供更弱的一致性和可用性，以容忍网络分区，如BASE理论)。</p>
<p>通常来说，CA和CP系统以严格的仲裁协议来达成一致，区别是CA系统完全无法容忍(没有考虑)任何网络分区，如2PC两段式提交。而CP系统通常可以容忍部分网络分区并为此舍弃(至少少数节点一侧的)可用性。至于AP系统，则通常包含如何解决数据冲突的协议，如DNS系统。</p>
<p>从另一个角度来看，C、A描述的是系统的行为，而P描述的是系统的假设和工作范围。当我们说一个系统或算法是CA的，本质是说，如果没有网络分区，那么它是一致可用的(典型如2PC)，但是现实中的网络分区往往不可避免，因此当所谓的CA系统遇上不得不考虑的P时，通常就会变成CP、AP甚至P(既不线性一致，也不可用)系统。如2PC，它通常被认为属于CA系统，但当发生网络分区时，它可能是CP(如果参与者一直独占资源等待协调者通知Commit)或者P(如果参与者等待Commit通知超时后，自己会执行Commit避免独占，此时既不可用，也不一致)。</p>
<p>总之，由于CAP的局限性和系统的可配置性，将很多系统简单以CA、AP、CP来归类和讨论可能是不合适的。</p>
<h3 id="FLP不可能定理"><a href="#FLP不可能定理" class="headerlink" title="FLP不可能定理"></a>FLP不可能定理</h3><p>FLP不可能定理讨论的是在异步网络模型(不考虑网络分区故障)下，哪怕只有一台机器可能因为Crash出错(Crash-Stop模型)，则没有任何确定性共识算法保证在有限时间内结束。这是一个咋一看比较”悲观”的定理，它定义了异步网络下共识算法的上限，好在现实中的网络大部分时候都比较可靠，系统可以在网络超时时，舍弃一些活性和安全性。</p>
<h3 id="拜占庭将军问题"><a href="#拜占庭将军问题" class="headerlink" title="拜占庭将军问题"></a>拜占庭将军问题</h3><p>拜占庭将军问题，本质讨论，在有节点作恶的情况下，如何达成共识。拜占庭问题是如此出名，以至于主流共识算法通常被分为支持拜占庭问题(BFT)和不支持拜占庭问题(CFT)两类:</p>
<ul>
<li>拜占庭容错(Byzantine Fault Tolerance，BFT): 容忍节点故障和节点作恶，通常用在公网区块链上，经典如 PoW算法(最多容忍1/2作恶节点)，PBFT算法(最多容忍1/3作恶节点)</li>
<li>宕机容错(Crash Fault Tolerance，CFT):  即容忍节点故障，但是不考虑节点作恶的情况，经典算法有Raft、Paxos等。在实践中的大部分非公网分布式系统，都采用CFT算法，因为其通常具备更好的性能、可理解和可实现性</li>
</ul>
<h2 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h2><p>“分”(分割)而”制”(复制)之是分布式系统的最核心最基础的技术方案，前者解决存储、计算、以及业务复杂度瓶颈，后者提升可用性和性能。</p>
<h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><p>在多台机器上维护相同的数据副本，为同样一份数据提供更多的处理能力、位置扩展和容错，提升系统的性能和可用性。数据复制的挑战主要在于一致性(读写一致性)和容错。由于分布式系统中，各个节点通常都是相同的确定性状态机，因此大部分场景下，复制问题也称为状态机复制(State-Machine Replication)问题。</p>
<h4 id="读写一致性"><a href="#读写一致性" class="headerlink" title="读写一致性"></a>读写一致性</h4><p>指多数据副本(复制集)场景下，系统对用户保证的读写预期。如A进程对复制集系统写入一个值，A或其他进程能立即读到这个值吗？理想情况下，用户最容易理解的是最强的线性一致性，因为它实现了如同单节点一般的读写预期，但其需要付出额外的可用性和性能(包括响应时延)取舍，CAP理论就明确指出了线性一致性和高可用性两者的矛盾。除了线性一致性，还有其他更弱的一致性模型，如顺序一致性、会话一致性、因果一致性、最终一致性等。我在<a href="wudaijun.com/2018/09/consistency/">这里</a>重点介绍了线性一致性和顺序一致性。</p>
<p>除了强一致性(线性一致性和顺序一致性，也有种理解认为只有线性一致性是强一致性)之外的一致性都称为弱一致性，弱一致性模型可以是和用户的任何读写约定，而理论上最弱的一致性就是完全不保证数据一致(即不提供一致性保证)，这显然缺乏实际意义，因此实践中最弱的一致性模型通常为最终一致性，即系统在经过一段时间后最终会达成一致。最终一致性承诺就像“人终有一死”一样，对用户来说仍然缺乏实际的指导意义，用户还需要关心:</p>
<ul>
<li>这个“最终”是指多久？或者有多大概率在多久内可以达成一致？(类似响应延迟SLA)</li>
<li>如何达成一致？是最后写入者成功？还是有其他解决冲突的方案？</li>
<li>其他保证: 如用户可以读到刚写入的值吗(读你写)？连续读某个键值，后读出的会比先读出的数据更旧吗(单调读)？等</li>
</ul>
<p>以DNS为例，我们都知道DNS是最终一致性系统，但知道DNS的最大同步时间(48h)、DNS如何达成一致(最后写入者成功)、以及DNS的单调读一致性等信息，才能让我们更好地使用DNS系统。对系统开发者而言，也需要根据业务场景为用户提供适合的一致性保证。</p>
<h4 id="共识"><a href="#共识" class="headerlink" title="共识"></a>共识</h4><p>和复制集、读写一致性一起出现的，通常还有共识(Consensus)一词，它是指多个节点如何就同一个提案(如某个键的值、谁是主节点、事件发生顺序等)达成一致。共识算法可以作为复制集多节点数据同步和主从切换的技术方案。共识关注的是复制集内部达成一致的过程，而读写一致性关注复制集对用户提供的读写预期。共识算法有一些基本属性:</p>
<ul>
<li>可终止性(Termination): 所有正确的进程最终都会认同某个提案，即保证能正常给出结果，也被称作活性(Liveness)，对应于CAP中的可用性</li>
<li>约同性(Agreement): 所有正确的进程最终认同的提案是同一个提案，即保证给出的结果是一致的，也被称作安全性(Safety)，对应于CAP中的一致性</li>
<li>合法性(Validity): 最终认同的提案，必然是某个节点提出的提案</li>
</ul>
<p>活性(Liveness)和安全性(Safety)是最常被提及的两个共识算法属性，因为它们在分布式的各种挑战下，往往不得不妥协。</p>
<p>以下介绍数据复制和共识算法的经典解决思路</p>
<h4 id="中心化方案"><a href="#中心化方案" class="headerlink" title="中心化方案"></a>中心化方案</h4><p>主从方案是复制算法最经典也是最容易理解的中心化方案，整个复制集由一个主节点(称作Primary或Leader)N个从节点(称作Backup或Follower)组成，由主节点对外提供写服务，并把操作同步给从节点，从而完成复制的目的。主从方案有一些权衡点:</p>
<ul>
<li>从节点是否可读: 支持从节点可读的性能更好，但读写一致性可能降低</li>
<li>主节点是否同步等待从节点确认: 同步等待确认的数据一致性更高，且主从切换时不容易发生数据丢失，但性能、响应延迟和可用性会降低</li>
<li>数据同步机制: 全量(同步数据快照)和增量(同步操作日志)各有优劣(前者下限高，后者上限高)，需要相互结合</li>
<li>容错性: 主节点失效时的主从切换(非常容易产生数据丢失或不一致)、从节点失效时的数据追赶(全量同步派上用场)、以及如何解决网络分区导致的脑裂问题(大部分算法不会考虑)</li>
</ul>
<p>主从方案的优势是实现相对简单，由于主节点通常需要和所有的从节点交互，因此只适用于小规模集群。</p>
<h4 id="去中心化"><a href="#去中心化" class="headerlink" title="去中心化"></a>去中心化</h4><p>去中心化是指所有节点地位平等，均可以处理用户请求，最终通过协商合并来达成最终数据一致。</p>
<p>去中心化的优势在于节点可以任意数量扩展，劣势在于性能和一致性较差。由于去中心化的特性，它通常被用在公网上，因此通常是容忍网络分区和拜占庭容错的。这里以比特币的共识算法PoW为例来了解去中心化的一些难点:</p>
<ul>
<li>如何容忍网络分区: 比特币为了可用性而牺牲强一致性(AP系统)，因此它将重心放到如何解决数据合并和冲突上</li>
<li>如何容忍占庭将军问题: 通过工作量证明来提升提案成本，通过最长链来解决数据冲突，使得作恶所需要的算力要高于总集群算力的50%。但代价是长周期的最终确认(解决分叉)的时间，以及大量的算力浪费</li>
</ul>
<h4 id="N段提交"><a href="#N段提交" class="headerlink" title="N段提交"></a>N段提交</h4><p>前面提到的主从数据同步，通常主节点和从节点单次数据同步只需要单次交互(1PC, 1-Phase Commit)，这可能会导致部分从节点提交成功而另一部分提交失败，引发读写一致性问题。两段提交(2PC, 2-Phase Commit)可以改进这个问题:</p>
<ol>
<li>协调节点先向参与节点咨询操作是否可执行，参与节点做对应的提前准备，当参与者回复OK时，意味着<strong>承诺操作在该节点一定能成功Commit</strong></li>
<li>协调节点如果发现有参与者回复失败，则向其他节点发送Rollback通知，否则如果所有参与节点都回复OK，则通知所有参与节点Commit，当协调节点发起Commit时，意味着<strong>承诺该事务一定能完成</strong></li>
<li>如果Commit/Rollback阶段参与节点宕机或者发生网络分区，协调节点负责重试，直到所有参与节点回复Commit成功</li>
<li>如果协调节点故障，协调节点通过持久化来容忍自身宕机，并在恢复后读取上一次的决策进度(崩溃-恢复-备忘模型)</li>
</ol>
<p>2PC相比1PC，通过第一阶段的Check+Prepare流程减少了第二阶段Commit结果不一致的可能性，也就增强了数据一致性，相应的也增加了响应延迟。2PC主要有如下缺点:</p>
<ol>
<li>协调者可能出现单点故障，可能导致参与节点处于阻塞或者临界状态 </li>
<li>执行过程中，参与节点的相关资源处于独占状态，系统吞吐量会降低 (如果超时释放或提交，就可能产生不一致)</li>
<li>最后一轮Commit，可能只通知到部分节点，导致数据不一致 (CA系统)</li>
</ol>
<p>当然，2PC还有很多细节，如要不要重试，协调者崩溃后，参与者是一直等协调者恢复(通常此时还持有锁或处于阻塞状态)，还是Abort或Commit等等。</p>
<p>基于2PC的部分缺点，3PC进行了一些改进，它将Check和Prepare分开，并在参与方引入超时机制，但由于更加复杂且响应时延较高，因此实践中仍以2PC为主。可以看到，1PC-&gt;2PC-&gt;3PC，消息交互的轮次越多，不一致或处于临界状态的时间窗口就越小，但响应延迟也会更高。</p>
<h4 id="多数表决机制"><a href="#多数表决机制" class="headerlink" title="多数表决机制"></a>多数表决机制</h4><p>前面讨论的主从，2PC等方案，都没有考虑网络分区问题。针对网络分区问题最经典的解决方案就是多数表决机制，它能容忍小于半数的节点发生网络分区，并在多数节点一侧继续对外提供一致性保证和服务。多数表决和中心化一样，都适用于较小、可信任的集群，因此它们通常被搭配使用，如经典的Raft/Paxos算法，以Raft为例，在执行写入操作时，和2PC类似，Leader节点会和Follower进行两段提交确认，在获得大于一半的节点同意后，才会执行写入。在Leader宕机或者Leader发生分区后，多数节点侧会通过随机错峰+多数表决的机制选出新的Leader，并通过Leader任期+提案号等机制来解决分区恢复后脑裂恢复。</p>
<h4 id="读写Quorum"><a href="#读写Quorum" class="headerlink" title="读写Quorum"></a>读写Quorum</h4><p>在中心化方案中，我们假设只有主(Primary/Leader)节点对外提供读写服务，这种方案实现比较简单，也具备较好的一致性，但是不利于性能扩展，因此部分复制系统(如MongoDB，DymanoDB)也为客户端提供读写策略选项，即WRN模型</p>
<ul>
<li>N为集群总节点数量</li>
<li>W代表写入操作需要征得多少节点成功响应</li>
<li>R代表读操作需要向多少个节点查询</li>
</ul>
<p>WRN常见的几种关系</p>
<ul>
<li>W+R&gt;N时: 系统能检测到读写冲突(读写必有交集)，是系统可以提供强数据一致性的基础(还有其他因素，如N是否稳定、分区是否脑裂等)，在此基础上，系统/用户可以在写入性能(W更小)和读取性能(R更小)中进行取舍</li>
<li>W&lt;(N+1)/2时: 系统将出现写分裂(如何检测和解决数据冲突是这类策略的考虑重点)</li>
<li>让R+W&lt;=N时: 将出现读写不一致(即弱一致性模型，典型如异步主从复制+从节点可读模型)</li>
</ul>
<p>读写策略是经典的一致性、可用性、性能的权衡策略，通过部分表决而非多数表决，给设计和使用上更高的灵活性。如MongoDB可以在每次读写操作时，指定WR表决数量。</p>
<h4 id="如何解决写入冲突"><a href="#如何解决写入冲突" class="headerlink" title="如何解决写入冲突"></a>如何解决写入冲突</h4><p>在容忍网络分区的复制模型中，如何检测和解决数据冲突，使数据最终收敛，也是个比较重要的的领域，尤其对于可用性大于一致性的分布式系统而言。经典的方案是在请求和响应中加入更多的元数据，如: 时间戳、矢量时钟、版本号等。更进一步的方案是无序编程(前面提过，对时间和顺序的依赖越低，越能发挥分布式的优势)，无序编程中的相关理论有CRDTs(Convergent Replicated Data Types，无冲突复制数据类型)以及CALM(Consistency As Logical Monotonicity，逻辑单调的一致性)定理等。MapReduce是典型地声明式的、无序的算法模型。</p>
<h4 id="拜占庭容错"><a href="#拜占庭容错" class="headerlink" title="拜占庭容错"></a>拜占庭容错</h4><p>前面的几种机制都没有考虑拜占庭容错，解决这个分布式系统最难容错模型的主流算法分两类：</p>
<p>一类仍然基于中心化+多数表决原理，如PBFT算法，而PBFT算法能容忍小于1/3的节点作恶，它通过三阶段提交(与3PC原理和目的有所不同)来达成共识，PBFT适用于内部的(不能防止女巫攻击)、小规模的(需要节点频繁通信)集群。</p>
<p>另一类基于去中心化+多数表决原理，如区块链的PoW(工作量证明)算法，不过PoW的”大多数”，不是基于节点数量，而是基于算力，即最长的链。PoW算法优点是开放(自动准入)、安全(拜占庭容错+防女巫攻击)，适用于公网。缺点是有算力浪费、达成共识的时间较长。</p>
<p>PS: 女巫攻击，指个人试图创建多个账号、节点或IP，来试图成为整个集群的大多数，达成恶意攻击的目的。女巫攻击是拜占庭容错模型的一种升级，通常只有在自由准入的公网集群才考虑。</p>
<h4 id="其他实现因素"><a href="#其他实现因素" class="headerlink" title="其他实现因素"></a>其他实现因素</h4><p>前面重点关注的是共识算法的一些实现思路(除了读写Quorum)，而非对外表现的读写一致性。读写一致性除了受底层共识算法的限制外，还要考虑应用层的实现。如Raft，它通过主从+2PC+多数表决+选举机制等算法实现了一套理论上可以实现线性一致性语义的共识算法和协议，这套协议在应用层的实现，如Follower节点是否可读、分区之后老的Leader节点是否可读、写入时应用层是否同步执行Raft 2PC+多数表决流程等等，都会影响读写一致性。又如前面讨论的主从同步(它也是一种简单的共识算法)，从节点是否可读、同步还是异步、是否做了主从切换、是否会有分区脑裂问题等，也都取决于应用层(或者用户配置)。</p>
<p>这里简单列举下可能影响到读写一致性的一些实现因素:</p>
<ul>
<li>会话粘性: 即是否将用户的请求绑定到一台服务器上，会话粘性使得会话一致性这类弱一致性比较容易实现，缺点是负载均衡能力和容错性降低，可以一定程度通过会话复制或会话共享来优化</li>
<li>同步vs异步: 这个前面已经多次提到过，同步的读写一致性更高，异步的吞吐量、可用性以及响应延迟更优</li>
<li>读写策略: 包括从节点是否可读、以及前面提到的WRN模型等，这些读写策略通常是用户可配置的</li>
<li>客户端缓存: 客户端(或会话)缓存技术，可以实现如单调读这类一致性</li>
</ul>
<h3 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h3><p>分片是指将数据集分为若干更小的数据集，用于避免数据集增长带来存储瓶颈和性能瓶颈。主流理解中的数据分片，主要指Kafka Partition、MongoDB Sharding这种存储中间件提供的分片技术。而我理解的广义上的数据分片，还包含应用层的数据和业务拆分(分表、分节点)。由于分片通常涉及到具体的中间件技术和业务场景，不如复制一般通用和抽象，因此鲜有脱离业务和DBMS的模型讨论。</p>
<p>数据分割不直接提升可用性，分割+复制才能提升可用性。数据分割主要解决性能(存储)瓶颈，分片主要考虑事务一致性的问题。</p>
<h4 id="事务一致性"><a href="#事务一致性" class="headerlink" title="事务一致性"></a>事务一致性</h4><p>指多节点场景下，分布式系统对”不变约束”的保证，即ACID中的事务一致性，它保证系统中所有的数据都是符合期望的，且相互关联的数据之间不会产生矛盾，是系统内部的数据状态一致性。</p>
<p>这里再提一下ACID，传统的理解，将A(原子性)、C(一致性)、I(隔离性)、D(持久性)作为达成事务的四个手段和原则，但如今也另有一种理解，就是将AID(以及DBMS提供的约束、触发器等)作为”因”，应用层事务一致性”C”(不包含DBMS本身提供的约束触发器)作为”果”来理解。这种理解更符合如今分布式大场景下，事务一致性理念的普适性。我个人也比较倾向于这种理解。</p>
<p>以转账系统为例，转出方和转入方数据可能不在一个分片(节点)上，那么转账前后双方的余额总数应该相等，双方的余额都不会为负数这些就是这个转账事务的”不变约束”，也就是事务一致性。应用层的事务一致性当然主要依赖应用程序本身的正确性，但另一方面，在多线程和分布式等场景下，如何确保应用层事务满足一致性，也是有一些套路和模式的。</p>
<p>注意，部分复制集中提到的解决方案，如N段提交方案(2PC、3PC)，仍然适用于事务一致性，以下不再复述。</p>
<h4 id="刚性事务"><a href="#刚性事务" class="headerlink" title="刚性事务"></a>刚性事务</h4><p>满足ACID四个要素的事务，被称为刚性事务，如单个RDBMS中的事务，由于不涉及网络，它们也被称作本地事务。RDBMS中的刚性事务通过Commiting Loging、Shadow Paging等技术来实现原子性和持久性(主要考虑磁盘崩溃和安全回滚问题)，通过锁(读锁/写锁/范围锁)来实现并发事务的不同的隔离级别(从MYSQL读未提交到可串行化)。刚性事务的实现方案很多，也不仅限于RDBMS，不过不属于这里的讨论重点。</p>
<p>刚性事务的这套实现机制，不适用于分布式场景，但ACID中的原子性、隔离性、持久性仍然可以作为分布式系统，实现事务一致性的重要维度参考。</p>
<h4 id="柔性事务"><a href="#柔性事务" class="headerlink" title="柔性事务"></a>柔性事务</h4><p>由于ACID不适用于分布式事务，因此BASE理论被提出，它通过牺牲一定的一致性来换取可用性。BASE中的S即Soft State，可理解为柔性状态、软状态或柔性事务。遵循BASE原则的事务被称为柔性事务。</p>
<p>在分布式事务中，柔性事务是主流思想，柔性事务关注最终一致性。在了解柔性事务的常见方案前，需要再理解下事务模型相较复制模型的区别:</p>
<ol>
<li>事务的每个参与者(表/分片/节点)都是整个事务不可缺少的一部分，任何一个参与者失败(事务参与者失败的概率要比复制场景中简单的读写大得多)、故障、分区，都将导致整个事务失败。而复制本身就是冗余换取可用和性能，因此可以容忍部分故障，也可以通过多数表决和仲裁来达成一致。</li>
<li>复杂事务可能有执行顺序依赖，事务整体的交互复杂度，很大程度取决于事务复杂度。复制模型比较简单，每个节点要做的事情(达成的共识)是一致的。</li>
<li>事务参与者与参与者之间是平等关系，它们都对外提供服务，不存在主从之分，因此要考虑并发隔离性的问题，典型如超售问题。复制模型中，并发隔离性本质影响的是读写一致性强弱的问题(如读到旧值)，而通常不会造成复制集内部数据不一致(共识算法至少会确保最终一致)，因此复制集中隔离性带来的问题影响相对较小(只要给了用户正确的读写一致性预期)。</li>
</ol>
<h5 id="最大努力交付"><a href="#最大努力交付" class="headerlink" title="最大努力交付"></a>最大努力交付</h5><p>最大努力交付方案(Best-Effort Delivery)的核心思路是，通过可靠消息服务、幂等、重试等机制，最大程度地容忍网络分区和节点故障，推进事务达成最终一致性。</p>
<p>以可靠消息队列方案为例，它的主要参与者有: 事务发起方、事务参与方、消息中间件。整个事务执行流程如下:</p>
<ol>
<li>事务发起方执行本地事务</li>
<li>事务发起方将要发送到其他事务参与方的消息写入自己的数据库，状态为”进行中”</li>
<li>启动一个消息服务，定时查询消息表，将消息表中的消息发送到事件参与方</li>
<li>如果3中出现任何网络异常和节点故障，消息服务会不断重试，直接事务参与方执行成功并返回</li>
<li>所有事务参与者均返回成功后，消息服务更新消息表对应消息状态为已完成，整个事务执行完成</li>
</ol>
<p>注意:</p>
<ul>
<li>上面流程中的1，2步，是在同一个本地事务中完成的(使用同一个数据库)</li>
<li>可靠消息队列假设，只要事务发起方本地事务完成，后续就没有失败回滚的概念，事务参与方只能成功，不能失败。因此主要还是适用相对简单的事务，可以让容易出错的操作方(比如扣款服务)，作为事务的发起方，事实上，可靠消息队列最常见的场景，就是第三方支付回调</li>
<li>可靠消息队列依赖消息幂等，否则出现网络异常，无法安全重试</li>
</ul>
<p>可靠消息队列的一种变形是引入消息中间件，事务发起方的消息服务将消息发给消息中间件，消息中间件接收成功后，即标记本地消息表已完成，由消息中间件的QoS来保证持续重试并达成最终一致性(当然，消息中间件本身实现高可用，仍然主要基于前面提到的复制冗余技术)。部分消息中间件如RocketMQ还提供了事务支持，如此就是不再需要本地消息表和消息服务，而是事务发起方通过RocketMQ提供的事务API和本地事务API通过一种比2PC更复杂的带重试的机制来保证执行本地事务和写入MQ消息这两件事情的事务一致性。</p>
<p>最大努力交付是一种非常普遍的容错思想，可靠消息队列只是其中一种方案，它通过本地事务+最大努力交付达成事务的最终一致性。</p>
<p>最大努力交付没有考虑事务参与方失败的问题，常见的事务失败处理策略分两种: 回滚和补偿。两种策略的代表分别是TCC和SAGA。</p>
<h5 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h5><p>TCC(Try-Confirm-Cancel)的核心思路是悲观预留:</p>
<ol>
<li>Try: 事务发起方通知各事务参与方执行业务检查，预留资源(如库存预扣除)</li>
<li>Confirm: 如果Try阶段所有参与方都返回成功，则事务发起方通知各参与方接入Confirm阶段，即真正提交本地事务。如果此阶段有节点故障或网络异常，事务发起方会不断重试，即最大努力交付</li>
<li>Cancel: 如果Try阶段任何事务参与方返回失败或者响应超时，则通知(包含重试)所有的参与方进行Cancel阶段，取消之前预留的资源</li>
</ol>
<p>注意，事务参与方的Confirm和Cancel接口都需要满足幂等。TCC的主要优势:</p>
<ul>
<li>通过预留资源，在业务层支持了回滚</li>
<li>通过预留资源，让事务具备了隔离性，能够避免超售问题</li>
<li>通过最大努力交付，使得其有一定的网络分区容忍度</li>
<li>相比2PC，TCC更偏业务层，预扣除也可以实现得很轻量，有性能优势</li>
</ul>
<p>TCC的劣势:</p>
<ul>
<li>对业务的侵入性较强，部分已有接口可能并不支持预留操作(如第三方支付接口，不支持预扣除操作)</li>
<li>业务层的开发成本较高</li>
</ul>
<h5 id="SAGA"><a href="#SAGA" class="headerlink" title="SAGA"></a>SAGA</h5><p>针对TCC业务侵入式强的缺点，SAGA的乐观补偿思路可以解决这个问题，SAGA的核心思路:</p>
<ul>
<li>将一个大的分布式事务T，分为N个子事务T1,T2,…,Tn</li>
<li>为每个子事务Ti实现一个对应的补偿操作Ci，即对应有C1,C2,….Cn</li>
</ul>
<p>Ti、Ci满足如下条件:</p>
<ul>
<li>Ti、Ci都可视为原子行为并且满足幂等</li>
<li>Ti和Ci满足交换律，即执行先执行Ti再执行Ci或者反过来，执行结果都是一样的(即没有影响)</li>
<li>Ci必需能成功提交，即不考虑Ci执行失败的情形</li>
</ul>
<p>如果T1,T2,…,Tn均成功执行，则事务T成功执行，正常完成。否则如果Ti执行失败，需要根据Ti特性和业务场景考虑两种恢复措施:</p>
<ul>
<li>正向恢复(Forward Recovery): 不断重试直至Ti执行成功(最大努力交付)</li>
<li>反向恢复(Backward Recovery): 尝试执行Ti对应的补偿操作Ci(最大努力交付)，整个执行链变为T1,T2,…,Ti,Ci,…,C2,C1</li>
</ul>
<p>SAGA协调者本身也可能崩溃，因此它需要持久化事务进度，并在crash-recover后，恢复对事务的进度跟踪和推进。</p>
<p>SAGA的优势:</p>
<ul>
<li>在某些场景，补偿比预留机制通常更容易实现(如银行扣款)</li>
<li>更适合长时间事务(Long Lived Transaction)</li>
</ul>
<p>SAGA的劣势:</p>
<ul>
<li>事务隔离性较差，这也是SAGA的最大痛点</li>
<li>执行整个事务的耗时较长(串行执行)</li>
<li>业务层的开发成本仍然较高</li>
</ul>
<h2 id="体会"><a href="#体会" class="headerlink" title="体会"></a>体会</h2><p>分布式基本理论是互联网和云计算的基础，它于每个软件工程师而言，都有很多值得学习的地方:</p>
<ul>
<li>打破单机的性能、位置、耦合度的局限性</li>
<li>在不可靠的网络和硬件上打造高可用系统</li>
<li>知不能完美，但仍在性能、可用性、一致性、扩展性等指标中不断权衡，寻求更优解</li>
</ul>
]]></content>
      <categories>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>distributed</tag>
        <tag>system</tag>
      </tags>
  </entry>
  <entry>
    <title>SLG跨服模型</title>
    <url>/2023/03/slg-cross-map-model/</url>
    <content><![CDATA[<p>SLG是重生态边界和导量策略的游戏，游戏到了中后期，为了维护玩家的新鲜感，扩大社交范围，提升留存和付费。会伴随各种各样的跨服玩法。其中以KvK(Kingdom vs Kingdom)持续时间最长(一个月左右)，最为复杂(玩家可以在KvK中参与城建、活动、联盟等各种玩法，与原服的体验很接近)。本文以KvK为出发点，聊聊关于SLG跨服模型的一些实践和思考。</p>
<p>在此之前，有必要对游戏中常见的跨服、合服、迁服几个概念进行区分:</p>
<ul>
<li>跨服: 生态的摩擦和碰撞</li>
<li>合服: 生态的融合和重组</li>
<li>迁服: 生态的流动和微调</li>
</ul>
<p>KvK跨服战场活动的简单示意图如下:</p>
<p><img src="/assets/image/202303/kvkserver.jpg" width="50%" height="50%"></p>
<p>对玩家而言，体验最好的KvK玩法应该是轻量的，即玩家可随时自愿加入和退出，KvK战场活动持续期间，原服和KvK服都可以有玩家在玩。并且玩家切换战场的成本应该最小化，如联盟关系、活动进度、邮件、聊天等数据都应该尽可能保留。</p>
<p>以下聊聊我们在实际项目中，对KvK跨服的三种理解(领域模型)和实现，并简单以Model1，Model2，Model3区分。</p>
<span id="more"></span>
<h3 id="Model1-将KvK实现为飞服"><a href="#Model1-将KvK实现为飞服" class="headerlink" title="Model1 将KvK实现为飞服"></a>Model1 将KvK实现为飞服</h3><p>服务器框架早期基于一个依赖赛季合服(冷数据处理)进行KvK的项目，因此框架早期并未对跨服模型做过多考虑，单个服务器的活动、联盟、地图、城建相关数据，均内聚在一个Game节点上。在之后的项目开发到中期的时候，发现想要实现竞品级别的KvK(尤其是保留活动和联盟数据)，成本非常高。因此有的项目综合考虑，选择了通过玩家飞服的方式来实现KvK。这种思路的核心是将KvK战场看做一个完整的服务器生态(Game节点)，在玩家进入KvK战场时，需要进行数据清洗、剥离、迁移和恢复:</p>
<ol>
<li>玩家数据: 剥离打包原服玩家数据并迁移到新服，如果想对原服生态造成的影响尽可能小(如想保留一份玩家数据镜像在联盟、排行榜等系统，避免原服快速过于”冷清”，或者是想管理一些原服强相关的玩家数据)，需要谨慎处理数据的清洗、迁移和合并。另外玩家在原服地图上是消失的，避免产生玩家交互引发数据变更</li>
<li>活动数据: 对活动数据做剥离和恢复(尤其是个人活动)，对于非个人活动而言，由于各服活动投放内容和进度不一样，很难跨地图保留(但可以回原服之后恢复)。并且由于活动本身的多样性性和灵活性，这个过程很容易产生各种BUG</li>
<li>联盟数据: 联盟数据与各系统的耦合较重，很难扩展为跨服联盟，因此玩家进入KvK服后，联盟关系会丢失，玩家在KvK服需要新建联盟，但为了保留原服生态，玩家在原服的联盟中会存在一个”镜像玩家”，同时也让跨服玩家回来(经过数据合并)也不需要重新加入联盟</li>
<li>服务器关系: 从玩法上而言，各个玩家并不算是真正迁入了KvK服(玩家所属服务器仍然为原服，否则很难制造生态摩擦)，因此玩家身上本质有两个字段，原服和KvK服，部分业务逻辑需要围绕这两个字段特殊处理，如登陆流程、两个全服聊天频道等</li>
<li>其他功能: 如聊天、邮件、以及其他需要单独跨服的功能，都需要单独评估，做数据剥离迁移</li>
</ol>
<p>Model1示意图如下:</p>
<p><img src="/assets/image/202303/kvk-by-transfer-server.jpg" width="50%" height="50%"></p>
<p>这种方案的优势:</p>
<ul>
<li>延迟跨服决策，前期开发效率高</li>
<li>单服大部分业务数据都在单节点内部，数据一致性高，并支持滚动部署(单个服务器只停服几分钟)</li>
</ul>
<p>劣势:</p>
<ul>
<li>对跨服玩法的原生支持比较差，如部分活动数据，联盟关系这类数据很难保留</li>
<li>基于各种考虑，最终的实现可能并不是纯粹的数据迁移，而是原服和KvK都有部分玩家数据，需要谨慎处理数据的清洗、剥离和合并</li>
<li>之后每添加一个(或想要从已有玩法切换为)跨服玩法，都要单独考虑数据的剥离和迁移，开发成本高，且容易产生各种BUG</li>
<li>对于其他更轻量的跨服地图玩法，如GvG(持续一小时左右的地图副本)，需要额外做跨服地图副本或迁服机制，无法复用KvK服逻辑(没必要做数据迁移)</li>
</ul>
<h3 id="Model2-将KvK实现为跨服"><a href="#Model2-将KvK实现为跨服" class="headerlink" title="Model2 将KvK实现为跨服"></a>Model2 将KvK实现为跨服</h3><p>鉴于Model1.0的一些经验，也有项目开始提前规划对跨服业务进行重构和拆分，即将联盟、活动这类跨服系统(需要在跨KvK战场时保留的系统)从原服抽离出来单独维护。如此玩家在进出KvK时，可以保留活动和联盟数据，同时玩家数据迁移也更轻量。</p>
<p>Model2示意图如下:</p>
<p><img src="/assets/image/202303/kvk-by-cross-server.jpg" width="50%" height="50%"></p>
<p>这种思路的主要考虑点:</p>
<ul>
<li>跨服活动: 解耦活动系统，支持多个服务器可以参加同一个活动(可以考虑实现为KvK服的活动，或者参与KvK的Server Group的活动)</li>
<li>跨服联盟: 解耦联盟系统，支持一个联盟的玩家可以处于不同的服务器上</li>
<li>数据迁移: 仍然要考虑玩家数据(主要是养成相关)剥离和迁移过程，及其性能、数据一致性、服务器关系等</li>
<li>架构设计: 如数据共享、依赖关系、网络拓扑、负载和部署策略、数据一致性等</li>
</ul>
<p>优势:</p>
<ul>
<li>相对完整的跨服功能支持</li>
<li>数据迁移更轻量</li>
</ul>
<p>劣势:</p>
<ul>
<li>需要较早地规划业务设计和解耦(尤其是需要跨服的功能)，对于业务已经成型的项目，还考验渐进重构的能力</li>
<li>这套思路有点往大服方向走，因此在前期开发效率、部署更新流程、数据一致性方面，也要多做考虑</li>
<li>对于更轻量的跨服地图玩法，仍然需要额外实现一套地图副本机制</li>
</ul>
<h3 id="Model3-将KvK实现为跨地图副本"><a href="#Model3-将KvK实现为跨地图副本" class="headerlink" title="Model3 将KvK实现为跨地图副本"></a>Model3 将KvK实现为跨地图副本</h3><p>在Model1和Model2的实现中，主要将KvK服理解为一个相对完整的生态，技术上也用独立的服务器进程来实现。</p>
<p>打个可能不是很恰当的比喻，KvK就像是车主因为某些原因，不得不换辆车:</p>
<ul>
<li>Model1: 为车主尽可能把车上装饰物和随身物品打包(数据剥离和迁移)好</li>
<li>Model2: 将车上的更多影响用户体验的组件，如方向盘(联盟系统)，座位(活动系统)，提前规划为可拆卸替换的(跨服系统)，这样用户在换车的时候，不会感到不适应</li>
</ul>
<p>而Model3的想法，是重新审视车主需求，即他为什么要换车。可能只是车胎没气了，那么对症下药，换车胎就行了。回到KvK来，KvK的本质是创造一个跨服临时战场，以激活后期生态(而不是合并后期生态)，刺激付费和留存。因此，<strong>KvK的本质不是跨服，而是跨地图副本</strong>。</p>
<p>Model3图示如下:</p>
<p><img src="/assets/image/202303/kvk-by-cross-map.jpg" width="50%" height="50%"></p>
<p>注: 联盟、活动、养成可以选择部署在一个节点上(数据一致性和开发效率更高)，也可以部署在不同的节点(如有真正的跨服联盟需求)，但部署边界不等于业务边界，联盟、活动、养成这些系统，从业务设计上应该尽可能解耦，提升可维护、可测试、可扩展性。</p>
<p>Model3模型核心思路:</p>
<ul>
<li>地图副本: 将地图和养成、联盟、活动等玩法解耦，原服大地图也通过副本机制来实现。除了活动和联盟，其他系统可能需要围绕地图进行调整，如排行榜，邮件聊天组，天下大势，养成系统(如果不同地图的养成线有差异)等。MapID和ServerID将是两个不同的概念，一个ServerID的玩家可能在不同的MapID，一个MapID的玩家也可能来自于不同的Server</li>
<li>跨地图联盟: 联盟本质不再需要跨服，只需要支持一个联盟的玩家可能处于不同的地图副本上(有不同的势力范围和联盟建筑)，这个要比跨服联盟实现起来更简单很多，也不需要额外的联盟节点</li>
<li>跨地图活动: 活动支持跨地图也比跨服更简单。真正的跨服活动，可以按照Map Owner(地图专属活动)，Cross Wrapper(轻度跨服活动)，ServerGroup Owner(重度跨服活动)等多种方案来扩展</li>
<li>数据迁移: 玩家的KvK战场切换，本质只是地图切换，只同步极少量地图需要的初始化数据即可，无需再迁移玩家、联盟、活动等数据</li>
</ul>
<p>如果我们沿着Model2的思路，将Model1切换KvK服要保留的联盟、活动、养成系统这些全部剥离出来，最终可能会发现，唯一不能保留，真正要切换的(车主换车的原因)，只有地图。而联盟、养成系统这类玩法，也并不是真的必须要支持跨服，而是只需支持跨地图。Model3是一种以终为始的方案，是对领域知识充分消化的结果。</p>
<p>优势:</p>
<ul>
<li>进一步精化了领域模型，解决了Model2一些领域模型不恰当导致问题，如需要剥离的跨”服”业务过多、玩家的服务器关系问题、原服和KvK服的活动冲突、KvK服不应该创建联盟、KvK服的动态生命周期等问题</li>
<li>用同一套方案处理原服地图、KvK、GvG等玩法，开发效率、复用性、健壮性方面都有优势</li>
<li>由于原服地图也拆为了副本，因此想要实现类似飞服(A服玩家可以飞到B服地图上去PK)这种玩法也比较容易，和跨KvK副本是一套机制</li>
<li>地图副本可以动态开启，灵活负载，更能满足SLG跨服常态化、轻量化、自动化的趋势</li>
</ul>
<p>劣势:</p>
<ul>
<li>拆分地图的技术难度，包括性能、数据一致性、依赖关系、部署策略，以及各种异常下的容错与故障恢复等等。尽管地图副本在MMO中是非常成熟的概念，但SLG的离线策略、实时战斗、无极缩放等特性，为这套机制带来了新的内容和挑战</li>
<li>需要持续和策划围绕地图副本的概念对各业务系统做必要的调整，持续迭代业务模型</li>
</ul>
<p>本文并不扩展讨论各种技术实现细节，更多地从业务领域的角度来讨论SLG跨服的实现思路和常见模型。模型没有优劣，只有是否和业务匹配之分，模型如架构，是设计的结果，也是权衡的结果。SLG跨服这类复杂业务而言，前期业务模型设计的优劣将很大程度决定后期架构的可扩展和可维护性。</p>
]]></content>
      <categories>
        <category>SLG</category>
      </categories>
      <tags>
        <tag>software design</tag>
        <tag>DDD</tag>
        <tag>SLG</tag>
      </tags>
  </entry>
</search>
